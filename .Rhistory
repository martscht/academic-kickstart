ylab("Average Stringency Index") +
theme_apa()#+xlim(c(0,630))
ggplot(data = df,aes(x = M_Cases_pP,y = M_Index)) +
# scale_x_continuous(trans = "log10", breaks = c(10, 1000, 100000),
#                   labels = c(10, 1000, "100000"))+
geom_point(mapping = aes(M_Cases_pP[Country=="Germany"], M_Index[Country=="Germany"]), cex = 5, col = "grey")+
geom_errorbar(aes(ymin = M_Index - SE_Index,ymax = M_Index + SE_Index),size = .2, color = "darkgrey") +
geom_errorbarh(aes(xmin = M_Cases_pP - SE_Cases_pP,xmax =  M_Cases_pP + SE_Cases_pP), size = .2, color = "darkgrey")+
geom_point(cex=0.8) +
xlab("Average Cumulative COVID-19 Cases per 100,000 Inhabitants")+
ylab("Average Stringency Index") +
theme_apa()+xlim(c(0,630))
ggplot(data = df,aes(x = M_Cases_pP,y = M_Index)) +
# scale_x_continuous(trans = "log10", breaks = c(10, 1000, 100000),
#                   labels = c(10, 1000, "100000"))+
geom_point(mapping = aes(M_Cases_pP[Country=="Germany"], M_Index[Country=="Germany"]), cex = 5, col = "grey")+
geom_errorbar(aes(ymin = M_Index - SE_Index,ymax = M_Index + SE_Index),size = .2, color = "darkgrey") +
geom_errorbarh(aes(xmin = M_Cases_pP - SE_Cases_pP,xmax =  M_Cases_pP + SE_Cases_pP), size = .2, color = "darkgrey")+
geom_point(cex=0.8) +
xlab("Average Cumulative COVID-19 Cases per 100,000 Inhabitants")+
ylab("Average Stringency Index") +
theme_apa()#+xlim(c(0,630))
ggplot(data = df,aes(x = M_Cases_pP,y = M_Index)) +
# scale_x_continuous(trans = "log10", breaks = c(10, 1000, 100000),
#                   labels = c(10, 1000, "100000"))+
geom_point(mapping = aes(M_Cases_pP[Country=="Germany"], M_Index[Country=="Germany"]), cex = 5, col = "grey")+
geom_errorbar(aes(ymin = M_Index - SE_Index,ymax = M_Index + SE_Index),size = .2, color = "darkgrey") +
geom_errorbarh(aes(xmin = M_Cases_pP - SE_Cases_pP,xmax =  M_Cases_pP + SE_Cases_pP), size = .2, color = "darkgrey")+
geom_point(cex=0.8) +
xlab("Average Cumulative COVID-19 Cases per 100,000 Inhabitants")+
ylab("Average Stringency Index") +
theme_apa()+xlim(c(0,630))
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
2^c(1,2)
2^c(-1,-2)
2^c(0.5,0.6)
982454635
0.0093*10^9
source('startup.R')
data(conspiracy, package = 'PsyBSc7')
load(url("https://pandar.netlify.app/post/conspiracy.rda"))
conspiracy$id <- as.factor(1:nrow(conspiracy))
ezANOVA(data = conspiracy, wid = id, dv = ET, between = urban)
library(ez)
ezANOVA(data = conspiracy, wid = id, dv = ET, between = urban)
aggregate(ET ~ urban, data = conspiracy, mean)
tapply(X = conspiracy$ET, INDEX = list(conspiracy$urban), FUN = mean)
tapply(X = conspiracy$ET, INDEX = conspiracy$urban, FUN = mean)
# Mithilfe des aggregate-Befehls
aggregate(ET ~ urban, data = conspiracy, mean)
aggregate(ET ~ edu, data = conspiracy, mean)
# Mithilfe des aggregate-Befehls mit anderer Schreibweise (wie bei tapply)
aggregate(conspiracy$ET, conspiracy$urban, mean)
# Mithilfe des aggregate-Befehls
aggregate(ET ~ urban, data = conspiracy, mean)
aggregate(ET ~ edu, data = conspiracy, mean)
# Mithilfe des aggregate-Befehls mit anderer Schreibweise (wie bei tapply)
aggregate(conspiracy$ET, list(conspiracy$urban), mean)
aggregate(conspiracy$ET, list(conspiracy$edu), mean)
# Mithilfe des describeBy-Befehls aus dem psych-Paket
library(psych)
describeBy(conspiracy$ET, conspiracy$urban)
describeBy(conspiracy$ET, conspiracy$edu)
load(url("https://pandar.netlify.app/post/fairplayer.rda"))
fairplayer$emt1z <- scale(fairplayer$emt1)
fairplayer
fairplayer$emt1
fairplayer
fairplayer$emt1 <- colMeans(fairplayer[, c("em1t1", "em2t1", "em3t1")], na.rm = T)
fairplayer$emt1
colMeans(fairplayer[, c("em1t1", "em2t1", "em3t1")], na.rm = T)
fairplayer$emt1 <- rowMeans(fairplayer[, c("em1t1", "em2t1", "em3t1")], na.rm = T)
fairplayer$emt1
fairplayer$sit1
fairplayer$sit1 <- rowMeans(fairplayer[, c("si1t1", "si2t1", "si3t1")], na.rm = T)
fairplayer$sit1
fairplayer$emt1 <- rowMeans(fairplayer[, c("em1t1", "em2t1", "em3t1")], na.rm = T)
fairplayer$sit1 <- rowMeans(fairplayer[, c("si1t1", "si2t1", "si3t1")], na.rm = T)
fairplayer$emt1z <- scale(fairplayer$emt1)
fairplayer$sit1z<-scale(fairplayer$sit1)
fairplayer$Int <- fairplayer$emt1z*fairplayer$sit1z
modLz <- '
# Regression
rat1 ~ 1
rat1 ~ sit1z
rat1 ~ emt1z
rat1 ~ Int
# Residuum
rat1 ~~ rat1'
fit_z <- lavaan(modLz, fairplayer)
library(lavaan)
modLz <- '
# Regression
rat1 ~ 1
rat1 ~ sit1z
rat1 ~ emt1z
rat1 ~ Int
# Residuum
rat1 ~~ rat1'
fit_z <- lavaan(modLz, fairplayer)
fairplayer$emt1 <- rowMeans(fairplayer[, c('em1t1', 'em2t1', 'em3t1')],
na.rm = TRUE)
fairplayer$sit1 <- rowMeans(fairplayer[, c('si1t1', 'si2t1', 'si3t1')],
na.rm = TRUE)
fairplayer$rat1 <- rowMeans(fairplayer[, c('ra1t1', 'ra2t1', 'ra3t1')],
na.rm = TRUE)
fairplayer$emt1z <- scale(fairplayer$emt1)
fairplayer$sit1z<-scale(fairplayer$sit1)
fairplayer$Int <- fairplayer$emt1z*fairplayer$sit1z
library(lavaan)
modLz <- '
# Regression
rat1 ~ 1
rat1 ~ sit1z
rat1 ~ emt1z
rat1 ~ Int
# Residuum
rat1 ~~ rat1'
fit_z <- lavaan(modLz, fairplayer)
summary(fit_z)
lm(rat1~sit1z*emt1z)
lm(rat1~sit1z*emt1z, data = fairplayer)
coef(fit_z)
lm(rat1~sit1z*emt1z, data = fairplayer)
load(url("https://pandar.netlify.app/post/fairplayer.rda"))
fairplayer$emt1 <- rowMeans(fairplayer[, c('em1t1', 'em2t1', 'em3t1')],
na.rm = TRUE)
fairplayer$sit1 <- rowMeans(fairplayer[, c('si1t1', 'si2t1', 'si3t1')],
na.rm = TRUE)
fairplayer$rat1 <- rowMeans(fairplayer[, c('ra1t1', 'ra2t1', 'ra3t1')],
na.rm = TRUE)
fairplayer$emt1z <- scale(fairplayer$emt1, scale = F)
fairplayer$sit1z<-scale(fairplayer$sit1, scale = F)
fairplayer$Int <- fairplayer$emt1z*fairplayer$sit1z
library(lavaan)
modLz <- '
# Regression
rat1 ~ 1
rat1 ~ sit1z
rat1 ~ emt1z
rat1 ~ Int
# Residuum
rat1 ~~ rat1'
fit_z <- lavaan(modLz, fairplayer)
summary(fit_z)
coef(fit_z)
lm(rat1~sit1z*emt1z, data = fairplayer)
summary(lm(ET ~ urban*edu, data = conspiracy))
anova(lm(ET ~ urban*edu, data = conspiracy))
summary(aov(ET ~ urban*edu, data = conspiracy))
options(contrasts=c(unordered="contr.sum", ordered="contr.poly"))
anova(lm(ET ~ urban*edu, data = conspiracy))
options(contrasts=c(unordered="contr.sum", ordered="contr.poly"))
anova(lm(ET ~ urban*edu, data = conspiracy))
options(contrasts=c(unordered="contr.treatment", ordered="contr.poly"))
anova(lm(ET ~ urban*edu, data = conspiracy))
??options
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
load(url("https://pandar.netlify.app/post/Schulleistungen.rda"))
Schulleistungen_std <- scale(Schulleistungen)
reg <- lm(math ~ IQ*reading, data = Schulleistungen_std)
Schulleistungen_std
Schulleistungen_std <- data.frame(scale(Schulleistungen))
reg <- lm(math ~ IQ*reading, data = Schulleistungen_std)
reg
summary(reg)
library(interactions)
mod_reg <- lm(math ~ IQ*reading, data = Schulleistungen_std)
mod_reg
summary(mod_reg)
interact_plot(model = mod_reg, pred = IQ, modx = reading)
interact_plot(model = mod_reg, pred = reading, modx = IQ)
X <- mvtnorm::rmvnorm(n = 10^4, mean = c(0,0), sigma = matrix(c(1,.5,.5,1),2,2))
X1 <- X[,1];X2<-X[,2]
Y <- 0.5*X1 + 0.3*X2 + 0.1*X1*X2 + rnorm(dim(X)[1])
summary(lm(Y~X1+X2))
summary(lm(Y~X1+X2+I(X1*X2)))
summary(lm(Y~X1+X2+I(X1^2)))
summary(lm(Y~X1+X2+I(X1^2)+I(X^2)))
summary(lm(Y~X1+X2+I(X1^2)+I(X2^2)))
summary(lm(Y~X1+X2+I(X1^2)+I(X2^2)+I(X1*X2)))
Y <- 0.5*X1 + 0.3*X2 + 0.1*X1^2 + rnorm(dim(X)[1])
summary(lm(Y~X1+X2))
summary(lm(Y~X1+X2+I(X1*X2)))
summary(lm(Y~X1+X2+I(X1^2)+I(X2^2)+I(X1*X2)))
mod_reg <- lm(reading ~ IQ*math, data = Schulleistungen_std)
mod_reg
summary(mod_reg)
mod_reg <- lm(reading ~ IQ*math + I(math^2)+I(IQ^2), data = Schulleistungen_std)
mod_reg
summary(mod_reg)
mod_reg <- lm(reading ~ IQ+math+ I(IQ*math) + I(math^2)+I(IQ^2), data = Schulleistungen_std)
mod_reg
summary(mod_reg)
mod_reg <- lm(reading ~ IQ+math+ I(math^2)+I(IQ*math) +I(IQ^2), data = Schulleistungen_std)
summary(mod_reg)
load(url("https://pandar.netlify.app/post/PISA2009.rda"))
names(PISA2009)
reg1 <- lm(Reading ~ JoyRead*LearnMins, data = PISA2009)
summary(reg1)
reg2 <- lm(Reading ~ JoyRead*LearnMins + I(JoyRead^2)+I(LearnMins^2), data = PISA2009)
summary(reg2)
summary(reg1)
coef(reg1)
coef(reg1)["JoyRead:LearnMins"]
coef(reg2)
coef(reg2)["JoyRead:LearnMins"]/coef(reg1)["JoyRead:LearnMins"]
coef(mod_reg)
coef(mod_reg)["I(IQ * math)"]
PISA2009_std <- data.frame(scale(PISA2009))
reg2 <- lm(Reading ~ JoyRead*LearnMins + I(JoyRead^2)+I(LearnMins^2), data = PISA2009)
summary(reg2)
reg1 <- lm(Reading ~ JoyRead*LearnMins, data = PISA2009_std)
summary(reg1)
PISA2009_std <- data.frame(scale(PISA2009))
reg2 <- lm(Reading ~ JoyRead*LearnMins + I(JoyRead^2)+I(LearnMins^2), data = PISA2009_std)
summary(reg2)
coef(reg2)["JoyRead:LearnMins"]/coef(reg1)["JoyRead:LearnMins"]
mod_reg <- lm(reading ~ IQ+math+ I(IQ*math), data = Schulleistungen_std)
mod_quad_reg <- lm(reading ~ IQ+math+ I(math^2)+I(IQ*math) +I(IQ^2), data = Schulleistungen_std)
coef(mod_reg)["I(IQ * math)"]/coef(mod_quad_reg)["I(IQ * math)"]
coef(mod_quad_reg)["I(IQ * math)"]
coef(mod_reg)["I(IQ * math)"]
mod_reg <- lm(reading ~ IQ+math+ I(IQ*math), data = Schulleistungen_std)
mod_quad_reg <- lm(reading ~ IQ+math+ I(math^2)+I(IQ*math) +I(IQ^2), data = Schulleistungen_std)
summary(mod_reg)
summary(mod_quad_reg)
summary(mod_reg)
coef(summary(mod_reg))
coef(summary(mod_reg))["I(IQ * math)",1:3]
coef(summary(mod_reg))["I(IQ * math)",1:3]/coef(summary(mod_quad_reg))["I(IQ * math)",1:3]
coef(summary(mod_quad_reg))["I(IQ * math)",1:3]/coef(summary(mod_reg))["I(IQ * math)",1:3]
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(car)
library(MASS)
### Datensatz: Corona-Pandemie 2020
confirmed <- read.csv('https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv')
deaths <- read.csv('https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv')
### Long format ---
confirmed_long <- reshape(confirmed,
varying = names(confirmed)[-c(1:4)],
v.names = 'Confirmed',
timevar = 'Day',
idvar = names(confirmed)[1:4],
direction = 'long')
deaths_long <- reshape(deaths,
varying = names(deaths)[-c(1:4)],
v.names = 'Deaths',
timevar = 'Day',
idvar = names(deaths)[1:4],
direction = 'long')
### Merged data ----
long <- merge(confirmed_long, deaths_long,
by = c('Province.State', 'Country.Region', 'Lat', 'Long', 'Day'))
### Full data ----
covid <- aggregate(cbind(Confirmed, Deaths) ~ Country.Region + Day, data = long, FUN = 'sum')
### Only data until Day 79 ----
covid_full <- covid
covid <- covid[covid$Day < 80, ]
### Subsets ----
covid_de <- covid[covid$Country.Region == 'Germany', ]
covid_sel <- covid[covid$Country.Region %in% c('France', 'Germany', 'Italy', 'Spain', 'United Kingdom'), ]
covid$Day
covid
confirmed
covid$Day
names(confirmed_long)
names(confirmed)
names(confirmed)[79+4]
confirmed[confirmed$Country.Region == "Germany"]
confirmed[confirmed$Country.Region == "Germany",]
Ger <- confirmed[confirmed$Country.Region == "Germany",]
Ger
Ger <- confirmed[confirmed$Country.Region == "Germany",-c(1:3)]
Ger
Ger <- confirmed[confirmed$Country.Region == "Germany",-c(1:4)]
Ger
Ger[,1:79]
sum(Ger[,1:79])
covid_de
(Ger[,79])
(Ger[,78:79])
confirmed[,1:4]
confirmed[1,1:4]
confirmed[confirmed$Country.Region == "Germany", (78+4):(79+4)]
covid_de[covid_de$Day == c(78,79),]
m_l <- lm(Confirmed ~ Day, data = covid_de) # linearer Verlauf
summary(m_l)
### Quadratisches Modell
m_q <- lm(Confirmed ~ poly(Day, 2), data = covid_de) # quadratischer Verlauf
summary(m_q)
summary(m_q)$r.squared - summary(m_l)$r.squared  # Inkrement
anova(m_l, m_q)
m_l <- lm(Confirmed ~ poly(Day,1), data = covid_de) # linearer Verlauf
summary(m_l)
### Quadratisches Modell
m_q <- lm(Confirmed ~ poly(Day, 2), data = covid_de) # quadratischer Verlauf
summary(m_q)
summary(m_q)$r.squared - summary(m_l)$r.squared  # Inkrement
anova(m_l, m_q)
covid_nation <- covid_sel[covid_sel$Country.Region == "France", ]
covid_nation$log_Confirmed <- log(covid_nation$Confirmed)               # Logarithmieren der "confirmed cases"
covid_sel
library(ggplot2)
library(car)
library(MASS)
### Datensatz: Corona-Pandemie 2020
confirmed <- read.csv('https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv')
deaths <- read.csv('https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv')
### Long format ---
confirmed_long <- reshape(confirmed,
varying = names(confirmed)[-c(1:4)],
v.names = 'Confirmed',
timevar = 'Day',
idvar = names(confirmed)[1:4],
direction = 'long')
deaths_long <- reshape(deaths,
varying = names(deaths)[-c(1:4)],
v.names = 'Deaths',
timevar = 'Day',
idvar = names(deaths)[1:4],
direction = 'long')
### Merged data ----
long <- merge(confirmed_long, deaths_long,
by = c('Province.State', 'Country.Region', 'Lat', 'Long', 'Day'))
### Full data ----
covid <- aggregate(cbind(Confirmed, Deaths) ~ Country.Region + Day, data = long, FUN = 'sum')
### Only data until Day 79 ----
covid_full <- covid
covid <- covid[covid$Day < 80, ]
### Subsets ----
covid_sel <- covid[covid$Country.Region %in% c('France', 'Germany', 'Italy', 'Spain', 'United Kingdom'), ]
covid_de <- covid_sel[covid_sel$Country.Region == "Germany", ]
covid_de$log_Confirmed <- log(covid_de$Confirmed)               # Logarithmieren der "confirmed cases"
covid_de$log_Confirmed[covid_de$log_Confirmed == -Inf] <- NA    # Ersetzen von -unendlich durch missing (NA)
ggplot(covid_de, aes(x = Day, y = log_Confirmed))+geom_line(lwd=2)
covid_de <- covid_de[!is.na(covid_de$log_Confirmed),] # Löschen aller Fälle, in welchen Confrimed = 0 war
### lineares Modell
m_l <- lm(Confirmed ~ poly(Day,1), data = covid_de) # linearer Verlauf
summary(m_l)
### Quadratisches Modell
m_q <- lm(Confirmed ~ poly(Day, 2), data = covid_de) # quadratischer Verlauf
summary(m_q)
summary(m_q)$r.squared - summary(m_l)$r.squared  # Inkrement
anova(m_l, m_q)
covid_de <- covid_de[!is.na(covid_de$log_Confirmed),] # Löschen aller Fälle, in welchen Confrimed = 0 war
covid_de
### lineares Modell
m_l <- lm(Confirmed ~ Day, data = covid_de) # linearer Verlauf
summary(m_l)
### Quadratisches Modell
m_q <- lm(Confirmed ~ poly(Day, 2), data = covid_de) # quadratischer Verlauf
summary(m_q)
summary(m_q)$r.squared - summary(m_l)$r.squared  # Inkrement
anova(m_l, m_q)
covid_de <- covid_sel[covid_sel$Country.Region == "Germany", ]
### lineares Modell
m_l <- lm(Confirmed ~ Day, data = covid_de) # linearer Verlauf
summary(m_l)
### Quadratisches Modell
m_q <- lm(Confirmed ~ poly(Day, 2), data = covid_de) # quadratischer Verlauf
summary(m_q)
summary(m_q)$r.squared - summary(m_l)$r.squared  # Inkrement
anova(m_l, m_q)
covid_de
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
tab = matrix(c(2,6,3,6,2,7,3,6,6,7,6,8,7,7,8,7,5,7,8,9), ncol = 2, byrow = T)
trans.tab = t(tab)
n = length(tab[,1])
mean.x1 = mean(tab[,1])
mean.x2 = mean(tab[,2])
spalte.mean = matrix(c(mean.x1, mean.x2))
spalte.mean
zeile.mean = matrix(c(mean.x1, mean.x2), ncol= 2, byrow = TRUE)
zeile.mean
1/n * trans.tab %*% tab - spalte.mean %*% zeile.mean
cov.mat = function(x, col) {
if (col == 2) {
trans.tab = t(x)
n = length(x[,1])
mean.x1 = mean(x[,1])
mean.x2 = mean(x[,2])
spalte.mean = matrix(c(mean.x1, mean.x2))
zeile.mean = matrix(c(mean.x1, mean.x2), ncol= 2, byrow = TRUE)
cov.mat = 1/n * trans.tab %*% x - spalte.mean %*% zeile.mean
} else if  (col == 3) {
trans.tab = t(x)
n = length(x[,1])
mean.x1 = mean(x[,1])
mean.x2 = mean(x[,2])
mean.x3 = mean(x[,3])
spalte.mean = matrix(c(mean.x1, mean.x2,mean.x3))
zeile.mean = matrix(c(mean.x1, mean.x2, mean.x3), ncol= 3, byrow = TRUE)
cov.mat = 1/n * trans.tab %*% x - spalte.mean %*% zeile.mean
} else if (col == 4) {
trans.tab = t(x)
n = length(x[,1])
mean.x1 = mean(x[,1])
mean.x2 = mean(x[,2])
mean.x3 = mean(x[,3])
mean.x4 = mean(x[,4])
spalte.mean = matrix(c(mean.x1, mean.x2,mean.x3, mean.x4))
zeile.mean = matrix(c(mean.x1, mean.x2, mean.x3,mean.x4), ncol= 4, byrow = TRUE)
cov.mat = 1/n * trans.tab %*% x - spalte.mean %*% zeile.mean
} else if (col == 5) {
trans.tab = t(x)
n = length(x[,1])
mean.x1 = mean(x[,1])
mean.x2 = mean(x[,2])
mean.x3 = mean(x[,3])
mean.x4 = mean(x[,4])
mean.x5 = mean(x[,5])
spalte.mean = matrix(c(mean.x1, mean.x2,mean.x3, mean.x4,mean.x5))
zeile.mean = matrix(c(mean.x1, mean.x2, mean.x3,mean.x4, mean.x5), ncol= 5, byrow = TRUE)
cov.mat = 1/n * trans.tab %*% x - spalte.mean %*% zeile.mean
}
return(cov.mat)
}
matrix_beispiel = matrix(c(6,24,32,46,53,62,76,87,92,160), ncol = 5, byrow = T)
matrix_beispiel
cov.mat(matrix_beispiel, 5)
cov(matrix_beispiel)
cov(matrix_beispiel)*(nrow(matrix_beispiel)-1)/nrow(matrix_beispiel)
Sigma <- matrix(0.5, 10, 10); diag(Sigma) <- 2:11
data <- mvtnorm::rmvnorm(n = 100, mean = rep(0, 10), sigma = )
data <- mvtnorm::rmvnorm(n = 100, mean = rep(0, 10), sigma = Sigma)
cov(data)*(nrow(data)-1)/nrow(data)
COV1 <- cov(data)*(nrow(data)-1)/nrow(data)
d <- data
n <- nrow(d)
zeile.mean <- t(colMeans(d))
zeile.mean
data <- mvtnorm::rmvnorm(n = 100, mean = 1:10, sigma = Sigma)
COV1 <- cov(data)*(nrow(data)-1)/nrow(data)
d <- data
n <- nrow(d)
zeile.mean <- t(colMeans(d))
zeile.mean
zeile.mean <- t(colMeans(d))
trans.tab <- t(d)
cov.mat = 1/n * trans.tab %*% x - spalte.mean %*% zeile.mean
n <- nrow(x)
zeile.mean <- t(colMeans(x))
x <- data
n <- nrow(x)
zeile.mean <- t(colMeans(x))
trans.tab <- t(x)
cov.mat = 1/n * trans.tab %*% x - spalte.mean %*% zeile.mean
spalte.mean <- t(zeile.mean)
trans.tab <- t(x)
cov.mat = 1/n * trans.tab %*% x - spalte.mean %*% zeile.mean
cov.mat
mycov <- function(x)
{
n <- nrow(x)
zeile.mean <- t(colMeans(x))
spalte.mean <- t(zeile.mean)
trans.tab <- t(x)
cov.mat = 1/n * trans.tab %*% x - spalte.mean %*% zeile.mean
return(cov.mat)
}
mycov(data)
COV2 <- mycov(data)
COV1-COV2
mycov_loop <- function(x)
{
n <- nrow(x)
p <- ncol(x)
means <- rep(NA, p) # leerer Vektor der Länge p (Anzahl Spalten)
for(i in 1:p)
{
means[i] <- mean(x[,i])
}
zeile.mean <- t(means)
spalte.mean <- t(zeile.mean)
trans.tab <- t(x)
cov.mat = 1/n * trans.tab %*% x - spalte.mean %*% zeile.mean
return(cov.mat)
}
mycov_loop(data)
COV3 - COV1
COV3 <-mycov_loop(data)
COV3 - COV1
round(COV3 - COV1, 10)
round(COV1 - COV2, 10)
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
