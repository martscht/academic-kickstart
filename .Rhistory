load(url("https://pandar.netlify.app/post/fairplayer.rda"))
fairplayer$emt1 <- rowMeans(fairplayer[, c('em1t1', 'em2t1', 'em3t1')],
na.rm = TRUE)
fairplayer$sit1 <- rowMeans(fairplayer[, c('si1t1', 'si2t1', 'si3t1')],
na.rm = TRUE)
fairplayer$rat1 <- rowMeans(fairplayer[, c('ra1t1', 'ra2t1', 'ra3t1')],
na.rm = TRUE)
fairplayer$emt1z <- scale(fairplayer$emt1, scale = F)
fairplayer$sit1z<-scale(fairplayer$sit1, scale = F)
fairplayer$Int <- fairplayer$emt1z*fairplayer$sit1z
library(lavaan)
modLz <- '
# Regression
rat1 ~ 1
rat1 ~ sit1z
rat1 ~ emt1z
rat1 ~ Int
# Residuum
rat1 ~~ rat1'
fit_z <- lavaan(modLz, fairplayer)
summary(fit_z)
coef(fit_z)
lm(rat1~sit1z*emt1z, data = fairplayer)
summary(lm(ET ~ urban*edu, data = conspiracy))
anova(lm(ET ~ urban*edu, data = conspiracy))
summary(aov(ET ~ urban*edu, data = conspiracy))
options(contrasts=c(unordered="contr.sum", ordered="contr.poly"))
anova(lm(ET ~ urban*edu, data = conspiracy))
options(contrasts=c(unordered="contr.sum", ordered="contr.poly"))
anova(lm(ET ~ urban*edu, data = conspiracy))
options(contrasts=c(unordered="contr.treatment", ordered="contr.poly"))
anova(lm(ET ~ urban*edu, data = conspiracy))
??options
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
load(url("https://pandar.netlify.app/post/Schulleistungen.rda"))
Schulleistungen_std <- scale(Schulleistungen)
reg <- lm(math ~ IQ*reading, data = Schulleistungen_std)
Schulleistungen_std
Schulleistungen_std <- data.frame(scale(Schulleistungen))
reg <- lm(math ~ IQ*reading, data = Schulleistungen_std)
reg
summary(reg)
library(interactions)
mod_reg <- lm(math ~ IQ*reading, data = Schulleistungen_std)
mod_reg
summary(mod_reg)
interact_plot(model = mod_reg, pred = IQ, modx = reading)
interact_plot(model = mod_reg, pred = reading, modx = IQ)
X <- mvtnorm::rmvnorm(n = 10^4, mean = c(0,0), sigma = matrix(c(1,.5,.5,1),2,2))
X1 <- X[,1];X2<-X[,2]
Y <- 0.5*X1 + 0.3*X2 + 0.1*X1*X2 + rnorm(dim(X)[1])
summary(lm(Y~X1+X2))
summary(lm(Y~X1+X2+I(X1*X2)))
summary(lm(Y~X1+X2+I(X1^2)))
summary(lm(Y~X1+X2+I(X1^2)+I(X^2)))
summary(lm(Y~X1+X2+I(X1^2)+I(X2^2)))
summary(lm(Y~X1+X2+I(X1^2)+I(X2^2)+I(X1*X2)))
Y <- 0.5*X1 + 0.3*X2 + 0.1*X1^2 + rnorm(dim(X)[1])
summary(lm(Y~X1+X2))
summary(lm(Y~X1+X2+I(X1*X2)))
summary(lm(Y~X1+X2+I(X1^2)+I(X2^2)+I(X1*X2)))
mod_reg <- lm(reading ~ IQ*math, data = Schulleistungen_std)
mod_reg
summary(mod_reg)
mod_reg <- lm(reading ~ IQ*math + I(math^2)+I(IQ^2), data = Schulleistungen_std)
mod_reg
summary(mod_reg)
mod_reg <- lm(reading ~ IQ+math+ I(IQ*math) + I(math^2)+I(IQ^2), data = Schulleistungen_std)
mod_reg
summary(mod_reg)
mod_reg <- lm(reading ~ IQ+math+ I(math^2)+I(IQ*math) +I(IQ^2), data = Schulleistungen_std)
summary(mod_reg)
load(url("https://pandar.netlify.app/post/PISA2009.rda"))
names(PISA2009)
reg1 <- lm(Reading ~ JoyRead*LearnMins, data = PISA2009)
summary(reg1)
reg2 <- lm(Reading ~ JoyRead*LearnMins + I(JoyRead^2)+I(LearnMins^2), data = PISA2009)
summary(reg2)
summary(reg1)
coef(reg1)
coef(reg1)["JoyRead:LearnMins"]
coef(reg2)
coef(reg2)["JoyRead:LearnMins"]/coef(reg1)["JoyRead:LearnMins"]
coef(mod_reg)
coef(mod_reg)["I(IQ * math)"]
PISA2009_std <- data.frame(scale(PISA2009))
reg2 <- lm(Reading ~ JoyRead*LearnMins + I(JoyRead^2)+I(LearnMins^2), data = PISA2009)
summary(reg2)
reg1 <- lm(Reading ~ JoyRead*LearnMins, data = PISA2009_std)
summary(reg1)
PISA2009_std <- data.frame(scale(PISA2009))
reg2 <- lm(Reading ~ JoyRead*LearnMins + I(JoyRead^2)+I(LearnMins^2), data = PISA2009_std)
summary(reg2)
coef(reg2)["JoyRead:LearnMins"]/coef(reg1)["JoyRead:LearnMins"]
mod_reg <- lm(reading ~ IQ+math+ I(IQ*math), data = Schulleistungen_std)
mod_quad_reg <- lm(reading ~ IQ+math+ I(math^2)+I(IQ*math) +I(IQ^2), data = Schulleistungen_std)
coef(mod_reg)["I(IQ * math)"]/coef(mod_quad_reg)["I(IQ * math)"]
coef(mod_quad_reg)["I(IQ * math)"]
coef(mod_reg)["I(IQ * math)"]
mod_reg <- lm(reading ~ IQ+math+ I(IQ*math), data = Schulleistungen_std)
mod_quad_reg <- lm(reading ~ IQ+math+ I(math^2)+I(IQ*math) +I(IQ^2), data = Schulleistungen_std)
summary(mod_reg)
summary(mod_quad_reg)
summary(mod_reg)
coef(summary(mod_reg))
coef(summary(mod_reg))["I(IQ * math)",1:3]
coef(summary(mod_reg))["I(IQ * math)",1:3]/coef(summary(mod_quad_reg))["I(IQ * math)",1:3]
coef(summary(mod_quad_reg))["I(IQ * math)",1:3]/coef(summary(mod_reg))["I(IQ * math)",1:3]
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(car)
library(MASS)
### Datensatz: Corona-Pandemie 2020
confirmed <- read.csv('https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv')
deaths <- read.csv('https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv')
### Long format ---
confirmed_long <- reshape(confirmed,
varying = names(confirmed)[-c(1:4)],
v.names = 'Confirmed',
timevar = 'Day',
idvar = names(confirmed)[1:4],
direction = 'long')
deaths_long <- reshape(deaths,
varying = names(deaths)[-c(1:4)],
v.names = 'Deaths',
timevar = 'Day',
idvar = names(deaths)[1:4],
direction = 'long')
### Merged data ----
long <- merge(confirmed_long, deaths_long,
by = c('Province.State', 'Country.Region', 'Lat', 'Long', 'Day'))
### Full data ----
covid <- aggregate(cbind(Confirmed, Deaths) ~ Country.Region + Day, data = long, FUN = 'sum')
### Only data until Day 79 ----
covid_full <- covid
covid <- covid[covid$Day < 80, ]
### Subsets ----
covid_de <- covid[covid$Country.Region == 'Germany', ]
covid_sel <- covid[covid$Country.Region %in% c('France', 'Germany', 'Italy', 'Spain', 'United Kingdom'), ]
covid$Day
covid
confirmed
covid$Day
names(confirmed_long)
names(confirmed)
names(confirmed)[79+4]
confirmed[confirmed$Country.Region == "Germany"]
confirmed[confirmed$Country.Region == "Germany",]
Ger <- confirmed[confirmed$Country.Region == "Germany",]
Ger
Ger <- confirmed[confirmed$Country.Region == "Germany",-c(1:3)]
Ger
Ger <- confirmed[confirmed$Country.Region == "Germany",-c(1:4)]
Ger
Ger[,1:79]
sum(Ger[,1:79])
covid_de
(Ger[,79])
(Ger[,78:79])
confirmed[,1:4]
confirmed[1,1:4]
confirmed[confirmed$Country.Region == "Germany", (78+4):(79+4)]
covid_de[covid_de$Day == c(78,79),]
m_l <- lm(Confirmed ~ Day, data = covid_de) # linearer Verlauf
summary(m_l)
### Quadratisches Modell
m_q <- lm(Confirmed ~ poly(Day, 2), data = covid_de) # quadratischer Verlauf
summary(m_q)
summary(m_q)$r.squared - summary(m_l)$r.squared  # Inkrement
anova(m_l, m_q)
m_l <- lm(Confirmed ~ poly(Day,1), data = covid_de) # linearer Verlauf
summary(m_l)
### Quadratisches Modell
m_q <- lm(Confirmed ~ poly(Day, 2), data = covid_de) # quadratischer Verlauf
summary(m_q)
summary(m_q)$r.squared - summary(m_l)$r.squared  # Inkrement
anova(m_l, m_q)
covid_nation <- covid_sel[covid_sel$Country.Region == "France", ]
covid_nation$log_Confirmed <- log(covid_nation$Confirmed)               # Logarithmieren der "confirmed cases"
covid_sel
library(ggplot2)
library(car)
library(MASS)
### Datensatz: Corona-Pandemie 2020
confirmed <- read.csv('https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv')
deaths <- read.csv('https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv')
### Long format ---
confirmed_long <- reshape(confirmed,
varying = names(confirmed)[-c(1:4)],
v.names = 'Confirmed',
timevar = 'Day',
idvar = names(confirmed)[1:4],
direction = 'long')
deaths_long <- reshape(deaths,
varying = names(deaths)[-c(1:4)],
v.names = 'Deaths',
timevar = 'Day',
idvar = names(deaths)[1:4],
direction = 'long')
### Merged data ----
long <- merge(confirmed_long, deaths_long,
by = c('Province.State', 'Country.Region', 'Lat', 'Long', 'Day'))
### Full data ----
covid <- aggregate(cbind(Confirmed, Deaths) ~ Country.Region + Day, data = long, FUN = 'sum')
### Only data until Day 79 ----
covid_full <- covid
covid <- covid[covid$Day < 80, ]
### Subsets ----
covid_sel <- covid[covid$Country.Region %in% c('France', 'Germany', 'Italy', 'Spain', 'United Kingdom'), ]
covid_de <- covid_sel[covid_sel$Country.Region == "Germany", ]
covid_de$log_Confirmed <- log(covid_de$Confirmed)               # Logarithmieren der "confirmed cases"
covid_de$log_Confirmed[covid_de$log_Confirmed == -Inf] <- NA    # Ersetzen von -unendlich durch missing (NA)
ggplot(covid_de, aes(x = Day, y = log_Confirmed))+geom_line(lwd=2)
covid_de <- covid_de[!is.na(covid_de$log_Confirmed),] # Löschen aller Fälle, in welchen Confrimed = 0 war
### lineares Modell
m_l <- lm(Confirmed ~ poly(Day,1), data = covid_de) # linearer Verlauf
summary(m_l)
### Quadratisches Modell
m_q <- lm(Confirmed ~ poly(Day, 2), data = covid_de) # quadratischer Verlauf
summary(m_q)
summary(m_q)$r.squared - summary(m_l)$r.squared  # Inkrement
anova(m_l, m_q)
covid_de <- covid_de[!is.na(covid_de$log_Confirmed),] # Löschen aller Fälle, in welchen Confrimed = 0 war
covid_de
### lineares Modell
m_l <- lm(Confirmed ~ Day, data = covid_de) # linearer Verlauf
summary(m_l)
### Quadratisches Modell
m_q <- lm(Confirmed ~ poly(Day, 2), data = covid_de) # quadratischer Verlauf
summary(m_q)
summary(m_q)$r.squared - summary(m_l)$r.squared  # Inkrement
anova(m_l, m_q)
covid_de <- covid_sel[covid_sel$Country.Region == "Germany", ]
### lineares Modell
m_l <- lm(Confirmed ~ Day, data = covid_de) # linearer Verlauf
summary(m_l)
### Quadratisches Modell
m_q <- lm(Confirmed ~ poly(Day, 2), data = covid_de) # quadratischer Verlauf
summary(m_q)
summary(m_q)$r.squared - summary(m_l)$r.squared  # Inkrement
anova(m_l, m_q)
covid_de
>>>>>>> df665f1f26029cb13a2f87c046bd58d80ad28012
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
<<<<<<< HEAD
knitr::opts_chunk$set(echo = TRUE, fig.align = "center")
knitr::include_graphics(![](/post/Comments.png){width = 100%})
knitr::opts_chunk$set(echo = TRUE, fig.align = "center")
knitr::include_graphics(![](/post/Comments.png){width = 100%})
knitr::opts_chunk$set(echo = TRUE, fig.align = "center")
knitr::include_graphics(![](/post/Comments.png){width = 100%})
knitr::opts_chunk$set(echo = TRUE, fig.align = "center")
knitr::include_graphics(![](/post/Comments.png){width = 100%})
![](/post/Comments.png){width = 100%}
<!-- https://i.redd.it/b9e4xbeg40151.jpg Ich habe keine Ahnung, ob das Bild urheberechtlich geschützt ist, und weiß nicht wie ich es herausfinden könnte-->
knitr::opts_chunk$set(echo = TRUE, fig.align = "center")
zahl <- 100
zahl = 100
log(100)
log(zahl)
args(round)
round(1.2859)
round(1.2859, digits = 2)
round(digits = 2, x = 1.2859)
zahlen <- c(8, 3, 4)
zahlen * 3
knitr::include_graphics("Vektoren.png")
str(zahlen)
class(zahlen) #alternativer Befehl
abfrage <- zahlen == 3 #elementenweise logische Abfrage
str(abfrage)
zeichen <- as.character(zahlen)
str(zeichen)
gender <- c(0, 1, 0, 2, 1, 1, 0, 0, 2)
str(gender)
gender_factor <- as.factor(gender)
str(gender_factor)
knitr::include_graphics("Matrizen.png")
mat<- matrix(c(7, 3, 9, 1, 4, 6), ncol = 2)
mat <- matrix(c(7, 3, 9, 1, 4, 6), ncol = 2)
mat[3, 1]
nrow(mat)
ncol(mat)
dim(mat) #alternativer Befehl
mat2 <-  matrix(c(8, 2, 11, 3, 5, 9), ncol = 2)
combined <- cbind(mat, mat2)
combined
knitr::include_graphics("Packages.png")
library(psych)
load(url("https://pandar.netlify.app/post/mach.rda"))
mean(mach$TIPI1)
mean(mach[,1]) #Alle Zeilen, erste Spalte
knitr::include_graphics("Screenshot1.png")
knitr::include_graphics("Screenshot2.png")
knitr::include_graphics("Screenshot3.png")
knitr::include_graphics("Screenshot4.png")
knitr::include_graphics("Screenshot5.png")
blogdown:::serve_site()
knitr::opts_chunk$set(echo = TRUE, fig.align = "center")
zahl <- 100
zahl = 100
log(100)
log(zahl)
args(round)
round(1.2859)
round(1.2859, digits = 2)
round(digits = 2, x = 1.2859)
zahlen <- c(8, 3, 4)
zahlen * 3
str(zahlen)
class(zahlen) #alternativer Befehl
abfrage <- zahlen == 3 #elementenweise logische Abfrage
str(abfrage)
zeichen <- as.character(zahlen)
str(zeichen)
gender <- c(0, 1, 0, 2, 1, 1, 0, 0, 2)
str(gender)
gender_factor <- as.factor(gender)
str(gender_factor)
mat<- matrix(c(7, 3, 9, 1, 4, 6), ncol = 2)
mat <- matrix(c(7, 3, 9, 1, 4, 6), ncol = 2)
mat[3, 1]
nrow(mat)
ncol(mat)
dim(mat) #alternativer Befehl
mat2 <-  matrix(c(8, 2, 11, 3, 5, 9), ncol = 2)
combined <- cbind(mat, mat2)
combined
library(psych)
load(url("https://pandar.netlify.app/post/mach.rda"))
mean(mach$TIPI1)
mean(mach[,1]) #Alle Zeilen, erste Spalte
blogdown:::serve_site()
knitr::include_graphics('/post/Matrizen.png')
![](/pandar/content/post/comments.png){width = 30%}
<!-- https://i.redd.it/b9e4xbeg40151.jpg Ich habe keine Ahnung, ob das Bild urheberechtlich geschützt ist, und weiß nicht wie ich es herausfinden könnte-->
![](/post/Matrizen.png){width=100%}
blogdown:::serve_site()
=======
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
tab = matrix(c(2,6,3,6,2,7,3,6,6,7,6,8,7,7,8,7,5,7,8,9), ncol = 2, byrow = T)
trans.tab = t(tab)
n = length(tab[,1])
mean.x1 = mean(tab[,1])
mean.x2 = mean(tab[,2])
spalte.mean = matrix(c(mean.x1, mean.x2))
spalte.mean
zeile.mean = matrix(c(mean.x1, mean.x2), ncol= 2, byrow = TRUE)
zeile.mean
1/n * trans.tab %*% tab - spalte.mean %*% zeile.mean
cov.mat = function(x, col) {
if (col == 2) {
trans.tab = t(x)
n = length(x[,1])
mean.x1 = mean(x[,1])
mean.x2 = mean(x[,2])
spalte.mean = matrix(c(mean.x1, mean.x2))
zeile.mean = matrix(c(mean.x1, mean.x2), ncol= 2, byrow = TRUE)
cov.mat = 1/n * trans.tab %*% x - spalte.mean %*% zeile.mean
} else if  (col == 3) {
trans.tab = t(x)
n = length(x[,1])
mean.x1 = mean(x[,1])
mean.x2 = mean(x[,2])
mean.x3 = mean(x[,3])
spalte.mean = matrix(c(mean.x1, mean.x2,mean.x3))
zeile.mean = matrix(c(mean.x1, mean.x2, mean.x3), ncol= 3, byrow = TRUE)
cov.mat = 1/n * trans.tab %*% x - spalte.mean %*% zeile.mean
} else if (col == 4) {
trans.tab = t(x)
n = length(x[,1])
mean.x1 = mean(x[,1])
mean.x2 = mean(x[,2])
mean.x3 = mean(x[,3])
mean.x4 = mean(x[,4])
spalte.mean = matrix(c(mean.x1, mean.x2,mean.x3, mean.x4))
zeile.mean = matrix(c(mean.x1, mean.x2, mean.x3,mean.x4), ncol= 4, byrow = TRUE)
cov.mat = 1/n * trans.tab %*% x - spalte.mean %*% zeile.mean
} else if (col == 5) {
trans.tab = t(x)
n = length(x[,1])
mean.x1 = mean(x[,1])
mean.x2 = mean(x[,2])
mean.x3 = mean(x[,3])
mean.x4 = mean(x[,4])
mean.x5 = mean(x[,5])
spalte.mean = matrix(c(mean.x1, mean.x2,mean.x3, mean.x4,mean.x5))
zeile.mean = matrix(c(mean.x1, mean.x2, mean.x3,mean.x4, mean.x5), ncol= 5, byrow = TRUE)
cov.mat = 1/n * trans.tab %*% x - spalte.mean %*% zeile.mean
}
return(cov.mat)
}
matrix_beispiel = matrix(c(6,24,32,46,53,62,76,87,92,160), ncol = 5, byrow = T)
matrix_beispiel
cov.mat(matrix_beispiel, 5)
cov(matrix_beispiel)
cov(matrix_beispiel)*(nrow(matrix_beispiel)-1)/nrow(matrix_beispiel)
Sigma <- matrix(0.5, 10, 10); diag(Sigma) <- 2:11
data <- mvtnorm::rmvnorm(n = 100, mean = rep(0, 10), sigma = )
data <- mvtnorm::rmvnorm(n = 100, mean = rep(0, 10), sigma = Sigma)
cov(data)*(nrow(data)-1)/nrow(data)
COV1 <- cov(data)*(nrow(data)-1)/nrow(data)
d <- data
n <- nrow(d)
zeile.mean <- t(colMeans(d))
zeile.mean
data <- mvtnorm::rmvnorm(n = 100, mean = 1:10, sigma = Sigma)
COV1 <- cov(data)*(nrow(data)-1)/nrow(data)
d <- data
n <- nrow(d)
zeile.mean <- t(colMeans(d))
zeile.mean
zeile.mean <- t(colMeans(d))
trans.tab <- t(d)
cov.mat = 1/n * trans.tab %*% x - spalte.mean %*% zeile.mean
n <- nrow(x)
zeile.mean <- t(colMeans(x))
x <- data
n <- nrow(x)
zeile.mean <- t(colMeans(x))
trans.tab <- t(x)
cov.mat = 1/n * trans.tab %*% x - spalte.mean %*% zeile.mean
spalte.mean <- t(zeile.mean)
trans.tab <- t(x)
cov.mat = 1/n * trans.tab %*% x - spalte.mean %*% zeile.mean
cov.mat
mycov <- function(x)
{
n <- nrow(x)
zeile.mean <- t(colMeans(x))
spalte.mean <- t(zeile.mean)
trans.tab <- t(x)
cov.mat = 1/n * trans.tab %*% x - spalte.mean %*% zeile.mean
return(cov.mat)
}
mycov(data)
COV2 <- mycov(data)
COV1-COV2
mycov_loop <- function(x)
{
n <- nrow(x)
p <- ncol(x)
means <- rep(NA, p) # leerer Vektor der Länge p (Anzahl Spalten)
for(i in 1:p)
{
means[i] <- mean(x[,i])
}
zeile.mean <- t(means)
spalte.mean <- t(zeile.mean)
trans.tab <- t(x)
cov.mat = 1/n * trans.tab %*% x - spalte.mean %*% zeile.mean
return(cov.mat)
}
mycov_loop(data)
COV3 - COV1
COV3 <-mycov_loop(data)
COV3 - COV1
round(COV3 - COV1, 10)
round(COV1 - COV2, 10)
>>>>>>> df665f1f26029cb13a2f87c046bd58d80ad28012
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
![Grafische Darstellung einer einfachen linearen Regression](images/Bild1.png){width="80%"}
blogdown:::new_post_addin()
confirmed <- read.csv('https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv')
deaths <- read.csv('https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv')
View(confirmed)
#Daten abrufen
load(url("https://pandar.netlify.app/post/Schulleistungen.rda"))
View(Schulleistungen)
# Vorbereitungen
knitr::opts_chunk$set(echo = TRUE, fig.align = "center")
load(url("https://pandar.netlify.app/post/WorldPopulation.rda"))
View(WorldPopulation)
knitr::opts_chunk$set(echo = TRUE, fig.align = "center")
load(url("https://pandar.netlify.app/post/conspiracy.rda"))
View(conspiracy)
knitr::opts_chunk$set(echo = TRUE, fig.align = "center")
load(url("https://pandar.netlify.app/post/PISA2009.rda"))
View(PISA2009)
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
knitr::opts_chunk$set(echo = TRUE, fig.align = "center")
load(url("https://pandar.netlify.app/post/PISA2009.rda"))
View(PISA2009)
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::new_post_addin()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
