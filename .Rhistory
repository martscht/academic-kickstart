Ger <- confirmed[confirmed$Country.Region == "Germany",-c(1:4)]
Ger
Ger[,1:79]
sum(Ger[,1:79])
covid_de
(Ger[,79])
(Ger[,78:79])
confirmed[,1:4]
confirmed[1,1:4]
confirmed[confirmed$Country.Region == "Germany", (78+4):(79+4)]
covid_de[covid_de$Day == c(78,79),]
m_l <- lm(Confirmed ~ Day, data = covid_de) # linearer Verlauf
summary(m_l)
### Quadratisches Modell
m_q <- lm(Confirmed ~ poly(Day, 2), data = covid_de) # quadratischer Verlauf
summary(m_q)
summary(m_q)$r.squared - summary(m_l)$r.squared  # Inkrement
anova(m_l, m_q)
m_l <- lm(Confirmed ~ poly(Day,1), data = covid_de) # linearer Verlauf
summary(m_l)
### Quadratisches Modell
m_q <- lm(Confirmed ~ poly(Day, 2), data = covid_de) # quadratischer Verlauf
summary(m_q)
summary(m_q)$r.squared - summary(m_l)$r.squared  # Inkrement
anova(m_l, m_q)
covid_nation <- covid_sel[covid_sel$Country.Region == "France", ]
covid_nation$log_Confirmed <- log(covid_nation$Confirmed)               # Logarithmieren der "confirmed cases"
covid_sel
library(ggplot2)
library(car)
library(MASS)
### Datensatz: Corona-Pandemie 2020
confirmed <- read.csv('https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv')
deaths <- read.csv('https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv')
### Long format ---
confirmed_long <- reshape(confirmed,
varying = names(confirmed)[-c(1:4)],
v.names = 'Confirmed',
timevar = 'Day',
idvar = names(confirmed)[1:4],
direction = 'long')
deaths_long <- reshape(deaths,
varying = names(deaths)[-c(1:4)],
v.names = 'Deaths',
timevar = 'Day',
idvar = names(deaths)[1:4],
direction = 'long')
### Merged data ----
long <- merge(confirmed_long, deaths_long,
by = c('Province.State', 'Country.Region', 'Lat', 'Long', 'Day'))
### Full data ----
covid <- aggregate(cbind(Confirmed, Deaths) ~ Country.Region + Day, data = long, FUN = 'sum')
### Only data until Day 79 ----
covid_full <- covid
covid <- covid[covid$Day < 80, ]
### Subsets ----
covid_sel <- covid[covid$Country.Region %in% c('France', 'Germany', 'Italy', 'Spain', 'United Kingdom'), ]
covid_de <- covid_sel[covid_sel$Country.Region == "Germany", ]
covid_de$log_Confirmed <- log(covid_de$Confirmed)               # Logarithmieren der "confirmed cases"
covid_de$log_Confirmed[covid_de$log_Confirmed == -Inf] <- NA    # Ersetzen von -unendlich durch missing (NA)
ggplot(covid_de, aes(x = Day, y = log_Confirmed))+geom_line(lwd=2)
covid_de <- covid_de[!is.na(covid_de$log_Confirmed),] # Löschen aller Fälle, in welchen Confrimed = 0 war
### lineares Modell
m_l <- lm(Confirmed ~ poly(Day,1), data = covid_de) # linearer Verlauf
summary(m_l)
### Quadratisches Modell
m_q <- lm(Confirmed ~ poly(Day, 2), data = covid_de) # quadratischer Verlauf
summary(m_q)
summary(m_q)$r.squared - summary(m_l)$r.squared  # Inkrement
anova(m_l, m_q)
covid_de <- covid_de[!is.na(covid_de$log_Confirmed),] # Löschen aller Fälle, in welchen Confrimed = 0 war
covid_de
### lineares Modell
m_l <- lm(Confirmed ~ Day, data = covid_de) # linearer Verlauf
summary(m_l)
### Quadratisches Modell
m_q <- lm(Confirmed ~ poly(Day, 2), data = covid_de) # quadratischer Verlauf
summary(m_q)
summary(m_q)$r.squared - summary(m_l)$r.squared  # Inkrement
anova(m_l, m_q)
covid_de <- covid_sel[covid_sel$Country.Region == "Germany", ]
### lineares Modell
m_l <- lm(Confirmed ~ Day, data = covid_de) # linearer Verlauf
summary(m_l)
### Quadratisches Modell
m_q <- lm(Confirmed ~ poly(Day, 2), data = covid_de) # quadratischer Verlauf
summary(m_q)
summary(m_q)$r.squared - summary(m_l)$r.squared  # Inkrement
anova(m_l, m_q)
covid_de
>>>>>>> df665f1f26029cb13a2f87c046bd58d80ad28012
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
<<<<<<< HEAD
knitr::opts_chunk$set(echo = TRUE, fig.align = "center")
knitr::include_graphics(![](/post/Comments.png){width = 100%})
knitr::opts_chunk$set(echo = TRUE, fig.align = "center")
knitr::include_graphics(![](/post/Comments.png){width = 100%})
knitr::opts_chunk$set(echo = TRUE, fig.align = "center")
knitr::include_graphics(![](/post/Comments.png){width = 100%})
knitr::opts_chunk$set(echo = TRUE, fig.align = "center")
knitr::include_graphics(![](/post/Comments.png){width = 100%})
![](/post/Comments.png){width = 100%}
<!-- https://i.redd.it/b9e4xbeg40151.jpg Ich habe keine Ahnung, ob das Bild urheberechtlich geschützt ist, und weiß nicht wie ich es herausfinden könnte-->
knitr::opts_chunk$set(echo = TRUE, fig.align = "center")
zahl <- 100
zahl = 100
log(100)
log(zahl)
args(round)
round(1.2859)
round(1.2859, digits = 2)
round(digits = 2, x = 1.2859)
zahlen <- c(8, 3, 4)
zahlen * 3
knitr::include_graphics("Vektoren.png")
str(zahlen)
class(zahlen) #alternativer Befehl
abfrage <- zahlen == 3 #elementenweise logische Abfrage
str(abfrage)
zeichen <- as.character(zahlen)
str(zeichen)
gender <- c(0, 1, 0, 2, 1, 1, 0, 0, 2)
str(gender)
gender_factor <- as.factor(gender)
str(gender_factor)
knitr::include_graphics("Matrizen.png")
mat<- matrix(c(7, 3, 9, 1, 4, 6), ncol = 2)
mat <- matrix(c(7, 3, 9, 1, 4, 6), ncol = 2)
mat[3, 1]
nrow(mat)
ncol(mat)
dim(mat) #alternativer Befehl
mat2 <-  matrix(c(8, 2, 11, 3, 5, 9), ncol = 2)
combined <- cbind(mat, mat2)
combined
knitr::include_graphics("Packages.png")
library(psych)
load(url("https://pandar.netlify.app/post/mach.rda"))
mean(mach$TIPI1)
mean(mach[,1]) #Alle Zeilen, erste Spalte
knitr::include_graphics("Screenshot1.png")
knitr::include_graphics("Screenshot2.png")
knitr::include_graphics("Screenshot3.png")
knitr::include_graphics("Screenshot4.png")
knitr::include_graphics("Screenshot5.png")
blogdown:::serve_site()
knitr::opts_chunk$set(echo = TRUE, fig.align = "center")
zahl <- 100
zahl = 100
log(100)
log(zahl)
args(round)
round(1.2859)
round(1.2859, digits = 2)
round(digits = 2, x = 1.2859)
zahlen <- c(8, 3, 4)
zahlen * 3
str(zahlen)
class(zahlen) #alternativer Befehl
abfrage <- zahlen == 3 #elementenweise logische Abfrage
str(abfrage)
zeichen <- as.character(zahlen)
str(zeichen)
gender <- c(0, 1, 0, 2, 1, 1, 0, 0, 2)
str(gender)
gender_factor <- as.factor(gender)
str(gender_factor)
mat<- matrix(c(7, 3, 9, 1, 4, 6), ncol = 2)
mat <- matrix(c(7, 3, 9, 1, 4, 6), ncol = 2)
mat[3, 1]
nrow(mat)
ncol(mat)
dim(mat) #alternativer Befehl
mat2 <-  matrix(c(8, 2, 11, 3, 5, 9), ncol = 2)
combined <- cbind(mat, mat2)
combined
library(psych)
load(url("https://pandar.netlify.app/post/mach.rda"))
mean(mach$TIPI1)
mean(mach[,1]) #Alle Zeilen, erste Spalte
blogdown:::serve_site()
knitr::include_graphics('/post/Matrizen.png')
![](/pandar/content/post/comments.png){width = 30%}
<!-- https://i.redd.it/b9e4xbeg40151.jpg Ich habe keine Ahnung, ob das Bild urheberechtlich geschützt ist, und weiß nicht wie ich es herausfinden könnte-->
![](/post/Matrizen.png){width=100%}
blogdown:::serve_site()
=======
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
tab = matrix(c(2,6,3,6,2,7,3,6,6,7,6,8,7,7,8,7,5,7,8,9), ncol = 2, byrow = T)
trans.tab = t(tab)
n = length(tab[,1])
mean.x1 = mean(tab[,1])
mean.x2 = mean(tab[,2])
spalte.mean = matrix(c(mean.x1, mean.x2))
spalte.mean
zeile.mean = matrix(c(mean.x1, mean.x2), ncol= 2, byrow = TRUE)
zeile.mean
1/n * trans.tab %*% tab - spalte.mean %*% zeile.mean
cov.mat = function(x, col) {
if (col == 2) {
trans.tab = t(x)
n = length(x[,1])
mean.x1 = mean(x[,1])
mean.x2 = mean(x[,2])
spalte.mean = matrix(c(mean.x1, mean.x2))
zeile.mean = matrix(c(mean.x1, mean.x2), ncol= 2, byrow = TRUE)
cov.mat = 1/n * trans.tab %*% x - spalte.mean %*% zeile.mean
} else if  (col == 3) {
trans.tab = t(x)
n = length(x[,1])
mean.x1 = mean(x[,1])
mean.x2 = mean(x[,2])
mean.x3 = mean(x[,3])
spalte.mean = matrix(c(mean.x1, mean.x2,mean.x3))
zeile.mean = matrix(c(mean.x1, mean.x2, mean.x3), ncol= 3, byrow = TRUE)
cov.mat = 1/n * trans.tab %*% x - spalte.mean %*% zeile.mean
} else if (col == 4) {
trans.tab = t(x)
n = length(x[,1])
mean.x1 = mean(x[,1])
mean.x2 = mean(x[,2])
mean.x3 = mean(x[,3])
mean.x4 = mean(x[,4])
spalte.mean = matrix(c(mean.x1, mean.x2,mean.x3, mean.x4))
zeile.mean = matrix(c(mean.x1, mean.x2, mean.x3,mean.x4), ncol= 4, byrow = TRUE)
cov.mat = 1/n * trans.tab %*% x - spalte.mean %*% zeile.mean
} else if (col == 5) {
trans.tab = t(x)
n = length(x[,1])
mean.x1 = mean(x[,1])
mean.x2 = mean(x[,2])
mean.x3 = mean(x[,3])
mean.x4 = mean(x[,4])
mean.x5 = mean(x[,5])
spalte.mean = matrix(c(mean.x1, mean.x2,mean.x3, mean.x4,mean.x5))
zeile.mean = matrix(c(mean.x1, mean.x2, mean.x3,mean.x4, mean.x5), ncol= 5, byrow = TRUE)
cov.mat = 1/n * trans.tab %*% x - spalte.mean %*% zeile.mean
}
return(cov.mat)
}
matrix_beispiel = matrix(c(6,24,32,46,53,62,76,87,92,160), ncol = 5, byrow = T)
matrix_beispiel
cov.mat(matrix_beispiel, 5)
cov(matrix_beispiel)
cov(matrix_beispiel)*(nrow(matrix_beispiel)-1)/nrow(matrix_beispiel)
Sigma <- matrix(0.5, 10, 10); diag(Sigma) <- 2:11
data <- mvtnorm::rmvnorm(n = 100, mean = rep(0, 10), sigma = )
data <- mvtnorm::rmvnorm(n = 100, mean = rep(0, 10), sigma = Sigma)
cov(data)*(nrow(data)-1)/nrow(data)
COV1 <- cov(data)*(nrow(data)-1)/nrow(data)
d <- data
n <- nrow(d)
zeile.mean <- t(colMeans(d))
zeile.mean
data <- mvtnorm::rmvnorm(n = 100, mean = 1:10, sigma = Sigma)
COV1 <- cov(data)*(nrow(data)-1)/nrow(data)
d <- data
n <- nrow(d)
zeile.mean <- t(colMeans(d))
zeile.mean
zeile.mean <- t(colMeans(d))
trans.tab <- t(d)
cov.mat = 1/n * trans.tab %*% x - spalte.mean %*% zeile.mean
n <- nrow(x)
zeile.mean <- t(colMeans(x))
x <- data
n <- nrow(x)
zeile.mean <- t(colMeans(x))
trans.tab <- t(x)
cov.mat = 1/n * trans.tab %*% x - spalte.mean %*% zeile.mean
spalte.mean <- t(zeile.mean)
trans.tab <- t(x)
cov.mat = 1/n * trans.tab %*% x - spalte.mean %*% zeile.mean
cov.mat
mycov <- function(x)
{
n <- nrow(x)
zeile.mean <- t(colMeans(x))
spalte.mean <- t(zeile.mean)
trans.tab <- t(x)
cov.mat = 1/n * trans.tab %*% x - spalte.mean %*% zeile.mean
return(cov.mat)
}
mycov(data)
COV2 <- mycov(data)
COV1-COV2
mycov_loop <- function(x)
{
n <- nrow(x)
p <- ncol(x)
means <- rep(NA, p) # leerer Vektor der Länge p (Anzahl Spalten)
for(i in 1:p)
{
means[i] <- mean(x[,i])
}
zeile.mean <- t(means)
spalte.mean <- t(zeile.mean)
trans.tab <- t(x)
cov.mat = 1/n * trans.tab %*% x - spalte.mean %*% zeile.mean
return(cov.mat)
}
mycov_loop(data)
COV3 - COV1
COV3 <-mycov_loop(data)
COV3 - COV1
round(COV3 - COV1, 10)
round(COV1 - COV2, 10)
>>>>>>> df665f1f26029cb13a2f87c046bd58d80ad28012
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
![Grafische Darstellung einer einfachen linearen Regression](images/Bild1.png){width="80%"}
blogdown:::new_post_addin()
confirmed <- read.csv('https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv')
deaths <- read.csv('https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv')
View(confirmed)
#Daten abrufen
load(url("https://pandar.netlify.app/post/Schulleistungen.rda"))
View(Schulleistungen)
# Vorbereitungen
knitr::opts_chunk$set(echo = TRUE, fig.align = "center")
load(url("https://pandar.netlify.app/post/WorldPopulation.rda"))
View(WorldPopulation)
knitr::opts_chunk$set(echo = TRUE, fig.align = "center")
load(url("https://pandar.netlify.app/post/conspiracy.rda"))
View(conspiracy)
knitr::opts_chunk$set(echo = TRUE, fig.align = "center")
load(url("https://pandar.netlify.app/post/PISA2009.rda"))
View(PISA2009)
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
knitr::opts_chunk$set(echo = TRUE, fig.align = "center")
load(url("https://pandar.netlify.app/post/PISA2009.rda"))
View(PISA2009)
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::new_post_addin()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
load(url("https://pandar.netlify.app/post/Schulleistungen.rda"))
Schulleistungen_std <- data.frame(scale(Schulleistungen)) # standardisierten Datensatz abspeichern als data.frame
library(plot3D)
# Übersichtlicher: Vorbereitung
x <- Schulleistungen_std$IQ
y <- Schulleistungen_std$reading
z <- Schulleistungen_std$math
# Übersichtlicher: Vorbereitung
x <- Schulleistungen_std$IQ
y <- Schulleistungen_std$reading
z <- Schulleistungen_std$math
fit <- lm(y ~ x*z + I(x^2) + I(z^2))
grid.lines = 26
x.pred <- seq(min(x), max(x), length.out = grid.lines)
z.pred <- seq(min(z), max(z), length.out = grid.lines)
xz <- expand.grid( x = x.pred, z = z.pred)
y.pred <- matrix(predict(fit, newdata = xz),
nrow = grid.lines, ncol = grid.lines)
fitpoints <- predict(fit)
# Plot:
scatter3D(x = x, y = z, z = y, pch = 16, cex = 1.2,
theta = 0, phi = 0, ticktype = "detailed",
xlab = "IQ", ylab = "math", zlab = "reading",
surf = list(x = x.pred, y = z.pred, z = y.pred,
facets = NA, fit = fitpoints),
main = "Moderierte Regression")
scatter3D(x = x, y = z, z = y, pch = 16, cex = 1.2,
theta = 20, phi = 20, ticktype = "detailed",
xlab = "IQ", ylab = "math", zlab = "reading",
surf = list(x = x.pred, y = z.pred, z = y.pred,
facets = NA, fit = fitpoints),
main = "Moderierte Regression")
# Plot:
scatter3D(x = x, y = z, z = y, pch = 16, cex = 1.2,
theta = 0, phi = 0, ticktype = "detailed",
xlab = "IQ", ylab = "math", zlab = "reading",
surf = list(x = x.pred, y = z.pred, z = y.pred,
facets = NA, fit = fitpoints),
main = "Moderierte Regression")
scatter3D(x = x, y = z, z = y, pch = 16, cex = 1.2,
theta = 20, phi = 20, ticktype = "detailed",
xlab = "IQ", ylab = "math", zlab = "reading",
surf = list(x = x.pred, y = z.pred, z = y.pred,
facets = NA, fit = fitpoints),
main = "Moderierte Regression")
mod_reg <- lm(reading ~ math + IQ + math:IQ, data = Schulleistungen_std)
mod_reg <- lm(reading ~ math + IQ + math:IQ+I(IQ^2)+I(math^2), data = Schulleistungen_std)
library(interactions)
interact_plot(model = mod_reg, pred = IQ, modx = math)
A <- seq(0, 10, 0.01)
cov(A, A^2)
2*mean(A)*var(A)
A_c <- A-mean(A)
cov(A_c,A_c^2)
cov(cbind(A, A^2, A^3))
cov(cbind(A_c,A_c^2, A_c^3))
round(cov(cbind(A_c,A_c^2, A_c^3)), 2)
round(cov(cbind(A_c,A_c^2, A_c^3, A_c^4)), 2)
round(poly(A,4),2)
poly(A,4)
round(as.matrix(poly(A,4)),2)
round(cbind(poly(A,4)),2)
round(cov(poly(A,4)),2)
round(cov(cbind(poly(A,4))),2)
cov(cbind(poly(A,4)))
cov(cbind(poly(A,4)), 10)
round(cov(cbind(poly(A,4))),10)
blogdown:::serve_site()
knitr::opts_chunk$set(echo = TRUE, fig.align = "center")
load(url("https://pandar.netlify.app/post/PISA2009.rda"))
cor(PISA2009$MotherEdu, PISA2009$MotherEdu^2)
cor(poly(PISA2009$MotherEdu, 2))
A <- seq(0, 10, 0.1)
cor(A, A^2)
cor(A_c, A_c^2)
cor(poly(A_c, 2))
cor(A_c, A_c^2)
cor(poly(A_c, 2))
# auf 15 Nachkommastellen gerundet:
round(cor(A_c, A_c^2), 15)
round(cor(poly(A_c, 2)), 15)
# auf 15 Nachkommastellen gerundet:
round(cor(cbind(A, A^2, A^3, A^4)), 15)
round(cor(cbind(A_c, A_c^2, A_c^3, A_c^4)), 15)
round(cor(poly(A_c, 4)), 15)
# auf 15 Nachkommastellen gerundet:
round(cor(cbind(A, A^2, A^3, A^4)), 2)
round(cor(cbind(A_c, A_c^2, A_c^3, A_c^4)), 2)
round(cor(poly(A_c, 4)), 2)
x <- seq(.1,.9,.1)
2^x
3^x
.5^x
.6^x
x <- seq(.1,2,.1)
.5^x<.6^x
x <- seq(-2,2,.1)
.5^x<.6^x
2^x<3^x
.5^ -3:-1 > .6^-3:-1
-3:-1
.5^(-3:-1) > .6^(-3:-1)
fontawesome::fa("smile")
knitr::opts_chunk$set(echo = TRUE, fig.align = "center")
load(url("https://pandar.netlify.app/post/PISA2009.rda"))
library(car)
library(MASS)
library(lm.beta) # erforderlich für standardiserte Gewichte
library(ggplot2)
library(interactions) # für Interaktionsplots in moderierten Regressionen
# Berechnung des Modells und Ausgabe der Ergebnisse
m1 <- lm(Reading ~ HISEI + MotherEdu + Books, data = PISA2009)
summary(lm.beta(m1))
# Residuenplots
residualPlots(m1, pch = 16)
res <- studres(m1) # Studentisierte Residuen als Objekt speichern
df_res <- data.frame(res) # als Data.Frame für ggplot
# Grafisch: Histogramm mit Normalverteilungskurve
library(ggplot2)
ggplot(data = df_res, aes(x = res)) +
geom_histogram(aes(y =..density..),
bins = 15,                    # Wie viele Balken sollen gezeichnet werden?
colour = "blue",              # Welche Farbe sollen die Linien der Balken haben?
fill = "skyblue") +           # Wie sollen die Balken gefüllt sein?
stat_function(fun = dnorm, args = list(mean = mean(res), sd = sd(res)), col = "darkblue") + # Füge die Normalverteilungsdiche "dnorm" hinzu und nutze den empirischen Mittelwert und die empirische Standardabweichung "args = list(mean = mean(res), sd = sd(res))", wähle dunkelblau als Linienfarbe
labs(title = "Histogramm der Residuen mit Normalverteilungsdichte", x = "Residuen") # Füge eigenen Titel und Achsenbeschriftung hinzu
# Test auf Abweichung von der Normalverteilung mit dem Shpiro Test
shapiro.test(res)
m1.b <- lm(Reading ~ HISEI + poly(MotherEdu, 2) + Books, data = PISA2009)
summary(lm.beta(m1.b))
cor(PISA2009$MotherEdu, PISA2009$MotherEdu^2)
cor(poly(PISA2009$MotherEdu, 2))
# Vergleich mit Modell ohne quadratischen Trend
summary(m1.b)$r.squared - summary(m1)$r.squared # Inkrement
anova(m1, m1.b)
summary(anova(m1, m1.b))
anova(m1, m1.b)$p.value
anova(m1, m1.b)$p
anova(m1, m1.b)$pvalue
anova(m1, m1.b)
anova(m1, m1.b)$`Pr(>F)`
anova(m1, m1.b)$`Pr(>F)`[2]
round(anova(m1, m1.b)$`Pr(>F)`[2], 4)
blogdown:::serve_site()
anova(m1, m1.b)
anova(m1, m1.b)
anova(m1, m1.b)[[4]]
anova(m1, m1.b)[[5]]
anova(m1, m1.b)[[6]]
load(url("https://pandar.netlify.app/post/Schulleistungen.rda"))
Schulleistungen_std <- data.frame(scale(Schulleistungen)) # standardisierten Datensatz abspeichern als data.frame
mod_reg <- lm(reading ~ math + IQ + math:IQ, data = Schulleistungen_std)
summary(mod_reg)
coef(summary(mod_reg)
)
coef(summary(mod_reg))[,4]
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
