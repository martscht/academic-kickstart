---
title: "Regressionsanalyse II"

date: '2021-04-28'
slug: reg2
categories:
     - BSc7
     
tags:
- Regression
- Zusammenhangsanalyse
- Erklärte Varianz
- Modelloptimierung
subtitle: 'Modelloptimierung'
summary: ''
authors: [hartig, schueller, irmer]
lastmod: '2022-03-22 12:00:12 CEST'
featured: no
header:
     image: "/header/PsyBSc7_Reg2.jpg"
     caption: "[Courtesy of pxhere](https://pxhere.com/de/photo/598938)"
projects: []
---

## Modelloptimierung

Bei der Regressionsanalyse hat die Modelloptimierung zum Ziel, ein Regresionsmodell zu verbessern, das heißt, möglichst viel Varianz der abhängigen Variable zu erklären. Dadurch wird die "Vorhersage" der abhängigen Variable genauer (die Streuung um die Regressionsgerade/hyperebene ist kleiner).

**Modelloptimierung** bedeutet, ein Modell zu verbessern, durch: 

* Aufnehmen zusätzlicher, bedeutsamer Prädiktoren
* Ausschließen von Prädiktoren, die nicht zur Varianzaufklärung beitragen

**Ziel** ist ein *sparsames Modell*, in dem 

* jeder enthaltene Prädiktor einen Beitrag zur Varianzaufklärung des Kriteriums leistet und
* kein wichtiger (= vorhersagestarker) Prädiktor vergessen wurde.

In diesem Kontext sind zwei Methoden interessant, nämlich

1. Das Testen von Änderungen in der erklärten Varianz, wenn zusätzliche Prädiktoren in ein Regressionsmodell aufgenommen werden (Inkrement) oder wenn Prädiktoren aus dem Modell entfernt werden (Dekrement).
2. Die schrittweise, “explorative” Auswahl von Prädiktoren aus einer größeren Menge möglicher Prädiktoren.

Dafür kann man beispielsweise das Inkrement, also den Zuwachs an erklärter Kriteriumsvarianz durch Hinzunahme eines Prädiktors, sowie das Dekrement, also die Verringerung an erklärter Varianz durch Ausschluss eines Prädiktors betrachten. Explorativ bedeutet hier, dass wir keiner zuvor hergeleiteter Theorie folgen, sondern die Daten möglichst genau untersuchen wollen. Hier kann es dann zum sogenannten Overfitting kommen, also einer zu starken Anpassung unseres Modells an die Daten. In weiteren (unabhängigen) Studien könnte dann das neu herausgearbeitete Modell konfirmatorisch (also von einer vor Analyse bestehenden Theorie abgeleitet/ theoriebestätigend) untersucht werden. 

### Übungs-Datensatz

Die Modelloptimierung wird am gleichen Datensatz demonstriert, der auch in der Sitzung zu [Regression I](/post/reg1) verwendet wurde. Eine Stichprobe von 100 Schülerinnen und Schülern hat einen Lese- und einen Mathematiktest bearbeitet, und zusätzlich dazu einen allgemeinen Intelligenztest absolviert. Im Datensatz enthalten ist zudem das Geschlecht (Variable: `female`, 0 = m, 1 = w). Die abhängige Variable ist die Matheleistung, die durch die anderen Variablen im Datensatz vorhergesagt werden soll.

Den Datensatz laden Sie  wie folgt:
```{r}
# Datensatz laden
load(url("https://pandar.netlify.app/post/Schulleistungen.rda"))
```

## Inkrement und Dekrement

Mit Inkrement und Dekrement meinen wir hier das Varianzinkrement/-dekrement, also das Hinzukommen oder die Abnahme der erklärten Varianz in unserem Modell.

### Testen eines Inkrements

Um ein Inkrement auf Signifikanz zu prüfen (also auf Verallgemeinerung auf die Population), müssen wir einen inferenzstatistischen Vergleich eines eingeschränkten Modells $M_c$ ($_c$ steht hier für "constraint", also eingeschränkt) mit weniger Prädiktoren gegen ein uneingeschränktes Modell $M_u$ ($_u$ steht hier für "unconstraint", also uneingeschränkt) mit zusätzlichen Prädiktoren. Beispiel: Inkrement durch Hinzunahme von Intelligenz. Wir können uns fragen: Führt die Hinzunahme von Intelligenz zu einem signifikanten Zuwachs an erklärter Varianz, wenn Lesekompetenz und Geschlecht bereits im Vorhersagemodell sind?

```{r}
m.c <- lm(math ~ reading + female, data = Schulleistungen)      # constrained
m.u <- lm(math ~ reading + female + IQ, data = Schulleistungen) # unconstrained
summary(m.c)
summary(m.u)
```

Wir interessieren uns insbesonderen für die erklärte Varianz, schauen uns also den Determinationskoeffizienten genauer an.

**Ergebniszusammenfassung: $R^2$**

* Determinationskoeffizient ohne IQ ("constrained"): $R_c^2=`r sprintf("%.2f",summary(m.c)$r.squared)`$
* Determinationskoeffizient mit IQ ("unconstrained"): $R_u^2=`r sprintf("%.2f",summary(m.u)$r.squared)`$

Das Inkrement ist nun die Differenz der beiden Determinationskoeffizienten. Sie ist immer $\ge0$. Diese können wir wie folgt berechnen:

```{r}
# Inkrement = Differenz in R2 aus restringiertem Modell 2 minus R2 aus unrestringiertem Modell 1
summary(m.u)$r.squared - summary(m.c)$r.squared
```


Wir sehen also, dass das Modell mit IQ als weiteren Prädiktor mehr Varianz erklärt als das ohne IQ. Die Hinzunahme des IQ führt zu einem Zuwachs von `r round((summary(m.u)$r.squared - summary(m.c)$r.squared)*100)`% erklärter Varianz ($\Delta R^2=`r round(summary(m.u)$r.squared - summary(m.c)$r.squared, 3)`$). Eine Signifikanzentscheidung können wir an dieser Stelle jedoch noch nicht treffen.

Dazu müssen wir zunächst dieses *Inkrement* auf Signifikanz testen. Der Modellvergleich kann mit der `anova`-Funktion vorgenommen werden. ANOVA steht hierbei für "**An**alysis **o**f **Va**riance", wir vergleichen ja nichts weiteres als Varianzen! Im Bezug auf Gruppenunterschiede hat die ANOVA eine besondere Bedeutung, weswegen wir ihr auch noch drei Blöcke widmen werten -- also in späteren Sitzungen zu diesem Thema mehr. 

Wir vergleichen die beiden Determinationskoeffizienten, indem wir der `anova`-Funktion einfach die beiden Modelle übergeben. Hierbei soll das eingeschränkte Modell stets links stehen, damit die Freiheitsgrade des Modellvergleichs positiv sind! Die Freiheitsgrade geben dann an, wie viele weiteren Parameter in unserem Modell zusätzlich geschätzt werden müssen.


```{r anova}
# Modellvergleich mit der anova-Funktion
anova(m.c, m.u)
```

Im Output sehen wir zunächst eine Übersicht über die beiden Modelle (auch mehr als 2 Modelle sind möglich, die Modelle müssen nur geschachtelt sein, also aus einander hervorgehen, damit sich sinnvoll miteinander verglichen werden können). Model 1 ist das Modell ohne IQ, während Model 2 das Modell mit IQ beschreibt. Die Zahlen 1 und 2 beschreiben dann die Zeilen der Modelle. `Res.Df` sind die Residualfreiheitsgrade (diese lassen sich bestimmen, indem von der Stichprobengröße $N$ die Anzahl der zu schätzenden Koeffizienten inklusive Interzept abgezogen werden). `RSS` ist die Residual Sum of Squares, also die Residualquadratsumme. `Df` sind die Freiheitsgrade (Degrees of Freedom). `Sum of Sq` ist die durch die hinzukommenden Prädiktoren erklärte Quadratsumme, welche sich einfach durch die Differenz der beiden `RSS` bestimmen lässt. `F` beschreibt den $F$-Wert, der die Änderung in den `Sum of Sq` an der zufälligen Streuung relativiert. `Pr(>F)` ist die Spalte mit den zu dem $F$-Werten gehörigen $p$-Werte, also die Spalte, die uns besonders interessiert!

Das Inkrement des IQs ist auf einem Alpha-Fehlerniveau von 0.05 signifikant von null verschieden ($p`r ifelse(anova(m.c, m.u)[[6]][2]<0.001, "<.001", paste0("=", round(anova(m.c, m.u)[[6]][2], 3)))`$). Somit wird der Anteil erklärter Varianz statistisch bedeutsam vergrößert.

Zum Vergleich finden Sie hier die Berechnung des F-Tests aus den Vorlesungs-Folien zur Regression:

```{r}
R2.u <- summary(m.u)$r.squared
R2.c <- summary(m.c)$r.squared
df.diff <- summary(m.u)$df[1] - summary(m.c)$df[1] # Änderung in den df
df.u <- summary(m.u)$df[2] # Freiheitsgrade des uneingeschränkten Modells
F.diff <- ((R2.u - R2.c) / df.diff) /
  ((1 - R2.u) / df.u)
p.diff <- 1-pf(F.diff, df.diff, df.u)
F.diff # F-Wert der Differenz in R^2
p.diff # zugehöriger p-Wert  
```

### Testen eines Dekrements

Das Dekrement ist ebenfalls ein Unterschied im $R^2$ zwischen dem restringierten Modell $M_c$ und dem unrestringierten Modell $M_u$. Wir gehen hier nur nicht von einer Hinzunähme von einem oder mehreren Prädiktoren aus, sondern von einem Herausnehmen von einem oder mehreren Prädiktoren. Es ändert sich also lediglich die Logik, in welcher wir das Modell verändern. Die Testung eines Dekrements erfolgt analog dem Inkrement: das eingeschränkte Modell $M_c$ mit weniger Prädiktoren wird mit dem uneingeschränkten Modell $M_u$ mit mehr Prädiktoren verglichen. Es soll nun geprüft werden, ob das *Weglassen* des Geschlechts aus dem Modell zu einem signifikanten Rückgang der erklärten Varianz führt. Dazu müssen wir im Grunde eigentlich wieder das Inkrement testen... Wir wissen also bereits wie das geht:

```{r}
m.u <- lm(math ~ reading + female + IQ, data = Schulleistungen) # unconstrained
m.c <- lm(math ~ reading + IQ, data = Schulleistungen) # constrained

summary(m.u)$r.squared - summary(m.c)$r.squared
# Modellvergleich mit der anova-Funktion
anova(m.c, m.u)
```

Der Ausschluss des Geschlechts führt zu einer Verringerung von `r round((summary(m.u)$r.squared - summary(m.c)$r.squared)*100)`% erklärter Varianz ($\Delta R^2=`r round(summary(m.u)$r.squared - summary(m.c)$r.squared, 3)`$). Dieser Unterschied ist *nicht* signifikant von null verschieden ($p=`r sprintf("%.3f",anova(m.c, m.u)[[6]][2])`$). Somit wird der Anteil erklärter Varianz nicht signifikant verringert!

## Schrittweise Selektion von Prädiktoren

Inkremente und Dekremente können theoriegeleitet auf Signifikanz getestet werden. Es gibt aber auch noch weitere Möglichkeiten unser Modell zu verändern:

Eine "theoriefreie" schrittweise Auswahl von Prädiktoren kann in R mit der `step`-Funktion erfolgen. Diese macht, anders als unser zuvor demonstriertes Vorgehen, nicht von Partialkorrelationen und Inkrementen Gebrauch, sondern vom sogenannten Informationskriterium AIC (*Akaike Information Criterion*). 
Dieses basiert auf der Likelihood eines geschätzten Modells $L(\hat{\theta})$ und der Anzahl der Modellparametern $p$:

$AIC=-2L(\hat{\theta}) + 2p$

Die Likelihood bezeichnet ein Maß für die Plausibilität/Wahrscheinlichkeit eines Modells, unter Berücksichtigung der gegebenen (empirisch erhobenen) Daten. Anders ausgedrückt: sie beantwortet die Frage, wie wahrscheinlich das Modell ist, wenn wir unsere gegeben Daten beobachtet haben. Um das beste Modell zu finden, kann man die Likelihood verschiedener Modelle vergleichen. Höhere Likelihoodwerte zeigen bessere Modelle an. Allerdings verbessert sich die Likelihood immer, wenn wir weitere Prädiktoren aufnehmen. Deshalb werden eben der Informationskriterien wie der AIC verwendet, da er zusätzlich zur Likelihood auch noch die Komplexität des Modells berücksichtigt. Komplexere Modelle mit vielen Prädiktoren werden bestraft durch den Bestrafungsterm $2p$.

Für lineare Regressionsmodelle lässt sich der AIC wie folgt darstellen:

$AIC_{\sigma}=n \cdot log(\sigma_e^2) + 2p$

Der AIC ist hier eine Funktion der Stichprobengröße $n$, der Residualvarianz $\sigma_e^2$ und der Anzahl der Parameter (= Regressionskoeffizienten) $p=m+1$. Es wird ersichtlich, dass der AIC von der Varianz der abhängigen Variablen abhängt, da diese wiederum die Residualvarianz beeinflusst.

Der AIC ist ein sogenanntes inverses Maß, das bedeutet, dass Modelle mit einem kleineren AIC besser sind als Modelle mit einem größeren AIC. Man kann sich den AIC also als eine Art Distanzmaß vorstellen (Achtung, das ist nur eine Anschauung) zwischen Daten und Modell. Der AIC wird durch den Term $n \cdot log(\sigma_e^2)$ kleiner, wenn die Residualvarianz kleiner wird, also mehr Varianz erklärt wird. Durch den "Strafterm" $2p$ wird der AIC größer, wenn das Modell mehr Prädiktoren enthält. 
Es soll also ein Modell gefunden werden, das mit möglichst wenigen Prädiktoren möglichst viel Varianz erklärt (*Sparsamkeitsprinzip*).

Die Schrittweise Selektion kann "vorwärts", "rückwärts", oder in beide Richtungen erfolgen. Die Standardeinstellung der `step`-Funktion ist die, dass ein Modell mit allen möglichen Prädiktoren als Ausgangspunkt genommen wird. Es wird dann der Prädiktor ausgeschlossen, der die größte Reduktion des AIC erlaubt, dann der nächste usw. In jedem Schritt wird auch wieder geprüft, ob Prädiktoren, die *nicht* im Modell sind, bei Aufnahme wieder zu einer Reduktion des AIC führen würden. Das Verfahren stoppt, wenn: 

1. nur noch Prädiktoren im Modell sind, deren Ausschluss zu einer Erhöhung des AIC führen würden und
2. nur Prädiktoren "übrig" sind, deren Einschluss den AIC nicht verbessern würde.

Einfaches Beispiel: Optimierung des Modells für Mathematikleistung, Start mit allen drei möglichen Prädiktoren:

```{r}
# Modell mit allen Prädiktoren
m <- lm(math ~ reading + female + IQ, data = Schulleistungen)
# Optimierung
summary(step(m))
```

Der Output enthält folgende Inhalte:

```{r, warning=FALSE, echo = F}
out <- summary(step(m)) |> capture.output()
begin <- "Start"; end <- "Df"
out[grep(pattern = begin, out):(grep(pattern = end, out)-1)] |> paste(collapse = "\n") |> cat()
```

zeigt uns das Anfangsmodell und den zugehörigen AIC.

```{r, warning=FALSE, echo = F}
begin <- "Df"; end <- "Step"
out[grep(pattern = begin, out):(grep(pattern = end, out)-1)] |> paste(collapse = "\n") |> cat()
```

ist der Output des ersten Schrittes. `<none>` beschreibt unser Modell (ohne Veränderung). Jede Zeile steht für ein Modell, in welchem jeweils maximal ein Prädiktor aus dem Modell ausgeschlossen wird oder maximal ein Prädiktor in das Modell aufgenommen wird. Das "Minus" am Anfang der Zeile zeigt an, dass hier ein Prädiktor ausgeschlossen wird. Eine "Plus" würde anzeigen, dass der jeweilige Prädiktor hinzukam (das ist hier ausgeschlossen, da lediglich eine "backward"-Selection gewählt wurde). Die `Df` zeigen wieder an, wie sich die Freiheitsgrade verändern. Würden wir eine Variable verwenden, die aus mehr als 2 Faktorstufen besteht, würden hier auch `Df` größer 1 stehen. `Sum of Sq` zeigt an, wie sich die Sum of Squares veränder. `RSS` ist wieder die Residual Sum of Squares, wie oben.

```{r, warning=FALSE, echo = F}
begin <- "Step"; end <- "Call"
out[grep(pattern = begin, out):(grep(pattern = end, out)-1)] |> paste(collapse = "\n") |> cat()
```

Der nächste Step beginnt nun mit dem verbesserten AIC, der erlangt wurde, indem die Leseleistung aus dem Modell gestrichen wurde. Da nun alle weiteren Modifikationen zu einer Verschlechterung des Modells führen, sind wir nach einer Modifikation bereits am Ende angelangt. 

**Zusammenfassung:**

Es ist zu sehen dass es im Ausgangsmodell nur eine Möglichkeit gibt, das Modell zu verbessern, nämlich den Ausschluss von Lesekompetenz (`reading`) (AIC von 889.88 auf 887.88). Danach gibt es keine Möglichkeit zur Verbesserung mehr, beide verbleibenden Prädiktoren würden bei einem Ausschluss zu einer Verschlechterung des AIC führen (`female` auf 888.39 und `IQ` auf 952.08). Damit sind Geschlecht und IQ die Prädiktoren für das optimierte Modell. An der Ausgabe für das "finale"  Modell am Schluss ist zu sehen, dass der Effekt von Geschlecht im finalen Modell hier *nicht* signifikant ist. Auch oben haben wir gesehen, dass unter Betrachtung des Dekrements dieser Prädiktor wegfallen würde. Wir sehen also, dass eine Auswahl mittels des AICs nicht notwendigerweise nur signifikante Prädiktoren auswählt!

Sparsamkeit wird beim AIC im "Strafterm" $2p$ nicht so hoch gewichtet wie bei anderen Informationskriterien. In der Funktion `step` kann man über die Veränderung des Parameters `k` steuern, wie streng die Prädiktorauswahl vorgenommen wird. Wenn man hier $k = log(n)$ angibt, wird statt des AIC das sogenannte Bayessche Informationskriterium BIC (*Bayesian Information Criterion*) verwendet.

$BIC=-2L(\hat{\theta}) + log(n)\cdot p$

Vorsicht, in der Ausgabe der `step`-Funktion steht immer AIC, auch wenn dies nur mit der Standardeinstellung von $k=2$ tatsächlich dem AIC entspricht!

```{r}
# Optimierung mit BIC
summary(step(m, k=log(nrow(Schulleistungen))))
```

Bei der Verwendung des stengeren Kriteriums wird auch Geschlecht aus dem Modell entfernt, es verbleibt nur der IQ im finalen Modell. Dies entspricht nun eher der Modellmodifikation inklusive finalem Modelltest, den wir beim ersten Modell durchgeführt haben. Der nicht signifikante Geschlechtseffekt wurde ebenfalls aus dem Modell entfernt. 

Eine Forwärts-Rückwärtsselektion (forward-backward-selection) erhalten wir, indem `direction = "both"` wir als Argument in `step` reinschreiben. 

### Weitere Möglichkeiten

Wie immer gibt es in R viele weitere Wege, zum selben Ziel zu kommen. Eine Vielzahl von Funktionen für die schrittweise Regression bietet z.B. das Paket `olsrr`,  Im Rahmen des Praktikums verwenden wir soweit möglich die Basis-Funktionen von R und beschränken uns daher bei den Aufgaben für schrittweise Analysen auf die `step`-Funktion.

Das Paket `olsrr` beinhaltet verschiedene Funktionen, die für die Regressionsanalyse nützlich sind, u.a. auch Funktionen, die die schrittweise Auswahl von Prädiktoren auf Basis verschiedener Kriterien und nach verschiedenen Methoden (vorwärts, rückwärts, etc.) ermöglichen. Finden Sie [hier](https://olsrr.rsquaredacademy.com/articles/variable_selection.html#best-subset-regression) mehr Informationen dazu. Die Funktion `ols_step_both_p` beinhaltet die Auswahl auf Basis der Signifikanz des Inkrements oder Dekrements und führt in jedem Schritt Tests für Einschluss und Ausschluss durch. Das ist sehr ähnlich zum AIC von zuvor, außer, dass jeder Schritt eben mit einer Signifikanzentscheidung untermauert wird. Diese Vorgehen ist nicht der Default, da durch das sehr häufige Testen das $\alpha$-Fehlerniveau nicht eingehalten werden kann. Eigentlich müsste dann nämlich bspw. Bonferroni korrigiert werden, was wiederum schwierig ist, wenn wir die Anzahl der Tests im Vorhinein kennen. Sie erkennen, das ganze Thema ist eine Wissenschaft für sich!

Nun zurück zur `ols_step_both_p`-Funktion: Der Input  ist ein Regressionsmodell, das mit der bekannten Funktion `lm` erstellt wurde. Über die zusätzlichen Argumente kann gesteuert werden, wie streng bei Aufnahme und Ausschluss getestet wird. Über das Argument `details` können Sie den gesamten Verlauf der schrittweisen Selektion (nicht nur das finale Ergebnis) anzeigen lassen. `pent` ist der p-Wert, der für das "entering" in das Modell zuständig ist. Also muss das Inkrement einen p-Wert von $p<.05$ haben, wenn wir `pent = .05` wählen.`prem` ist der p-Wert, der für das "removing" aus dem Modell zuständig ist. Also muss das Dekremnt einen p-Wert von $p>.11$ haben, wenn wir `pent = .10` wählen. `details = TRUE` fordert weitere Informationen an.

```{r}
# install.packages("olsrr")
library(olsrr)
ols_step_both_p(m, pent = .05, prem = .10, details = TRUE)
```

Der Output ist extrem detailliert, wobei allerdings nicht aufgeführt wird, wie die jeweiligen Inkremente oder Dekremente der anderen Variablen ausgefallen waren, die nicht selegiert wurden. Mit der `ols_step_both_p` wählen wir nur den IQ als Prädiktor aus! Uns wird nach jedem Step zunächst gesagt, welcher Prädiktor gewählt wurde und wie sich verschiedene Fit-Maße verhalten. Für uns ist an dieser Stelle besonder das $R^2$ (`R-Squared`) von Relevanz. Die ANOVA im Output beschreibt einfach eine ANOVA der zu vergleicheneden Modelle, wobei zunächst mit dem Null-Modell, welches nur das Interzept enthält, begonnen wird. 

Unter `Parameter Estimates` finden wir das finale geschätzte Modell. `Stepwise Selection Summary` zeigt uns das Vorgehen dieses Auswahlalgorithmus.

***

## R-Skript
Den gesamten `R`-Code, der in dieser Sitzung genutzt wird, können Sie [`r fontawesome::fa("download")` hier herunterladen](/post/PsyBSc7_R_Files/Regression-II.R).

