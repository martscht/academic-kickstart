---
title: Tests für abhängige Stichproben
date: '2022-12-06'
slug: gruppenvergleiche-abhaengig
categories:
  - BSc2
tags:
  - t-Test
  - abhängige Stichproben
subtitle: ''
summary: ''
authors: [koehler, buchholz, irmer, nehler]
lastmod: '2022-12-15T16:00:20+01:00'
featured: no
header:
  image: "/header/BSc2_test_abh_stpr.jpg"
  caption: "[Courtesy of pxhere](https://pxhere.com/en/photo/449195)"
projects: []
---

<script src="/rmarkdown-libs/header-attrs/header-attrs.js"></script>


<p>Nachdem wir uns mit <strong>unabhängige Stichproben</strong> in der (<a href="/post/gruppenvergleiche-unabhaengig">letzten Sitzung</a>) beschäftigt haben wollen wir diesmal mit abhängigen Stichproben beschäftigen. Anwendungen dafür in der Praxis sind beispielsweise Zwillinge, Paare oder auch Messwiederholungen.</p>
<details>
<summary>
Kernfragen der Lehreinheiten über Gruppenvergleiche
</summary>
<ul>
<li>Wie fertige ich Deskriptivstatistiken (Grafiken, Kennwerte) zur Veranschaulichung des Unterschieds zwischen zwei Gruppen an?<br />
</li>
<li>Was sind Voraussetzungen des abhängigen <em>t</em>-Tests und wie prüfe ich sie?</li>
<li>Wie führe ich einen abhängigen <em>t</em>-Test in R durch?</li>
<li>Wie berechne ich den standardisierten Populationseffekt für abhängige Stichproben?<br />
</li>
<li>Wie führe ich einen abhängigen Wilcoxon-Test in R durch?</li>
<li>Wie berichte ich statistische Ergebnisse formal?</li>
</ul>
</details>
<hr />
<div id="prep" class="section level2">
<h2>Vorbereitende Schritte</h2>
<p>Den Datensatz haben wir bereits unter diesem <a href="/post/fb22.rda"><i class="fas fa-download"></i> Link heruntergeladen</a> und können ihn über den lokalen Speicherort einladen oder Sie können Ihn direkt mittels des folgenden Befehls aus dem Internet in das Environment bekommen. In den vorherigen Tutorials und den dazugehörigen Aufgaben haben wir bereits Änderungen am Datensatz durchgeführt, die hier nochmal aufgeführt sind, um den Datensatz auf dem aktuellen Stand zu haben:</p>
<pre class="r"><code>#### Was bisher geschah: ----

# Daten laden
load(url(&#39;https://pandar.netlify.app/post/fb22.rda&#39;))  

# Nominalskalierte Variablen in Faktoren verwandeln
fb22$geschl_faktor &lt;- factor(fb22$geschl,
                             levels = 1:3,
                             labels = c(&quot;weiblich&quot;, &quot;männlich&quot;, &quot;anderes&quot;))
fb22$fach &lt;- factor(fb22$fach,
                    levels = 1:5,
                    labels = c(&#39;Allgemeine&#39;, &#39;Biologische&#39;, &#39;Entwicklung&#39;, &#39;Klinische&#39;, &#39;Diag./Meth.&#39;))
fb22$ziel &lt;- factor(fb22$ziel,
                        levels = 1:4,
                        labels = c(&quot;Wirtschaft&quot;, &quot;Therapie&quot;, &quot;Forschung&quot;, &quot;Andere&quot;))

fb22$wohnen &lt;- factor(fb22$wohnen, 
                      levels = 1:4, 
                      labels = c(&quot;WG&quot;, &quot;bei Eltern&quot;, &quot;alleine&quot;, &quot;sonstiges&quot;))

fb22$ort &lt;- factor(fb22$ort, levels=c(1,2), labels=c(&quot;FFM&quot;, &quot;anderer&quot;))

fb22$job &lt;- factor(fb22$job, levels=c(1,2), labels=c(&quot;nein&quot;, &quot;ja&quot;))
# Skalenbildung

fb22$prok2_r &lt;- -1 * (fb22$prok2 - 5)
fb22$prok3_r &lt;- -1 * (fb22$prok3 - 5)
fb22$prok5_r &lt;- -1 * (fb22$prok5 - 5)
fb22$prok7_r &lt;- -1 * (fb22$prok7 - 5)
fb22$prok8_r &lt;- -1 * (fb22$prok8 - 5)

# Prokrastination
fb22$prok_ges &lt;- fb22[, c(&#39;prok1&#39;, &#39;prok2_r&#39;, &#39;prok3_r&#39;,
                          &#39;prok4&#39;, &#39;prok5_r&#39;, &#39;prok6&#39;,
                          &#39;prok7_r&#39;, &#39;prok8_r&#39;, &#39;prok9&#39;, 
                          &#39;prok10&#39;)] |&gt; rowMeans()
# Naturverbundenheit
fb22$nr_ges &lt;-  fb22[, c(&#39;nr1&#39;, &#39;nr2&#39;, &#39;nr3&#39;, &#39;nr4&#39;, &#39;nr5&#39;,  &#39;nr6&#39;)] |&gt; rowMeans()
fb22$nr_ges_z &lt;- scale(fb22$nr_ges) # Standardisiert

# Weitere Standardisierugen
fb22$nerd_std &lt;- scale(fb22$nerd)
fb22$neuro_std &lt;- scale(fb22$neuro)</code></pre>
<hr />
</div>
<div id="fragestellung-d-haben-psychologiestudierende-vergleichbare-werte-auf-den-skalen-neurotizismus-und-extraversion" class="section level2">
<h2>4. Fragestellung D: Haben Psychologiestudierende vergleichbare Werte auf den Skalen Neurotizismus und Extraversion?</h2>
<p>Die Werte auf beiden Variablen sind insofern voneinander abhängig, dass jede Person die Fragen zu Neurotizismus und die Fragen zu Extraversion beantwortet hat (→ Messwiederholung). Es gibt daher Faktoren innerhalb der Person, die einen gemeinsamen Teil der Varianz erzeugen.</p>
<p>Anmerkung: Wir fragen hier bewusst nicht, ob Psychologiestudierende neurotischer sind als extravertiert. Dies würde voraussetzen, dass die Items der beiden Skalen vergleichbar schwierig sind.</p>
<p>Wir wollen im Folgenden lediglich die Frage beantworten, ob die Differenz zwischen den beiden Skalen (also die Mittelwerte für Neurotizismus und Extraversion) statistisch bedeutsam ist.</p>
<div id="deskriptivstatistik" class="section level3">
<h3>4.1. Deskriptivstatistik</h3>
<p>Wie immer beginnen wir mit der deskriptivstatistischen Analyse unserer Daten.</p>
<div id="grafisch" class="section level4">
<h4>4.1.1. grafisch</h4>
<p>Mithilfe von Histogrammen</p>
<pre class="r"><code># Je ein Histogramm pro Skala, untereinander dargestellt, vertikale Linie für den jeweiligen Mittelwert
par(mfrow=c(2,1), mar=c(3,3,2,0))
hist(fb22$neuro, 
     xlim=c(1,5),
     ylim = c(0,50),
     main=&quot;Neurotizismus&quot;, 
     xlab=&quot;&quot;, 
     ylab=&quot;&quot;, 
     las=1)
abline(v=mean(fb22$neuro), 
       lty=2, 
       lwd=2)

hist(fb22$extra, 
     xlim=c(1,5),
     ylim = c(0,50),
     main=&quot;Extraversion&quot;, 
     xlab=&quot;&quot;, 
     ylab=&quot;&quot;, 
     las=1)
abline(v=mean(fb22$extra), 
       lty=2, 
       lwd=2)</code></pre>
<p><img src="/post/2022-12-09-test-fuer-abhaengige-stichproben_files/figure-html/unnamed-chunk-2-1.png" width="672" /></p>
<pre class="r"><code>par(mfrow=c(1,1)) #Zurücksetzen des Plotfensters, zuvor hatten wir &quot;dev.off()&quot; kennengelernt</code></pre>
<p><code>abline</code> fügt eine Linie in eine Grafik ein. Mit dem Zusatzargument <code>v</code> geben wir eine vertikale Linie in den Plot (hier den Mittelwert). Insgesamt scheinen sich die beiden Verteilungen zu unterscheiden: Der Mittelwert von Neurotizismus liegt höher als der von Extraversion.</p>
</div>
<div id="statistisch" class="section level4">
<h4>4.1.2. statistisch</h4>
<p>Deskriptivstatistisch sehen die Ergebnisse so aus:</p>
<pre class="r"><code>summary(fb22$neuro)</code></pre>
<pre><code>##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##   1.250   3.250   3.750   3.626   4.250   5.000</code></pre>
<pre class="r"><code>summary(fb22$extra)</code></pre>
<pre><code>##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##   1.500   3.000   3.250   3.379   3.750   5.000</code></pre>
<pre class="r"><code>#alternativ
library(psych)
describe(fb22$neuro)</code></pre>
<pre><code>##    vars   n mean   sd median trimmed  mad  min max range  skew kurtosis   se
## X1    1 159 3.63 0.72   3.75    3.65 0.74 1.25   5  3.75 -0.43     0.09 0.06</code></pre>
<pre class="r"><code>describe(fb22$extra)</code></pre>
<pre><code>##    vars   n mean   sd median trimmed  mad min max range  skew kurtosis   se
## X1    1 159 3.38 0.71   3.25    3.39 0.74 1.5   5   3.5 -0.06    -0.31 0.06</code></pre>
<p>Achtung: Bei den hier berichteten SD handelt es sich (wie immer in R) um den Populationsschätzer. Die Mittelwerte der beiden Gruppen unterscheiden sich. Die Frage ist nun, ob sich dieser Unterschied auf die Population verallgemeinern lässt.</p>
</div>
</div>
<div id="voraussetzungsprüfung" class="section level3">
<h3>4.2. Voraussetzungsprüfung</h3>
<p>Um den Ergebnissen eines <span class="math inline">\(t\)</span>-Test für abhängige Stichproben vertrauen zu können, müssen dessen Voraussetzungen erfüllt sein:</p>
<p><strong>Voraussetzungen für die Durchführung des <em>t</em>-Tests für abhängige Stichproben:</strong></p>
<ol style="list-style-type: decimal">
<li>Die abhängige Variable ist intervallskaliert <span class="math inline">\(\rightarrow\)</span> ok<br />
</li>
<li>Die Messwerte innerhalb der Paare dürfen sich gegenseitig beeinflussen/voneinander abhängig sein; keine Abhängigkeiten zwischen den Messwertpaaren <span class="math inline">\(\rightarrow\)</span> ok<br />
</li>
<li>Die Differenzvariable <em>d</em> muss in der Population normalverteilt sein <span class="math inline">\(\rightarrow\)</span> ab <span class="math inline">\(n \ge 30\)</span> meist gegeben (s. zentraler Grenzwertsatz), ggf. grafische Prüfung oder Hintergrundwissen</li>
</ol>
<p><strong>zu 3. Normalverteilung von <em>d</em></strong></p>
<p>Da wir hier die Differenzvariable betrachten müssen, müssen wir diese zunächst erstellen. Anschließend schauen wir uns das Histogramm der Differenzvariable und den QQ-Plot an:</p>
<pre class="r"><code>difference &lt;- fb22$neuro-fb22$extra
hist(difference, 
     xlim=c(-3,3), 
     ylim = c(0,1),
     main=&quot;Verteilung der Differenzen&quot;, 
     xlab=&quot;Differenzen&quot;, 
     ylab=&quot;&quot;, 
     las=1,
     probability = T)
curve(dnorm(x, mean=mean(difference), sd=sd(difference)), 
      col=&quot;blue&quot;, 
      lwd=2, 
      add=T)</code></pre>
<p><img src="/post/2022-12-09-test-fuer-abhaengige-stichproben_files/figure-html/unnamed-chunk-5-1.png" width="672" /></p>
<pre class="r"><code>qqnorm(difference)
qqline(difference, col=&quot;blue&quot;)</code></pre>
<p><img src="/post/2022-12-09-test-fuer-abhaengige-stichproben_files/figure-html/unnamed-chunk-5-2.png" width="672" /></p>
<p><span class="math inline">\(\Rightarrow\)</span> Differenzen sehen normalverteilt aus, es wird also Normalverteilung angenommen. Somit sind alle drei Voraussetzungen für die Durchführung des <em>t</em>-Tests für abhängige Stichproben erfüllt.</p>
</div>
<div id="inferenzstatistik-t-test-für-abhängige-stichproben" class="section level3">
<h3>4.3. Inferenzstatistik: <em>t</em>-Test für abhängige Stichproben</h3>
<p>Zur Erinnerung:</p>
<blockquote>
<p>Fragestellung D: “Haben Psychologiestudierende vergleichbare Werte auf den Skalen Neurotizismus und Extraversion?”</p>
</blockquote>
<p><strong>Hypothesen:</strong></p>
<ul>
<li>Art des Effekts: Unterschiedshypothese</li>
<li>Richtung des Effekts: Ungerichtet</li>
<li>Grösse des Effekts: Unspezifisch</li>
</ul>
<p>Hyothesenpaar (inhaltlich):</p>
<ul>
<li>H0: Psychologiestudierende haben vergleichbare Werte auf den Skalen Neurotizismus und Extraversion.</li>
<li>H1: Bei Psychologiestudierende unterscheiden sich die Werte auf den Skalen Neurotizismus und Extraversion.</li>
</ul>
<p>Hypothesenpaar (statistisch):</p>
<ul>
<li>H0: <span class="math inline">\(\mu_\text{neuro} = \mu_\text{extra}\)</span> bzw. <span class="math inline">\(\mu_{d} = 0\)</span><br />
</li>
<li>H1: <span class="math inline">\(\mu_\text{neuro} \ne \mu_\text{extra}\)</span> bzw. <span class="math inline">\(\mu_{d} \ne 0\)</span></li>
</ul>
<p><strong>Signifikanzniveau</strong></p>
<p>Das Signifikanzniveau muss vor der Untersuchung festgelegt werden. Es soll hier 5% betragen. <span class="math inline">\(\rightarrow\)</span> <span class="math inline">\(\alpha=.05\)</span></p>
<p><strong>Durchführung des abhängigen <em>t</em>-Tests in R:</strong></p>
<p>Wir verwenden hier die Funktion <code>t.test</code>. Diesmal müssen wir allerdings die beiden Variablen einzeln der Funktion übergeben. Dies geschieht über die Argumente <code>x</code> und <code>y</code>. Das Argument <code>paired = T</code> führt dazu, dass der <em>t</em>-Test für abhängige (gepaarte) Stichproben durchgeführt wird.</p>
<pre class="r"><code>t.test(x = fb22$extra, y = fb22$neuro, # die beiden abhaengigen Variablen
      paired = T,                      # Stichproben sind abhaengig
      conf.level = .95)   </code></pre>
<pre><code>## 
##  Paired t-test
## 
## data:  fb22$extra and fb22$neuro
## t = -3.2465, df = 158, p-value = 0.001427
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  -0.39703668 -0.09667401
## sample estimates:
## mean of the differences 
##              -0.2468553</code></pre>
<p><span class="math inline">\(\rightarrow\)</span> <em>t</em>(158) = 3.25, <em>p</em> &lt; .01 <span class="math inline">\(\rightarrow\)</span> signifikant, H0 wird verworfen.</p>
</div>
<div id="schätzung-des-standardisierten-populationseffekts" class="section level3">
<h3>4.4. Schätzung des standardisierten Populationseffekts</h3>
<p>Formel: <span class="math display">\[d_2&#39;&#39; = \frac{\bar{d}} {\hat{sd}_{d}}\]</span></p>
<p>wobei</p>
<ul>
<li><span class="math inline">\(\bar{d}\)</span>: Mittelwert der Differenz aller Wertepaare<br />
</li>
<li><span class="math inline">\(\hat{sd}_{d}\)</span>: geschätzte SD der Differenzen</li>
</ul>
<p>Wir führen die Berechnung von Cohen’s <em>d</em> für abhängige Stichproben zunächst von Hand durch. Dafür speichern wir uns die nötigen Größen ab und wenden dann die präsentierte Formel an:</p>
<pre class="r"><code>mean_d &lt;- mean(difference)
sd.d.est &lt;- sd(difference)
d_Wert &lt;- mean_d/sd.d.est
d_Wert</code></pre>
<pre><code>## [1] 0.2574633</code></pre>
<p><strong>Berechnung mit Funktion <code>cohen.d()</code></strong></p>
<pre class="r"><code>#alternativ:
#install.packages(&quot;effsize&quot;)
library(&quot;effsize&quot;)</code></pre>
<pre class="r"><code>d2 &lt;- cohen.d(fb22$neuro, fb22$extra, 
      paired = T,  #paired steht fuer &#39;abhaengig&#39;
      within = F)   #wir brauchen nicht die Varianz innerhalb
d2</code></pre>
<pre><code>## 
## Cohen&#39;s d
## 
## d estimate: 0.2574633 (small)
## 95 percent confidence interval:
##      lower      upper 
## 0.09886578 0.41606085</code></pre>
<p>Mit dem Argument <code>within = T</code>, was der Default ist, wird für die Varianzberechnung die Varianz innerhalb der Gruppen herangezogen (vergleiche Formel Cohen’s <em>d</em> für unanghängige Stichproben).</p>
<p>Konventionen nach Cohen (1988) für <em>t</em>-Test für abhängige Stichproben
(Achtung: Werte unterscheiden sich zw. abhängigem und unabhängigem <em>t</em>-Test):</p>
<table>
<thead>
<tr class="header">
<th align="center"><em>d’’</em></th>
<th align="center">Interpretation</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">~ .14</td>
<td align="center">kleiner Effekt</td>
</tr>
<tr class="even">
<td align="center">~ .35</td>
<td align="center">mittlerer Effekt</td>
</tr>
<tr class="odd">
<td align="center">~ .57</td>
<td align="center">großer Effekt</td>
</tr>
</tbody>
</table>
<p><span class="math inline">\(\Rightarrow\)</span> der standardisierte Populationseffekt beträgt <span class="math inline">\(d_2&#39;&#39;\)</span> = 0.26 und ist laut Konventionen klein bis mittel.</p>
</div>
<div id="ergebnisinterpretation" class="section level3">
<h3>4.5. Ergebnisinterpretation</h3>
<p>Es wurde an Psychologiestudierenden untersucht, ob sie vergleichbare Werte auf den Skalen Neurotizismus und Extraversion aufweisen. Zunächst findet sich deskriptiv ein Unterschied: Psychologiestudierende weisen einen durchschnittlichen Neurotizismus-Wert von 3.63 (<em>SD</em> = 0.72) auf, während der durchschnittliche Extraversions-Wert 3.38 (<em>SD</em> = 0.71) beträgt. Zur Beantwortung der Fragestellung wurde ein ungerichteter <em>t</em>-Test für abhängige Stichproben durchgeführt. Der Gruppenunterschied ist signifikant (<em>t</em>(158) = 3.25, <em>p</em> &lt; .01), somit wird die Nullhypothese verworfen. Psychologiestudierende weisen einen höheren Wert auf der Skala Neurotizismus als auf der Skala Extraversion auf. Dieser Unterschied ist nach dem standardisierten Populationseffekt von <span class="math inline">\(d_2&#39;&#39;\)</span> = 0.26 klein bis mittel.</p>
<hr />
</div>
</div>
<div id="fragestellung-e-sind-jüngere-geschwister-kooperativer-als-ältere-rightarrow-wilcoxon-test" class="section level2">
<h2>5. Fragestellung E: Sind jüngere Geschwister kooperativer als ältere? <span class="math inline">\(\rightarrow\)</span> Wilcoxon-Test</h2>
<p>In unserem <code>fb22</code> Datensatz findet sich kein schönes Beispiel zur Illustration des Wilcoxon-Tests für abhängige Stichproben. Aus diesem Grund verwenden wir einen anderen Datensatz. Der Datensatz stammt aus Eid, Gollwitzer &amp; Schmitt: “Statistik und Forschungsmethoden” (4. Auflage, S. 370).</p>
<ul>
<li>Abhängige Variable (AV): Kooperationsbereitschaft (stetige Variable mit Werten von 0 [nicht kooperativ] bis 1 [maximal kooperativ])</li>
<li>Gruppen: das jeweils ältere Geschwisterteil (Gruppe “Älter”) vs. das jeweils jüngere Geschwisterteil (Gruppe “Jünger”)</li>
</ul>
<pre class="r"><code># Datensatz generieren
dataKooperation &lt;- data.frame(Paar = 1:10,  Juenger = c(0.49,0.25,0.51,0.55,0.35,0.54,0.24,0.49,0.38,0.50), Aelter = c(0.4,0.25,0.31,0.44,0.25,0.33,0.26,0.38,0.23,0.35))
dataKooperation # überprüfen, ob alles geklappt hat</code></pre>
<pre><code>##    Paar Juenger Aelter
## 1     1    0.49   0.40
## 2     2    0.25   0.25
## 3     3    0.51   0.31
## 4     4    0.55   0.44
## 5     5    0.35   0.25
## 6     6    0.54   0.33
## 7     7    0.24   0.26
## 8     8    0.49   0.38
## 9     9    0.38   0.23
## 10   10    0.50   0.35</code></pre>
<p>Ein Blick auf die Messwertpaare lässt bereits erkennen, dass die Stichproben (also die Messwerte in den beiden experimentellen Bedingungen) voneinander abhängig sind. Die Geschwisterpaare ähneln sich hinsichtlich ihrer kooperativen Verhaltenstendenzen. Auch inhaltlich sind sie von einander abhängig, da die meisten Geschwister miteinander verwandt sind, also ähnliche Gene aufweisen, und in der Regel im gleichen Zuhause aufwachsen und somit gleiche/sehr ähnliche Umwelteinflüsse genießen.</p>
<p>Relevant ist nun die Frage, ob die Differenz zwischen den beiden Mittelwerten (also zwischen jüngeren und älteren Geschwistern) statistisch bedeutsam ist - also ob die mittlere Differenz zwischen den Paaren von Null verschieden ist.</p>
<div id="deskriptivstatistik-1" class="section level3">
<h3>5.1. Deskriptivstatistik</h3>
<p>Wie immer beginnen wir mit der deskriptivstatistischen Analyse unserer Daten.</p>
<div id="grafisch-1" class="section level4">
<h4>5.1.1. grafisch</h4>
<p>Mithilfe von Histogrammen</p>
<pre class="r"><code># Je ein Histogramm pro Gruppe, untereinander dargestellt, vertikale Linie für den jeweiligen Mittelwert
par(mfrow=c(2,1), mar=c(3,3,2,0))
hist(dataKooperation[, &quot;Juenger&quot;], 
     xlim=c(0,1), 
     main=&quot;Kooperationsbereitschaft jüngeres Geschwisterteil&quot;, 
     xlab=&quot;&quot;, 
     ylab=&quot;&quot;, 
     las=1)
abline(v=mean(dataKooperation[, &quot;Juenger&quot;]), 
       lty=2, 
       lwd=2)

hist(dataKooperation[, &quot;Aelter&quot;], 
     xlim=c(0,1), 
     main=&quot;Kooperationsbereitschaft älteres Geschwisterteil&quot;, 
     xlab=&quot;&quot;, 
     ylab=&quot;&quot;, 
     las=1)
abline(v=mean(dataKooperation[, &quot;Aelter&quot;]), 
       lty=2, 
       lwd=2)</code></pre>
<p><img src="/post/2022-12-09-test-fuer-abhaengige-stichproben_files/figure-html/unnamed-chunk-12-1.png" width="672" /></p>
<pre class="r"><code>par(mfrow=c(1,1)) #Zurücksetzen des Plotfensters</code></pre>
<p>Die Histogramme sind via <code>xlim</code> so gewählt, dass sie die gleiche x-Achse aufweisen und somit ausgesprochen gut vergleichbar sind. <code>abline</code> fügt eine Linie in eine Grafik ein. Mit dem Zusatzargument <code>v</code> geben wir eine vertikale Linie in den Plot (hier den Mittelwert). Insgesamt scheinen sich die beiden Verteilungen etwas zu unterscheiden!</p>
</div>
<div id="statistisch-1" class="section level4">
<h4>5.1.2. statistisch</h4>
<p>Deskriptivstatistisch sehen die Ergebnisse so aus:</p>
<pre class="r"><code>summary(dataKooperation[, &quot;Juenger&quot;])</code></pre>
<pre><code>##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##  0.2400  0.3575  0.4900  0.4300  0.5075  0.5500</code></pre>
<pre class="r"><code>summary(dataKooperation[, &quot;Aelter&quot;])</code></pre>
<pre><code>##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##  0.2300  0.2525  0.3200  0.3200  0.3725  0.4400</code></pre>
<pre class="r"><code>#alternativ
library(psych)
describe(dataKooperation[, &quot;Juenger&quot;])</code></pre>
<pre><code>##    vars  n mean   sd median trimmed  mad  min  max range  skew kurtosis   se
## X1    1 10 0.43 0.12   0.49    0.44 0.08 0.24 0.55  0.31 -0.57    -1.46 0.04</code></pre>
<pre class="r"><code>describe(dataKooperation[, &quot;Aelter&quot;])</code></pre>
<pre><code>##    vars  n mean   sd median trimmed mad  min  max range skew kurtosis   se
## X1    1 10 0.32 0.07   0.32    0.32 0.1 0.23 0.44  0.21 0.23    -1.57 0.02</code></pre>
<p>Achtung: Bei den hier berichteten <em>SD</em> handelt es sich (wie immer in R) um den Populationsschätzer.</p>
<p>Die Mittelwerte der beiden Gruppen unterscheiden sich leicht. Die Frage ist nun, ob sich dieser Unterschied auf die Population verallgemeinern lässt.</p>
</div>
</div>
<div id="voraussetzungsprüfung-1" class="section level3">
<h3>5.2. Voraussetzungsprüfung</h3>
<p>Zunächst prüfen wir, ob wir zur Beantwortung der Fragestellung einen <span class="math inline">\(t\)</span>-Test für abhängige Stichproben verwenden können:</p>
<p><strong>Voraussetzungen für die Durchführung des <em>t</em>-Tests für abhängige Stichproben:</strong></p>
<ol style="list-style-type: decimal">
<li>Die abhängige Variable ist intervallskaliert <span class="math inline">\(\rightarrow\)</span> ok<br />
</li>
<li>Die Messwerte innerhalb der Paare dürfen sich gegenseitig beeinflussen/voneinander abhängig sein; keine Abhängigkeiten zwischen den Messwertpaaren <span class="math inline">\(\rightarrow\)</span> ok<br />
</li>
<li>Die Differenzvariable <em>d</em> muss in der Population normalverteilt sein <span class="math inline">\(\rightarrow\)</span> ab <span class="math inline">\(n \ge 30\)</span> meist gegeben (s. zentraler Grenzwertsatz), ggf. grafische Prüfung oder Hintergrundwissen</li>
</ol>
<p><strong>zu 3. Normalverteilung von <em>d</em></strong></p>
<p>Da wir die Differenzvariable betrachten müssen, erstellen wir diese zunächst. Das passiert vektorwertig. Anschließend schauen wir uns wie immer das Histogramm und den QQ-Plot an:</p>
<pre class="r"><code>difference &lt;- dataKooperation[, &quot;Juenger&quot;]-dataKooperation[, &quot;Aelter&quot;]
hist(difference, 
     xlim=c(-.3,.3), 
     ylim = c(0,5.5),
     main=&quot;Verteilung der Differenzen&quot;, 
     xlab=&quot;Differenzen&quot;, 
     ylab=&quot;&quot;, 
     las=1)
curve(dnorm(x, mean=mean(difference), sd=sd(difference)), 
      col=&quot;blue&quot;, 
      lwd=2, 
      add=T)</code></pre>
<p><img src="/post/2022-12-09-test-fuer-abhaengige-stichproben_files/figure-html/unnamed-chunk-15-1.png" width="672" /></p>
<pre class="r"><code>qqnorm(difference)
qqline(difference, col=&quot;blue&quot;)</code></pre>
<p><img src="/post/2022-12-09-test-fuer-abhaengige-stichproben_files/figure-html/unnamed-chunk-15-2.png" width="672" /></p>
<p><span class="math inline">\(\Rightarrow\)</span> Differenzen sehen nicht normalverteilt aus.</p>
<p>Da die letzte Voraussetzung nicht erfüllt ist, führen wir einen Wilcoxon-Test (für abhängige Stichproben) durch.</p>
<p>Auch für diesen Test gilt es, Voraussetzungen zu untersuchen:</p>
<p><strong>Voraussetzungen für die Durchführung des Wilcoxon-Tests (für abhängige Stichproben):</strong></p>
<ol style="list-style-type: decimal">
<li>die Differenzvariable ist in der Population stetig (zumindest singulär ordinlal) <span class="math inline">\(\rightarrow\)</span> ok<br />
</li>
<li>die Messwerte innerhalb der Paare dürfen sich gegenseitig beeinflussen/voneinander abhängig sein; keine Abhängigkeiten zwischen den Messwertpaaren <span class="math inline">\(\rightarrow\)</span> ok<br />
</li>
<li>die Differenzvariable ist symmetrisch verteilt (nicht notwendigerweise normalverteilt) <span class="math inline">\(\rightarrow\)</span> ok </li>
</ol>
</div>
<div id="inferenzstatistik-wilcoxon-test-für-abhängige-stichproben" class="section level3">
<h3>5.3. Inferenzstatistik: Wilcoxon-Test für abhängige Stichproben</h3>
<p>Zur Erinnerung:</p>
<blockquote>
<p>Fragestellung E: “Sind jüngere Geschwister kooperativer als ältere?”</p>
</blockquote>
<p><strong>Hypothesen:</strong></p>
<ul>
<li>Art des Effekts: Unterschiedshypothese</li>
<li>Richtung des Effekts: Gerichtet - positiver Effekt</li>
<li>Grösse des Effekts: Unspezifisch</li>
</ul>
<p>Hyothesenpaar (inhaltlich):</p>
<ul>
<li>H0: Jüngere Geschwister sind genau so oder weniger kooperativ wie ältere Geschwister.</li>
<li>H1: Jüngere Geschwister sind kooperativer als ältere Geschwister.</li>
</ul>
<p>Hypothesenpaar (statistisch):</p>
<ul>
<li>H0: <span class="math inline">\(\mu_\text{jünger} \le \mu_\text{älter}\)</span> bzw. <span class="math inline">\(\mu_{d} \le 0\)</span><br />
</li>
<li>H1: <span class="math inline">\(\mu_\text{jünger} &gt; \mu_\text{älter}\)</span> bzw. <span class="math inline">\(\mu_{d} &gt; 0\)</span></li>
</ul>
<p><strong>Signifikanzniveau</strong></p>
<p>Das Signifikanzniveau muss vor der Untersuchung festgelegt werden. Es soll hier 5% betragen. <span class="math inline">\(\rightarrow\)</span> <span class="math inline">\(\alpha=.05\)</span></p>
<p><strong>Durchführung des Wilcoxon-Tests für abhängige Stichproben in R:</strong></p>
<p>Die Funktion für den Wilcoxon-Test für abhängige Stichproben sieht dem des <em>t</em>-Tests für abhängige Stichproben sehr ähnlich.</p>
<pre class="r"><code>wilcox.test(x = dataKooperation[, &quot;Juenger&quot;], 
            y  = dataKooperation[, &quot;Aelter&quot;], # die beiden abhängigen Gruppen
            paired = T,      # Stichproben sind abhängig
            alternative = &quot;greater&quot;, # gerichtete Hypothese
            conf.level = .95)                 # alpha = .05</code></pre>
<pre><code>## 
##  Wilcoxon signed rank test with continuity correction
## 
## data:  dataKooperation[, &quot;Juenger&quot;] and dataKooperation[, &quot;Aelter&quot;]
## V = 44, p-value = 0.006426
## alternative hypothesis: true location shift is greater than 0</code></pre>
<p><em>V</em> = 44, <em>p</em> &lt; .01 <span class="math inline">\(\rightarrow\)</span> H0 wird verworfen.</p>
</div>
<div id="ergebnisinterpretation-1" class="section level3">
<h3>5.4 Ergebnisinterpretation</h3>
<p>Es wurde an Geschwisterpaaren untersucht, ob jüngere Geschwister kooperativer sind als ältere Geschwister. Zunächst findet sich deskriptiv ein Unterschied: Jüngere Geschwister weisen einen durchschnittlichen Wert (Median) von 0.49 (<em>IQR</em> = 0.15) auf, während die älteren Geschwister einen Wert (Median) von 0.32 (<em>IQR</em> = 0.12) aufweisen [IQR ist die Interquartil-Range also die Distanz vom Prozentrang 25% bis zum Prozentrang 75%]. Da die Differenzen nicht normalverteilt waren, wurde ein Wilcoxon-Test für abhängige Stichproben durchgeführt. Der Unterschied wurde bei einem Signifikanzniveau von alpha = .05 signifikant (<em>V</em> = 44, <em>p</em> &lt; .01). Somit wird die Nullhypothese verworfen. Der Befund deutet darauf hin, dass jüngere Geschwister kooperativer sind als ihr jeweils älteres Geschwisterteil.</p>
</div>
</div>
