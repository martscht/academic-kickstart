---
title: Tests für abhängige Stichproben
date: '2021-09-20'
slug: gruppenvergleiche-abhaengig
categories:
  - BSc2
tags:
  - t-Test
  - abhängige Stichproben
subtitle: ''
summary: ''
authors: [koehler, buchholz, irmer]
lastmod: '2021-12-22T17:00:20+01:00'
featured: no
header:
  image: "/header/BSc2_test_abh_stpr.jpg"
  caption: "[Courtesy of pxhere](https://pxhere.com/en/photo/449195)"
projects: []
---

<script src="/rmarkdown-libs/header-attrs/header-attrs.js"></script>


<details>
<summary>
Kernfragen der Lehreinheiten über Gruppenvergleiche
</summary>
<ul>
<li>Wie fertige ich Deskriptivstatistiken (Grafiken, Kennwerte) zur Veranschaulichung des Unterschieds zwischen zwei Gruppen an?</li>
</ul>
<p><strong>unabhängige Stichproben</strong> (<a href="/post/gruppenvergleiche-unabhaengig">letzte Sitzung</a>) <span class="math inline">\(\rightarrow\)</span> bereits erledigt!</p>
<ul>
<li>Was sind Voraussetzungen des <em>t</em>-Tests und wie prüfe ich sie? <span class="math inline">\(\rightarrow\)</span> bereits erledigt!</li>
<li>Wie führe ich einen <em>t</em>-Test in R durch? <span class="math inline">\(\rightarrow\)</span> bereits erledigt!</li>
<li>Wie berechne ich die Effektstärke Cohen’s <em>d</em>? <span class="math inline">\(\rightarrow\)</span> bereits erledigt!</li>
<li>Wie führe ich den Wilcoxon-Tests (auch “Mann-Whitney-Test”, “U-Test”, “Mann-Whitney-U-Test”, “Wilcoxon-Rangsummentest”) in R durch? <span class="math inline">\(\rightarrow\)</span> bereits erledigt!</li>
<li>Wie führe ich den Vierfelder-Chi-Quadrat-Tests in R durch? <span class="math inline">\(\rightarrow\)</span> bereits erledigt!</li>
</ul>
<p><strong>abhängige Stichproben</strong> (<a href="/post/gruppenvergleiche-abhaengig">diese Sitzung</a>)</p>
<ul>
<li><p>Was sind Voraussetzungen des abhängigen <em>t</em>-Tests und wie prüfe ich sie?</p></li>
<li><p>Wie führe ich einen abhängigen <em>t</em>-Test in R durch?<br />
</p></li>
<li><p>Wie berechne ich den standardisierten Populationseffekt für abhängige Stichproben?<br />
</p></li>
<li><p>Wie führe ich einen abhängigen Wilcoxon-Test in R durch?</p></li>
<li><p>Wie berichte ich statistische Ergebnisse formal?</p></li>
</ul>
</details>
<hr />
<div id="was-erwartet-sie" class="section level2">
<h2>Was erwartet Sie?</h2>
<p>Nachdem wir uns die Woche vor der Weihnachtspause mit dem Unterschied zwischen dem Mittelwert einer Stichprobe und dem Mittelwert der dazugehörigen Population, aus der die Stichprobe stammt, auseinandergesetzt haben, fokussieren wir uns nun auf Unterschiede zwischen zwei Gruppen (also zwei Stichproben). Hierbei muss zwischen unabhängigen und abhängigen Stichproben unterschieden werden.</p>
</div>
<div id="aufbau-der-sitzungen-zu-gruppenvergleichen" class="section level2">
<h2>Aufbau der Sitzungen zu Gruppenvergleichen</h2>
<ol style="list-style-type: decimal">
<li>Fragestellung A: Unterscheidet sich die Anzahl erreichter Punkte in der Statistik-Klausur zwischen Personen, die das Tutorium regelmäßig besucht haben und denen, die nur unregelmäßig da waren? (<em>t-Test und Cohen’s d für unabhängige Stichproben</em>) <span class="math inline">\(\rightarrow\)</span> bereits erledigt!</li>
<li>Fragestellung B: Sind Studentinnen verträglicher als Studenten? (<em>Wilcoxon-Test für unabhängige Stichproben</em>) <span class="math inline">\(\rightarrow\)</span> bereits erledigt!</li>
<li>Fragestellung C: Haben Studierende mit Wohnort in Uninähe (Frankfurt) mit gleicher Wahrscheinlichkeit einen Nebenjob wie Studierende, deren Wohnort außerhalb von Frankfurt liegt? (<em>Vierfelder-<span class="math inline">\(\chi^2\)</span>-Test</em>) <span class="math inline">\(\rightarrow\)</span> bereits erledigt!</li>
<li>Fragestellung D: Sind jüngere Geschwister kooperativer als ältere? (<em>t-Test und Cohen’s d für abhängige Stichproben</em>)</li>
<li>Fragestellung E: Sind jüngere Geschwister kooperativer als ältere? (<em>Wilcoxon-Test für abhängige Stichproben</em>)</li>
</ol>
<p>Fragen 1.- 3. wurden in der letzte Sitzung behandelt. In dieser Sitzung schauen wir uns Fragestellung 4.- 5. an.</p>
<hr />
<p>In dem Datensatz, den Sie am Anfang des Semesters ausgefüllt haben, gibt es keine sinnvollen abhängige Stichproben. Aus diesem Grund verwenden wir einen anderen Datensatz.</p>
</div>
<div id="fragestellung-d-sind-jüngere-geschwister-kooperativer-als-ältere" class="section level2">
<h2>4. Fragestellung D: Sind jüngere Geschwister kooperativer als ältere?</h2>
<p>Der Datensatz stammt aus Eid, Gollwitzer &amp; Schmitt: “Statistik und Forschungsmethoden” (4. Auflage, S. 370).</p>
<ul>
<li>Abhängige Variable (AV): Kooperationsbereitschaft (stetige Variable mit Werten von 0 [nicht kooperativ] bis 1 [maximal kooperativ])</li>
<li>Gruppen: das jeweils ältere Geschwisterteil (Gruppe “Älter”) vs. das jeweils jüngere Geschwisterteil (Gruppe “Jünger”)</li>
</ul>
<pre class="r"><code># Datensatz generieren
dataKooperation &lt;- data.frame(Paar = 1:10,  Juenger = c(0.49,0.25,0.51,0.55,0.35,0.54,0.24,0.49,0.38,0.50), Aelter = c(0.4,0.25,0.31,0.44,0.25,0.33,0.26,0.38,0.23,0.35))
dataKooperation # überprüfen, ob alles geklappt hat</code></pre>
<pre><code>##    Paar Juenger Aelter
## 1     1    0.49   0.40
## 2     2    0.25   0.25
## 3     3    0.51   0.31
## 4     4    0.55   0.44
## 5     5    0.35   0.25
## 6     6    0.54   0.33
## 7     7    0.24   0.26
## 8     8    0.49   0.38
## 9     9    0.38   0.23
## 10   10    0.50   0.35</code></pre>
<p>Ein Blick auf die Messwertpaare lässt bereits erkennen, dass die Stichproben (also die Messwerte in den beiden experimentellen Bedingungen) voneinander abhängig sind. Die Geschwisterpaare ähneln sich hinsichtlich ihrer kooperativen Verhaltenstendenzen. Auch inhaltlich sind sie von einander abhängig, da die meisten Geschwister miteinander verwandt sind, also ähnliche Gene aufweisen, und in der Regel im gleichen Zuhause aufwachsen und somit gleiche/sehr ähnliche Umwelteinflüsse genießen.</p>
<p>Für unsere Analysen ist es jedoch unwichtig, welche Ursachen diese Ähnlichkeiten haben. Entscheidend ist, dass es sich um Faktoren handelt, die sowohl einen Teil der Varianz in der ersten Gruppe als auch einen Teil der Varianz in der zweiten Gruppe erzeugen.</p>
<p>Relevant ist nun die Frage, ob die Differenz zwischen den beiden Mittelwerten (also zwischen jüngeren und älteren Geschwistern) statistisch bedeutsam ist - also ob die mittlere Differenz zwischen den Paaren von Null verschieden ist.</p>
<div id="deskriptivstatistik" class="section level3">
<h3>4.1. Deskriptivstatistik</h3>
<p>Wie immer beginnen wir mit der deskriptivstatistischen Analyse unserer Daten.</p>
<div id="grafisch" class="section level4">
<h4>4.1.1. grafisch</h4>
<p>Mithilfe von Histogrammen</p>
<pre class="r"><code># Je ein Histogramm pro Gruppe, untereinander dargestellt, vertikale Linie für den jeweiligen Mittelwert
par(mfrow=c(2,1), mar=c(3,3,2,0))
hist(dataKooperation[, &quot;Juenger&quot;], 
     xlim=c(0,1), 
     main=&quot;Kooperationsbereitschaft juengeres Geschwisterteil&quot;, 
     xlab=&quot;&quot;, 
     ylab=&quot;&quot;, 
     las=1)
abline(v=mean(dataKooperation[, &quot;Juenger&quot;]), 
       lty=2, 
       lwd=2)

hist(dataKooperation[, &quot;Aelter&quot;], 
     xlim=c(0,1), 
     main=&quot;Kooperationsbereitschaft aelteres Geschwisterteil&quot;, 
     xlab=&quot;&quot;, 
     ylab=&quot;&quot;, 
     las=1)
abline(v=mean(dataKooperation[, &quot;Aelter&quot;]), 
       lty=2, 
       lwd=2)</code></pre>
<p><img src="/post/2021-09-20-test-fuer-abhaengige-stichproben_files/figure-html/unnamed-chunk-2-1.png" width="672" /></p>
<pre class="r"><code>par(mfrow=c(1,1)) #Zurücksetzen des Plotfensters, zuvor hatten wir &quot;dev.off()&quot; kennengelernt</code></pre>
<p>Die Histogramme sieht via <code>xlim</code> so gewählt, dass sie die gleiche x-Achse aufweisen und somit ausgesprochen gut vergleichbar sind. <code>abline</code> fügt eine Linie in eine Grafik ein. Mit dem Zusatzargument <code>v</code> geben wir eine vertikale Linie in den Plot (hier den Mittelwert). Insgesamt sehen die beiden Verteilungen etwas verschoben aus!</p>
</div>
<div id="statistisch" class="section level4">
<h4>4.1.2. statistisch</h4>
<p>Deskriptivstatistisch sehen die Ergebnisse so aus:</p>
<pre class="r"><code>summary(dataKooperation[, &quot;Juenger&quot;])</code></pre>
<pre><code>##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##  0.2400  0.3575  0.4900  0.4300  0.5075  0.5500</code></pre>
<pre class="r"><code>summary(dataKooperation[, &quot;Aelter&quot;])</code></pre>
<pre><code>##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##  0.2300  0.2525  0.3200  0.3200  0.3725  0.4400</code></pre>
<pre class="r"><code>#alternativ
library(psych)
describe(dataKooperation[, &quot;Juenger&quot;])</code></pre>
<pre><code>##    vars  n mean   sd median trimmed  mad  min  max range  skew kurtosis   se
## X1    1 10 0.43 0.12   0.49    0.44 0.08 0.24 0.55  0.31 -0.57    -1.46 0.04</code></pre>
<pre class="r"><code>describe(dataKooperation[, &quot;Aelter&quot;])</code></pre>
<pre><code>##    vars  n mean   sd median trimmed mad  min  max range skew kurtosis   se
## X1    1 10 0.32 0.07   0.32    0.32 0.1 0.23 0.44  0.21 0.23    -1.57 0.02</code></pre>
<p>Achtung: Bei den hier berichteten SD handelt es sich (wie immer in R) um den Populationsschätzer. Die Mittelwerte der beiden Gruppen unterscheiden sich leicht. Die Frage ist nun, ob sich dieser Unterschied auf die Population verallgemeinern lässt.</p>
</div>
</div>
<div id="voraussetzungsprüfung" class="section level3">
<h3>4.2. Voraussetzungsprüfung</h3>
<p>Um den Ergebnissen eines <span class="math inline">\(t\)</span>-Test für abhängige Stichproben vertrauen zu können, müssen dessen Voraussetzungen erfüllt sein:</p>
<p><strong>Voraussetzungen für die Durchführung des <em>t</em>-Tests für abhängige Stichproben:</strong></p>
<ol style="list-style-type: decimal">
<li>Die abhängige Variable ist intervallskaliert <span class="math inline">\(\rightarrow\)</span> ok<br />
</li>
<li>Die Messwerte innerhalb der Paare dürfen sich gegenseitig beeinflussen/voneinander abhängig sein; keine Abhängigkeiten zwischen den Messwertpaaren <span class="math inline">\(\rightarrow\)</span> ok<br />
</li>
<li>Die Differenzvariable <em>d</em> muss in der Population normalverteilt sein <span class="math inline">\(\rightarrow\)</span> ab <em>n</em> =&gt; 30 meist gegeben (s. zentraler Grenzwertsatz), ggf. grafische Prüfung oder Hintergrundwissen</li>
</ol>
<p><strong>zu 3. Normalverteilung von <em>d</em></strong></p>
<p>Da wir hier die Differenzvariable betrachten müssen, müssen wir diese zunächst erstellen. Das passiert vektorwertig. Anschließend schauen wir uns wie immer das Histogramm und den QQ-Plot an:</p>
<pre class="r"><code>difference &lt;- dataKooperation[, &quot;Juenger&quot;]-dataKooperation[, &quot;Aelter&quot;]
hist(difference, 
     xlim=c(-.3,.3), 
     ylim = c(0,5.5),
     main=&quot;Verteilung der Differenzen&quot;, 
     xlab=&quot;Differenzen&quot;, 
     ylab=&quot;&quot;, 
     las=1)
curve(dnorm(x, mean=mean(difference), sd=sd(difference)), 
      col=&quot;blue&quot;, 
      lwd=2, 
      add=T)</code></pre>
<p><img src="/post/2021-09-20-test-fuer-abhaengige-stichproben_files/figure-html/unnamed-chunk-5-1.png" width="672" /></p>
<pre class="r"><code>qqnorm(difference)
qqline(difference, col=&quot;blue&quot;)</code></pre>
<p><img src="/post/2021-09-20-test-fuer-abhaengige-stichproben_files/figure-html/unnamed-chunk-5-2.png" width="672" /></p>
<p><span class="math inline">\(\Rightarrow\)</span> Differenzen sehen nicht normalverteilt aus! Allerdings steht in Eid, Gollwitzer &amp; Schmitt: “Zur Messung zur Kooperationsbereitschaft verwendet [der Forscher] ein standardisiertes Instrument, das Messwerte auf Intervallskalenniveau liefert und in der Population normalverteilt ist.”</p>
<p><span class="math inline">\(\Rightarrow\)</span> Es wird also Normalverteilung angenommen, somit sind alle drei Voraussetzungen für die Durchführung des <em>t</em>-Tests für abhängige Stichproben erfüllt.</p>
</div>
<div id="Hypothesen" class="section level3">
<h3>4.3. Inferenzstatistik: <em>t</em>-Test für abhängige Stichproben</h3>
<p>Zur Erinnerung:</p>
<blockquote>
<p>Fragestellung D: “Sind jüngere Geschwister kooperativer als Ältere?”</p>
</blockquote>
<p><strong>Hypothesen:</strong></p>
<ul>
<li>Art des Effekts: Unterschiedshypothese</li>
<li>Richtung des Effekts: Gerichtet - positiver Effekt</li>
<li>Grösse des Effekts: Unspezifisch</li>
</ul>
<p>Hyothesenpaar (inhaltlich):</p>
<ul>
<li>H0: Jüngere Geschwister sind genau so oder weniger kooperativ wie ältere Geschwister.</li>
<li>H1: Jüngere Geschwister sind kooperativer als ältere Geschwister.</li>
</ul>
<p>Hypothesenpaar (statistisch):</p>
<ul>
<li>H0: <span class="math inline">\(\mu_\text{jünger} \le \mu_\text{älter}\)</span> bzw. <span class="math inline">\(\mu_{d} \le 0\)</span><br />
</li>
<li>H1: <span class="math inline">\(\mu_\text{jünger} &gt; \mu_\text{älter}\)</span> bzw. <span class="math inline">\(\mu_{d} &gt; 0\)</span></li>
</ul>
<p><strong>Signifikanzniveau</strong></p>
<p>Das Signifikanzniveau muss vor der Untersuchung festgelegt werden. Es soll hier 5% betragen. <span class="math inline">\(\rightarrow\)</span> <span class="math inline">\(\alpha=.05\)</span></p>
<p><strong>Durchfürhung des abhängigen <em>t</em>-Tests in R:</strong></p>
<p>Wir verwenden hier die Funktion <code>t.test</code>. Diesmal müssen wir allerdings die beiden Gruppen einzeln der Funktion übergeben. Dies geschieht über die Argumente <code>x</code> und <code>y</code>. Das Argument <code>paired = T</code> führt dazu, dass der <em>t</em>-Test für abhängige (gepaarte) Stichproben durchgeführt wird.</p>
<pre class="r"><code>t.test(x = dataKooperation[, &quot;Juenger&quot;], y  = dataKooperation[, &quot;Aelter&quot;], # die beiden abhängigen Gruppen
       paired = T,                                                         # Stichproben sind abhängig
       alternative = &quot;greater&quot;,                                            # gerichtete Hypothese
       conf.level = .95)                                                   # alpha = .05</code></pre>
<pre><code>## 
##  Paired t-test
## 
## data:  dataKooperation[, &quot;Juenger&quot;] and dataKooperation[, &quot;Aelter&quot;]
## t = 4.63, df = 9, p-value = 0.0006183
## alternative hypothesis: true difference in means is greater than 0
## 95 percent confidence interval:
##  0.06644883        Inf
## sample estimates:
## mean of the differences 
##                    0.11</code></pre>
<p><em>df</em> bei <em>t</em>-test mit abhängigen Stichproben: <span class="math inline">\(n - 1\)</span> (wobei <span class="math inline">\(n\)</span> die Anzahl der Paare darstellt)<br />
<span class="math inline">\(\rightarrow\)</span> <em>t</em>(9) = 4.63, <em>p</em> &lt; .001 <span class="math inline">\(\rightarrow\)</span> signifikant, H0 wird verworfen, H1 wird angenommen.</p>
</div>
<div id="schätzung-des-standardisierten-populationseffekts" class="section level3">
<h3>4.4. Schätzung des standardisierten Populationseffekts</h3>
<p>Formel: <span class="math display">\[d_2&#39;&#39; = \frac{\bar{d}} {sd_{\hat{d}}}\]</span></p>
<p>wobei</p>
<ul>
<li><span class="math inline">\(\bar{d}\)</span>: Mittelwert der Differenz aller Wertepaare<br />
</li>
<li><span class="math inline">\(sd_{\hat{d}}\)</span>: geschätzte SD der Differenzen</li>
</ul>
<pre class="r"><code>mean_d &lt;- mean(difference)
sd.d.est &lt;- sd(difference)
d_Kooperation &lt;- mean_d/sd.d.est
d_Kooperation</code></pre>
<pre><code>## [1] 1.464138</code></pre>
<p>Konventionen nach Cohen (1988) für <em>t</em>-Test für abhängige Stichproben
(Achtung: Werte unterscheiden sich zw. abhängigem und unabhängigem <em>t</em>-Test):</p>
<table>
<thead>
<tr class="header">
<th align="center"><em>d’’</em></th>
<th align="center">Interpretation</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">~ .14</td>
<td align="center">kleiner Effekt</td>
</tr>
<tr class="even">
<td align="center">~ .35</td>
<td align="center">mittlerer Effekt</td>
</tr>
<tr class="odd">
<td align="center">~ .57</td>
<td align="center">großer Effekt</td>
</tr>
</tbody>
</table>
<p><span class="math inline">\(\Rightarrow\)</span> der standardisierte Populationseffekt beträgt <span class="math inline">\(d_2&#39;&#39;\)</span> = 1.46 und ist laut Konventionen groß.</p>
</div>
<div id="ergebnisinterpretation" class="section level3">
<h3>4.5. Ergebnisinterpretation</h3>
<p>Es wurde an Geschwisterpaaren untersucht, ob jüngere Geschwister kooperativer sind als ältere Geschwister. Zunächst findet sich deskriptiv ein Unterschied: Jüngere Geschwister weisen einen durchschnittlichen Wert von 0.43 (<em>SD</em> = 0.12) auf, während die älteren Geschwister einen Wert von 0.32 (<em>SD</em> = 0.07) aufweisen. Zur Beantwortung der Fragestellung wurde ein gerichteter <em>t</em>-Test für abhängige Stichproben durchgeführt. Der Gruppenunterschied ist signifikant (<em>t</em>(9) = 4.63, <em>p</em> &lt; .001), somit wird die Nullhypothese verworfen. Jüngere Geschwister sind kooperativer als ihre älteren Geschwister. Dieser Unterschied ist nach dem standardisierten Populationseffekt von <span class="math inline">\(d_2&#39;&#39;\)</span> = 1.46 groß.</p>
<hr />
</div>
</div>
<div id="fragestellung-e-sind-jüngere-geschwister-kooperativer-als-ältere-rightarrow-wilcoxon-test" class="section level2">
<h2>5. Fragestellung E: Sind jüngere Geschwister kooperativer als ältere? <span class="math inline">\(\rightarrow\)</span> Wilcoxon-Test</h2>
<p>Zuvor hatten wir bemerkt, dass die Normalverteilungsannahme der Differenzen eigentlich nicht gegeben war. Wir hatten dann trotzdem einen <em>t</em>-Test für abhängige Stichproben durchgeführt, da die verwendete Skala als normalverteilt angenommen werden kann. Wir wollen nun die Analyse mit Hilfe des Wilcoxon-Test wiederholen. Der Grund wäre, dass die Normalverteilungsannahme empirisch verletzt war und wir nur theoretisch dagegen argumentiert hatten.</p>
<p><strong>Signifikanzniveau</strong></p>
<p>Das Signifikanzniveau muss vor der Untersuchung festgelegt werden. Es soll hier 5% betragen. <span class="math inline">\(\rightarrow\)</span> <span class="math inline">\(\alpha=.05\)</span></p>
<p>Die Hypothesen sind identisch zu jenen des <em>t</em>-Tests (siehe <a href="#Hypothesen">Hypothesen</a>). Sie werden nicht erneut aufgelistet.</p>
<p><strong>Durchführung des Wilcoxon-Tests für abhängige Stichproben in R:</strong></p>
<p>Der Wilcoxon-Test-Befehl für abhängige Stichproben sieht dem des <em>t</em>-Tests für abhängige Stichproben sehr ähnlich.</p>
<pre class="r"><code>wilcox.test(x = dataKooperation[, &quot;Juenger&quot;], 
            y  = dataKooperation[, &quot;Aelter&quot;], # die beiden abhängigen Gruppen
            paired = T,      # Stichproben sind abhängig
            alternative = &quot;greater&quot;, # gerichtete Hypothese
            conf.level = .95)                 # alpha = .05</code></pre>
<pre><code>## 
##  Wilcoxon signed rank test with continuity correction
## 
## data:  dataKooperation[, &quot;Juenger&quot;] and dataKooperation[, &quot;Aelter&quot;]
## V = 44, p-value = 0.006426
## alternative hypothesis: true location shift is greater than 0</code></pre>
<p><em>V</em> = 44, <em>p</em> &lt; .01 <span class="math inline">\(\rightarrow\)</span> H0 wird verworfen, H1 wird angenommen.</p>
<div id="ergebnisinterpretation-1" class="section level3">
<h3>5.1 Ergebnisinterpretation</h3>
<p>Es wurde an Geschwisterpaaren untersucht, ob jüngere Geschwister kooperativer sind als ältere Geschwister. Zunächst findet sich deskriptiv ein Unterschied: Jüngere Geschwister weisen einen durchschnittlichen Wert von 0.43 (<em>SD</em> = 0.12) auf, während die älteren Geschwister einen Wert von 0.32 (<em>SD</em> = 0.07) aufweisen. Da die Differenzen nicht normalverteilt waren, wurde ein Wilcoxon-Test für abhängige Stichproben durchgeführt. Der Unterschied wurde bei einem Signifikanzniveau von alpha = .05 signifikant (<em>V</em> = 44, <em>p</em> &lt; .01). Somit wird die Nullhypothese verworfen und die Alternativhypothese angenommen: Jüngere Geschwister sind kooperativer als ihre älteren Geschwister.</p>
</div>
<div id="vergleich-t-test-und-wilcoxon-test" class="section level3">
<h3>5.2 Vergleich <em>t</em>-Test und Wilcoxon-Test</h3>
<p>Der <em>t</em>-Test und der Wilcoxon-Test haben unterschiedliche Annahmen. Die des <em>t</em>-Tests sind strenger. Sind Annahmen verletzt, so kann es fälschlicherweise zu signifikanten Ergebnissen kommen. In unserem Beispiel ist es nun so, dass der <em>t</em>-Test <em>p</em> &lt; 0.001 und der Wilcoxon-Test <em>p</em> &lt; 0.01 sich hinsichtlich der p-Werte drastisch unterscheiden. Dies kann sich auf die Power der Tests auswirken. Dazu erfahren Sie in den Aufgaben zu Simulation und Poweranalysen am Ende des Semesters mehr!</p>
<hr />
</div>
</div>
