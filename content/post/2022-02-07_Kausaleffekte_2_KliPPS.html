---
title: "Schätzung von Kausaleffekten 2"
output:
  html_document:
   code_folding: show
  
date: '2022-02-07'
slug: kausal2
categories:
     - MSc5a
    
tags:
- Kausalität
- Propensity Scores
- ANCOVA
- Gewichtung
- Matching

subtitle: 'Propensity Scores'
summary: ''
authors: [hartig]
lastmod: '2022-02-14 17:00:00 CEST'
featured: no
header:
     image: "/header/Kausal2_Head.jpg"
     caption: "[Courtesy of pxhere](https://pxhere.com/de/photo/795494)"
projects: []
---

<script src="/rmarkdown-libs/header-attrs/header-attrs.js"></script>


<div id="pakete-laden" class="section level4">
<h4>Pakete laden</h4>
<pre class="r"><code># Benötigte Pakete --&gt; Installieren, falls nicht schon vorhanden
library(psych)        # Für logistische Transformationen
library(ggplot2)      # Grafiken
library(gridExtra)
library(MatchIt)      # Für das Propensity Score Matching</code></pre>
</div>
<div id="inhalte" class="section level3">
<h3>Inhalte</h3>
<ul>
<li><a href="#Konstruktion">Konstruktion des PS mittels logistischer Regression</a></li>
<li><a href="#ANCOVA">Propensity Score als Kontrollvariable</a></li>
<li><a href="#Matching">Propensity Score Matching</a></li>
<li><a href="#Stratifizierung">Stratifizierung nach dem Propensity Score</a></li>
<li><a href="#Gewichtung">Gewichtung mit dem Propensity Score</a></li>
</ul>
</div>
<div id="Einleitung" class="section level2">
<h2>Datenbeispiel</h2>
<p>Wir verwenden wieder unserer fiktives Datenbeispiel, in dem Patient*innen, die an einer Depression oder einer Angststörung leiden, entweder mit einer kognitiven Verhaltenstherapie (CBT) behandelt oder in einer Wartekontrollgruppe belassen wurden. Die Zuordnung konnte nicht randomisiert erfolgen, weshalb der Effekt der Behandlung nicht ohne weiteres berechenbar ist.</p>
<pre class="r"><code>load(url(&quot;https://pandar.netlify.app/post/CBTdata.rda&quot;))
head(CBTdata)</code></pre>
<table>
<thead>
<tr class="header">
<th align="right">Age</th>
<th align="left">Gender</th>
<th align="left">Treatment</th>
<th align="left">Disorder</th>
<th align="right">BDI_pre</th>
<th align="right">SWL_pre</th>
<th align="right">BDI_post</th>
<th align="right">SWL_post</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">39</td>
<td align="left">female</td>
<td align="left">CBT</td>
<td align="left">ANX</td>
<td align="right">27</td>
<td align="right">10</td>
<td align="right">24</td>
<td align="right">15</td>
</tr>
<tr class="even">
<td align="right">36</td>
<td align="left">female</td>
<td align="left">CBT</td>
<td align="left">ANX</td>
<td align="right">22</td>
<td align="right">13</td>
<td align="right">13</td>
<td align="right">17</td>
</tr>
<tr class="odd">
<td align="right">61</td>
<td align="left">female</td>
<td align="left">CBT</td>
<td align="left">ANX</td>
<td align="right">24</td>
<td align="right">11</td>
<td align="right">17</td>
<td align="right">14</td>
</tr>
<tr class="even">
<td align="right">70</td>
<td align="left">female</td>
<td align="left">CBT</td>
<td align="left">ANX</td>
<td align="right">30</td>
<td align="right">15</td>
<td align="right">22</td>
<td align="right">19</td>
</tr>
<tr class="odd">
<td align="right">64</td>
<td align="left">female</td>
<td align="left">CBT</td>
<td align="left">DEP</td>
<td align="right">32</td>
<td align="right">12</td>
<td align="right">26</td>
<td align="right">20</td>
</tr>
<tr class="even">
<td align="right">50</td>
<td align="left">female</td>
<td align="left">CBT</td>
<td align="left">ANX</td>
<td align="right">24</td>
<td align="right">15</td>
<td align="right">23</td>
<td align="right">22</td>
</tr>
</tbody>
</table>
<p>Wir wissen auch bereits, dass der Prima-Facie-Effekt (PFE) von 0.39 Punkten nicht signifikant ist. Im Folgenden werden wir auf Basis von Kovariaten einen Propensity Score schätzen und auf verschiedene Weisen verwenden, um eine adjustierte Schätzung des Treatment-Effekts vorzunehmen.</p>
</div>
<div id="Konstruktion" class="section level2">
<h2>Konstruktion des Propensity Scores</h2>
<p>Zur Bildung des Propensity Scores verwenden wir eine logistische Regression mit den Variablen, von denen wir bereits wissen, dass sich die Gruppen darin Unterscheiden: Art der Störung, Prätest im BDI und Prätest im SWL:</p>
<pre class="r"><code># Vorhersage des Treatments durch Kovariaten
mod_ps1 &lt;- glm(Treatment ~ Disorder + BDI_pre + SWL_pre,
              family = &quot;binomial&quot;, data = CBTdata)
summary(mod_ps1)</code></pre>
<pre><code>## 
## Call:
## glm(formula = Treatment ~ Disorder + BDI_pre + SWL_pre, family = &quot;binomial&quot;, 
##     data = CBTdata)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -2.3543  -0.8633   0.4130   0.8568   2.1566  
## 
## Coefficients:
##             Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept) -0.89704    1.12602  -0.797  0.42565    
## DisorderDEP -0.77678    0.27580  -2.816  0.00486 ** 
## BDI_pre      0.16953    0.03750   4.520 6.18e-06 ***
## SWL_pre     -0.13763    0.03443  -3.998 6.39e-05 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 449.86  on 325  degrees of freedom
## Residual deviance: 349.89  on 322  degrees of freedom
## AIC: 357.89
## 
## Number of Fisher Scoring iterations: 4</code></pre>
<p>Wir sehen, dass alle Kovariaten auch bei gemeinsamer Berücksichtigung einen signifikanten Effekt auf die Treatment-Zugehörigkeit haben. Sicherheitshalber untersuchen wir auch die Wechselwirkungen:</p>
<pre class="r"><code># Einschluss von Wechselwirkungen, hierzu zunächst Zentrierung der Prädiktoren
CBTdata$BDI_pre_c &lt;- scale(CBTdata$BDI_pre, scale = F)
CBTdata$SWL_pre_c &lt;- scale(CBTdata$SWL_pre, scale = F)

mod_ps2 &lt;- glm(Treatment ~ Disorder + BDI_pre_c + SWL_pre_c +
                Disorder:BDI_pre_c + Disorder:SWL_pre_c + BDI_pre_c:SWL_pre_c +
                Disorder:BDI_pre_c:SWL_pre_c,
              family = &quot;binomial&quot;, data = CBTdata)
summary(mod_ps2)</code></pre>
<pre><code>## 
## Call:
## glm(formula = Treatment ~ Disorder + BDI_pre_c + SWL_pre_c + 
##     Disorder:BDI_pre_c + Disorder:SWL_pre_c + BDI_pre_c:SWL_pre_c + 
##     Disorder:BDI_pre_c:SWL_pre_c, family = &quot;binomial&quot;, data = CBTdata)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -2.0858  -0.8247   0.5448   0.7892   2.2328  
## 
## Coefficients:
##                                 Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)                      0.69555    0.20390   3.411 0.000647 ***
## DisorderDEP                     -0.82670    0.28607  -2.890 0.003854 ** 
## BDI_pre_c                        0.14802    0.05433   2.724 0.006446 ** 
## SWL_pre_c                       -0.13322    0.05650  -2.358 0.018378 *  
## DisorderDEP:BDI_pre_c            0.05187    0.07791   0.666 0.505586    
## DisorderDEP:SWL_pre_c           -0.03984    0.07692  -0.518 0.604514    
## BDI_pre_c:SWL_pre_c              0.01808    0.01161   1.557 0.119472    
## DisorderDEP:BDI_pre_c:SWL_pre_c -0.02353    0.01893  -1.243 0.213798    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 449.86  on 325  degrees of freedom
## Residual deviance: 345.66  on 318  degrees of freedom
## AIC: 361.66
## 
## Number of Fisher Scoring iterations: 4</code></pre>
<p>Da keiner der Wechselwirkungs-Terme signifikant ist, verwenden wir im nächsten Schritt das einfachere Modell <code>mod_ps1</code>. Mit der <code>predict</code>-Funktion erhalten wir Vorhergesagte Werte in Logit-Einheiten, mit der <code>logistic</code>-Funktion des <code>psych</code>-Paktets können wir diese in Wahrscheinlichkeiten transformieren:</p>
<pre class="r"><code>CBTdata$PS_logit &lt;- predict(mod_ps1)
CBTdata$PS_P &lt;- logistic(CBTdata$PS_logit)
plot(CBTdata$PS_logit, CBTdata$PS_P)</code></pre>
<p><img src="/post/2022-02-07_Kausaleffekte_2_KliPPS_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
<div id="prüfung-des-overlap" class="section level3">
<h3>Prüfung des Overlap</h3>
<p>Die Unterschiede im resultierenden Propensity Score in Logit-Einheiten können wir uns durch eine grafische Darstellung der Verteilungen in den Gruppen veranschaulichen. Die Treatment-Wahrscheinlichkeit ist in der Treatment-Gruppe deutlich höher, was z.B. durch eine Selektion nach Dringlichkeit der Fälle zustande gekommen sein kann. Durch ein Abtragen der Treatmentwahrscheinlichkeiten können wir zusätzlich veranschaulichen, wie groß die Überschneidungen der Gruppen (<em>common support</em>) sind. In dieser Grafik sind auch das Minimum der Wahrscheinlichkeit in der Treatment-Gruppe und das Maximum in der Kontrollgruppe eingetragen - diese definieren die Grenzen der Überschneidung zwischen den Gruppen.</p>
<pre class="r fold-hide"><code>## Overlap &amp; Common Support ----
p1 &lt;- ggplot(CBTdata, aes(x=PS_logit, fill = Treatment)) + 
  theme_bw() + theme(legend.position=&quot;top&quot;) +
  scale_fill_manual(values=c(&quot;#E69F00&quot;, &quot;#56B4E9&quot;)) +
  geom_density(alpha=0.5)

p2 &lt;- ggplot(CBTdata, aes(x=PS_P, fill = Treatment)) + 
  theme_bw() +
  labs(x=&quot;P(X=1)&quot;, y=&quot;&quot;) + xlim(c(0,1)) +
  scale_y_continuous(breaks=c(-1.5,1.5),     # &quot;manuelle&quot; Achsenbeschriftungen, um die Gruppen einzutragen
                     labels=c(&quot;CBT&quot;, &quot;WL&quot;)) +
  geom_histogram(data = CBTdata[CBTdata$Treatment==&quot;WL&quot;,], aes(y=..density..),   # Histogramm WL
                 alpha=0.5, fill=&quot;#E69F00&quot;) +
  geom_histogram(data = CBTdata[CBTdata$Treatment==&quot;CBT&quot;,], aes(y=-..density..), # Histogramm CBT
                 alpha=0.5, fill=&quot;#56B4E9&quot;) +
  # Minimum in CBT und maximum in WL einzeichnen
  geom_vline(xintercept = c(min(CBTdata$PS_P[CBTdata$Treatment==&quot;CBT&quot;]),
                            max(CBTdata$PS_P[CBTdata$Treatment==&quot;WL&quot;])),
             linetype=2) +
  coord_flip()
grid.arrange(p1, p2, nrow=1) # Beide Plots nebeneinander</code></pre>
<p><img src="/post/2022-02-07_Kausaleffekte_2_KliPPS_files/figure-html/unnamed-chunk-8-1.png" width="672" /></p>
<p>Für Fälle außerhalb der <em>common support region</em> können keine kausalen Effekte geschätzt werden. Wir schließen daher 16 Fälle aus, die außerhalb des Überschneidungsbereichs liegen:</p>
<pre class="r"><code>### Fälle außerhalb der Überschneidung ausschließen ----
# Fälle der Kontrollgruppe entfernen, deren Wahrscheinlichkeit kleiner ist als
# die kleinste Wahrscheinlichkeit in der Treatment-Gruppe
CBTdata &lt;- CBTdata[!(CBTdata$Treatment==&quot;WL&quot; &amp; 
                               CBTdata$PS_P &lt; min(subset(CBTdata, Treatment==&quot;CBT&quot;)$PS_P)),]
# Fälle der Treatment-Gruppe entfernen, deren Wahrscheinlichkeit größer ist als
# die größte Wahrscheinlichkeit in der Kontrollgruppe
CBTdata &lt;- CBTdata[!(CBTdata$Treatment==&quot;CBT&quot; &amp; 
                               CBTdata$PS_P &gt; max(subset(CBTdata, Treatment==&quot;WL&quot;)$PS_P)),]</code></pre>
<p>Nach dieser Korrektur überlappen sich die Propensity Scores beider Gruppen vollständig:</p>
<pre class="r fold-hide"><code>## Overlap &amp; Common Support nach Fallausschluss ----
p1 &lt;- ggplot(CBTdata, aes(x=PS_logit, fill = Treatment)) + 
  theme_bw() + theme(legend.position=&quot;top&quot;) +
  scale_fill_manual(values=c(&quot;#E69F00&quot;, &quot;#56B4E9&quot;)) +
  geom_density(alpha=0.5)

p2 &lt;- ggplot(CBTdata, aes(x=PS_P, fill = Treatment)) + 
  theme_bw() +
  labs(x=&quot;P(X=1)&quot;, y=&quot;&quot;) + xlim(c(0,1)) +
  scale_y_continuous(breaks=c(-1.5,1.5),     # &quot;manuelle&quot; Achsenbeschriftungen, um die Gruppen einzutragen
                     labels=c(&quot;CBT&quot;, &quot;WL&quot;)) +
  geom_histogram(data = CBTdata[CBTdata$Treatment==&quot;WL&quot;,], aes(y=..density..),   # Histogramm WL
                 alpha=0.5, fill=&quot;#E69F00&quot;) +
  geom_histogram(data = CBTdata[CBTdata$Treatment==&quot;CBT&quot;,], aes(y=-..density..), # Histogramm CBT
                 alpha=0.5, fill=&quot;#56B4E9&quot;) +
  coord_flip()
grid.arrange(p1, p2, nrow=1) # Beide Plots nebeneinander</code></pre>
<p><img src="/post/2022-02-07_Kausaleffekte_2_KliPPS_files/figure-html/unnamed-chunk-10-1.png" width="672" /></p>
</div>
</div>
<div id="ANCOVA" class="section level2">
<h2>Verwendung des Propensity Score in der ANCOVA</h2>
<p>Wir können den Treatment-Effekt schätzen, indem wir den Propensity Score anstelle der ursprünglichen Kovariaten als Kontrollvariable verwenden. Wir vergleichen hier die klassische ANCOVA mit allen Kovariaten mit einem Modell, in dem nur der Propensity Score kontrolliert wird (Achtung, aufgrund der Reduktion des Datensatzes entsprechen die Ergebnisse des 1. Modells nicht exakt <a href="https://pandar.netlify.app/post/kausal/#ANCOVA">denen im ersten Teil dieses Blocks</a>! Wir sehen, dass die auf beiden Wegen geschätzen Effekte praktisch identisch sind.</p>
<pre class="r"><code>BDI.adj &lt;- lm(BDI_post ~ Treatment + Disorder + BDI_pre + SWL_pre, data = CBTdata)
round(coef(BDI.adj)[2],2)</code></pre>
<pre><code>## TreatmentCBT 
##        -4.08</code></pre>
<pre class="r"><code>BDI.PS &lt;- lm(BDI_post ~ Treatment + PS_logit, data = CBTdata)
round(coef(BDI.PS)[2],2)</code></pre>
<pre><code>## TreatmentCBT 
##        -4.15</code></pre>
</div>
<div id="Matching" class="section level2">
<h2>Propensity Score Matching</h2>
<div id="auswirkung-der-zulässigen-distanz" class="section level3">
<h3>Auswirkung der zulässigen Distanz</h3>
<p>Matching können wir komfortabel mit der Funktion <code>matchit</code> aus dem Paket <code>MatchIt</code> durchführen. Mit Standard-Einstellungen wird als Methode zur Paarbildung ein “greedy nearest neighbor matching” verwendet, bei dem jedem Fall aus der Treatment-Gruppe nacheinander der ähnlichste Fall der Kontrollgruppe zugeordnet wird. Hier ist es wichtig, die Option <code>caliper</code> zu nutzen, um den zulässigen Höchstabstand zwischen den “Zwillingen” zu definieren (ausgedrückt in SD-Einheiten). Die folgende Grafik demonstriert den Effekt des caliper auf die Balance des Propensity Scores und auf die Anzahl der Fälle, die in der Analyse verbleiben.</p>
<div class="figure">
<img src="MatchIt.Caliper.gif" alt="" />
<p class="caption"><em>Abbildung: PS-Score-Dichte mit unterschiedlichen Werten für den caliper</em></p>
</div>
</div>
<div id="kontrolle-der-balance" class="section level3">
<h3>Kontrolle der Balance</h3>
<p>Mit einem caliper von 0.1 wird in der obigen Grafik augenscheinlich schon eine recht gute Balance erreicht, so dass wir diesen Wert für die weiteren Analysen verwenden.</p>
<pre class="r"><code>PS.match &lt;- matchit(Treatment ~ Disorder + BDI_pre + SWL_pre, method = &quot;nearest&quot;,
                    data = CBTdata, link = &quot;logit&quot;, caliper = 0.1)</code></pre>
<pre><code>## Warning: Fewer control units than treated units; not all treated units will get
## a match.</code></pre>
<p>Die Balance hinsichtlich des Propensity Scores <span class="math inline">\(\pi\)</span> und die Lage der nicht-gepaarten Fälle lässt sich auch gut mit einem Plot der <code>matchit</code>-Funktion veranschaulichen. Wir sehen, dass vor allem Fälle der Kontrollgruppe mit niedriger und Fälle der Treatment-Gruppe mit hoher Treatment-Wahrscheinlichkeit vom Matching ausgeschlossen werden:</p>
<pre class="r"><code>plot(PS.match, type = &quot;jitter&quot;, interactive = F)</code></pre>
<p><img src="/post/2022-02-07_Kausaleffekte_2_KliPPS_files/figure-html/unnamed-chunk-13-1.png" width="672" /></p>
<p>Die <code>summary</code> des <code>matchit</code>-Objekts liefert detailierte Informationen zur Balance der einbezogenen Kovariaten. Wir sehen, dass die Differenzen in den Kovariaten sehr gut reduziert werden konnten. In der gematchten Stichprobe sind allerdings auch nur noch 168 (2 * 84) Fälle verblieben. 142 wurden ausgeschlossen, da sie nicht mit einem hinreichend ähnlichen Fall “gepaart” werden konnten.</p>
<pre class="r"><code>summary(PS.match)</code></pre>
<pre><code>## 
## Call:
## matchit(formula = Treatment ~ Disorder + BDI_pre + SWL_pre, data = CBTdata, 
##     method = &quot;nearest&quot;, link = &quot;logit&quot;, caliper = 0.1)
## 
## Summary of Balance for All Data:
##             Means Treated Means Control Std. Mean Diff. Var. Ratio eCDF Mean
## distance           0.6546        0.4140          1.2129     0.7774    0.2806
## DisorderANX        0.6450        0.3191          0.6809          .    0.3258
## DisorderDEP        0.3550        0.6809         -0.6809          .    0.3258
## BDI_pre           23.6509       20.3546          0.8805     0.9477    0.1433
## SWL_pre           15.0414       17.7872         -0.7177     0.9862    0.1262
##             eCDF Max
## distance      0.4689
## DisorderANX   0.3258
## DisorderDEP   0.3258
## BDI_pre       0.3627
## SWL_pre       0.3057
## 
## 
## Summary of Balance for Matched Data:
##             Means Treated Means Control Std. Mean Diff. Var. Ratio eCDF Mean
## distance           0.5471        0.5370          0.0505     1.0724    0.0157
## DisorderANX        0.4881        0.4643          0.0498          .    0.0238
## DisorderDEP        0.5119        0.5357         -0.0498          .    0.0238
## BDI_pre           22.2262       22.0000          0.0604     1.2695    0.0233
## SWL_pre           16.2262       16.2262          0.0000     1.3760    0.0303
##             eCDF Max Std. Pair Dist.
## distance      0.0595          0.0582
## DisorderANX   0.0238          0.6966
## DisorderDEP   0.0238          0.6966
## BDI_pre       0.0714          0.6710
## SWL_pre       0.0952          3.1667
## 
## Percent Balance Improvement:
##             Std. Mean Diff. Var. Ratio eCDF Mean eCDF Max
## distance               95.8       72.2      94.4     87.3
## DisorderANX            92.7          .      92.7     92.7
## DisorderDEP            92.7          .      92.7     92.7
## BDI_pre                93.1     -344.3      83.7     80.3
## SWL_pre               100.0    -2195.1      76.0     68.8
## 
## Sample Sizes:
##           Control Treated
## All           141     169
## Matched        84      84
## Unmatched      57      85
## Discarded       0       0</code></pre>
<p>Eine grafische Zusammenfassung der Kovariaten-Balance lässt sich durch einen <code>plot</code> der <code>summary</code> des <code>matchit</code>-Objekts erzeugen. Auch hier sehen wir, dass die Balance zufriedenstellend ist:</p>
<pre class="r"><code>plot(summary(PS.match),
     var.order = &quot;unmatched&quot;, abs = FALSE)</code></pre>
<p><img src="/post/2022-02-07_Kausaleffekte_2_KliPPS_files/figure-html/unnamed-chunk-15-1.png" width="672" /></p>
</div>
<div id="effektschätzung" class="section level3">
<h3>Effektschätzung</h3>
<p>Um den ATT zu schätzen, wird mit der Funktion <code>match.data</code> der gematchte Datensatz aus dem <code>matchit</code>-Objekt gebildet. Mit diesem können wir ein einfaches lineares Modell zur Schätzung des Treatment-Effekts nutzen. Die Effektschätzung von -3.96 entspricht wieder recht gut den Ergebnissen, die wir mit anderen Methoden erhalten hatten.</p>
<pre class="r"><code>CBTdata.PSM &lt;- match.data(PS.match)
BDI.match &lt;- lm(BDI_post ~ Treatment, data = CBTdata.PSM)
summary(BDI.match)</code></pre>
<pre><code>## 
## Call:
## lm(formula = BDI_post ~ Treatment, data = CBTdata.PSM)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -13.7857  -3.8214   0.1964   3.2143  15.2143 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)   20.7857     0.5472  37.989  &lt; 2e-16 ***
## TreatmentCBT  -3.9643     0.7738  -5.123 8.26e-07 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 5.015 on 166 degrees of freedom
## Multiple R-squared:  0.1365, Adjusted R-squared:  0.1313 
## F-statistic: 26.25 on 1 and 166 DF,  p-value: 8.263e-07</code></pre>
</div>
</div>
<div id="Stratifizierung" class="section level2">
<h2>Stratifizierung</h2>
<p>Stratifizierung ist als Methode <code>subclass</code> in der <code>matchit</code>-Funktion enthalten. Wir bilden fünf Strata und extrahieren den Datensatz, der die Zugehörigkeit zu den Strata enthält (Variable <code>subclass</code>). Die Kreuztabelle zeigt, dass die Strata so gebildet wurden, dass die Treatment-Gruppe gleichmäßig aufgeteilt wurde. Die Anzahl der jeweils “passenden” Kontrollgruppen-Fälle in den Strata unterscheidet sich stark.</p>
<pre class="r"><code>PS.strat &lt;- matchit(Treatment ~ Disorder + BDI_pre + SWL_pre, data = CBTdata,
                 distance = &#39;logit&#39;, method = &#39;subclass&#39;, subclass = 5)
CBTdata.strat &lt;- match.data(PS.strat)
# Zugehörigkeit der Fälle zu Treatment und Stratum
table(CBTdata.strat$Treatment, CBTdata.strat$subclass)</code></pre>
<pre><code>##      
##        1  2  3  4  5
##   WL  91 21 15  7  7
##   CBT 34 34 33 33 35</code></pre>
<p>Die folgende Grafik veranschaulicht die gebildeten Strata, als Grenzen sind jeweils die Untergrenzen (Minima in den Gruppen) eingezeichnet:</p>
<pre class="r fold-hide"><code>ggplot(CBTdata.strat, aes(x=distance, fill = Treatment)) + 
  theme_bw() + theme(text = element_text(size = 20)) +
  labs(x=&quot;P(X=1)&quot;, y=&quot;&quot;) +
  scale_y_continuous(breaks=c(-1.5,1.5),     # &quot;manuelle&quot; Achsenbeschriftungen, um die Gruppen einzutragen
                     labels=c(&quot;CBT&quot;, &quot;WL&quot;)) +
  geom_histogram(data = CBTdata.strat[CBTdata.strat$Treatment==&quot;WL&quot;,], aes(y=..density..),   # Histogramm WL
                 alpha=0.5, fill=&quot;#E69F00&quot;) +
  geom_histogram(data = CBTdata.strat[CBTdata.strat$Treatment==&quot;CBT&quot;,], aes(y=-..density..), # Histogramm CBT
                 alpha=0.5, fill=&quot;#56B4E9&quot;) +
  coord_flip() +
  geom_vline(xintercept = aggregate(CBTdata.strat$distance, by=list(CBTdata.strat$subclass), FUN=min)$x[2:5],
             linetype=2) +
  coord_flip()</code></pre>
<p><img src="/post/2022-02-07_Kausaleffekte_2_KliPPS_files/figure-html/unnamed-chunk-18-1.png" width="672" /></p>
<p>Den Treatment-Effekt berechnen wir hier jetzt “per Hand”. Die Funktion <code>tapply</code> wird hierbei benutzt, um die Mittelwerte von Treatment- und Kontrollgruppe in den Strata zu berechnen, diese werden dann als Schätzer für <span class="math inline">\(Y^0\)</span> und <span class="math inline">\(Y^1\)</span> verwendet, aus ihrer Differenz ergibt sich der ATT innerhalb jedes Stratum.
Für jedes Stratum wird anhand des Anteils der Fälle an der Gesamtstichprobe ein Gewichtungsfaktor berechtet. Der ATT ergibt sich dann als gewichtete Summe der Effekte innerhalb der Strata. Wir erhalten hier mit -3.51 einen geringfügig geringeren Effekt als bei anderen Methoden.</p>
<pre class="r"><code>##ATEs in den Strata berechnen und als neuen Datensatz
MWs &lt;- tapply(CBTdata.strat$BDI_post, list(CBTdata.strat$subclass, CBTdata.strat$Treatment), mean)
MWW &lt;- data.frame(Y0 = MWs[, 1], Y1 = MWs[, 2], ATEq = MWs[, 2]-MWs[, 1])
MWW</code></pre>
<pre><code>##         Y0       Y1      ATEq
## 1 16.18681 14.52941 -1.657401
## 2 21.57143 15.61765 -5.953782
## 3 21.46667 18.57576 -2.890909
## 4 23.28571 19.66667 -3.619048
## 5 29.00000 22.54286 -6.457143</code></pre>
<pre class="r"><code>##Gesamt-ATE als gewichtetes Mittel über die Strata berechnen 
MWW$Wq &lt;- tabulate(CBTdata.strat$subclass)/nrow(CBTdata.strat) # Anteil des Stratum an der Stichprobe
# Gesamteffekt als gewichtete Summe:
sum(MWW$Wq*MWW$ATEq)</code></pre>
<pre><code>## [1] -3.51406</code></pre>
</div>
<div id="Gewichtung" class="section level2">
<h2>Gewichtung mit dem Propensity Score</h2>
<p>Gewichte konstruieren wir auf Basis der Propensity Scores <span class="math inline">\(\pi\)</span> und der Treatmentgruppen-Zugehörigkeit <span class="math inline">\(X \in \{0,1\}\)</span> nach der Formel</p>
<p><span class="math display">\[\frac{X_i}{\pi_i}+\frac{1-X_i}{1-\pi_i}\]</span></p>
<pre class="r"><code># mit (CBTdata$Treatment==&quot;CBT&quot;)*1 wird Treatment numerisch mit 1, Kontrollgruppe mit 0 kodiert
CBTdata$ps_w &lt;- (CBTdata$Treatment==&quot;CBT&quot;)*1/CBTdata$PS_P + (1 - (CBTdata$Treatment==&quot;CBT&quot;)*1)/(1 - CBTdata$PS_P)</code></pre>
<p>Diese Gewichte können in der <code>lm</code>-Funktion verwendet werden, um eine Schätzung mittels <em>weighted least squares</em> (WLS) vorzunehmen. Hierbei erhalten wir mit einem geschätzten Treatment-Effekt von -5.08 eine etwas “optimistischere” Schätzung als mit den anderen Methoden.</p>
<pre class="r"><code>BDI.weighted &lt;- lm(BDI_post ~ Treatment, data = CBTdata, weights = ps_w)
summary(BDI.weighted)</code></pre>
<pre><code>## 
## Call:
## lm(formula = BDI_post ~ Treatment, data = CBTdata, weights = ps_w)
## 
## Weighted Residuals:
##     Min      1Q  Median      3Q     Max 
## -24.514  -6.297  -0.823   3.910  54.230 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)   21.7474     0.4601  47.263  &lt; 2e-16 ***
## TreatmentCBT  -5.0833     0.6617  -7.682  2.1e-13 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 8.391 on 308 degrees of freedom
## Multiple R-squared:  0.1608, Adjusted R-squared:  0.1581 
## F-statistic: 59.01 on 1 and 308 DF,  p-value: 2.104e-13</code></pre>
</div>
