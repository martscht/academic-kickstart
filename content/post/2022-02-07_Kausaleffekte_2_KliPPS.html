---
title: "Schätzung von Kausaleffekten 2"
output:
  html_document:
   code_folding: show
  
date: '2023-01-26'
slug: kausal2
categories:
     - MSc5a
    
tags:
- Kausalität
- Propensity Scores
- ANCOVA
- Gewichtung
- Matching

subtitle: 'Propensity Scores'
summary: ''
authors: [hartig]
lastmod: '2022-02-14 17:00:00 CEST'
featured: no
header:
     image: "/header/Kausal2_Head.jpg"
     caption: "[Courtesy of pxhere](https://pxhere.com/de/photo/795494)"
projects: []
---

<script src="/rmarkdown-libs/kePrint/kePrint.js"></script>
<link href="/rmarkdown-libs/lightable/lightable.css" rel="stylesheet" />


<div id="pakete-laden" class="section level4">
<h4>Pakete laden</h4>
<pre class="r"><code># Benötigte Pakete --&gt; Installieren, falls nicht schon vorhanden
library(psych)        # Für logistische Transformationen
library(ggplot2)      # Grafiken
library(gridExtra)
library(MatchIt)      # Für das Propensity Score Matching
library(questionr)    # Für gewichtete Tabellen</code></pre>
</div>
<div id="Einleitung" class="section level2">
<h2>Datenbeispiel</h2>
<p>Wir verwenden wieder unserer fiktives Datenbeispiel, in dem Patient*innen, die an einer Depression oder einer Angststörung leiden, entweder mit einer kognitiven Verhaltenstherapie (CBT) behandelt oder in einer Wartekontrollgruppe belassen wurden. Die Zuordnung konnte nicht randomisiert erfolgen, weshalb der Effekt der Behandlung nicht ohne weiteres berechenbar ist.</p>
<pre class="r"><code>load(url(&quot;https://pandar.netlify.app/post/CBTdata.rda&quot;))
head(CBTdata)</code></pre>
<table>
<thead>
<tr>
<th style="text-align:right;">
Age
</th>
<th style="text-align:left;">
Gender
</th>
<th style="text-align:left;">
Treatment
</th>
<th style="text-align:left;">
Disorder
</th>
<th style="text-align:right;">
BDI_pre
</th>
<th style="text-align:right;">
SWL_pre
</th>
<th style="text-align:right;">
BDI_post
</th>
<th style="text-align:right;">
SWL_post
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right;">
39
</td>
<td style="text-align:left;">
female
</td>
<td style="text-align:left;">
CBT
</td>
<td style="text-align:left;">
ANX
</td>
<td style="text-align:right;">
27
</td>
<td style="text-align:right;">
10
</td>
<td style="text-align:right;">
24
</td>
<td style="text-align:right;">
15
</td>
</tr>
<tr>
<td style="text-align:right;">
36
</td>
<td style="text-align:left;">
female
</td>
<td style="text-align:left;">
CBT
</td>
<td style="text-align:left;">
ANX
</td>
<td style="text-align:right;">
22
</td>
<td style="text-align:right;">
13
</td>
<td style="text-align:right;">
13
</td>
<td style="text-align:right;">
17
</td>
</tr>
<tr>
<td style="text-align:right;">
61
</td>
<td style="text-align:left;">
female
</td>
<td style="text-align:left;">
CBT
</td>
<td style="text-align:left;">
ANX
</td>
<td style="text-align:right;">
24
</td>
<td style="text-align:right;">
11
</td>
<td style="text-align:right;">
17
</td>
<td style="text-align:right;">
14
</td>
</tr>
<tr>
<td style="text-align:right;">
70
</td>
<td style="text-align:left;">
female
</td>
<td style="text-align:left;">
CBT
</td>
<td style="text-align:left;">
ANX
</td>
<td style="text-align:right;">
30
</td>
<td style="text-align:right;">
15
</td>
<td style="text-align:right;">
22
</td>
<td style="text-align:right;">
19
</td>
</tr>
<tr>
<td style="text-align:right;">
64
</td>
<td style="text-align:left;">
female
</td>
<td style="text-align:left;">
CBT
</td>
<td style="text-align:left;">
DEP
</td>
<td style="text-align:right;">
32
</td>
<td style="text-align:right;">
12
</td>
<td style="text-align:right;">
26
</td>
<td style="text-align:right;">
20
</td>
</tr>
<tr>
<td style="text-align:right;">
50
</td>
<td style="text-align:left;">
female
</td>
<td style="text-align:left;">
CBT
</td>
<td style="text-align:left;">
ANX
</td>
<td style="text-align:right;">
24
</td>
<td style="text-align:right;">
15
</td>
<td style="text-align:right;">
23
</td>
<td style="text-align:right;">
22
</td>
</tr>
</tbody>
</table>
<p>Wir wissen auch bereits, dass der Prima-Facie-Effekt (PFE) von 0.39 Punkten nicht signifikant ist. Im Folgenden werden wir auf Basis von Kovariaten einen Propensity Score schätzen und auf verschiedene Weisen verwenden, um eine adjustierte Schätzung des Treatment-Effekts vorzunehmen.</p>
</div>
<div id="Konstruktion" class="section level2">
<h2>Konstruktion des Propensity Scores</h2>
<p>Zur Bildung des Propensity Scores verwenden wir eine logistische Regression mit den Variablen, von denen wir bereits wissen, dass sich die Gruppen darin Unterscheiden: Art der Störung, Prätest im BDI und Prätest im SWL:</p>
<pre class="r"><code># Vorhersage des Treatments durch Kovariaten
mod_ps1 &lt;- glm(Treatment ~ Disorder + BDI_pre + SWL_pre,
              family = &quot;binomial&quot;, data = CBTdata)
summary(mod_ps1)</code></pre>
<pre><code>## 
## Call:
## glm(formula = Treatment ~ Disorder + BDI_pre + SWL_pre, family = &quot;binomial&quot;, 
##     data = CBTdata)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -2.3543  -0.8633   0.4130   0.8568   2.1566  
## 
## Coefficients:
##             Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept) -0.89704    1.12602  -0.797  0.42565    
## DisorderDEP -0.77678    0.27580  -2.816  0.00486 ** 
## BDI_pre      0.16953    0.03750   4.520 6.18e-06 ***
## SWL_pre     -0.13763    0.03443  -3.998 6.39e-05 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 449.86  on 325  degrees of freedom
## Residual deviance: 349.89  on 322  degrees of freedom
## AIC: 357.89
## 
## Number of Fisher Scoring iterations: 4</code></pre>
<p>Wir sehen, dass alle Kovariaten auch bei gemeinsamer Berücksichtigung einen signifikanten Effekt auf die Treatment-Zugehörigkeit haben. Sicherheitshalber untersuchen wir auch die Wechselwirkungen:</p>
<pre class="r"><code># Einschluss von Wechselwirkungen, hierzu zunächst Zentrierung der Prädiktoren
CBTdata$BDI_pre_c &lt;- scale(CBTdata$BDI_pre, scale = F)
CBTdata$SWL_pre_c &lt;- scale(CBTdata$SWL_pre, scale = F)

mod_ps2 &lt;- glm(Treatment ~ Disorder + BDI_pre_c + SWL_pre_c +
                Disorder:BDI_pre_c + Disorder:SWL_pre_c + BDI_pre_c:SWL_pre_c +
                Disorder:BDI_pre_c:SWL_pre_c,
              family = &quot;binomial&quot;, data = CBTdata)
summary(mod_ps2)</code></pre>
<pre><code>## 
## Call:
## glm(formula = Treatment ~ Disorder + BDI_pre_c + SWL_pre_c + 
##     Disorder:BDI_pre_c + Disorder:SWL_pre_c + BDI_pre_c:SWL_pre_c + 
##     Disorder:BDI_pre_c:SWL_pre_c, family = &quot;binomial&quot;, data = CBTdata)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -2.0858  -0.8247   0.5448   0.7892   2.2328  
## 
## Coefficients:
##                                 Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)                      0.69555    0.20390   3.411 0.000647 ***
## DisorderDEP                     -0.82670    0.28607  -2.890 0.003854 ** 
## BDI_pre_c                        0.14802    0.05433   2.724 0.006446 ** 
## SWL_pre_c                       -0.13322    0.05650  -2.358 0.018378 *  
## DisorderDEP:BDI_pre_c            0.05187    0.07791   0.666 0.505586    
## DisorderDEP:SWL_pre_c           -0.03984    0.07692  -0.518 0.604514    
## BDI_pre_c:SWL_pre_c              0.01808    0.01161   1.557 0.119472    
## DisorderDEP:BDI_pre_c:SWL_pre_c -0.02353    0.01893  -1.243 0.213798    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 449.86  on 325  degrees of freedom
## Residual deviance: 345.66  on 318  degrees of freedom
## AIC: 361.66
## 
## Number of Fisher Scoring iterations: 4</code></pre>
<p>Da keiner der Wechselwirkungs-Terme signifikant ist, verwenden wir im nächsten Schritt das einfachere Modell <code>mod_ps1</code>. Mit der <code>predict</code>-Funktion erhalten wir Vorhergesagte Werte in Logit-Einheiten, mit der <code>logistic</code>-Funktion des <code>psych</code>-Paktets können wir diese in Wahrscheinlichkeiten transformieren:</p>
<pre class="r"><code>CBTdata$PS_logit &lt;- predict(mod_ps1)
CBTdata$PS_P &lt;- logistic(CBTdata$PS_logit)
plot(CBTdata$PS_logit, CBTdata$PS_P)</code></pre>
<p><img src="/post/2022-02-07_Kausaleffekte_2_KliPPS_files/figure-html/unnamed-chunk-8-1.png" width="672" /></p>
<div id="prüfung-des-overlap" class="section level3">
<h3>Prüfung des Overlap</h3>
<p>Die Unterschiede im resultierenden Propensity Score in Logit-Einheiten können wir uns durch eine grafische Darstellung der Verteilungen in den Gruppen veranschaulichen. Die Treatment-Wahrscheinlichkeit ist in der Treatment-Gruppe deutlich höher, was z.B. durch eine Selektion nach Dringlichkeit der Fälle zustande gekommen sein kann. Durch ein Abtragen der Treatmentwahrscheinlichkeiten können wir zusätzlich veranschaulichen, wie groß die Überschneidungen der Gruppen (<em>common support</em>) sind. In dieser Grafik sind auch das Minimum der Wahrscheinlichkeit in der Treatment-Gruppe und das Maximum in der Kontrollgruppe eingetragen - diese definieren die Grenzen der Überschneidung zwischen den Gruppen.</p>
<pre class="r fold-hide"><code>## Overlap &amp; Common Support ----
p1 &lt;- ggplot(CBTdata, aes(x=PS_logit, fill = Treatment)) + 
  theme_bw() + theme(legend.position=&quot;top&quot;) +
  scale_fill_manual(values=c(&quot;#E69F00&quot;, &quot;#56B4E9&quot;)) +
  geom_density(alpha=0.5)

p2 &lt;- ggplot(CBTdata, aes(x=PS_P, fill = Treatment)) + 
  theme_bw() +
  labs(x=&quot;P(X=1)&quot;, y=&quot;&quot;) + xlim(c(0,1)) +
  scale_y_continuous(breaks=c(-1.5,1.5),     # &quot;manuelle&quot; Achsenbeschriftungen, um die Gruppen einzutragen
                     labels=c(&quot;CBT&quot;, &quot;WL&quot;)) +
  geom_histogram(data = CBTdata[CBTdata$Treatment==&quot;WL&quot;,], aes(y=..density..),   # Histogramm WL
                 alpha=0.5, fill=&quot;#E69F00&quot;) +
  geom_histogram(data = CBTdata[CBTdata$Treatment==&quot;CBT&quot;,], aes(y=-..density..), # Histogramm CBT
                 alpha=0.5, fill=&quot;#56B4E9&quot;) +
  # Minimum in CBT und maximum in WL einzeichnen
  geom_vline(xintercept = c(min(CBTdata$PS_P[CBTdata$Treatment==&quot;CBT&quot;]),
                            max(CBTdata$PS_P[CBTdata$Treatment==&quot;WL&quot;])),
             linetype=2) +
  coord_flip()
grid.arrange(p1, p2, nrow=1) # Beide Plots nebeneinander</code></pre>
<p><img src="/post/2022-02-07_Kausaleffekte_2_KliPPS_files/figure-html/unnamed-chunk-10-1.png" width="672" /></p>
<p>Für Fälle außerhalb der <em>common support region</em> können keine kausalen Effekte geschätzt werden. Wir schließen daher 16 Fälle aus, die außerhalb des Überschneidungsbereichs liegen:</p>
<pre class="r"><code>### Fälle außerhalb der Überschneidung ausschließen ----
# Fälle der Kontrollgruppe entfernen, deren Wahrscheinlichkeit kleiner ist als
# die kleinste Wahrscheinlichkeit in der Treatment-Gruppe
CBTdata.red &lt;- CBTdata[!(CBTdata$Treatment==&quot;WL&quot; &amp;
                           CBTdata$PS_P &lt; min(subset(CBTdata, Treatment==&quot;CBT&quot;)$PS_P)),]
# Fälle der Treatment-Gruppe entfernen, deren Wahrscheinlichkeit größer ist als
# die größte Wahrscheinlichkeit in der Kontrollgruppe
CBTdata.red &lt;- CBTdata.red[!(CBTdata.red$Treatment==&quot;CBT&quot; &amp;
                               CBTdata.red$PS_P &gt; max(subset(CBTdata, Treatment==&quot;WL&quot;)$PS_P)),]</code></pre>
<p>Nach dieser Korrektur überlappen sich die Propensity Scores beider Gruppen vollständig:</p>
<pre class="r fold-hide"><code>## Overlap &amp; Common Support nach Fallausschluss ----
p1 &lt;- ggplot(CBTdata.red, aes(x=PS_logit, fill = Treatment)) + 
  theme_bw() + theme(legend.position=&quot;top&quot;) +
  scale_fill_manual(values=c(&quot;#E69F00&quot;, &quot;#56B4E9&quot;)) +
  geom_density(alpha=0.5)

p2 &lt;- ggplot(CBTdata.red, aes(x=PS_P, fill = Treatment)) + 
  theme_bw() +
  labs(x=&quot;P(X=1)&quot;, y=&quot;&quot;) + xlim(c(0,1)) +
  scale_y_continuous(breaks=c(-1.5,1.5),     # &quot;manuelle&quot; Achsenbeschriftungen, um die Gruppen einzutragen
                     labels=c(&quot;CBT&quot;, &quot;WL&quot;)) +
  geom_histogram(data = CBTdata.red[CBTdata.red$Treatment==&quot;WL&quot;,], aes(y=..density..),   # Histogramm WL
                 alpha=0.5, fill=&quot;#E69F00&quot;) +
  geom_histogram(data = CBTdata.red[CBTdata.red$Treatment==&quot;CBT&quot;,], aes(y=-..density..), # Histogramm CBT
                 alpha=0.5, fill=&quot;#56B4E9&quot;) +
  coord_flip()
grid.arrange(p1, p2, nrow=1) # Beide Plots nebeneinander</code></pre>
<p><img src="/post/2022-02-07_Kausaleffekte_2_KliPPS_files/figure-html/unnamed-chunk-12-1.png" width="672" /></p>
</div>
</div>
<div id="ANCOVA" class="section level2">
<h2>Verwendung des Propensity Score in der ANCOVA</h2>
<p>Wir können den Treatment-Effekt schätzen, indem wir den Propensity Score anstelle der ursprünglichen Kovariaten als Kontrollvariable verwenden. Wir vergleichen hier die klassische ANCOVA mit allen Kovariaten mit einem Modell, in dem nur der Propensity Score kontrolliert wird (Achtung, aufgrund der Reduktion des Datensatzes entsprechen die Ergebnisse des 1. Modells nicht exakt <a href="https://pandar.netlify.app/post/kausal/#ANCOVA">denen im ersten Teil dieses Blocks</a>! Wir sehen, dass die auf beiden Wegen geschätzen Effekte praktisch identisch sind.</p>
<pre class="r"><code>BDI.adj &lt;- lm(BDI_post ~ Treatment + Disorder + BDI_pre + SWL_pre, data = CBTdata.red)
round(coef(BDI.adj)[2],2)</code></pre>
<pre><code>## TreatmentCBT 
##        -4.08</code></pre>
<pre class="r"><code>BDI.PS &lt;- lm(BDI_post ~ Treatment + PS_logit, data = CBTdata.red)
round(coef(BDI.PS)[2],2)</code></pre>
<pre><code>## TreatmentCBT 
##        -4.15</code></pre>
</div>
<div id="Matching" class="section level2">
<h2>Propensity Score Matching</h2>
<p>Im Folgenden führen wir ein Matching mit der Funktion <code>matchit</code> aus dem Paket <code>MatchIt</code> mit zwei verschiedenen Algorithmen ein Matching durch. <em>Optimal Pair Matching</em> bildet “statistische Zwillinge”, <em>Full Optimal Matching</em> bildet unterschiedlich große Subklassen mit Gewichtung. Mit den Optionen <code>distance = "glm"</code> und <code>link = "logit"</code>wird eingestellt, dass das Matching mit Propensity Scores erfolgt, die durch logistische Regression gebildet werden (das ist auch die Standardeinstellung, könnte man also auch weglassen). Für die Methode, die Zwillingspaare bildet, erhalten wir eine Warnung, da die Stichprobe weniger Kontrollpersonen als Treatmentpersonen enthält und dadurch Personen aus der Treatment-Gruppe ausgeschlossen werden.</p>
<pre class="r"><code># Optimal Pair Matching
m.optimal &lt;- matchit(Treatment ~ Disorder + BDI_pre + SWL_pre, method = &quot;optimal&quot;,
                     data = CBTdata, distance = &quot;glm&quot;, link = &quot;logit&quot;)</code></pre>
<pre><code>## Warning: Fewer control units than treated units; not all treated units will get
## a match.</code></pre>
<pre class="r"><code># Full Optimal Matching
m.full &lt;- matchit(Treatment ~ Disorder + BDI_pre + SWL_pre, method = &quot;full&quot;,
                  data = CBTdata, distance = &quot;glm&quot;, link = &quot;logit&quot;)</code></pre>
<div id="inspektion-der-datensätze" class="section level3">
<h3>Inspektion der Datensätze</h3>
<p>Für beide Methoden wird der durch das Matching gebildete Datensatz mit der Funktion <code>match.data</code> extrahiert.</p>
<pre class="r"><code># Datensätze speichern und nach Subklasse &amp; Treatment sortieren
df.optimal &lt;- match.data(m.optimal) 
df.optimal &lt;- df.optimal[order(df.optimal$subclass, df.optimal$Treatment),]

df.full &lt;- match.data(m.full) 
df.full &lt;- df.full[order(df.full$subclass, df.full$Treatment),] </code></pre>
<p>Das Optimal Pair Matching resultiert in einem Datensatz, in dem Paare (Variable <code>subclass</code>) mit je einer Person aus der Treatment- und eine aus der Kontrollgruppe enthalten sind. Die Gewichtung (Variable <code>weights</code>) ist für alle Personen 1. Wir sehen zudem, dass die von <code>matchit</code> erzeugte Distanz (<code>distance</code>) unserem oben erzeugten Propensity Score entspricht.</p>
<em>Datensatz df.optimal (Auszug)</em>
<table class="table" style="margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:right;">
Age
</th>
<th style="text-align:left;">
Gender
</th>
<th style="text-align:left;">
Treatment
</th>
<th style="text-align:left;">
Disorder
</th>
<th style="text-align:right;">
BDI_pre
</th>
<th style="text-align:right;">
SWL_pre
</th>
<th style="text-align:right;">
BDI_post
</th>
<th style="text-align:right;">
SWL_post
</th>
<th style="text-align:right;">
PS_logit
</th>
<th style="text-align:right;">
PS_P
</th>
<th style="text-align:right;">
distance
</th>
<th style="text-align:right;">
weights
</th>
<th style="text-align:left;">
subclass
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
177
</td>
<td style="text-align:right;">
40
</td>
<td style="text-align:left;">
female
</td>
<td style="text-align:left;">
WL
</td>
<td style="text-align:left;">
DEP
</td>
<td style="text-align:right;">
19
</td>
<td style="text-align:right;">
21
</td>
<td style="text-align:right;">
15
</td>
<td style="text-align:right;">
25
</td>
<td style="text-align:right;">
-1.3430306
</td>
<td style="text-align:right;">
0.2070121
</td>
<td style="text-align:right;">
0.2070121
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:left;">
1
</td>
</tr>
<tr>
<td style="text-align:left;">
28
</td>
<td style="text-align:right;">
20
</td>
<td style="text-align:left;">
male
</td>
<td style="text-align:left;">
CBT
</td>
<td style="text-align:left;">
DEP
</td>
<td style="text-align:right;">
22
</td>
<td style="text-align:right;">
18
</td>
<td style="text-align:right;">
18
</td>
<td style="text-align:right;">
20
</td>
<td style="text-align:right;">
-0.4215617
</td>
<td style="text-align:right;">
0.3961431
</td>
<td style="text-align:right;">
0.3961431
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:left;">
1
</td>
</tr>
<tr>
<td style="text-align:left;">
186
</td>
<td style="text-align:right;">
68
</td>
<td style="text-align:left;">
female
</td>
<td style="text-align:left;">
WL
</td>
<td style="text-align:left;">
ANX
</td>
<td style="text-align:right;">
16
</td>
<td style="text-align:right;">
15
</td>
<td style="text-align:right;">
16
</td>
<td style="text-align:right;">
17
</td>
<td style="text-align:right;">
-0.2490556
</td>
<td style="text-align:right;">
0.4380560
</td>
<td style="text-align:right;">
0.4380560
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:left;">
2
</td>
</tr>
<tr>
<td style="text-align:left;">
18
</td>
<td style="text-align:right;">
38
</td>
<td style="text-align:left;">
female
</td>
<td style="text-align:left;">
CBT
</td>
<td style="text-align:left;">
ANX
</td>
<td style="text-align:right;">
27
</td>
<td style="text-align:right;">
18
</td>
<td style="text-align:right;">
20
</td>
<td style="text-align:right;">
19
</td>
<td style="text-align:right;">
1.2028520
</td>
<td style="text-align:right;">
0.7690317
</td>
<td style="text-align:right;">
0.7690317
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:left;">
2
</td>
</tr>
<tr>
<td style="text-align:left;">
276
</td>
<td style="text-align:right;">
43
</td>
<td style="text-align:left;">
female
</td>
<td style="text-align:left;">
WL
</td>
<td style="text-align:left;">
DEP
</td>
<td style="text-align:right;">
23
</td>
<td style="text-align:right;">
14
</td>
<td style="text-align:right;">
22
</td>
<td style="text-align:right;">
14
</td>
<td style="text-align:right;">
0.2984828
</td>
<td style="text-align:right;">
0.5740716
</td>
<td style="text-align:right;">
0.5740716
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:left;">
3
</td>
</tr>
<tr>
<td style="text-align:left;">
57
</td>
<td style="text-align:right;">
52
</td>
<td style="text-align:left;">
female
</td>
<td style="text-align:left;">
CBT
</td>
<td style="text-align:left;">
ANX
</td>
<td style="text-align:right;">
24
</td>
<td style="text-align:right;">
12
</td>
<td style="text-align:right;">
16
</td>
<td style="text-align:right;">
16
</td>
<td style="text-align:right;">
1.5200477
</td>
<td style="text-align:right;">
0.8205455
</td>
<td style="text-align:right;">
0.8205455
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:left;">
3
</td>
</tr>
</tbody>
</table>
<p>Das Full Optimal Matching (h) resultiert in einem Datensatz, in dem in den Subklassen unterschiedlich viele Fälle enthalten sind. Die Personen der Treatmentgruppe (<code>CBT</code>) erhalten ein Gewicht von 1, die Personen aus der Kontrollgruppe werden so gewichtet, dass die Häufigkeit der Subklassen derjenigen der Treatment-Gruppe entspricht. Im Auszug sind in Subklasse 5 mehr Kontroll- als Treatment-Fälle enthalten, diese werden entsprechend geringer gewichtet. In Subklasse 6 sind mehr Treatment-Fälle, hier erhält der Kontroll-Fall ein höheres Gewicht (in die Gewichte geht zusätzlich noch die Verteilung der Treatment-Fälle auf die Subklassen ein, s. <a href="#Gewichtung">Anhang</a>).</p>
<em>Datensatz df.full (Auszug, Subklassen 5 und 6)</em>
<table class="table" style="margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:right;">
Age
</th>
<th style="text-align:left;">
Gender
</th>
<th style="text-align:left;">
Treatment
</th>
<th style="text-align:left;">
Disorder
</th>
<th style="text-align:right;">
BDI_pre
</th>
<th style="text-align:right;">
SWL_pre
</th>
<th style="text-align:right;">
BDI_post
</th>
<th style="text-align:right;">
SWL_post
</th>
<th style="text-align:right;">
PS_logit
</th>
<th style="text-align:right;">
PS_P
</th>
<th style="text-align:right;">
distance
</th>
<th style="text-align:right;">
weights
</th>
<th style="text-align:left;">
subclass
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
203
</td>
<td style="text-align:right;">
25
</td>
<td style="text-align:left;">
male
</td>
<td style="text-align:left;">
WL
</td>
<td style="text-align:left;">
DEP
</td>
<td style="text-align:right;">
20
</td>
<td style="text-align:right;">
25
</td>
<td style="text-align:right;">
14
</td>
<td style="text-align:right;">
25
</td>
<td style="text-align:right;">
-1.7240213
</td>
<td style="text-align:right;">
0.1513539
</td>
<td style="text-align:right;">
0.1513539
</td>
<td style="text-align:right;">
0.1420455
</td>
<td style="text-align:left;">
5
</td>
</tr>
<tr>
<td style="text-align:left;">
241
</td>
<td style="text-align:right;">
45
</td>
<td style="text-align:left;">
male
</td>
<td style="text-align:left;">
WL
</td>
<td style="text-align:left;">
DEP
</td>
<td style="text-align:right;">
15
</td>
<td style="text-align:right;">
19
</td>
<td style="text-align:right;">
15
</td>
<td style="text-align:right;">
25
</td>
<td style="text-align:right;">
-1.7458793
</td>
<td style="text-align:right;">
0.1485677
</td>
<td style="text-align:right;">
0.1485677
</td>
<td style="text-align:right;">
0.1420455
</td>
<td style="text-align:left;">
5
</td>
</tr>
<tr>
<td style="text-align:left;">
248
</td>
<td style="text-align:right;">
52
</td>
<td style="text-align:left;">
male
</td>
<td style="text-align:left;">
WL
</td>
<td style="text-align:left;">
DEP
</td>
<td style="text-align:right;">
11
</td>
<td style="text-align:right;">
15
</td>
<td style="text-align:right;">
10
</td>
<td style="text-align:right;">
11
</td>
<td style="text-align:right;">
-1.8734693
</td>
<td style="text-align:right;">
0.1331408
</td>
<td style="text-align:right;">
0.1331408
</td>
<td style="text-align:right;">
0.1420455
</td>
<td style="text-align:left;">
5
</td>
</tr>
<tr>
<td style="text-align:left;">
253
</td>
<td style="text-align:right;">
22
</td>
<td style="text-align:left;">
female
</td>
<td style="text-align:left;">
WL
</td>
<td style="text-align:left;">
DEP
</td>
<td style="text-align:right;">
20
</td>
<td style="text-align:right;">
25
</td>
<td style="text-align:right;">
15
</td>
<td style="text-align:right;">
27
</td>
<td style="text-align:right;">
-1.7240213
</td>
<td style="text-align:right;">
0.1513539
</td>
<td style="text-align:right;">
0.1513539
</td>
<td style="text-align:right;">
0.1420455
</td>
<td style="text-align:left;">
5
</td>
</tr>
<tr>
<td style="text-align:left;">
278
</td>
<td style="text-align:right;">
67
</td>
<td style="text-align:left;">
female
</td>
<td style="text-align:left;">
WL
</td>
<td style="text-align:left;">
DEP
</td>
<td style="text-align:right;">
15
</td>
<td style="text-align:right;">
20
</td>
<td style="text-align:right;">
15
</td>
<td style="text-align:right;">
22
</td>
<td style="text-align:right;">
-1.8835087
</td>
<td style="text-align:right;">
0.1319864
</td>
<td style="text-align:right;">
0.1319864
</td>
<td style="text-align:right;">
0.1420455
</td>
<td style="text-align:left;">
5
</td>
</tr>
<tr>
<td style="text-align:left;">
293
</td>
<td style="text-align:right;">
49
</td>
<td style="text-align:left;">
female
</td>
<td style="text-align:left;">
WL
</td>
<td style="text-align:left;">
DEP
</td>
<td style="text-align:right;">
13
</td>
<td style="text-align:right;">
17
</td>
<td style="text-align:right;">
11
</td>
<td style="text-align:right;">
18
</td>
<td style="text-align:right;">
-1.8096743
</td>
<td style="text-align:right;">
0.1406775
</td>
<td style="text-align:right;">
0.1406775
</td>
<td style="text-align:right;">
0.1420455
</td>
<td style="text-align:left;">
5
</td>
</tr>
<tr>
<td style="text-align:left;">
38
</td>
<td style="text-align:right;">
29
</td>
<td style="text-align:left;">
female
</td>
<td style="text-align:left;">
CBT
</td>
<td style="text-align:left;">
DEP
</td>
<td style="text-align:right;">
19
</td>
<td style="text-align:right;">
24
</td>
<td style="text-align:right;">
10
</td>
<td style="text-align:right;">
26
</td>
<td style="text-align:right;">
-1.7559188
</td>
<td style="text-align:right;">
0.1473022
</td>
<td style="text-align:right;">
0.1473022
</td>
<td style="text-align:right;">
1.0000000
</td>
<td style="text-align:left;">
5
</td>
</tr>
<tr>
<td style="text-align:left;">
208
</td>
<td style="text-align:right;">
44
</td>
<td style="text-align:left;">
male
</td>
<td style="text-align:left;">
WL
</td>
<td style="text-align:left;">
ANX
</td>
<td style="text-align:right;">
25
</td>
<td style="text-align:right;">
17
</td>
<td style="text-align:right;">
19
</td>
<td style="text-align:right;">
18
</td>
<td style="text-align:right;">
1.0014276
</td>
<td style="text-align:right;">
0.7313392
</td>
<td style="text-align:right;">
0.7313392
</td>
<td style="text-align:right;">
1.7045455
</td>
<td style="text-align:left;">
6
</td>
</tr>
<tr>
<td style="text-align:left;">
108
</td>
<td style="text-align:right;">
67
</td>
<td style="text-align:left;">
male
</td>
<td style="text-align:left;">
CBT
</td>
<td style="text-align:left;">
DEP
</td>
<td style="text-align:right;">
28
</td>
<td style="text-align:right;">
15
</td>
<td style="text-align:right;">
21
</td>
<td style="text-align:right;">
17
</td>
<td style="text-align:right;">
1.0084878
</td>
<td style="text-align:right;">
0.7327241
</td>
<td style="text-align:right;">
0.7327241
</td>
<td style="text-align:right;">
1.0000000
</td>
<td style="text-align:left;">
6
</td>
</tr>
<tr>
<td style="text-align:left;">
152
</td>
<td style="text-align:right;">
20
</td>
<td style="text-align:left;">
male
</td>
<td style="text-align:left;">
CBT
</td>
<td style="text-align:left;">
ANX
</td>
<td style="text-align:right;">
29
</td>
<td style="text-align:right;">
22
</td>
<td style="text-align:right;">
18
</td>
<td style="text-align:right;">
27
</td>
<td style="text-align:right;">
0.9913882
</td>
<td style="text-align:right;">
0.7293620
</td>
<td style="text-align:right;">
0.7293620
</td>
<td style="text-align:right;">
1.0000000
</td>
<td style="text-align:left;">
6
</td>
</tr>
</tbody>
</table>
<div id="demonstration-der-gewichtung" class="section level4">
<h4>Demonstration der Gewichtung</h4>
<p>Der Vergleich der Häufigkeiten der Subklassen in den Gruppen mit gewichteten Häufigkeiten zeigt den Effekt der Gewichtung. Die gewichteten relativen Häufigkeiten der Subklassen in der Kontrollgruppe entsprechen denjenigen der Treatment-Gruppe (die absoluten Werte sind etwas niedriger, da in der Kontrollgruppe weniger Fälle sind als in der Kontrollgruppe).</p>
<pre class="r"><code># Auszug as dem Datensatz
demo.df &lt;- subset(df.full, as.numeric(subclass) &lt; 10)
demo.df$subclass &lt;- droplevels(demo.df$subclass)
# Ungewichtete Häufigkeiten
table(demo.df$Treatment, demo.df$subclass)</code></pre>
<pre><code>##      
##       1 2 3 4 5 6 7 8 9
##   WL  1 1 1 1 6 1 1 1 1
##   CBT 7 9 6 4 1 2 1 6 1</code></pre>
<pre class="r"><code># Gewichtete Häufigkeiten
round(wtd.table(y = demo.df$subclass, x = demo.df$Treatment, weights = demo.df$weights), 3)</code></pre>
<pre><code>##         1     2     3     4     5     6     7     8     9
## WL  5.966 7.670 5.114 3.409 0.852 1.705 0.852 5.114 0.852
## CBT 7.000 9.000 6.000 4.000 1.000 2.000 1.000 6.000 1.000</code></pre>
</div>
</div>
<div id="kontrolle-der-balance" class="section level3">
<h3>Kontrolle der Balance</h3>
<p>Die mit beiden Methoden erzielte Balance der Kovariaten lassen wir uns mit <code>plot(summary())</code> anzeigen. Wir sehen, dass die bestehenden Unterschiede durch das Optimal Pair Matching nur geringfügig reduziert werden. Durch das ungünstige Verhältnis von Treatment- zu Kontrollfällen sind die Möglichkeiten der Zwillingsbildung für den Datensatz sehr begrenzt. Die Reduktion der Unterschiede kommt nur durch den Ausschluss der “unpassendsten” Treatment-Fälle (!) zustande. Im Unterschied hierzu erreicht das Full Optimal Matching eine sehr gute Balance.</p>
<p><img src="/post/2022-02-07_Kausaleffekte_2_KliPPS_files/figure-html/unnamed-chunk-19-1.png" width="50%" /><img src="/post/2022-02-07_Kausaleffekte_2_KliPPS_files/figure-html/unnamed-chunk-19-2.png" width="50%" /></p>
</div>
<div id="effektschätzung" class="section level3">
<h3>Effektschätzung</h3>
<p>Für das Optimal Pair Matching kann eine Effektschätzung einfach unter Verwendung des gematchten Datensatzes erfolgen. Wir sehen, dass sich der Effekt von <span class="math inline">\(\beta = -0.54\)</span> gegenüber der Analyse mit dem Gesamtdatensatz (<span class="math inline">\(\beta = 0.39\)</span>) nur geringfügig verändert und weiterhin nicht signifikant ist.</p>
<pre class="r"><code>lm.PFE &lt;- lm(BDI_post ~ Treatment, data = CBTdata)
summary(lm.PFE)</code></pre>
<pre><code>## 
## Call:
## lm(formula = BDI_post ~ Treatment, data = CBTdata)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -12.4943  -3.4943  -0.1067   3.5057  17.8933 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)   18.1067     0.4235  42.750   &lt;2e-16 ***
## TreatmentCBT   0.3877     0.5764   0.672    0.502    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 5.187 on 324 degrees of freedom
## Multiple R-squared:  0.001394,   Adjusted R-squared:  -0.001688 
## F-statistic: 0.4523 on 1 and 324 DF,  p-value: 0.5017</code></pre>
<pre class="r"><code>lm.optimal &lt;- lm(BDI_post ~ Treatment, data = df.optimal)
summary(lm.optimal)</code></pre>
<pre><code>## 
## Call:
## lm(formula = BDI_post ~ Treatment, data = df.optimal)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -11.5667  -3.2217  -0.1067   3.4333  17.8933 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)    18.107      0.408  44.379   &lt;2e-16 ***
## TreatmentCBT   -0.540      0.577  -0.936     0.35    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 4.997 on 298 degrees of freedom
## Multiple R-squared:  0.00293,    Adjusted R-squared:  -0.0004154 
## F-statistic: 0.8758 on 1 and 298 DF,  p-value: 0.3501</code></pre>
<p>Bei der Analyse der mit Full Optimal Matching gebildeten Daten muss die Gewichtung verwendet werden. Hier finden wir einen starken signifikanten Effekt des Treatments (<span class="math inline">\(\beta = -4.34\)</span>), der ähnlich ausfällt wie der im ersten Teil dieses Themenblocks mit Kontrolle der Kovariaten geschätzten Effekt (dieser betrug <span class="math inline">\(\beta = -4.06\)</span>).</p>
<pre class="r"><code>lm.full &lt;- lm(BDI_post ~ Treatment, data = df.full, weights = weights)
summary(lm.full)</code></pre>
<pre><code>## 
## Call:
## lm(formula = BDI_post ~ Treatment, data = df.full, weights = weights)
## 
## Weighted Residuals:
##     Min      1Q  Median      3Q     Max 
## -13.385  -3.538  -1.494   1.506  29.775 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)   22.8329     0.4315  52.918  &lt; 2e-16 ***
## TreatmentCBT  -4.3386     0.5872  -7.388 1.27e-12 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 5.284 on 324 degrees of freedom
## Multiple R-squared:  0.1442, Adjusted R-squared:  0.1415 
## F-statistic: 54.59 on 1 and 324 DF,  p-value: 1.273e-12</code></pre>
</div>
</div>
<div id="stratifizierung" class="section level2">
<h2>Stratifizierung</h2>
<p>Stratifizierung ist als Methode <code>subclass</code> in der <code>matchit</code>-Funktion enthalten. Wir bilden fünf Strata und extrahieren den Datensatz, der die Zugehörigkeit zu den Strata enthält (Variable <code>subclass</code>). Die Kreuztabelle zeigt, dass die Strata so gebildet wurden, dass die Treatment-Gruppe gleichmäßig aufgeteilt wurde. Die Anzahl der jeweils “passenden” Kontrollgruppen-Fälle in den Strata unterscheidet sich stark.</p>
<pre class="r"><code>m.strat &lt;- matchit(Treatment ~ Disorder + BDI_pre + SWL_pre, data = CBTdata,
                 distance = &#39;logit&#39;, method = &#39;subclass&#39;, subclass = 5)
df.strat &lt;- match.data(m.strat)
# Zugehörigkeit der Fälle zu Treatment und Stratum
table(df.strat$Treatment, df.strat$subclass)</code></pre>
<pre><code>##      
##         1   2   3   4   5
##   WL  101  23  12   8   6
##   CBT  35  34  36  35  36</code></pre>
<p>Die folgende Grafik veranschaulicht die gebildeten Strata, als Grenzen sind jeweils die Untergrenzen (Minima in den Gruppen) eingezeichnet:</p>
<pre class="r fold-hide"><code>ggplot(df.strat, aes(x=distance, fill = Treatment)) + 
  theme_bw() + theme(text = element_text(size = 20)) +
  labs(x=&quot;P(X=1)&quot;, y=&quot;&quot;) +
  scale_y_continuous(breaks=c(-1.5,1.5),     # &quot;manuelle&quot; Achsenbeschriftungen, um die Gruppen einzutragen
                     labels=c(&quot;CBT&quot;, &quot;WL&quot;)) +
  geom_histogram(data = df.strat[df.strat$Treatment==&quot;WL&quot;,], aes(y=..density..),   # Histogramm WL
                 alpha=0.5, fill=&quot;#E69F00&quot;) +
  geom_histogram(data = df.strat[df.strat$Treatment==&quot;CBT&quot;,], aes(y=-..density..), # Histogramm CBT
                 alpha=0.5, fill=&quot;#56B4E9&quot;) +
  coord_flip() +
  geom_vline(xintercept = aggregate(df.strat$distance, by=list(df.strat$subclass), FUN=min)$x[2:5],
             linetype=2) +
  coord_flip()</code></pre>
<p><img src="/post/2022-02-07_Kausaleffekte_2_KliPPS_files/figure-html/unnamed-chunk-24-1.png" width="672" /></p>
<p>Der Effekt der bei der Stratifizierung gebildeten Gewichte lässt sich veranschaulichen, indem dieselbe Grafik mit gewichteten Häufigkeiten erzeugt wird. Die Häufigkeiten in der Treatment-Gruppe bleiben unverändert, die in der Kontrollgruppe werden der Treatmentgruppe angeglichen:</p>
<pre class="r fold-hide"><code>ggplot(df.strat, aes(x=distance, fill = Treatment, weights=weights)) + 
         theme_bw() + theme(text = element_text(size = 20)) +
         labs(x=&quot;P(X=1)&quot;, y=&quot;&quot;) +
         scale_y_continuous(breaks=c(-1.5,1.5),     # &quot;manuelle&quot; Achsenbeschriftungen, um die Gruppen einzutragen
                            labels=c(&quot;CBT&quot;, &quot;WL&quot;)) +
         geom_histogram(data = df.strat[df.strat$Treatment==&quot;WL&quot;,], aes(y=..density..),   # Histogramm WL
                        alpha=0.5, fill=&quot;#E69F00&quot;) +
         geom_histogram(data = df.strat[df.strat$Treatment==&quot;CBT&quot;,], aes(y=-..density..), # Histogramm CBT
                        alpha=0.5, fill=&quot;#56B4E9&quot;) +
         coord_flip() +
         geom_vline(xintercept = aggregate(df.strat$distance, by=list(df.strat$subclass), FUN=min)$x[2:5],
                    linetype=2) +
         coord_flip()</code></pre>
<p><img src="/post/2022-02-07_Kausaleffekte_2_KliPPS_files/figure-html/unnamed-chunk-25-1.png" width="672" /></p>
<div id="effektschätzung-1" class="section level3">
<h3>Effektschätzung</h3>
<p>Den Treatment-Effekt können wir “per Hand” berechnen. Die Funktion <code>tapply</code> wird hierbei benutzt, um die Mittelwerte von Treatment- und Kontrollgruppe in den Strata zu berechnen, diese werden dann als Schätzer für <span class="math inline">\(Y^0\)</span> und <span class="math inline">\(Y^1\)</span> verwendet, aus ihrer Differenz ergibt sich der ATT innerhalb jedes Stratum.
Für jedes Stratum wird anhand des Anteils der Fälle an der Gesamtstichprobe ein Gewichtungsfaktor berechtet. Der ATT ergibt sich dann als gewichtete Summe der Effekte innerhalb der Strata. Wir erhalten hier mit -3.18 einen geringfügig geringeren Effekt als bei anderen Methoden.</p>
<pre class="r"><code>##ATEs in den Strata berechnen und als neuen Datensatz
MWs &lt;- tapply(df.strat$BDI_post, list(df.strat$subclass, df.strat$Treatment), mean)
MWW &lt;- data.frame(Y0 = MWs[, 1], Y1 = MWs[, 2], ATEq = MWs[, 2]-MWs[, 1])
MWW</code></pre>
<pre><code>##         Y0       Y1      ATEq
## 1 15.78218 14.71429 -1.067893
## 2 22.08696 15.47059 -6.616368
## 3 20.66667 18.52778 -2.138889
## 4 23.37500 19.80000 -3.575000
## 5 29.83333 23.72222 -6.111111</code></pre>
<pre class="r"><code>##Gesamt-ATE als gewichtetes Mittel über die Strata berechnen 
MWW$Wq &lt;- tabulate(df.strat$subclass)/nrow(df.strat) # Anteil des Stratum an der Stichprobe
# Gesamteffekt als gewichtete Summe:
sum(MWW$Wq*MWW$ATEq)</code></pre>
<pre><code>## [1] -3.176149</code></pre>
<p>Eine weitere Möglichkeit ist, wie für das Full Optimal Matching, eine Schätzung mit dem linearen Modell unter Verwendung der Gewichte. Der hier resultierende Effekt von <span class="math inline">\(\beta = -3.89\)</span> ist ähnlich dem beim Full Optimal Matching. Beide Methoden sind sich konzeptuell ähnlich, bei der Stratifizierung werden mit einer einfacheren Methode weniger Subklassen gebildet.</p>
<pre class="r"><code>lm.strat &lt;- lm(BDI_post ~ Treatment, data = df.strat, weights = weights)
summary(lm.strat)</code></pre>
<pre><code>## 
## Call:
## lm(formula = BDI_post ~ Treatment, data = df.strat, weights = weights)
## 
## Weighted Residuals:
##     Min      1Q  Median      3Q     Max 
## -15.004  -4.494  -1.494   1.506  30.792 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)   22.3833     0.4458  50.206  &lt; 2e-16 ***
## TreatmentCBT  -3.8890     0.6068  -6.409 5.16e-10 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 5.46 on 324 degrees of freedom
## Multiple R-squared:  0.1125, Adjusted R-squared:  0.1098 
## F-statistic: 41.08 on 1 and 324 DF,  p-value: 5.156e-10</code></pre>
</div>
</div>
<div id="gewichtung-mit-dem-propensity-score" class="section level2">
<h2>Gewichtung mit dem Propensity Score</h2>
<p>Alternativ zur Bildung von Gewichten durch Matching können wir die Gewichte direkt auf Basis des Propensity Scores <span class="math inline">\(\pi\)</span> und der Treatmentgruppen-Zugehörigkeit <span class="math inline">\(X \in \{0,1\}\)</span> konstruieren. Die Formel hierfür ist</p>
<p><span class="math display">\[\frac{X_i}{\pi_i}+\frac{1-X_i}{1-\pi_i}\]</span></p>
<pre class="r"><code># mit (CBTdata$Treatment==&quot;CBT&quot;)*1 wird Treatment numerisch mit 1, Kontrollgruppe mit 0 kodiert
CBTdata$ps_w &lt;- (CBTdata$Treatment==&quot;CBT&quot;)*1/CBTdata$PS_P + (1 - (CBTdata$Treatment==&quot;CBT&quot;)*1)/(1 - CBTdata$PS_P)</code></pre>
<p>Diese Gewichte können in der <code>lm</code>-Funktion verwendet werden, um eine Schätzung mittels <em>weighted least squares</em> (WLS) vorzunehmen. Hierbei erhalten wir mit einem geschätzten Treatment-Effekt von -4.59 eine ähnliche Schätzung wie mit den anderen Methoden.</p>
<pre class="r"><code>BDI.weighted &lt;- lm(BDI_post ~ Treatment, data = CBTdata, weights = ps_w)
summary(BDI.weighted)</code></pre>
<pre><code>## 
## Call:
## lm(formula = BDI_post ~ Treatment, data = CBTdata, weights = ps_w)
## 
## Weighted Residuals:
##     Min      1Q  Median      3Q     Max 
## -25.164  -6.222  -0.731   3.931  55.347 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)   21.4538     0.4603  46.611  &lt; 2e-16 ***
## TreatmentCBT  -4.5866     0.6629  -6.919 2.43e-11 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 8.515 on 324 degrees of freedom
## Multiple R-squared:  0.1287, Adjusted R-squared:  0.1261 
## F-statistic: 47.88 on 1 and 324 DF,  p-value: 2.435e-11</code></pre>
<hr />
</div>
<div id="r-skript" class="section level2">
<h2>R-Skript</h2>
<p>Den gesamten <code>R</code>-Code, der in dieser Sitzung genutzt wird, können Sie <a href="/post/KliPPs_MSc5a_R_Files/10_Kausalschätzer_2_RCode.R"><svg aria-hidden="true" role="img" viewBox="0 0 512 512" style="height:1em;width:1em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:currentColor;overflow:visible;position:relative;"><path d="M216 0h80c13.3 0 24 10.7 24 24v168h87.7c17.8 0 26.7 21.5 14.1 34.1L269.7 378.3c-7.5 7.5-19.8 7.5-27.3 0L90.1 226.1c-12.6-12.6-3.7-34.1 14.1-34.1H192V24c0-13.3 10.7-24 24-24zm296 376v112c0 13.3-10.7 24-24 24H24c-13.3 0-24-10.7-24-24V376c0-13.3 10.7-24 24-24h146.7l49 49c20.1 20.1 52.5 20.1 72.6 0l49-49H488c13.3 0 24 10.7 24 24zm-124 88c0-11-9-20-20-20s-20 9-20 20 9 20 20 20 20-9 20-20zm64 0c0-11-9-20-20-20s-20 9-20 20 9 20 20 20 20-9 20-20z"/></svg> hier herunterladen</a>.</p>
<hr />
</div>
<div id="Gewichtung" class="section level2">
<h2>Anhang: Bildung der Gewichte</h2>
<p>Die Gewichte zur Schätzung des ATT, mit denen die relativen Häufigkeiten der Kovariaten-Subklassen der Treatment-Gruppe, an die Kontrollgruppe angeglichen werden, werden wie folgt gebildet:</p>
<p><span class="math display">\[w_{Cs}=\frac{N_C}{n_{Cs}}*\frac{n_{Ts}}{N_T}\]</span>
Hierbei sind</p>
<ul>
<li><span class="math inline">\(w_{Cs}\)</span> das Gewicht für Kontrollpersonen in Subklasse <span class="math inline">\(s\)</span></li>
<li><span class="math inline">\(N_C\)</span> die Größe der Kontrollgruppe</li>
<li><span class="math inline">\(N_T\)</span> die Größe der Treatment-Gruppe</li>
<li><span class="math inline">\(n_{Cs}\)</span> die Anzahl von Kontrollpersonen in Subklasse <span class="math inline">\(s\)</span></li>
<li><span class="math inline">\(n_{Ts}\)</span> die Anzahl von Treatment-Personen in Subklasse <span class="math inline">\(s\)</span></li>
</ul>
<p>Die Gewichte werden also umso größer, je mehr Treatment-Personen in einer Subklasse <span class="math inline">\(s\)</span> sind, und um so kleiner, je mehr Kontrollpersonen der Subklasse sind. Die Summe der Gewichte über alle Subklassen <span class="math inline">\(S\)</span> entspricht der urprünglichen Fallzahl:</p>
<p><span class="math display">\[\sum^S_{s=1}{w_{Cs}}=N_C\]</span></p>
</div>
