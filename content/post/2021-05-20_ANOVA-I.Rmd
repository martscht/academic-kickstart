---
title: "ANOVA I: einfaktorielle ANOVA"
date: '2021-05-20'
slug: einfaktorielle-ANOVA
categories:
  - BSc7
tags:
  - ANOVA
  - einfaktoriell
  - ezANOVA
  - Mittelwertsvergleiche
  - Normalverteilung
  - Homoskedastizität
  - Post-Hoc
  - Tukey
subtitle: '1-fakt. ANOVA'
summary: ''
authors: [scheppa-lahyani,irmer,wallot]
lastmod: '2021-05-20T08:32:21+02:00'
featured: no
header:
  image: "/header/ANOVA1headphoto.jpg"
  caption: "[Courtesy of pxhere](https://pxhere.com/de/photo/804791)"
projects: []
---


```{r setup, include=FALSE}
# Vorbereitungen
knitr::opts_chunk$set(echo = TRUE, fig.align = "center")
```


In den letzten Sitzungen haben wir uns ausführlicher mit dem Zusammenhang zwischen Variablen in Form von Korrelation und Regression beschäftigt. Nun möchten wir untersuchen, ob es einen Unterschied zwischen mehreren Gruppen hinsichtlich der Mittelwerte in einer Variablen gibt. Im letzten Semester haben Sie schon den **t-Test** kennen gelernt, mit dem Mittelwertsunterschiede zwischen zwei Gruppen untersucht werden können. Wenn wir nun mehr als zwei Gruppen miteinander vergleichen möchten, müssten wir mehrere *t-Tests* mit allen Kombinationen durchführen. Bei z. B. 3 Gruppen müssten wir $\binom{3}{2}$ *t-Tests* durchführen. Wie Sie sicherlich noch wissen, führt dies aber zu einer **$\alpha$-Fehler Inflation oder Kumulierung**. In diesem Fall muss demnach eine **ANOVA** genutzt werden. Da wir den Unterschied *einer Gruppenvariable* wissen wollen, nutzen wir die *einfaktorielle ANOVA*. Wie das Verfahren für mehrere Gruppenvariablen ist, wird in der nächsten Sitzung besprochen. Mehr zur *einfaktoriellen ANOVA* finden Sie in [`Eid, Gollwitzer und Schmitt (2017, Kapitel 13 und insb. 13.1 und folgend)`](https://hds.hebis.de/ubffm/Record/HEB366849158). 

Wir arbeiten mit dem Datensatz "**conspiracy**".

### Daten laden
Wir laden zunächst die Daten: entweder lokal von Ihrem Rechner:

```{r, eval = F}
load("C:/Users/Musterfrau/Desktop/conspiracy.rda")
```

oder wir laden sie direkt über die Website:

```{r, eval = T}
load(url("https://pandar.netlify.app/post/conspiracy.rda"))
```

Der Datensatz enthält die Werte von 2451 Personen auf 9 Variablen und stammt aus einer Untersuchung zum Thema *verschwörungstheoretische Überzegungen*. 

```{r}
head(conspiracy)
```

Die **ersten vier Variablen** enthalten Informationen über den demographischen Hintergrund der Personen: höchster Bildungsabschluss (`edu`), Typ des Wohnortes (`urban`), Geschlecht (`gender`) und Alter (`age`). Die **fünf restlichen Variablen** sind Skalenwerte bezüglich verschiedener subdimensionen verschwörungstheoretischer Überzeugungen: `GM` (goverment malfeasance), `MG` (malevolent global conspiracies), `ET` (extraterrestrial cover-up), `PW` (personal well-being) und `CI` (control of information).

### Aufgestellte Hypothesen

Es soll untersucht werden, ob sich Personen je nach Ländlichkeit ihres Wohnortes (*rural*, *suburban*, *urban*) in der Überzeugung unterscheiden, inwiefern die Existenz von Außerirdischen geheimgehalten wird (Beispielitem: Evidence of alien contact is being concealed from the public).

In der *einfaktoriellen ANOVA* wird die **Gleichheit aller Gruppenmittelwerte als Nullhypothese** posutliert - also das sich Bewohner des ländlichen Raums (rural), des vorstädtischen Raums (suburban) und der Stadt (urban) nicht hinsichtlicher ihrer Zustimmung zur Verschwörungstheorie *Extraterrestrial Cover-Up* unterscheiden:

$H_0: \mu_{\text{rural}} = \mu_{\text{suburban}} = \mu_{\text{urban}}$

Bei der Alternativhypothese wird angenommen, dass sich **mindestens zwei dieser Subgruppen** im Mittel voneinander unterscheiden:

$H_1: \mu_j \neq \mu_k$ für mindestens ein Paar $(j, k)$ mit $j \neq k$

Wir benutzen hier die Indizes $j$ und $k$, um den Vergleich der Mittelwerte von zwei unterschiedlichen Subgruppen darzustellen. Für $j = 1$ und $k = 2$ könnte dies z. B. den Vergleich der Subgruppen "rural" und "suborban" anzeigen. Die Ungleichung $j \neq k$ bedeutet in diesem Zusammenhang, dass wir in der Formulierung der Alternativhypothese immer nur unterschiedliche Gruppen miteinander vergleichen, nie aber eine Subgruppe mit sich selbst, was im Übrigen auch ein aussageloser Vergleich wäre, da wir --- dies wäre nur sinnvoll, wenn wir die gleiche Stichprobe mehrfach gemessen hätten. Wie dies dann mitmodelliert wird, erfahren wir im Rahmen der ANOVA mit Messwiederholung.

## Voraussetzungsprüfung

Es werden drei Voraussetzungen für die Anwendung einer ANOVA vorgegeben:

1) Unabhängigkeit der Residuen
2) Homoskedastizität
3) Normalverteilung

### 1) Unabhängigkeit der Residuen

Die Unabhängigkeit der Residuen wäre dann verletzt, wenn abhängige Stichproben vorliegen oder die Stichproben in den Gruppen nicht zufällig zustande gekommen sind (keine Randomisierung). Dies muss also beachtet werden. In unserem Beispiel sind die Stichproben über die Wohnorte hinweg wahrscheinlich nicht abhängig voneinander. Es kann zwar familiäre Bezüge geben, jedoch sollten deren Effekte eher gering ausfallen. Auch die Residuen innerhalb der Gruppen sollten unabhängig sein, da die Personen nicht bewusst einem bestimmten Wohnort zugeordnet wurden, sondern sich dies durch viele Faktoren ergibt. Daher sollte in unserem Beispiel die Unabhängigkeit der Residuen gegeben sein. Wie Sie merken ist die Unabhängigkeitsannahme schwer zu prüfen und wird daher so gut wie immer durch das Design der Studie "gewährleistet" --- bspw. durch Randomisierung. 

### 2) Homoskedastizität

Die Homoskedastizitätsannahme besagt, dass die Varianzen jeder Gruppe über die Gruppen hinweg gleich sind. Deshalb wird diese Annahme auch häufig Varianzhomogenitätsannahme genannt. Zur Überprüfung der Homoskedatizität kann der **Levene Test** herangezogen werden. Dieser kann mithilfe des `car` Pakets angefordert werden. Dazu laden wir zunächst das Paket und führen anschließend die Funnktion `leveneTest` aus:

```{r ANOVA_II, exercise=TRUE, exercise.lines = 2}
library(car)
leveneTest(conspiracy$ET ~ conspiracy$urban)
```

Die Funktion nimmt die Variable selbst entgegen sowie die Gruppierungsvariable. `ET` aus dem `conspiracy`-Datensatz stellt hierbei die AV dar, die Gruppierungsvariable `urban` ist die UV. Wir erkennen im Output, was genau der Levene-Test eigentlich macht: `Levene's Test for Homogeneity of Variance`, nämlich die Varianzen auf Homogenität prüfen.  Das Ergebnis ist nicht signifikant. In diesem Fall muss die Annahme der Varianzhomogenität über die drei Gruppen hinweg also *nicht verworfen* werden. 

### 3) Normalverteilung

Innerhalb jeder Gruppe sollte eine Normalverteilung vorliegen. Diese Annahme bezieht sich, entgegen häufiger Vermutung, auf die Residuen der ANOVA. Wir erkennen diese Annahme aus der Regressionsanalyse wieder, wo wir ebenfalls die [Normalverteilung der Residuen, behandelt in Regression III,](/post/reg3) annahmen, um Inferenzstatistik zu betreiben. Um auf die Residuen einer ANOVA zuzugreifen, kann der Befehl `residuals` oder `resid` auf ein `aov` Objekt angewendet werden. Mehr zum `aov`-Befehl folgt beim Tukey Test.

## Einfaktorielle ANOVA per Hand

Die *einfaktorielle ANOVA* arbeitet mit einer Quadratsummenzerlegung. Hierbei werden Unterschiede/Variationen zwischen den Gruppen ($QS_{zw}$) und Unterschiede/Variationen innerhalb der Gruppen ($QS_{inn}$) getrennt betrachtet und bestimmt. Die Variation zwischen den Gruppen kann als bedingt durch die unterschiedliche Gruppenzugehörigkeit interpretiert werden, wobei die Variation innerhalb einer Gruppe von den Individuen, die der Gruppe zugehörig sind, bedingt wird. Die Gesamtvariation wird als **totale Quadratsumme** ($QS_{tot}$) bezeichnet und ergibt sich wie folgt:

$$QS_{tot} = QS_{zw} + QS_{inn}$$

wobei

$$QS_{tot} = \sum_{k = 1}^{K} \sum_{i = 1}^{n_k} (y_{ik}-\overline{y})^2$$

$$QS_{zw} = \sum_{k = 1}^{K} n_k* (\overline{y_k}-\overline{y})^2$$

$$QS_{inn} = \sum_{k = 1}^{K} \sum_{i = 1}^{n_k} (y_{ik}-\overline{y_k})^2$$

mit $i$ = Index der Personen, $k$ = Index der Gruppe, $K$ = Anzahl der Gruppen, $n_k$ ist die Gruppengröße der k-ten Gruppen.

Die Quadratsummen der ANOVA können per Hand bestimmt werden. Hierzu nutzen wir den `aggregate()`-Befehl, der es erlaubt, eine zusammenfassende Statistik (wie Mittelwert oder Standardabweichung) für eine Variable getrennt nach verschiedenen Subgruppen zu berechnen. Dabei übergeben wir `aggregate` die Variable selbst sowie die Gruppierungsvariable als Liste (deshalb steht im Befehl auch `list(conspiracy$urban)`), als drittes Argument wird die Funktion übergeben, die durchgeführt werden soll:

```{r calc_qs_I, exercise=TRUE, exercise.lines = 11}
# Gruppenmittelwerte ermitteln
mu_k <- aggregate(conspiracy$ET, list(conspiracy$urban), mean)
names(mu_k) <- c('urban', 'ET_mu_k')
temp <- merge(conspiracy, mu_k, by = 'urban')

# Gesamtmittelwert ermitteln
mu <- mean(conspiracy$ET)

# Gruppengrößen ermitteln
n_k <- table(conspiracy$urban)
```

`temp <- merge(conspiracy, mu_k, by = 'urban')` erzeugt einen neuen Datensatz `temp`, der zusätzlich zu `conspiracy` auch noch die Mittelwerte pro Gruppe enthält. Das brauchen wir für später!

Somit können wir die Quadratsummen $QS_{inn}$ und $QS_{zw}$ berechnen (vgl. Gleichungen von oben)

```{r calc_qs_II, exercise=TRUE, exercise.lines = 3}
QS_inn <- sum((temp$ET - temp$ET_mu_k)^2)
QS_zw <- sum(n_k * (mu_k[, 2] - mu)^2)
```

`mu_k[, 2]` wird hier so verwendet, da in `mu_k` in der ersten Spalte die Gruppenzugehörigkeiten stehen und in der 2. Spalte die Mittelwerte selbst.

Zur inferenzstatistischen Prüfung wird der $F$-Test herangezogen. Um diesen verwenden zu können, brauchen wir die mittleren Quadratsummen $MQS_{zw} = \frac{QS_{zw}}{K-1}$ und $MQS_{inn} = \frac{QS_{inn}}{N-K}$. Diese können wir auch per Hand bestimmen:

```{r calc_qs_III, exercise=TRUE, exercise.lines = 3}
MQS_inn <- QS_inn / (nrow(conspiracy) - nlevels(conspiracy$urban))
MQS_zw <- QS_zw / (nlevels(conspiracy$urban)-1)
```

Nun können wir den $F$-Wert bestimmen. Dieser ergibt sich als

$$F_{emp} = \frac{MQS{zw}}{MQS{inn}}$$
Wir erkennen, dass hier einfach die Variation zwischen den Gruppen (Variation der Mittelwerte) relativ zur (zufälligen) Variation innerhalb der Gruppen betrachtet wird. Ist die Variation zwischen den Gruppen relativ zur zufälligen Variation groß, so kann dies nicht durch Zufall passiert sein: die Mittelwerte müssen sich also bei einem großen $F$-Wert unterscheiden. 

Das Verhältnis der Quadratsummen ist mit $df_1 = K - 1$ und $df_2 = N - K$ $F$-verteilt. Daher wird der $F_{emp}$ mit dem $F_{krit}$ mit $df_1 = K - 1$ (Zählerfreiheitsgraden) und $df_2 = N - K$ (Nennerfreiheitsgraden) verglichen. In `R` geht das automatisch mit `pf` (die Verteilungsfunktion/ kommulative Dichtefunktion der $F$-Verteilung) --- sie gibt uns den $p$-Wert wieder. Hierbei muss zunächst der $F_{emp}$ angegeben werden, danach $df_1$ und als letztes $df_2$.

```{r calc_qs_IV, exercise=TRUE, exercise.lines = 4}
F_wert <- MQS_zw/MQS_inn
pf(F_wert, nlevels(conspiracy$urban)-1, nrow(conspiracy) - nlevels(conspiracy$urban), lower.tail = FALSE)
```

`lower.tail = FALSE` zeigt uns, dass wir gerne die Wahrscheinlichkeit (Fläche unter der Kurve) für extremere Werte als unseren beobachtenen $F_{emp}$ angezeigt bekommen:

```{r, echo = FALSE}
library(ggplot2)
Fs <- data.frame(x = seq(0, 7, .1))
Fs$y <- df(Fs$x,  nlevels(conspiracy$urban)-1, nrow(conspiracy) - nlevels(conspiracy$urban))
Fs$p <- pf(Fs$x,  nlevels(conspiracy$urban)-1, nrow(conspiracy) - nlevels(conspiracy$urban))
ggplot(Fs, aes(x = x, y = y)) +
  geom_line() + theme_minimal() +
  labs(x = expression(paste('F-Wert')), y = 'Dichte') +
  geom_ribbon(data = subset(Fs, p > .95), aes(ymax = y), ymin = 0, fill = "darkblue")
```

## Die `ezANOVA`

Da das Ausrechnen per Hand nun doch etwas umständlich ist, bietet `R` uns einige andere Möglichkeiten, z. B. `anova` oder `aov` und diverse Pakete (z. B. `Anova` aus `car`). Allerdings haben die verschiedenen Ansätze jeweils ihre Vor- und Nachteile, weshalb die `ezANOVA`-Funktion aus dem `ez`-Paket erstellt wurde, um als Meta-Funktion zu dienen, die sich situationsspezifisch bei den grundlegenden Funktionen bedient.

```{r loadlib, exercise=FALSE, exercise.lines = 3}
# Paket laden (ggf. vorher installieren mit install.packages)
library(ez)
```

Weil die Funktion für verschiedene Arten von *ANOVAs* geeignet ist, benötigt sie einige sehr spezifisiche Argumente. Für die *einfaktorielle ANOVA* werden vier Argumente benötigt:

- `data = `: der genutzte Datensatz
- `wid = `: eine Personen ID-Variable
- `dv = `: die abhängige Variable (dependent variable)
- `between = `: eine Gruppierungsvariable (die *zwischen* Personen unterscheidet)

In unserem Datensatz liegt leider noch keine ID-Variable vor, diese muss also zunächst erstellt werden. Der Einfachheit halber nummerieren wir die Personen von 1 bis `r nrow(conspiracy)` durch. Damit festgehalten wird, dass es sich bei der ID um eine nominalskalierte Variable handelt, wandeln wir diese direkt in einen `factor` um.

```{r prep_ANOVA, exercise=TRUE, exercise.lines = 3}
conspiracy$id <- as.factor(1:nrow(conspiracy))
```

Jetzt kann die ANOVA mit dem `ezANOVA`-Befehl durchgeführt werden, indem wir einfach den oben stehenden Argumenten unsere Variablen übergeben:

```{r ANOVA_I, exercise=TRUE, exercise.lines = 2}
ezANOVA(conspiracy, wid = id, dv = ET, between = urban)
```

Zunächst werden wir mit einer `## Warning` darauf hingewiesen, dass das Desgin *unbalanciert* ist: die Gruppen sind nicht alle gleich groß. Das kann Konsequenzen auf die Vertrauenswürdigkeit der Ergebnisse haben, wenn wir ANOVAs mit mehr als einem Faktor bestimmen (dazu mehr in der nächsten Sitzung zur [zweifaktoriellen ANOVA](/post/zweifaktorielle-ANOVA).

Die zweite Hälfte der Ergebnisse (`$Levene's Test for Homogeneity of Variance`) liefern die Überprüfung der Homoskedastizitätsannahme mit dem Levene Test. Dieser wird von `ezANOVA` immer automatisch mitgeliefert. Wie zu erwarten, zeigt sich das selbe Ergebnis wie mit dem `leveneTest` aus dem `car`-Paket.

Der erste Abschnitt der Ausgabe der `ezANOVA`-Funktion liefert die Ergebnisse der *ANOVA* selbst. Dabei wird zunächst die unabhängige Variable aufgeführt (`Effect`), dann die Anzahl der Zählerfreiheitsgrade (`DFn` = $df_1$), dann die Anzahl der Nennerfreiheitsgrade (`DFd` = $df_2$). Darauf wiederum folgt der $F$-Wert (`F` = $F_{emp}$) und der resultierende $p$-Wert. In diesem Fall wird die Nullhypothese bei einem $\alpha$-Fehlerniveau von .05 verworfen: die Mittelwerte der drei Gruppen sind nicht gleich. Der `*` in der nächsten Spalte liefert uns diesbezüglich einen optischen Hinweis. 

Die letzte Spalte liefert das generalisierte $\eta^2$ (`ges` = *Generalized Eta-Squared*), ein Effektstärkemaß für ANOVAs. Dieses berechnet sich in diesem Fall einfach aus $\eta^2 = \frac{QS_{zw}}{QS_{tot}}$. Um die Quadtratsummen (`SSn` = $QS_{zw}$,`SSd` = $QS_{inn}$) zu erhalten, kann mithilfe des Arguments `detailed = TRUE` eine detaillierte Ausgabe angefordert werden.

```{r ANOVA_III, exercise=TRUE, exercise.lines = 2}
ezANOVA(conspiracy, wid = id, dv = ET, between = urban, detailed = TRUE)
```

Für $\eta^2$ haben sich - wie für viele Effektgrößen - Konventionen bezüglich der Interpretation etabliert. Für die Varianzanalyse wird $\eta^2 \approx .01$ als kleiner, $\eta^2 \approx .06$ als mittlerer und $\eta^2 \approx .14$ als großer Effekt interpretiert. Der Wert in unserem Beispiel liegt somit noch unter der Schwelle zu einem kleinen Effekt - die Gruppenunterschiede sind zwar statistisch signifikant von null verschieden, praktisch aber kaum bedeutsam.

## Post-Hoc Analysen

Die **ANOVA** ist ein **Omnibustest** - es wird lediglich die Gleichheit aller Gruppen geprüft. Wenn die Nullhypothese verworfen wird, geben die Ergebnisse zunächst keine Auskunft darüber, *welche* Gruppen sich unterscheiden. Die detaillierte Untersuchung der Gruppenunterschiede wird in der **Post-Hoc-Analyse** unternommen.

### t-Tests

Die naheliegende Untersuchung wäre hier, alle drei Gruppen mithilfe einfacher $t$-Tests zu vergleichen:

```{r posthoc_I, exercise=TRUE, exercise.lines = 2}
pairwise.t.test(conspiracy$ET, conspiracy$urban, p.adjust = 'bonferroni')
```

Aufgrund der $\alpha$-Fehler Kumulierung müssen die $p$-Werte adjustiert werden (`p.adjust = 'bonferroni'`). Dabei ist die Bonferroni-Korrektur einer der einfachsten (und gleichzeitig konservatisten) Ansätze: $\alpha_{\text{kor}} = \frac{\alpha}{m}$, wobei $m = \binom{K}{2}$ die Anzahl der durchgeführten Tests ist. Hier zeigt sich, dass sich ausschließlich Personen aus `urban` und `suburban` Umgegbungen in ihrer Überzeugung bezüglich des *Extraterrestrial Cover-Ups* unterscheiden ($p$ < .05).

### Tukey Test

Ein präziserer Ansatz als die einfachen $t$-Tests bietet **Tukeys Honest Significant Difference** (auch *Tukey Test*). Dieser kann in `R` allerdings nur auf `aov`-Objekte angewendet werden. Der `aov`-Befehl führt zum selben Ergebnis wie `ezANOVA`. Zu Unterschieden kann es erst bei der [zweifaktoriellen ANOVA](/post/zweifaktorielle-ANOVA) kommen, da dort der Typ der Quadratsumme ein Rolle spielt, wie diese ausfällt. 

#### aov-Befehl

In unserem Beispiel sieht der `aov`-Befehl so aus, wobei wir direkt die `summary`-Funktion, analog zur Regressionanalyse, darauf anwenden, um die Signifikanzentscheidungen zu sehen:

```{r}
summary(aov(ET ~ urban, data = conspiracy))
```
Der Befehl sieht dabei so aus, wie der einer Regressionsanalyse und im Übrigen auch so wie die Gleichung aussah im `leveneTest` aus dem `car`-Paket. Schauen wir uns nun Tukey's Test an: 

```{r posthoc_II, exercise=TRUE, exercise.lines = 2}
TukeyHSD(aov(ET ~ urban, data = conspiracy), conf.level = 0.95)
```

Das Ergebnis bietet neben den einfachen $p$-Werten auch korrigierte Konfidenzintervalle für die Mittelwertsdifferenzen. Darüber hinaus können die Ergebnisse auch in einem Plot dargestellt werden:

```{r posthoc_III, exercise=TRUE, exercise.lines = 3, fig.height=6}
tuk <- TukeyHSD(aov(ET ~ urban, data = conspiracy))
plot(tuk)
```

Schließt das Konfidenzintervall für die Mittelwertsdifferenz die Null (gestrichelte Linie) ein, so ist diese Mittelwertsdifferenz statistisch signifikant! In unserer Stichprobe kam es zu Mittelwertsunterschieden auf `ET`, da sich die Gruppen `urban` (städtisch) und `suburban` (vorstädtisch) hinsichtlich der Zustimmung zur Überzeugung, dass die Existenz von Außerirdischen geheimgehalten wird, unterscheiden.

#### ezANOVA-Befehl

Es ist auch möglich das `aov`-Objekt gleichzeitig mit der ezANOVA ausgeben zu lassen. Dies ist möglich, indem man im `ezANOVA`-Befehl die Bedingung `return_aov = TRUE` hinzufügt und dann mit `$aov` auf das `aov`-Objekt zugreift. Dies kann dann im Environment abspeichert und weiterverwendet werden.

```{r}
aov_t <- ezANOVA(conspiracy, wid = id, dv = ET, between = urban, return_aov = T)$aov
TukeyHSD(aov_t, conf.level = 0.95)
```


***

## R-Skript
Den gesamten `R`-Code, der in dieser Sitzung genutzt wird, können Sie [`r fontawesome::fa("download")` hier herunterladen](/post/PsyBSc7_R_Files/ANOVA-I.R).

***

## Literatur
[Eid, M., Gollwitzer, M., & Schmitt, M. (2017).](https://hds.hebis.de/ubffm/Record/HEB366849158) *Statistik und Forschungsmethoden* (5. Auflage, 1. Auflage: 2010). Weinheim: Beltz. 


* <small> *Blau hinterlegte Autorenangaben führen Sie direkt zur universitätsinternen Ressource.*
