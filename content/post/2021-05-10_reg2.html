---
title: "Regressionsanalyse II"
date: '2021-04-28'
slug: reg2
categories:
     - BSc7
tags:
- Regression
- Zusammenhangsanalyse
- Erklärte Varianz
- Modelloptimierung
subtitle: 'Modelloptimierung'
summary: ''
authors: [irmer, hartig, schueller, nehler]
lastmod: '2022-05-17 12:00:12 CEST'
featured: no
header:
     image: "/header/PsyBSc7_Reg2.jpg"
     caption: "[Courtesy of pxhere](https://pxhere.com/de/photo/598938)"
projects: []
---



<div>
<div id="modelloptimierung" class="section level2">
<h2>Modelloptimierung</h2>
<p>Bei der Regressionsanalyse hat die Modelloptimierung zum Ziel, ein Regresionsmodell zu verbessern - das heißt, möglichst viel Varianz der abhängigen Variable zu erklären. Dadurch wird die “Vorhersage” der abhängigen Variable genauer (die Streuung der Werte um die Regressionsgerade/-hyperebene ist kleiner).</p>
<p><strong>Modelloptimierung</strong> bedeutet, ein Modell zu verbessern, durch:</p>
<ul>
<li>Aufnehmen zusätzlicher, bedeutsamer Prädiktoren</li>
<li>Ausschließen von Prädiktoren, die nicht zur Varianzaufklärung beitragen</li>
</ul>
<p><strong>Ziel</strong> ist ein <em>sparsames Modell</em>, in dem</p>
<ul>
<li>jeder enthaltene Prädiktor einen Beitrag zur Varianzaufklärung des Kriteriums leistet und</li>
<li>kein wichtiger (= vorhersagestarker) Prädiktor vergessen wurde.</li>
</ul>
<p>In diesem Kontext sind zwei unterschiedliche Fragestellungen von Interesse:</p>
<ol style="list-style-type: decimal">
<li>Die theoriegeleitete Arbeit: Aus der Literatur werden Modelle abgeleitet, die von Interesse sind. Diese unterscheiden sich in der Anzahl der Prädiktoren und können mittels Modellvergleich gegeneinander getestet werden. Hier geht es also um die Testung von spezfisichen Hypothesen.</li>
<li>Die schrittweise, “explorative” Auswahl von Prädiktoren aus einer größeren Menge möglicher Prädiktoren: Explorativ bedeutet hier, dass wir keiner zuvor hergeleiteter Theorie folgen, sondern die Daten möglichst genau untersuchen wollen. Hier kann es dann zum sogenannten Overfitting kommen, also zu einer zu starken Anpassung unseres Modells an die Daten. In weiteren (unabhängigen / mit neuen Daten) Studien könnte dann das neu herausgearbeitete Modell konfirmatorisch (also von einer vor Analyse bestehenden Theorie abgeleitet/ theoriebestätigend) untersucht werden.</li>
</ol>
<div id="übungs-datensatz" class="section level3">
<h3>Übungs-Datensatz</h3>
<p>Die Modelloptimierung wird am gleichen Datensatz demonstriert, der auch in der Sitzung zu <a href="/post/reg1">Regression I</a> verwendet wurde. Eine Stichprobe von 100 Schüler:innen hat einen Lese- und einen Mathematiktest bearbeitet, und zusätzlich dazu einen allgemeinen Intelligenztest absolviert. Im Datensatz enthalten ist zudem das Geschlecht (Variable: <code>female</code>, 0 = m, 1 = w). Die abhängige Variable ist die Matheleistung, die durch die anderen Variablen im Datensatz vorhergesagt werden soll.</p>
<p>Den Datensatz laden Sie wie folgt:</p>
<pre class="r"><code># Datensatz laden
load(url(&quot;https://pandar.netlify.app/post/Schulleistungen.rda&quot;))</code></pre>
</div>
</div>
<div id="hypothesentestung-theoriegeleitete-testung" class="section level2">
<h2>Hypothesentestung / Theoriegeleitete Testung</h2>
<p>Wie bereits beschrieben werden in der theoriegeleiteten Testung Modelle aus den Hypothesen abgeleitet und dann gegeneinander getestet. Dabei soll das Modell identifziert werden, dass die Varianz der abhängigen Variable besser erklären kann. Der Unterschied in der erklärten Varianz zwischen zwei Modellen wird je nach Fragestellung als Inkrement / Dekrement bezeichnet. Mit Inkrement und Dekrement meinen wir hier das Varianzinkrement/-dekrement, also das Hinzukommen oder die Abnahme der erklärten Varianz in unserem Modell.</p>
<div id="bestimmung-eines-inkrements" class="section level3">
<h3>Bestimmung eines Inkrements</h3>
<p>Das Inkrement beschreibt den Zugewinn an erklärter Varianz, wenn wir einen zusätzlichen Prädiktor in das Modell mit aufnehmen. Für seine Bestimmung stellen wir dabei ein eingeschränktes Modell <span class="math inline">\(M_c\)</span> (<span class="math inline">\(_c\)</span> steht hier für “constrained”, also eingeschränkt) mit weniger Prädiktoren und ein uneingeschränktes Modell <span class="math inline">\(M_u\)</span> (<span class="math inline">\(_u\)</span> steht hier für “unconstrained”, also uneingeschränkt) mit zusätzlichen Prädiktoren auf.</p>
<p>Orientieren wir uns an einem Beispiel: Nehmen wir an, dass in der Literatur ein Modell existiert, in dem <code>math</code> durch <code>reading</code> und das Geschlecht vorhergesagt wird. Wir haben uns jetzt aber mit dem Thema beschäftigt und aus der Literatur auch herleiten können, dass die Hinzunahme von Intelligenz (<code>IQ</code>) zu einem signifikanten Zuwachs an erklärter Varianz führen sollte. Nähern wir uns dem ganzen erstmal deskriptiv, indem wir das Inkrement der Intelligenz bestimmen. Dafür stellen wir im folgenden Code erstmal das eingeschränkte und uneingeschränkte Modell auf.</p>
<pre class="r"><code>m.c &lt;- lm(math ~ reading + female, data = Schulleistungen)      # constrained
m.u &lt;- lm(math ~ reading + female + IQ, data = Schulleistungen) # unconstrained
summary(m.c)</code></pre>
<pre><code>## 
## Call:
## lm(formula = math ~ reading + female, data = Schulleistungen)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -204.12  -64.84   -7.69   45.14  490.01 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 369.9663    51.1049   7.239 1.07e-10 ***
## reading       0.4431     0.1011   4.381 2.99e-05 ***
## female      -52.3994    21.4960  -2.438   0.0166 *  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 106.2 on 97 degrees of freedom
## Multiple R-squared:  0.1897,	Adjusted R-squared:  0.173 
## F-statistic: 11.36 on 2 and 97 DF,  p-value: 3.701e-05</code></pre>
<pre class="r"><code>summary(m.u)</code></pre>
<pre><code>## 
## Call:
## lm(formula = math ~ reading + female + IQ, data = Schulleistungen)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -96.46 -50.69 -20.66  18.53 455.03 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  75.416510  55.602607   1.356    0.178    
## reading      -0.002986   0.098679  -0.030    0.976    
## female      -26.310648  17.318600  -1.519    0.132    
## IQ            5.112758   0.663512   7.706 1.19e-11 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 83.91 on 96 degrees of freedom
## Multiple R-squared:  0.4994,	Adjusted R-squared:  0.4837 
## F-statistic: 31.92 on 3 and 96 DF,  p-value: 2.121e-14</code></pre>
<p>Wir interessieren uns insbesonders für die erklärte Varianz, schauen uns also den Determinationskoeffizienten genauer an.</p>
<p><strong>Ergebniszusammenfassung: <span class="math inline">\(R^2\)</span></strong></p>
<ul>
<li>Determinationskoeffizient ohne IQ (“constrained”): <span class="math inline">\(R_c^2=0.19\)</span></li>
<li>Determinationskoeffizient mit IQ (“unconstrained”): <span class="math inline">\(R_u^2=0.50\)</span></li>
</ul>
<p>Das Inkrement ist nun die Differenz der beiden Determinationskoeffizienten. Wir können diese natürlich per Hand bestimmen, aber besser ist die Nutzung dieses Codes:</p>
<pre class="r"><code># Inkrement = Differenz in R2 aus restringiertem Modell 2 minus R2 aus unrestringiertem Modell 1
summary(m.u)$r.squared - summary(m.c)$r.squared</code></pre>
<pre><code>## [1] 0.3096366</code></pre>
<p>Wir sehen also, dass das Modell mit IQ als weiteren Prädiktor mehr Varianz erklärt als das ohne IQ. Die Hinzunahme des IQ führt zu einem Zuwachs von 31% erklärter Varianz (<span class="math inline">\(\Delta R^2 = R_u^2 - R_c^2 = 0.31\)</span>). Eine Signifikanzentscheidung können wir an dieser Stelle jedoch noch nicht treffen, denn der Zuwachs an erklärter Varianz ist immer <span class="math inline">\(\ge0\)</span>. Die Hinzunahme von Prädiktoren erhöht den Anteil an erklärter Varianz also immer, aber wir haben in der Einführung bereits das Sparsamkeitsprinzip angesprochen. Ein Prädiktor sollte also nur aufgenommen werden, wenn sein Inkrement auch verschieden von 0 ist.</p>
</div>
<div id="inferenzstatistische-testung-eines-inkrements" class="section level3">
<h3>Inferenzstatistische Testung eines Inkrements</h3>
<p>Wir müssen das <em>Inkrement</em> also auf Signifikanz testen. Die inferenzstatistische Testung starten wir am besten, indem wir Hypothesen aufstellen.</p>
<p>Für die statistische Hypothese nehmen wir erstmal an, dass <span class="math inline">\(\Delta R^2\)</span> den unterschied in der erklärten Varianz zwischen dem eingeschränkten und dem uneingeschränkten Modell beschreibt.</p>
<p><span class="math display">\[\Delta R^2 = R_u^2 - R_c^2\]</span>
Daher können wir das Hypothesenpaar so formulieren, dass unter der <span class="math inline">\(H_0\)</span> die Differenz der nicht erklärten Varianz bei 0 liegt, während sie in der <span class="math inline">\(H_1\)</span> verschieden von 0 ist.
<span class="math display">\[H0: \Delta R^2 = 0; H1: \Delta R^2 \neq 0\]</span></p>
<p>Der Modellvergleich kann mit der <code>anova</code>-Funktion vorgenommen werden. ANOVA steht hierbei für “<strong>An</strong>alysis <strong>o</strong>f <strong>Va</strong>riance”, wir vergleichen ja nichts weiteres als Varianzen! Im Bezug auf Gruppenunterschiede hat die ANOVA eine besondere Bedeutung, weswegen wir ihr auch noch drei Blöcke widmen werden – also in späteren Sitzungen mehr zu diesem Thema. Wir vergleichen die beiden Determinationskoeffizienten, indem wir der <code>anova</code>-Funktion einfach die beiden Modelle übergeben. Hierbei soll das eingeschränkte Modell stets links stehen, damit die Freiheitsgrade des Modellvergleichs positiv sind! Die Freiheitsgrade geben dann an, wie viele weiteren Parameter in unserem Modell zusätzlich geschätzt werden müssen.</p>
<pre class="r"><code># Modellvergleich mit der anova-Funktion
anova(m.c, m.u)</code></pre>
<pre><code>## Analysis of Variance Table
## 
## Model 1: math ~ reading + female
## Model 2: math ~ reading + female + IQ
##   Res.Df     RSS Df Sum of Sq      F    Pr(&gt;F)    
## 1     97 1094086                                  
## 2     96  675987  1    418099 59.376 1.186e-11 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>Im Output sehen wir zunächst eine Übersicht über die beiden Modelle (auch mehr als 2 Modelle sind möglich, die Modelle müssen nur geschachtelt sein, also auseinander hervorgehen, damit sie sinnvoll miteinander verglichen werden können). Model 1 ist das Modell ohne IQ, während Model 2 das Modell mit IQ beschreibt. Die Zahlen 1 und 2 beschreiben dann die Zeilen der Modelle. <code>Res.Df</code> sind die Residualfreiheitsgrade (diese lassen sich bestimmen, indem von der Stichprobengröße <span class="math inline">\(N\)</span> die Anzahl der zu schätzenden Koeffizienten inklusive Interzept abgezogen werden). <code>RSS</code> ist die Residual Sum of Squares, also die Residualquadratsumme. <code>Df</code> sind die Freiheitsgrade (Degrees of Freedom). <code>Sum of Sq</code> ist die durch die hinzukommenden Prädiktoren erklärte Quadratsumme, welche sich einfach durch die Differenz der beiden <code>RSS</code> bestimmen lässt. <code>F</code> beschreibt den <span class="math inline">\(F\)</span>-Wert, der die Änderung in den <code>Sum of Sq</code> an der zufälligen Streuung relativiert. <code>Pr(&gt;F)</code> ist die Spalte mit den zu dem <span class="math inline">\(F\)</span>-Werten gehörigen <span class="math inline">\(p\)</span>-Werte, also die Spalte, die uns besonders interessiert!</p>
<p>Das Inkrement des IQs ist auf einem Alpha-Fehlerniveau von 0.05 signifikant von null verschieden (<span class="math inline">\(p&lt;.001\)</span>). Somit wird der Anteil erklärter Varianz statistisch bedeutsam vergrößert.</p>
<p>Zum Vergleich finden Sie hier die Berechnung des F-Tests zu Fuß zur Regression:</p>
<p><span class="math display">\[F = \frac{\frac{R^2_u-R_c^2}{df_{u}-df_c}}{\frac{1-R_u^2}{df_{e}}}.\]</span></p>
<p>Dabei bezeichnen: <span class="math inline">\(R^2_u\)</span> den Determinationskoeffizient des uneingeschränkten (unconstrained) Modells, <span class="math inline">\(R^2_c\)</span> den Determinationskoeffizient des eingeschränkten (constrained) Modells, <span class="math inline">\(df_u\)</span> die Anzahl an Freiheitsgraden des uneingeschränkten (unconstrained) Modells [entspricht Anzahl der <span class="math inline">\(b/\beta\)</span>-Gewichte inklusive Interzept], <span class="math inline">\(df_u\)</span> die Anzahl an Freiheitsgraden des eingeschränkten (constrained) Modells [entspricht Anzahl der <span class="math inline">\(b/\beta\)</span>-Gewichte inklusive Interzept] und <span class="math inline">\(df_e\)</span> die Residualfreiheitsgrade des uneingeschränkten Modells.</p>
<p>In <code>R</code>:</p>
<pre class="r"><code>R2.u &lt;- summary(m.u)$r.squared
R2.c &lt;- summary(m.c)$r.squared
df.diff &lt;- summary(m.u)$df[1] - summary(m.c)$df[1] # Änderung in den df
df.e &lt;- summary(m.u)$df[2] # Fehlerfreiheitsgrade des uneingeschränkten Modells
F.diff &lt;- ((R2.u - R2.c) / df.diff) /
  ((1 - R2.u) / df.e)
p.diff &lt;- 1-pf(F.diff, df.diff, df.e)
F.diff # F-Wert der Differenz in R^2</code></pre>
<pre><code>## [1] 59.37622</code></pre>
<pre class="r"><code>p.diff # zugehöriger p-Wert  </code></pre>
<pre><code>## [1] 1.186384e-11</code></pre>
</div>
<div id="zusammenhang-des-inkrements-und-der-semipartialkorrelation" class="section level3">
<h3>Zusammenhang des Inkrements und der Semipartialkorrelation</h3>
<p>Außerdem sei an dieser Stelle erwähnt, dass das Inkrement auch über die Semipartialkorrelation bestimmt werden kann. Das Varianzinkrement <code>R2.u - R2.c</code> des IQs über Leseleistung und Geschlecht hinaus ist ja nichts anderes als die quadrierte Semipartialkorrelation zwischen Matheleistung und IQ wobei Leseleistung und Geschlecht herauspartialisiert wurden.</p>
<pre class="r"><code>R2.u - R2.c # Inkrement</code></pre>
<pre><code>## [1] 0.3096366</code></pre>
<pre class="r"><code>library(ppcor)</code></pre>
<pre><code>## Loading required package: MASS</code></pre>
<pre class="r"><code>sp &lt;- spcor.test(x = Schulleistungen$math, y = Schulleistungen$IQ, z = Schulleistungen[, c(&quot;reading&quot;, &quot;female&quot;)])
sp$estimate^2 # ebenfalls Inkrement!</code></pre>
<pre><code>## [1] 0.3096366</code></pre>
<p>Wir stellen keinen Unterschied im Wert selbst fest. Beachtet aber, dass die inferenzstatistische Testung mit dem Modellvergleich nicht die Semipartialkorrelation nutzt. Für Interessierte: Vertiefende Infos zu dieser Situation werden wir im <a href="#Appendix">Anhang</a> bereitstellen. Falls die Testung des Inkrements / Dekrements in einer Übung verlangt wird, nutzen Sie die <span class="math inline">\(p\)</span>-Werte aus dem <span class="math inline">\(F\)</span>-Test (<code>anova</code>).</p>
</div>
<div id="testen-eines-dekrements" class="section level3">
<h3>Testen eines Dekrements</h3>
<p>Das Dekrement ist ebenfalls ein Unterschied im <span class="math inline">\(R^2\)</span> zwischen dem restringierten Modell <span class="math inline">\(M_c\)</span> und dem unrestringierten Modell <span class="math inline">\(M_u\)</span>. Wir gehen hier nur nicht von einer Hinzunahme von einem oder mehreren Prädiktoren aus, sondern von einem Herausnehmen von einem oder mehreren Prädiktoren. Es ändert sich also lediglich die Logik, in welcher wir das Modell verändern. Die Testung eines Dekrements erfolgt analog zum Inkrement: das eingeschränkte Modell <span class="math inline">\(M_c\)</span> mit weniger Prädiktoren wird mit dem uneingeschränkten Modell <span class="math inline">\(M_u\)</span> mit mehr Prädiktoren verglichen. Es soll nun geprüft werden, ob das <em>Weglassen</em> des Geschlechts aus dem Modell zu einem signifikanten Rückgang der erklärten Varianz führt. Dazu müssen wir im Grunde eigentlich wieder das Inkrement testen… Wir wissen also bereits wie das geht:</p>
<pre class="r"><code>m.u &lt;- lm(math ~ reading + female + IQ, data = Schulleistungen) # unconstrained
m.c &lt;- lm(math ~ reading + IQ, data = Schulleistungen) # constrained

summary(m.u)$r.squared - summary(m.c)$r.squared</code></pre>
<pre><code>## [1] 0.01203586</code></pre>
<pre class="r"><code># Modellvergleich mit der anova-Funktion
anova(m.c, m.u)</code></pre>
<pre><code>## Analysis of Variance Table
## 
## Model 1: math ~ reading + IQ
## Model 2: math ~ reading + female + IQ
##   Res.Df    RSS Df Sum of Sq     F Pr(&gt;F)
## 1     97 692239                          
## 2     96 675987  1     16252 2.308  0.132</code></pre>
<p>Der Ausschluss des Geschlechts führt zu einer Verringerung von 1% erklärter Varianz (<span class="math inline">\(\Delta R^2=0.012\)</span>). Dieser Unterschied ist <em>nicht</em> signifikant von 0 verschieden (<span class="math inline">\(p=0.132\)</span>). Somit wird der Anteil erklärter Varianz nicht signifikant verringert!</p>
</div>
</div>
<div id="explorative-modellauswahl" class="section level2">
<h2>Explorative Modellauswahl</h2>
<p>Inkremente und Dekremente können theoriegeleitet auf Signifikanz getestet werden. In manchen Untersuchungen gibt es für die Modelle aber noch keine Hypothesen und mögliche Prädiktoren sollen erstmal exploriert werden. Es gibt verschiedene Vorgehensweisen bei der explorativen Suche nach einem Modell. Es kann variierte werden, ob vorwärts, rückwärts oder in beide Richtungen gesucht wird. Weiterhin kann das Kriterium für den Einschluss und Ausschluss von Prädiktoren variiert werden. Wir betrachten im folgenden zwei Beispiele aus diesem weiten Raum an Möglichkeiten.</p>
<div id="nutzung-der-testung-von-inkrementen-und-dekrementen" class="section level3">
<h3>Nutzung der Testung von Inkrementen und Dekrementen</h3>
<p>Wie immer gibt es in <code>R</code> viele weitere Wege, zum selben Ziel zu kommen. Das Paket <code>olsrr</code> beinhaltet verschiedene Funktionen, die für die Regressionsanalyse nützlich sind, u.a. auch Funktionen, die die schrittweise Auswahl von Prädiktoren auf Basis verschiedener Kriterien und nach verschiedenen Methoden (vorwärts, rückwärts, etc.) ermöglichen. Finden Sie <a href="https://olsrr.rsquaredacademy.com/articles/variable_selection.html#best-subset-regression">hier</a> mehr Informationen dazu.</p>
<pre class="r"><code># install.packages(&quot;olsrr&quot;)
library(olsrr)</code></pre>
<pre><code>## 
## Attaching package: &#39;olsrr&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:MASS&#39;:
## 
##     cement</code></pre>
<pre><code>## The following object is masked from &#39;package:datasets&#39;:
## 
##     rivers</code></pre>
<p>Die Funktion <code>ols_step_both_p()</code> beinhaltet die Auswahl auf Basis der Signifikanz des Inkrements oder Dekrements und führt in jedem Schritt Tests für Einschluss und Ausschluss durch. Sie nutzt also die Technik, die wir gerade für den theorigeleiteten Modellvergleich auch genommen haben. Dieses Vorgehen sollte nicht als Default angesehen werden, da einige Probleme bestehen, auf die wir nach der Demonstration eingehen. Aufgrund der Prävalenz des Vorgehens haben wir uns dazu entschieden, es auch zu präsentieren.</p>
<p>Nun zu der Anwendung der <code>ols_step_both_p()</code>-Funktion: Der Input ist ein Regressionsmodell, das mit der bekannten Funktion <code>lm</code> erstellt wurde. Über die zusätzlichen Argumente kann gesteuert werden, wie streng bei Aufnahme und Ausschluss getestet wird. Über das Argument <code>details</code> können Sie den gesamten Verlauf der schrittweisen Selektion (nicht nur das finale Ergebnis) anzeigen lassen. <code>pent</code> ist der p-Wert, der für das “entering” in das Modell zuständig ist. Also muss das Inkrement einen p-Wert von <span class="math inline">\(p&lt;.05\)</span> haben, wenn wir <code>pent = .05</code> wählen.<code>prem</code> ist der p-Wert, der für das “removing” aus dem Modell zuständig ist. Also muss das Dekremnt einen p-Wert von <span class="math inline">\(p&gt;.10\)</span> haben, wenn wir <code>pent = .10</code> wählen. <code>details = TRUE</code> fordert weitere Informationen an.</p>
<pre class="r"><code># Modell mit allen Prädiktoren
m &lt;- lm(math ~ reading + female + IQ, data = Schulleistungen)

# Anwendung der iterativen Modellbildung
ols_step_both_p(m, pent = .05, prem = .10, details = TRUE)</code></pre>
<pre><code>## Stepwise Selection Method   
## ---------------------------
## 
## Candidate Terms: 
## 
## 1. reading 
## 2. female 
## 3. IQ 
## 
## We are selecting variables based on p value...
## 
## 
## Stepwise Selection: Step 1 
## 
## - IQ added 
## 
##                          Model Summary                           
## ----------------------------------------------------------------
## R                       0.698       RMSE                 84.105 
## R-Squared               0.487       Coef. Var            14.980 
## Adj. R-Squared          0.481       MSE                7073.620 
## Pred R-Squared          0.468       MAE                  52.958 
## ----------------------------------------------------------------
##  RMSE: Root Mean Square Error 
##  MSE: Mean Square Error 
##  MAE: Mean Absolute Error 
## 
##                                  ANOVA                                  
## -----------------------------------------------------------------------
##                    Sum of                                              
##                   Squares        DF    Mean Square      F         Sig. 
## -----------------------------------------------------------------------
## Regression     657075.570         1     657075.570    92.891    0.0000 
## Residual       693214.751        98       7073.620                     
## Total         1350290.321        99                                    
## -----------------------------------------------------------------------
## 
##                                    Parameter Estimates                                    
## -----------------------------------------------------------------------------------------
##       model      Beta    Std. Error    Std. Beta      t       Sig       lower      upper 
## -----------------------------------------------------------------------------------------
## (Intercept)    53.901        53.330                 1.011    0.315    -51.931    159.733 
##          IQ     5.172         0.537        0.698    9.638    0.000      4.107      6.237 
## -----------------------------------------------------------------------------------------
## 
## 
## 
## No more variables to be added/removed.
## 
## 
## Final Model Output 
## ------------------
## 
##                          Model Summary                           
## ----------------------------------------------------------------
## R                       0.698       RMSE                 84.105 
## R-Squared               0.487       Coef. Var            14.980 
## Adj. R-Squared          0.481       MSE                7073.620 
## Pred R-Squared          0.468       MAE                  52.958 
## ----------------------------------------------------------------
##  RMSE: Root Mean Square Error 
##  MSE: Mean Square Error 
##  MAE: Mean Absolute Error 
## 
##                                  ANOVA                                  
## -----------------------------------------------------------------------
##                    Sum of                                              
##                   Squares        DF    Mean Square      F         Sig. 
## -----------------------------------------------------------------------
## Regression     657075.570         1     657075.570    92.891    0.0000 
## Residual       693214.751        98       7073.620                     
## Total         1350290.321        99                                    
## -----------------------------------------------------------------------
## 
##                                    Parameter Estimates                                    
## -----------------------------------------------------------------------------------------
##       model      Beta    Std. Error    Std. Beta      t       Sig       lower      upper 
## -----------------------------------------------------------------------------------------
## (Intercept)    53.901        53.330                 1.011    0.315    -51.931    159.733 
##          IQ     5.172         0.537        0.698    9.638    0.000      4.107      6.237 
## -----------------------------------------------------------------------------------------</code></pre>
<pre><code>## 
##                               Stepwise Selection Summary                               
## --------------------------------------------------------------------------------------
##                      Added/                   Adj.                                        
## Step    Variable    Removed     R-Square    R-Square     C(p)        AIC        RMSE      
## --------------------------------------------------------------------------------------
##    1       IQ       addition       0.487       0.481    2.4470    1174.1802    84.1048    
## --------------------------------------------------------------------------------------</code></pre>
<p>Der Output ist extrem detailliert, wobei allerdings nicht aufgeführt wird, wie die jeweiligen Inkremente oder Dekremente der anderen Variablen ausgefallen waren, die nicht selektiert wurden. Mit der <code>ols_step_both_p</code> wählen wir nur den IQ als Prädiktor aus! Uns wird nach jedem Step zunächst gesagt, welcher Prädiktor gewählt wurde und wie sich verschiedene Fit-Maße verhalten (bspw. AIC oder <span class="math inline">\(R^2\)</span>). Für uns ist an dieser Stelle besonders das <span class="math inline">\(R^2\)</span> (<code>R-Squared</code>) von Relevanz. Die ANOVA im Output beschreibt einfach eine ANOVA der zu vergleichenden Modelle, wobei zunächst mit dem Null-Modell, welches nur das Interzept enthält, begonnen wird.</p>
<p>Unter <code>Parameter Estimates</code> finden wir das finale geschätzte Modell. <code>Stepwise Selection Summary</code> zeigt uns das Vorgehen dieses Auswahlalgorithmus.</p>
<p>Wie bereits angekündigt, kann man die Nutzung der Testung von Inkrementen und Dekrementen im explorative Fall in Frage stellen. Durch das sehr häufige Testen, besonders bei einer großen Menge an möglichen Prädiktoren, kann das <span class="math inline">\(\alpha\)</span>-Fehlerniveau nicht eingehalten werden kann. Eigentlich müsste dann nämlich bspw. Bonferroni korrigiert werden, was wiederum schwierig ist, wenn wir die Anzahl der Tests im Vorhinein kennen. Sie erkennen, das ganze Thema ist eine Wissenschaft für sich! Weiterhin ist es auch aus forschungstheoretischer Sicht fraglich, Inferenzstatistik an dieser Stelle zu benutzen, da diese mit Hypothesen einhergeht. Im explorativen Fall haben wir aber gerade keine Hypothesen. Wir empfehlen daher ein anderes Vorgehen bei der explorativen Suche, das wir im folgenden Abschnitt beschreiben.</p>
</div>
<div id="nutzung-von-informationskriterien" class="section level3">
<h3>Nutzung von Informationskriterien</h3>
<p>Eine weitere “theoriefreie” schrittweise Auswahl von Prädiktoren kann in <code>R</code> mit der <code>step()</code>-Funktion erfolgen. Diese macht, anders als unser zuvor demonstriertes Vorgehen, nicht von Inkrementen und deren inferenzstatistischer Absicherung Gebrauch, sondern standardmäßig vom sogenannten Informationskriterium AIC (<em>Akaike Information Criterion</em>). Dieses basiert auf der <strong>Likelihood</strong> eines geschätzten Modells <span class="math inline">\(L(\hat{\theta})\)</span> und der Anzahl der Modellparameter <span class="math inline">\(p\)</span>:</p>
<p><span class="math inline">\(AIC=-2L(\hat{\theta}) + 2p\)</span></p>
<p>Die Likelihood bezeichnet ein Maß für die Plausibilität/Wahrscheinlichkeit eines Modells, unter Berücksichtigung der gegebenen (empirisch erhobenen) Daten. Anders ausgedrückt: sie beantwortet die Frage, wie wahrscheinlich das Modell ist, wenn wir unsere gegeben Daten beobachtet haben. Um das beste Modell zu finden, kann man die Likelihood verschiedener Modelle vergleichen. Höhere Likelihoodwerte zeigen bessere Modelle an. Allerdings verbessert sich die Likelihood immer, wenn wir weitere Prädiktoren aufnehmen. Deshalb werden eben Informationskriterien wie der AIC verwendet, da er zusätzlich zur Likelihood auch noch die Komplexität des Modells berücksichtigt. Komplexere Modelle mit vielen Prädiktoren werden bestraft durch den Bestrafungsterm <span class="math inline">\(2p\)</span>.</p>
<p>Für lineare Regressionsmodelle lässt sich der AIC wie folgt darstellen:</p>
<p><span class="math inline">\(AIC_{\sigma}=n \cdot log(\sigma_e^2) + 2p\)</span></p>
<p>Der AIC ist hier eine Funktion der Stichprobengröße <span class="math inline">\(n\)</span>, der Residualvarianz <span class="math inline">\(\sigma_e^2\)</span> und der Anzahl der Parameter (= Regressionskoeffizienten) <span class="math inline">\(p=m+1\)</span>. Es wird ersichtlich, dass der AIC von der Varianz der abhängigen Variablen abhängt, da diese wiederum die Residualvarianz beeinflusst.</p>
<p>Der AIC ist ein sogenanntes inverses Maß, das bedeutet, dass Modelle mit einem kleineren AIC besser sind als Modelle mit einem größeren AIC. Man kann sich den AIC also als eine Art Distanzmaß vorstellen (Achtung, das ist nur eine Anschauung) zwischen Daten und Modell. Der AIC wird durch den Term <span class="math inline">\(n \cdot log(\sigma_e^2)\)</span> kleiner, wenn die Residualvarianz kleiner wird, also mehr Varianz erklärt wird. Durch den “Strafterm” <span class="math inline">\(2p\)</span> wird der AIC größer, wenn das Modell mehr Prädiktoren enthält.
Es soll also ein Modell gefunden werden, das mit möglichst wenigen Prädiktoren möglichst viel Varianz erklärt (<em>Sparsamkeitsprinzip</em>).</p>
<p>Auch hier kann die Selektion “vorwärts”, “rückwärts”, oder in beide Richtungen erfolgen. Wir wollen eine Foward-Backward (also vor und rückwärts) Selektion durchführen und wählen daher <code>direction = "both"</code>. Eine reine Forward oder reine Backward Selektion können wir auch über <code>direction</code> einstellen. Lesen Sie dazu <code>?step</code>. Die Standardeinstellung der <code>step</code>-Funktion ist die, dass ein Modell mit allen möglichen Prädiktoren als Ausgangspunkt genommen wird. Es wird dann der Prädiktor ausgeschlossen, der die größte Reduktion des AIC erlaubt, dann der nächste, usw. In jedem Schritt wird auch wieder geprüft, ob Prädiktoren, die <em>nicht</em> im Modell sind, bei Aufnahme wieder zu einer Reduktion des AIC führen würden. Das Verfahren stoppt, wenn:</p>
<ol style="list-style-type: decimal">
<li>nur noch Prädiktoren im Modell sind, deren Ausschluss zu einer Erhöhung des AIC führen würden und</li>
<li>nur Prädiktoren “übrig” sind, deren Einschluss den AIC nicht verbessern würde.</li>
</ol>
<p>Einfaches Beispiel: Optimierung des Modells für Mathematikleistung, Start mit allen drei möglichen Prädiktoren:</p>
<pre class="r"><code># Optimierung des Modells nach AIC
summary(step(m, direction = &quot;both&quot;))</code></pre>
<pre><code>## Start:  AIC=889.88
## math ~ reading + female + IQ
## 
##           Df Sum of Sq     RSS    AIC
## - reading  1         6  675993 887.88
## &lt;none&gt;                  675987 889.88
## - female   1     16252  692239 890.25
## - IQ       1    418099 1094086 936.03
## 
## Step:  AIC=887.88
## math ~ female + IQ
## 
##           Df Sum of Sq     RSS    AIC
## &lt;none&gt;                  675993 887.88
## - female   1     17222  693215 888.39
## + reading  1         6  675987 889.88
## - IQ       1    634538 1310531 952.08</code></pre>
<pre><code>## 
## Call:
## lm(formula = math ~ female + IQ, data = Schulleistungen)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -96.60 -50.72 -20.91  18.41 455.09 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  75.1532    54.6335   1.376    0.172    
## female      -26.4255    16.8102  -1.572    0.119    
## IQ            5.1010     0.5346   9.542 1.31e-15 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 83.48 on 97 degrees of freedom
## Multiple R-squared:  0.4994,	Adjusted R-squared:  0.489 
## F-statistic: 48.38 on 2 and 97 DF,  p-value: 2.67e-15</code></pre>
<p>Der Output enthält folgende Inhalte:</p>
<pre><code>## Start:  AIC=889.88
## math ~ reading + female + IQ</code></pre>
<p>zeigt uns das Anfangsmodell und den zugehörigen AIC.</p>
<pre><code>##           Df Sum of Sq     RSS    AIC
## - reading  1         6  675993 887.88
## &lt;none&gt;                  675987 889.88
## - female   1     16252  692239 890.25
## - IQ       1    418099 1094086 936.03</code></pre>
<p>ist der Output des ersten Schrittes. <code>&lt;none&gt;</code> beschreibt unser Modell (ohne Veränderung). Jede Zeile steht für ein Modell, in welchem jeweils maximal ein Prädiktor aus dem Modell ausgeschlossen wird oder maximal ein Prädiktor in das Modell aufgenommen wird. Das “Minus” (<code>-</code>) am Anfang der Zeile zeigt an, dass hier ein Prädiktor ausgeschlossen wird. Eine “Plus” (<code>+</code>) zeigt an, dass der jeweilige Prädiktor hinzukam. Die <code>Df</code> zeigen wieder an, wie sich die Freiheitsgrade verändern. Würden wir eine Variable verwenden, die aus mehr als 2 Faktorstufen besteht, würden hier auch <code>Df</code> größer 1 stehen. <code>Sum of Sq</code> zeigt an, wie sich die Sum of Squares verändern. <code>RSS</code> ist wieder die Residual Sum of Squares, wie oben.</p>
<pre><code>## Step:  AIC=887.88
## math ~ female + IQ
## 
##          Df Sum of Sq     RSS    AIC
## &lt;none&gt;                 675993 887.88
## - female  1     17222  693215 888.39
## - IQ      1    634538 1310531 952.08</code></pre>
<p>Der nächste Step beginnt nun mit dem verbesserten AIC, der erlangt wurde, indem die Leseleistung aus dem Modell gestrichen wurde. Da nun alle weiteren Modifikationen zu einer Verschlechterung des Modells führen, sind wir nach einer Modifikation bereits am Ende angelangt.</p>
<p><strong>Zusammenfassung:</strong></p>
<p>Es ist zu sehen dass es im Ausgangsmodell nur eine Möglichkeit gibt, das Modell zu verbessern, nämlich den Ausschluss von Lesekompetenz (<code>reading</code>) (AIC von 889.88 auf 887.88). Danach gibt es keine Möglichkeit zur Verbesserung mehr, beide verbleibenden Prädiktoren würden bei einem Ausschluss zu einer Verschlechterung des AIC führen (<code>female</code> auf 888.39 und <code>IQ</code> auf 952.08) und eine Wiederaufnahme von <code>reading</code> ist auch nicht sinnvoll, da wir dann das Modell wieder verschlechtern würden (zurück auf 889.88). Damit sind Geschlecht und IQ die Prädiktoren für das optimierte Modell. An der Ausgabe für das “finale” Modell am Schluss ist zu sehen, dass der Effekt von Geschlecht im finalen Modell hier <em>nicht</em> signifikant ist. Auch oben haben wir gesehen, dass unter Betrachtung des Dekrements dieser Prädiktor wegfallen würde. Wir sehen also, dass eine Auswahl mittels des AICs nicht notwendigerweise nur signifikante Prädiktoren auswählt!</p>
<p>Sparsamkeit wird beim AIC im “Strafterm” <span class="math inline">\(2p\)</span> nicht so hoch gewichtet wie bei anderen Informationskriterien. In der Funktion <code>step</code> kann man über die Veränderung des Parameters <code>k</code> steuern, wie streng die Prädiktorauswahl vorgenommen wird. Wenn man hier <span class="math inline">\(k = log(n)\)</span> angibt, wird statt des AIC das sogenannte Bayes’sche Informationskriterium BIC (<em>Bayesian Information Criterion</em>) verwendet.</p>
<p><span class="math inline">\(BIC=-2L(\hat{\theta}) + log(n)\cdot p\)</span></p>
<p>Vorsicht, in der Ausgabe der <code>step</code>-Funktion steht immer AIC, auch wenn dies nur mit der Standardeinstellung von <span class="math inline">\(k=2\)</span> tatsächlich dem AIC entspricht!</p>
<pre class="r"><code># Optimierung mit BIC
summary(step(m, direction = &quot;both&quot;, k=log(nrow(Schulleistungen))))</code></pre>
<pre><code>## Start:  AIC=900.3
## math ~ reading + female + IQ
## 
##           Df Sum of Sq     RSS    AIC
## - reading  1         6  675993 895.69
## - female   1     16252  692239 898.07
## &lt;none&gt;                  675987 900.30
## - IQ       1    418099 1094086 943.84
## 
## Step:  AIC=895.69
## math ~ female + IQ
## 
##           Df Sum of Sq     RSS    AIC
## - female   1     17222  693215 893.60
## &lt;none&gt;                  675993 895.69
## + reading  1         6  675987 900.30
## - IQ       1    634538 1310531 957.29
## 
## Step:  AIC=893.6
## math ~ IQ
## 
##           Df Sum of Sq     RSS    AIC
## &lt;none&gt;                  693215 893.60
## + female   1     17222  675993 895.69
## + reading  1       976  692239 898.07
## - IQ       1    657076 1350290 955.67</code></pre>
<pre><code>## 
## Call:
## lm(formula = math ~ IQ, data = Schulleistungen)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -84.14 -51.06 -18.69  24.02 468.71 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  53.9006    53.3302   1.011    0.315    
## IQ            5.1721     0.5366   9.638 7.39e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 84.1 on 98 degrees of freedom
## Multiple R-squared:  0.4866,	Adjusted R-squared:  0.4814 
## F-statistic: 92.89 on 1 and 98 DF,  p-value: 7.392e-16</code></pre>
<p>Bei der Verwendung des stengeren Kriteriums wird auch Geschlecht aus dem Modell entfernt, es verbleibt nur der IQ im finalen Modell. Dies entspricht nun eher der Modellmodifikation inklusive finalem Modelltest, den wir beim ersten Modell durchgeführt haben.</p>
<p>An dieser Stelle sei nochmal erwähnt, dass nach der explorativen Suche von Prädiktoren eine konformative, also theoriegeleitete Studie folgen sollte, in der wir Hypothesen aufstellen und diese inferenzstatistisch prüfen. Durch das explorative Vorgehen haben wir das Modell gewonnen, das auf unseren vorliegenden Datensatz am besten passt - ein Übertrag auf die Population sollte dadurch aber noch nicht gemacht werden.</p>
<div id="ergänzung-unterschiede-im-aic" class="section level4">
<h4>Ergänzung: Unterschiede im AIC</h4>
<p>Wer den Output der beiden neu gelernten Funktionen etwas genauer betrachtet, bemerkt, dass der AIC, der in der <code>step()</code>-Funktion berichtet wird, nicht identisch mit demjenigen AIC ist, der in <code>ols_step_both_p()</code> angezeigt wird. Zu Recht kann man sich nun fragen, ob hier ein Fehler passiert. Die Antwort ist nein (und ja). Es werden tatsächlich unterschiedliche Berechnungen für den AIC herangezogen. In <code>step()</code> wird intern die <code>extractAIC()</code>-Funktion verwendet, während in <code>ols_step_both_p()</code> die <code>AIC</code>-Funktion verwendet wird:</p>
<pre class="r"><code>model &lt;- lm(math ~ reading + female, data = Schulleistungen)
AIC(model)</code></pre>
<pre><code>## [1] 1221.814</code></pre>
<pre class="r"><code>extractAIC(model) # erstes Argument ist die Anzahl der Parameter (p)</code></pre>
<pre><code>## [1]   3.000 936.026</code></pre>
<p>Die <code>AIC()</code>-Funktion gibt den “vollständigen” AIC an, während <code>extractAIC()</code> eine korrigierte Version heranzieht, aus der sämtlichen irrelevanten Konstanten entfernt wurden. Da der AIC immer nur für Vergleiche auf dem selben Datensatz herangezogen werden sollte, können Konstanten in der Berechnung getrost ignoriert werden, da sie nicht vom betrachteten Modell abhängen. Dazu ein Gedankenexperiment: Für zwei Zahlen <span class="math inline">\(a\)</span> und <span class="math inline">\(b\)</span> (welche bspw. zwei AICs repräsentieren können) gilt: <span class="math inline">\(a&gt;b \Longrightarrow a + c &gt; b + c\)</span> für eine dritte Zahl <span class="math inline">\(c\)</span>. Sie sehen also, dass Konstanten, die überall “draufaddiert” werden, den Modellvergleich nicht beeinflussen.</p>
<p>Um jetzt den Unterschied genau zu erkennen, müssen wir zunächst die <strong>Loglikelihood</strong> (den Logarithmus der Likelihood) unseres Modells bestimmen. Dies geht über den Kurs an dieser Stelle hinaus. Wer sich allerdings für die Überführung des <code>extractAIC()</code> zum AIC sowie die Berechnung beider interessiert, kann gerne im <a href="#AppendixB">Appendix B</a> vorbeischauen.</p>
<hr />
</div>
</div>
</div>
<div id="AppendixA" class="section level2 anchorhead">
<h2>Appendix A</h2>
<details>
<summary>
<strong>Inferenzstatistik der Semipartialkorrelation und der Modellvergleich</strong>
</summary>
<p>Wir arbeiten weiterhin mit dem Datensatz <code>Schulleistungen</code> und gehen davon aus, dass wir bereits <code>reading</code> und <code>female</code> zur Vorhersage von <code>math</code> nutzen. nun soll zusätzlich noch <code>IQ</code> aufgenommen werden. Den Modelltest erlangen wir über das eingeschränkte und uneingeschränkte Modell mit der Funktion <code>anova()</code>.</p>
<pre class="r"><code>m.c &lt;- lm(math ~ reading + female, data = Schulleistungen)      # constrained
m.u &lt;- lm(math ~ reading + female + IQ, data = Schulleistungen) # unconstrained
anova(m.c, m.u)</code></pre>
<pre><code>## Analysis of Variance Table
## 
## Model 1: math ~ reading + female
## Model 2: math ~ reading + female + IQ
##   Res.Df     RSS Df Sum of Sq      F    Pr(&gt;F)    
## 1     97 1094086                                  
## 2     96  675987  1    418099 59.376 1.186e-11 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>Die Semipartialkorrelation wird auch wie im Tutorial mit <code>spcor.test()</code> berechnet.</p>
<pre class="r"><code>sp &lt;- spcor.test(x = Schulleistungen$math, y = Schulleistungen$IQ, z = Schulleistungen[, c(&quot;reading&quot;, &quot;female&quot;)])
sp$estimate^2    # Quadrat der Semipartialkorrelation</code></pre>
<pre><code>## [1] 0.3096366</code></pre>
<pre class="r"><code>sp$p             # p-Wert der Semipartialkorrelation</code></pre>
<pre><code>## [1] 2.695227e-09</code></pre>
<p>Weiterhin sehen wir, dass das Inkrement und die quadrierte Semipartialkorrelation derselbe Wert sind. Die <span class="math inline">\(p\)</span>-Werte hingegen unterscheiden sich. Dies kommt daher, dass der Modelltest eigentlich die Partialkorrelation testet. Einschlägige Literatur begründet das damit, dass für diese der Standardfehler weniger komplex zu bestimmt wäre. Weiterhin sind sich die Nullhypothesen auch ähnlich, wodurch in den allermeisten Fällen der Modelltest und die Prüfung der Semipartialkorrelation zur selben Signifikanzentscheidung führen.</p>
</details>
</div>
<div id="AppendixB" class="section level2 anchorhead">
<h2>Appendix B</h2>
<details>
<summary>
<strong>Bestimmen von AIC und Vergleich zwischen <code>AIC</code> und <code>extractAIC</code></strong>
</summary>
<p>Wie bereits oben besprochen, benötigen wir für die Berechnung des AIC die Loglikelihood (Logarithmus der Likelihood) der Daten. Diese erhalten wir ganz einfach mit der <code>logLik</code> Funktion.</p>
<pre class="r"><code>logLik(model)</code></pre>
<pre><code>## &#39;log Lik.&#39; -606.9068 (df=4)</code></pre>
<p><code>df</code> ist die Anzahl der Freiheitsgrade in der Likelihood: hier wird zu den <span class="math inline">\(\beta\)</span>-Koeffizienten noch die Residualvarianz <span class="math inline">\(\sigma\)</span> hinzugezählt.</p>
<p>Sie ergibt sich aus der Verteilungsannahme an unserem Modell. Diese werden wir in der nächsten Sitzung auch noch genauer prüfen. Jedoch wissen wir aus den inhaltlichen Sitzungen, dass das Residuum der Regression oft als normalverteilt angenommen wird. Das Residuum ist ja aber gerade <span class="math inline">\(\varepsilon_i = Y_i - (\beta_0 + \beta_1X_1 + \dots + \beta_mX_m)\)</span>. Außerdem nehmen wir an, dass für alle (Personen) <span class="math inline">\(i\)</span> die Varianz der Residuen gleich groß ist (Varianzhomogenität), nämlich <span class="math inline">\(\sigma^2\)</span> und deren Erwartung 0 ist, also <span class="math inline">\(\mathbb{E}[\varepsilon_i]=0\)</span>. Die Wahrscheinlichkeitsverteilung des normalverteilten Residuums <span class="math inline">\(\varepsilon_i\)</span> ist also über die Normalverteilung definiert. Einsetzen in die Verteilung ergibt</p>
<p><span class="math display">\[\frac{1}{\sqrt{2\pi\sigma^2}}e^{-\frac{(Y_i - (\beta_0 + \beta_1X_1 + \dots + \beta_mX_m))^2}{2\sigma^2}} = \frac{1}{\sqrt{2\pi\sigma^2}}e^{-\frac{\varepsilon_i^2}{2\sigma^2}}.\]</span></p>
<p>Sie sehen als Unbekannte in dieser Darstellung gibt es nur die Parameter <span class="math inline">\(\beta_0, \beta_1, \dots,\beta_m,\sigma^2\)</span>. Diese gilt es zu finden. Dies geschieht meist über die Loglikelihood. Logarithmieren wir also:</p>
<p><span class="math display">\[-\frac{1}{2}\log(2\pi) -\frac{1}{2}\log(\sigma^2) - \frac{\varepsilon_i^2}{2\sigma^2}\]</span></p>
<p>Haben wir nun ganz viele Beobachtungen, müssen diese bzgl. der Likelihood multipliziert werden (unabhängige Ereignisse werden multipliziert - das folgt dem gleichen Konzept, wie als wenn wir zweimal einen Würfel würfeln, dann müssen die Wahrscheinlichkeiten bspw. die 6 zu würfeln, multipliziert werden). Wenn wir dann logarithmieren, entsteht eine Summe, mit der relativ leicht umgegangen werden kann (deswegen wird auch zumeist die Loglikelihood genutzt, da diese genau dann wenn die Likelihood maximal ist, auch maximal ist, allerdings leichter zu “handlen” ist):</p>
<p><span class="math display">\[\sum_{i=1}^n-\frac{1}{2}\log(2\pi) -\frac{1}{2}\log(\sigma^2) - \frac{\varepsilon_i^2}{2\sigma^2} = \frac{n}{2}\log(2\pi) -\frac{n}{2}\log(\sigma^2) - \frac{1}{2\sigma^2} \sum_{i=1}^n \varepsilon_i^2\]</span></p>
<p>den letzten Ausdruck kennen wir aber! Das ist die Fehlerquadratsumme! Es gilt <span class="math inline">\(\sum_{i=1}^n \varepsilon_i^2 = n\sigma^2\)</span>. Wir können also <span class="math inline">\(\frac{1}{2\sigma^2}\sum_{i=1}^n \varepsilon_i^2\)</span> kürzen: <span class="math inline">\(\frac{1}{2\sigma^2}\sum_{i=1}^n \varepsilon_i^2 = \frac{1}{2\sigma^2}n\sigma^2 = \frac{n}{2}\)</span> (<span class="math inline">\(\sigma^2\)</span> fliegt raus). Also ist die Loglikelihood unserer Daten:</p>
<p><span class="math display">\[-\frac{n}{2}\log(2\pi) -\frac{n}{2}\log(\sigma^2) - \frac{n}{2}\]</span></p>
<p>An dieser Stelle muss noch einmal erwähnt werden, dass in der Likelihoodschreibweise die Schätzer der Fehlervarianz etwas anders ausfallen, da die Parameter alle simultan geschätzt werden können und nicht von den <span class="math inline">\(\beta\)</span>-Gewichten abhängen. Deshalb müssen wir die Fehlervarianz anders bestimmen (die Logik ist ein wenig so, wie wenn man die Populationsschätzer und die Stichprobenschätzer der Varianz vergleicht).</p>
<pre class="r"><code>LL &lt;- logLik(model) # Loglikelihood des Modells
p &lt;- length(coef(model))+1 # betas + sigma
n &lt;- nrow(Schulleistungen) # Stichprobengröße (nur so möglich, wenn keine Missings!)
sigma &lt;-summary(model)$sigma * sqrt((n-3)/n) # Korrektur um die Freiheitsgrade df_e = n - (Anzahl beta-Gewichte)
LL</code></pre>
<pre><code>## &#39;log Lik.&#39; -606.9068 (df=4)</code></pre>
<pre class="r"><code>-n/2*log(2*pi) - n*log(sigma) - n/2</code></pre>
<pre><code>## [1] -606.9068</code></pre>
<p>So, jetzt haben wir die Loglikelihood bestimmt, jetzt fehlt nur noch der AIC:</p>
<pre class="r"><code>myAIC &lt;- -2*LL[1] + 2*p
myAIC</code></pre>
<pre><code>## [1] 1221.814</code></pre>
<pre class="r"><code>AIC(model)</code></pre>
<pre><code>## [1] 1221.814</code></pre>
<p>Super! Die beiden sind schon mal identisch.</p>
<p>Wie erhalten wir nun den Unterschied zu <code>extractAIC</code>? Wir hatten gesagt, dass in <code>extractAIC</code> alle “Konstanten” herausgelassen werden, also jene Informationen, die nicht vom Modell beeinflusst werden, solange es auf die gleichen Daten angewandt wird. Die Formel für die Loglikelihood sah so aus: <span class="math inline">\(-\frac{n}{2}\log(2\pi) -\frac{n}{2}\log(\sigma^2) - \frac{n}{2}\)</span>. Hier hängt nur der Term <span class="math inline">\(-\frac{n}{2}\log(\sigma^2)\)</span> vom Modell ab, da nur die Residualvarianz <span class="math inline">\(\sigma^2\)</span> von der Inklusion der Prädiktoren abhängt. Somit haben wir also unsere fehlenden Terme gefunden! Da die Loglikelihood in der Bestimmung des AICs mit -2 multipliziert wird, müssen wir also die “Konstanten” nur noch damit multiplizieren und auf <code>extractAIC</code> draufaddieren. Außerdem müssen wir die Anzahl der Parameter um die Residualvarianz vergrößern, also müssen wir zusätlich 2*1 addieren:</p>
<pre class="r"><code>extractAIC(model)[2] + n + n*log(2*pi) + 2</code></pre>
<pre><code>## [1] 1221.814</code></pre>
<pre class="r"><code>myAIC</code></pre>
<pre><code>## [1] 1221.814</code></pre>
<pre class="r"><code>AIC(model)</code></pre>
<pre><code>## [1] 1221.814</code></pre>
<p>Nun sind alle AICs gleich! Warum ist das aber kein Problem? Vergleichen wir doch mal 2 Modelle:</p>
<pre class="r"><code>model1 &lt;- lm(math ~ reading + female, data = Schulleistungen)
model2 &lt;- lm(math ~ reading , data = Schulleistungen)

AIC(model1) - AIC(model2)</code></pre>
<pre><code>## [1] -3.94554</code></pre>
<pre class="r"><code>extractAIC(model1) - extractAIC(model2)</code></pre>
<pre><code>## [1]  1.00000 -3.94554</code></pre>
<p>Der Unterschied in den bestimmten AICs ist identisch. Somit sehen wir, dass die Unterschiede in den absoluten Werten keinen Einfluss auf die Auswahl der Modelle nimmt. Was für ein Aufwand. Wir hoffen, dass die Herleitung beim Verstehen des Sachverhalts hilft.</p>
</details>
<hr />
</div>
<div id="r-skript" class="section level2">
<h2>R-Skript</h2>
<p>Den gesamten <code>R</code>-Code, der in dieser Sitzung genutzt wird, können Sie <a href="/post/PsyBSc7_R_Files/05_reg2.R"><svg aria-hidden="true" role="img" viewBox="0 0 512 512" style="height:1em;width:1em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:currentColor;overflow:visible;position:relative;"><path d="M288 32c0-17.7-14.3-32-32-32s-32 14.3-32 32V274.7l-73.4-73.4c-12.5-12.5-32.8-12.5-45.3 0s-12.5 32.8 0 45.3l128 128c12.5 12.5 32.8 12.5 45.3 0l128-128c12.5-12.5 12.5-32.8 0-45.3s-32.8-12.5-45.3 0L288 274.7V32zM64 352c-35.3 0-64 28.7-64 64v32c0 35.3 28.7 64 64 64H448c35.3 0 64-28.7 64-64V416c0-35.3-28.7-64-64-64H346.5l-45.3 45.3c-25 25-65.5 25-90.5 0L165.5 352H64zm368 56a24 24 0 1 1 0 48 24 24 0 1 1 0-48z"/></svg> hier herunterladen</a>.</p>
</div>
</div>
