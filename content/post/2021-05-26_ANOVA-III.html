---
title: "ANOVA III: Varianzanalyse mit Messwiederholung"
date: '2021-05-20'
slug: anova3
categories:
  - BSc7
tags:
  - ANOVA
  - Messwiederholung
  - ezANOVA
  - Mittelwertsvergleiche
  - Normalverteilung
  - Homoskedastizität
  - Post-Hoc
  - Kontraste
subtitle: 'ANOVA mit Messwiederholung'
summary: ''
authors: [scheppa-lahyani,irmer,schultze]
lastmod: '2021-06-17T08:32:21+02:00'
featured: no
header:
  image: "/header/ANOVA3.jpg"
  caption: "[Courtesy of pxhere](https://pxhere.com/en/photo/628743)"
projects: []
---

<script src="/rmarkdown-libs/header-attrs/header-attrs.js"></script>


<p>In den letzten beiden Sitzungen ging es darum Unterschiede <em>zwischen</em> Personen zu untersuchen, indem wir Mittelwertsunterschiede zwischen verschiedenen Gruppen von Personen geprüft haben (in englischsprachiger Literatur wird dies als <em>between subjects</em> ANOVA bezeichnet). In dieser Sitzung soll es darum gehen, Unterschiede <em>innerhalb</em> von Personen (im Englischen <em>within subjects</em> ANOVA) mithilfe der <strong>ANOVA mit Messwiederholung</strong> zu untersuchen. Diese Unterschiede können dabei z.B. dadurch entstehen, dass wir unterschiedliche Messzeitpunkte untersuchen. Die <em>Messwiederholung</em> muss nicht zwingend durch Zeit zustande kommen - andere Möglichkeiten der Messwiederholung sind z.B. unterschiedliche Tests oder Informationsquellen. Wir könnten z.B. Verhaltensauffälligkeiten von Kindern erheben, indem wir sie durch Psychotherapeutinnen und -therapeuten beobachten lassen und die Eltern sowie die Kita-Erzieher und -Erzieherinnen befragen. Auch so messen wir wiederholt das Gleiche und können untersuchen, inwiefern sich hierbei mittlere Unterschiede zeigen. Diese Analysen von Messwiederholungen lassen sich zudem mit den <em>Zwischen-Subjekt Analysen</em> kombinieren, die wir bereits behandelt haben. Mehr zur <em>ANOVA mit Messwiederholung</em> finden Sie in <a href="https://hds.hebis.de/ubffm/Record/HEB366849158"><code>Eid, Gollwitzer und Schmitt (2017, Kapitel 14 und insb. 14.1 und folgend)</code></a>.</p>
<div id="datensatz-laden" class="section level3">
<h3>Datensatz laden</h3>
<p>Wir laden zunächst die Daten, entweder lokal von Ihrem Rechner:</p>
<pre class="r"><code>load(&quot;C:/Users/Musterfrau/Desktop/alc.rda&quot;)</code></pre>
<p>oder wir laden sie direkt über die Website:</p>
<pre class="r"><code>load(url(&quot;https://pandar.netlify.app/post/alc.rda&quot;))</code></pre>
<pre class="r"><code>dim(alc)</code></pre>
<pre><code>## [1] 82  7</code></pre>
<pre class="r"><code>head(alc)</code></pre>
<pre><code>##    id male      peer coa alcuse.14 alcuse.15 alcuse.16
## 1   1    0 1.2649111   1  1.732051         2  2.000000
## 4   2    1 0.8944272   1  0.000000         0  1.000000
## 7   3    1 0.8944272   1  1.000000         2  3.316625
## 10  4    1 1.7888544   1  0.000000         2  1.732051
## 13  5    0 0.8944272   1  0.000000         0  0.000000
## 16  6    1 1.5491934   1  3.000000         3  3.162278</code></pre>
<p>Der Datensatz stammt aus einer Erhebung von Curran, Stice und Chassin (1997) in der der <strong>Alkoholkonsum von Jugendlichen</strong> längsschnittlich untersucht wurde. Die enthaltenen Variablen sind der <em>Personen-Identifikator</em> (<code>id</code>), das dichotom kodierte <em>Geschlecht</em> (<code>male</code>, mit 0 = weiblich), das <em>berichtete Ausmaß, in dem Peers Alkohol konsumieren</em> (<code>peer</code>, ein Durchschnittswert über mehrere Items mit 0 = keine und 5 = alle) und ob derjenige/diejenige <em>Kind eines/einer Alkoholikers/Alkoholikerin</em> ist (<code>coa</code>, “child of alcoholic”, mit 0 = nein). Darüber hinaus gibt es zu drei verschiedenen Zeitpunkten (jeweils im Alter von 14, 15 und 16) die <em>selbstberichtete Häufigkeit, mit der Alkohol konsumiert wird</em> (<code>alcuse</code>, ein Durchschnittswert über mehrere Items mit 0 = nie und 7 = täglich).</p>
</div>
<div id="datenformat-und-reshape" class="section level3">
<h3>Datenformat und <code>reshape</code></h3>
<p>Die Unterscheidung zwischen Long- und Wide-Format hatten wir schon in der <a href="/post/grafiken-mit-ggplot2/">2. Sitzung</a> (<code>ggplot2</code>) gesehen. Als kurze Erinnerung: Bei der Formatierung von sozialwissenschaftlichen Datensätzen können zwei generelle Typen unterschieden werden: das <em>Long-Format</em> und das <em>Wide-Format</em>. Die Bezeichnung bezieht sich dabei (meistens) auf die Anordnung von Messwiederholungen der gleichen Personen. Im geladenen Datensatz stellt eine Zeile jeweils eine Person zu einem Zeitpunkt dar. Jede Personen-ID kommt also genau ein mal vor:</p>
<pre class="r"><code>table(alc$id)</code></pre>
<pre><code>## 
##  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 
##  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 
## 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 
##  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 
## 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 
##  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 
## 79 80 81 82 
##  1  1  1  1</code></pre>
<p>Manche Analyseverfahren benötigen Datensätze im langen Format (wie z.B. die Messwiederholte ANOVA mit <code>ez</code>), andere benötigen Datensätze im breiten Format (wie z.B. multivariate Regression). Die Umwandlung zwischen den beiden Formaten hatten wir in der <a href="/post/grafiken-mit-ggplot2/">2. Sitzung</a> mit <code>reshape</code> durchgeführt.</p>
<p>Probieren Sie kurz aus, ob Sie sich noch daran erinnern (oder rekonstruieren können), wie Sie den Datensatz ins lange Format übertragen! Nennen Sie den neuen Datensatz am besten <code>alc_long</code> und lassen Sie sich am Ende der Umstellung die ersten 6 Zeilen mit <code>head</code> ausgeben (<em>der letzte Schritt ist nötig, damit geprüft werden kann, ob Sie die Umstellung richtig gemacht haben</em>). Beachten Sie, dass die Variablen <code>male</code>, <code>peer</code> und <code>coa</code> jeweils nur einmal (zu Beginn der Studie) gemessen wurden und dass für die Zeiten das Alter (14, 15 und 16) statt 1, 2 und 3 vergeben werden sollten.</p>
<details>
<summary>
<strong>Tipp 1</strong>
</summary>
<pre class="r"><code># Umwandeln des Datensatzes
alc_long &lt;- ...

# Kopfzeilen ausgeben
head(alc_long)</code></pre>
</details>
<details>
<summary>
<strong>Tipp 2</strong>
</summary>
<pre class="r"><code># Notwendige Argumente
alc_long &lt;- reshape(data = ...,
  varying = list(...),
  direction = ...)</code></pre>
</details>
<details>
<summary>
<strong>Tipp 3</strong>
</summary>
<pre class="r"><code># Zusatz für bessere Aufbereitung
alc_long &lt;- reshape(data = ...,
  varying = list(...),
  direction = ...,
  timevar = &#39;age&#39;,
  v.names = &#39;alcuse&#39;,
  times = c(14, 15, 16))</code></pre>
</details>
<div id="wiederholung-reshape" class="section level4">
<h4>Wiederholung: <code>reshape</code></h4>
<p>Für die Transformation der Daten aus einem in das andere Format gibt es die <code>reshape</code>-Funktion, welche unterschiedliche Argumente benötigt, je nachdem, in welche Richtung die Daten transformiert werden sollen. Hier wollen wir aus dem breiten Format ins lange Format transformieren, um die Daten hinterher für die Varianzanalyse mit Messwiederholung nutzen zu können.</p>
<p>Weil die Benennung und Handhabung von Argumenten in <code>reshape</code> mitunter etwas unübersichtlich ist, empfiehlt es sich mit <code>?reshape</code> (in einem neuen R-Fenster) die Hilfe aufzurufen. Für die Umwandlung von breit nach lang sind drei Argumente zwingend erforderlich:</p>
<ul>
<li><code>data</code>: der Datensatz</li>
<li><code>varying</code>: eine Liste der Variablen, die wiederholt gemessen wurden</li>
<li><code>direction</code>: die Richtung, in die der Datensatz transformiert werden soll (hier <code>'long'</code>)</li>
</ul>
<p>Im Minimalfall sieht die Umwandlung also so aus:</p>
<pre class="r"><code>alc_long &lt;- reshape(data = alc,
  varying = list(c(&#39;alcuse.14&#39;, &#39;alcuse.15&#39;, &#39;alcuse.16&#39;)),
  direction = &#39;long&#39;)

head(alc_long)</code></pre>
<pre><code>##     id male      peer coa time alcuse.14
## 1.1  1    0 1.2649111   1    1  1.732051
## 2.1  2    1 0.8944272   1    1  0.000000
## 3.1  3    1 0.8944272   1    1  1.000000
## 4.1  4    1 1.7888544   1    1  0.000000
## 5.1  5    0 0.8944272   1    1  0.000000
## 6.1  6    1 1.5491934   1    1  3.000000</code></pre>
<p>Das Argument <code>varying</code> bedarf einer zweiten Betrachtung: hier wird eine Liste von Vektoren erstellt. Die Vektoren enthalten jeweils die Namen der Variablen, die zusammen Messwiederholungen der gleichen Variable sind. Wenn wir z.B. einen weiteren Satz aus drei Variablen hätten, die <code>weeduse</code> hieße, würde diese Liste so aussehen:</p>
<pre class="r"><code>varying = list(c(&#39;alcuse.14&#39;, &#39;alcuse.15&#39;, &#39;alcuse.16&#39;),
  c(&#39;weeduse.14&#39;, &#39;weeduse.15&#39;, &#39;weeduse.16&#39;))</code></pre>
<p>Per Voreinstellung werden alle Variablen übernommen, die nicht explizit als <code>varying</code> angegeben werden. Diese Variablen haben dann für jede Zeile, die die gleiche Person betrifft, auch den gleichen Wert. Wenn wir die Werte für die erste Person betrachten:</p>
<pre class="r"><code>alc_long[alc_long$id == 1, ]</code></pre>
<pre><code>##     id male     peer coa time alcuse.14
## 1.1  1    0 1.264911   1    1  1.732051
## 1.2  1    0 1.264911   1    2  2.000000
## 1.3  1    0 1.264911   1    3  2.000000</code></pre>
<p>sehen wir diese Variablen in den ersten vier Spalten wieder (id, male, peer, coa). Die nächste Variable ist die Zeitvariable, die von R automatisch als <code>time</code> benannt wird. Wenn wir etwas anderes nutzen möchten, können wir mit <code>timevar</code> explizit einen Namen vergeben (weil die Wiederholungen das Alter der Jugendlichen sind, bietet sich <code>age</code> an):</p>
<pre class="r"><code>alc_long &lt;- reshape(data = alc,
  varying = list(c(&#39;alcuse.14&#39;, &#39;alcuse.15&#39;, &#39;alcuse.16&#39;)),
  direction = &#39;long&#39;,
  timevar = &#39;age&#39;)

head(alc_long)</code></pre>
<pre><code>##     id male      peer coa age alcuse.14
## 1.1  1    0 1.2649111   1   1  1.732051
## 2.1  2    1 0.8944272   1   1  0.000000
## 3.1  3    1 0.8944272   1   1  1.000000
## 4.1  4    1 1.7888544   1   1  0.000000
## 5.1  5    0 0.8944272   1   1  0.000000
## 6.1  6    1 1.5491934   1   1  3.000000</code></pre>
<p>Das Problem mit dieser neuen Variable ist jetzt noch, dass sie nicht das korrekte Alter der Jugendlichen kodiert, sondern stattdessen einfach bei 1 anfängt und hoch zählt. Auch das können wir per Argument ändern:</p>
<pre class="r"><code>alc_long &lt;- reshape(data = alc,
  varying = list(c(&#39;alcuse.14&#39;, &#39;alcuse.15&#39;, &#39;alcuse.16&#39;)),
  direction = &#39;long&#39;,
  timevar = &#39;age&#39;,
  times = c(14, 15, 16))

head(alc_long)</code></pre>
<pre><code>##      id male      peer coa age alcuse.14
## 1.14  1    0 1.2649111   1  14  1.732051
## 2.14  2    1 0.8944272   1  14  0.000000
## 3.14  3    1 0.8944272   1  14  1.000000
## 4.14  4    1 1.7888544   1  14  0.000000
## 5.14  5    0 0.8944272   1  14  0.000000
## 6.14  6    1 1.5491934   1  14  3.000000</code></pre>
<p>Zu guter Letzt wird für die neuen Variablen automatisch der erste Name wiederverwendet. Hier ist der Name der neuen, messwiederholten Variable also <code>alcuse.14</code>. Weil in der Variable aber jetzt nicht mehr nur der Alkoholkonsum im 14. Lebensjahr enthalten ist, sondern für alle Jahre von 14 bis 16, bietet es sich an, hier auch einen allgemeineren Namen zu verwenden:</p>
<pre class="r"><code>alc_long &lt;- reshape(data = alc,
  varying = list(c(&#39;alcuse.14&#39;, &#39;alcuse.15&#39;, &#39;alcuse.16&#39;)),
  direction = &#39;long&#39;,
  timevar = &#39;age&#39;,
  times = c(14, 15, 16),
  v.names = &#39;alcuse&#39;)

head(alc_long)</code></pre>
<pre><code>##      id male      peer coa age   alcuse
## 1.14  1    0 1.2649111   1  14 1.732051
## 2.14  2    1 0.8944272   1  14 0.000000
## 3.14  3    1 0.8944272   1  14 1.000000
## 4.14  4    1 1.7888544   1  14 0.000000
## 5.14  5    0 0.8944272   1  14 0.000000
## 6.14  6    1 1.5491934   1  14 3.000000</code></pre>
<div id="rückübertragung-in-breites-format" class="section level5">
<h5>Rückübertragung in breites Format</h5>
<p>Der Vollständigkeit halber können wir auch noch überlegen, wie man diesen Datensatz dann wieder in das breite Format zurück übertragen kann. Dafür benötigt man fünf Argumente:</p>
<ul>
<li><code>data</code>: der Datensatz</li>
<li><code>v.names</code>: Variablen die wiederholt gemessen wurden (und sich über die Messungen unterscheiden können)</li>
<li><code>timevar</code>: die Variable, die Wiederholungen kennzeichnet</li>
<li><code>idvar</code>: der Personen-Identifikator</li>
<li><code>direction</code>: das Zielformat des neuen Datensatzes</li>
</ul>
<pre class="r"><code>alc_wide &lt;- reshape(alc_long, 
            v.names = &#39;alcuse&#39;, 
            timevar = &#39;age&#39;, 
            idvar = &#39;id&#39;, 
            direction = &#39;wide&#39;)
head(alc_wide)</code></pre>
<pre><code>##      id male      peer coa alcuse.14 alcuse.15 alcuse.16
## 1.14  1    0 1.2649111   1  1.732051         2  2.000000
## 2.14  2    1 0.8944272   1  0.000000         0  1.000000
## 3.14  3    1 0.8944272   1  1.000000         2  3.316625
## 4.14  4    1 1.7888544   1  0.000000         2  1.732051
## 5.14  5    0 0.8944272   1  0.000000         0  0.000000
## 6.14  6    1 1.5491934   1  3.000000         3  3.162278</code></pre>
<p>Für Variablen, die nicht explizit aufgeführt werden, wird von <code>reshape</code> wieder angenommen, dass es nicht wiederholt gemessene “feste” Variablen sind. Im vorliegenden Fall sind Geschlecht (<code>male</code>) und die Menge alkoholkonsumierender Peers (<code>peer</code>) nur ein Mal gemessen worden und können daher nicht über Messzeitpunkte variieren. Um Variablen bei der Transformation aus dem Datensatz zu entfernen, kann das <code>drop</code> Argument genutzt werden.</p>
<p>Wenn ein Datensatz durch <code>reshape</code> umgewandelt wurde - z.B. dann, wenn man einen Datensatz mit unterschiedlichen Auswertungsansätzen untersucht und zwischen den Formaten wechseln muss - kann er mit <code>reshape(data)</code> direkt in seine Ursprungsform zurückgewandelt werden.</p>
</div>
</div>
</div>
<div id="einfaktorielle-anova-mit-messwiederholung" class="section level2">
<h2>Einfaktorielle ANOVA (mit Messwiederholung)</h2>
<p>Zur Untersuchung von Veränderung können wir die - in den letzten Sitzungen behandelten - Funktionen aus dem <code>ez</code>-Paket wieder benutzen. Dafür gucken wir uns zuerst die Deskriptivstatistik an und führen dann die ANOVA durch.</p>
<div id="deskriptivstatistik" class="section level3">
<h3>Deskriptivstatistik</h3>
<p>In diesem Fall ist von Interesse, wie sich der <strong>Alkoholkonsum von Jugendlichen zwischen 14 und 16 verändert</strong>. Dafür können wir zunächst deskriptiv betrachten, wie die Mittelwerte sich über die Zeit verändern:</p>
<pre class="r"><code>library(ez)
ezStats(alc_long, alcuse, id, within = age)</code></pre>
<pre><code>## Warning: &quot;age&quot; will be treated as numeric.</code></pre>
<pre><code>## Warning: There is at least one numeric within variable, therefore aov() will be
## used for computation and no assumption checks will be obtained.</code></pre>
<pre><code>##   age  N      Mean       SD      FLSD
## 1  14 82 0.6304662 0.938912 0.2500601
## 2  15 82 0.9636295 1.047373 0.2500601
## 3  16 82 1.1717690 1.135350 0.2500601</code></pre>
<p><code>ezStats</code> wartet hier direkt mit einer Warnung auf, die darauf hinweist, dass <code>age</code> als numerische Variable vorliegt. Weil in der Varianzanalyse davon ausgegangen wird, dass die unabhängigen Variablen nominalskaliert sind, möchte das <code>ez</code>-Paket sie auch im dazugehörigen Format. Deswegen wandeln wir die Altersvariable schnell in einen <code>factor</code> um:</p>
<pre class="r"><code>alc_long$age &lt;- as.factor(alc_long$age)</code></pre>
<p>Jetzt sollte der <code>ezStats</code>-Befehl ohne die Warnung funktionieren:</p>
<pre class="r"><code>ezStats(alc_long, alcuse, id, within = age)</code></pre>
<pre><code>##   age  N      Mean       SD      FLSD
## 1  14 82 0.6304662 0.938912 0.2165844
## 2  15 82 0.9636295 1.047373 0.2165844
## 3  16 82 1.1717690 1.135350 0.2165844</code></pre>
<p>Statt das Argument <code>between</code> wie in den letzten Sitzungen zu nutzen, wird mithilfe des <code>within</code> Arguments die Variable benannt, die zwischen Messungen <em>innerhalb</em> der gleichen Personen unterscheidet. In diesem Fall unterscheiden sich die Messungen der gleichen Personen bezogen auf das Alter, zu dem Sie befragt wurden. Deskriptiv zeigt sich (vielleicht nicht allzu überraschend) ein Anstieg des Alkoholkonsums über die Jahre. Grafisch dargestellt:</p>
<pre class="r"><code>ezPlot(alc_long, alcuse, id, within = age,
  x = age)</code></pre>
<p><img src="/post/2021-05-26_ANOVA-III_files/figure-html/unnamed-chunk-14-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>Wie schon in der <a href="/post/anova2/">letzten Sitzung</a> erklärt, sind die Intervalle um die Mittelwerte herum die <em>Fisher’s Least Significant Difference</em> (FLSD) - wenn sich zwei Mittelwerte um diesen Betrag unterscheiden, sollten sie auch statistisch bedeutsam sein.</p>
</div>
<div id="ezanova-für-messwiederholungen" class="section level3">
<h3><code>ezANOVA</code> für Messwiederholungen</h3>
<p>Als Äquivalent zur Homoskedastizitätsannahme in der ANOVA <em>ohne</em> Messwiederholung, wird in der ANOVA <em>mit</em> Messwiederholung die <strong>Sphärizitätsannahme</strong> getroffen. Unter dieser Annahme sollten die Varianzen der Differenzen zwischen allen Zeitpunkten identisch sein (vgl. <a href="https://hds.hebis.de/ubffm/Record/HEB366849158">Eid et al., 2017</a>, S. 474 f.). Im breiten Datenformat sind diese Differenzen einfach zu erstellen:</p>
<pre class="r"><code>alc$diff_1415 &lt;- alc$alcuse.15 - alc$alcuse.14
alc$diff_1416 &lt;- alc$alcuse.16 - alc$alcuse.14
alc$diff_1516 &lt;- alc$alcuse.16 - alc$alcuse.15
var(alc[, c(&#39;diff_1415&#39;, &#39;diff_1416&#39;, &#39;diff_1516&#39;)])</code></pre>
<pre><code>##            diff_1415 diff_1416  diff_1516
## diff_1415  0.7235404 0.5391093 -0.1844311
## diff_1416  0.5391093 1.2951897  0.7560804
## diff_1516 -0.1844311 0.7560804  0.9405115</code></pre>
<p>Wir konzentrieren uns auf die Diagonale. Rein deskriptiv lässt sich erkennen, dass die Varianz der Differenz zwischen 14 und 16 Jahren beinahe doppelt so groß ist, wie die zwischen 14 und 15 Jahren. Wie schon bei der Homoskedastizitätsannahme, wird auch die Sphärizität von <code>ezANOVA</code> mitgetestet:</p>
<pre class="r"><code>ezANOVA(data = alc_long, dv = alcuse, wid = id, within = age)</code></pre>
<pre><code>## $ANOVA
##   Effect DFn DFd        F            p p&lt;.05       ges
## 2    age   2 162 12.39539 9.793248e-06     * 0.0441567
## 
## $`Mauchly&#39;s Test for Sphericity`
##   Effect         W           p p&lt;.05
## 2    age 0.8858857 0.007854286     *
## 
## $`Sphericity Corrections`
##   Effect       GGe        p[GG] p[GG]&lt;.05       HFe        p[HF] p[HF]&lt;.05
## 2    age 0.8975739 2.342158e-05         * 0.9166239 1.991144e-05         *</code></pre>
<p>Der sogenannte <strong>Mauchly Test</strong> (<code>Mauchly's Test for Sphericity</code>) zeigt hier an, dass es bedeutsame Abweichungen von der <em>Annahme der Sphärizität</em> gibt (<span class="math inline">\(p\)</span> &lt; .05), die Annahme also nicht als gegeben betrachtet werden kann. Weil diese Situation sehr häufig vorkommt, gibt es eine Reihe verbreiteter Korrekturen, von denen <code>ezANOVA</code> die <strong>Greenhouse-Geisser</strong> (<code>GGe</code>) und die <strong>Huynh-Feldt Korrekturen</strong> (<code>HFe</code>) anbietet. Es hat sich gezeigt, dass die <em>Greenhouse-Geisser Korrektur</em> mitunter zu strikt ist (also zu selten bedeutsame Ergebnisse gefunden werden), weswegen beide Varianten ausgegeben werden.</p>
<p>In diesem Fall können also der ersten Tabelle der <span class="math inline">\(F\)</span>-Wert und das generalisierte <span class="math inline">\(\eta^2\)</span> entnommen werden, der korrekte <span class="math inline">\(p\)</span>-Wert bezüglich der Hypothesenprüfung sollte allerdings der dritten, korrigierten Tabelle entnommen werden, weil der <em>Mauchly Test</em> gezeigt hat, dass die Sphärizitätsannahme nicht hält. In unserem Fall (egal, ob wir Greenhouse-Geisser oder Huynh-Feldt nutzen) zeigt sich <strong>ein bedeutsamer Unterschied im Alkoholkonsum zwischen dem 14, 15 und 16. Lebensjahr</strong> (<span class="math inline">\(p\)</span> &lt; .05).</p>
<p>Ob es sich hier um einen konstanten Anstieg handelt, der Alkoholkonsum stetig abnimmt, oder aber im Alter von 15 Jahren den Höhepunkt erreicht wird, können wir aus diesen Ergebnissen allein nicht unterscheiden. Wie bereits aus den letzten beiden Sitzungen bekannt ist, bietet die ANOVA uns einen Omnibustest dafür, <em>ob</em> es Unterschiede gibt. Um genauer zu verstehen, <em>welche</em> Unterschiede es gibt, können wir <a href="#Kontraste">Kontraste</a> nutzen.</p>
</div>
<div id="effektgröße-und-intraklassenkorrelation" class="section level3">
<h3>Effektgröße und Intraklassenkorrelation</h3>
<p>Die <strong>Intraklassenkorrelation</strong> (ICC) bezeichnet generell das Ausmaß, in dem die Varianz von Beobachtungen von der “Klasse” abhängen, aus dem diese Beobachtungen kommen. Im Fall von Längsschnittanalysen bedeutet das, dass die ICC das Ausmaß von <em>intraindividueller Stabilität</em> anzeigt. Effektgrößen sollten unter Berücksichtigung dieser Stabilität interpretiert werden. Eine generelle Richtlinie für die ICC-bedingte Interpretation von <span class="math inline">\(\eta^2\)</span> liefert Cohen (1988), hier dargestellt nach <a href="https://hds.hebis.de/ubffm/Record/HEB366849158">Eid et al. (2017</a>, S. 478):</p>
<table>
<thead>
<tr class="header">
<th>ICC</th>
<th>klein</th>
<th>mittel</th>
<th>groß</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>.20</td>
<td>.012</td>
<td>.074</td>
<td>.169</td>
</tr>
<tr class="even">
<td>.40</td>
<td>.016</td>
<td>.096</td>
<td>.213</td>
</tr>
<tr class="odd">
<td>.60</td>
<td>.024</td>
<td>.138</td>
<td>.289</td>
</tr>
<tr class="even">
<td>.80</td>
<td>.048</td>
<td>.242</td>
<td>.449</td>
</tr>
</tbody>
</table>
<p>Die ICC kann generell als <span class="math inline">\(\frac{\sigma^2_{\pi}}{\sigma^2_{\pi} + \sigma^2_{\epsilon}}\)</span> berechnet werden. Dabei ist <span class="math inline">\(\sigma^2_{\pi}\)</span> die Personenvarianz und <span class="math inline">\(\sigma^2_{\epsilon}\)</span> die Residualvarianz. Beide können direkt aus den mittleren Quadratsummen berechnet werden. Alternativ kann die <code>ICC</code>-Funktion aus dem <code>psych</code>-Paket genutzt werden:</p>
<pre class="r"><code>psych::ICC(alc[, c(&#39;alcuse.14&#39;, &#39;alcuse.15&#39;, &#39;alcuse.16&#39;)])</code></pre>
<pre><code>## Call: psych::ICC(x = alc[, c(&quot;alcuse.14&quot;, &quot;alcuse.15&quot;, &quot;alcuse.16&quot;)])
## 
## Intraclass correlation coefficients 
##                          type  ICC   F df1 df2       p lower bound upper bound
## Single_raters_absolute   ICC1 0.51 4.1  81 164 1.4e-14        0.40        0.61
## Single_random_raters     ICC2 0.51 4.6  81 162 6.3e-17        0.40        0.62
## Single_fixed_raters      ICC3 0.55 4.6  81 162 6.3e-17        0.44        0.64
## Average_raters_absolute ICC1k 0.75 4.1  81 164 1.4e-14        0.67        0.82
## Average_random_raters   ICC2k 0.76 4.6  81 162 6.3e-17        0.67        0.83
## Average_fixed_raters    ICC3k 0.78 4.6  81 162 6.3e-17        0.71        0.84
## 
##  Number of subjects = 82     Number of Judges =  3
## See the help file for a discussion of the other 4 McGraw and Wong estimates,</code></pre>
<p>Der in diesem Fall relevante ICC-Typ (<code>type</code>) ist als <code>ICC1</code> gelistet. In diesem Fall (ICC = .51) bedeutet es also, dass ca. 50% der Unterschiede zwischen Messungen auf stabile Personeneigenschaften zurückgehen. In Anbetracht dieser ICC, hat das Alter mit einem <span class="math inline">\(\eta^2\)</span> von <em>.016</em> &lt; <span class="math inline">\(\eta^2\)</span> = .0442 &lt; <em>.096</em> also einen kleinen Effekt auf das Ausmaß an Alkoholkonsum bei Jugendlichen.</p>
</div>
</div>
<div id="Kontraste" class="section level2">
<h2>Kontraste</h2>
<p>Wie für eine <a href="/post/anova2/">ANOVA ohne Messwiederholung</a>, kann auch in diesem Fall mit dem <code>emmeans</code>-Paket die Kontrastanalyse durchgeführt werden.</p>
<pre class="r"><code>library(emmeans)</code></pre>
<p>Die <code>contrast</code>-Funktion des Pakets benötigt als Input ein <code>aov</code>-Objekt. Um zu kennzeichnen, dass es sich um eine ANOVA mit Messwiederholung handelt, muss dabei <code>Error()</code> benutzt werden, um die Personen ID und die Zeitvariable in Beziehung zu setzen. Genauso kann uns natürlich auch <code>ezANOVA</code> diese Arbeit abnehmen, indem wir das nötige Argument spezifizieren, allerdings scheint es hier zurzeit Probleme mit dem Paket zu geben, weswegen wir hier nun auf <code>aov</code> ausweichen müssen:</p>
<pre class="r"><code># aov-Objekt erzeugen
wdh_aov &lt;- aov(alcuse ~ age + Error(id/age), 
  data = alc_long)
wdh_aov</code></pre>
<pre><code>## 
## Call:
## aov(formula = alcuse ~ age + Error(id/age), data = alc_long)
## 
## Grand Mean: 0.9219549
## 
## Stratum 1: id
## 
## Terms:
##                 Residuals
## Sum of Squares   184.7733
## Deg. of Freedom        81
## 
## Residual standard error: 1.510348
## 
## Stratum 2: id:age
## 
## Terms:
##                      age Residuals
## Sum of Squares  12.22698  79.89952
## Deg. of Freedom        2       162
## 
## Residual standard error: 0.7022869
## Estimated effects may be unbalanced</code></pre>
<pre class="r"><code># Kontraste vorbereiten
em &lt;- emmeans(wdh_aov, ~ age)</code></pre>
<pre><code>## Note: re-fitting model with sum-to-zero contrasts</code></pre>
<pre class="r"><code>em</code></pre>
<pre><code>##  age emmean    SE  df lower.CL upper.CL
##  14   0.630 0.115 152    0.403    0.858
##  15   0.964 0.115 152    0.736    1.191
##  16   1.172 0.115 152    0.944    1.399
## 
## Warning: EMMs are biased unless design is perfectly balanced 
## Confidence level used: 0.95</code></pre>
<p>Die Formel wird wie folgt aufgestellt: links steht die abhängige Variable (hier <code>alcuse</code>) getrennt von der <code>~</code> stehen dann die Gruppenvariablen (hier die Zeit: <code>age</code>) anschleißend wird mir <code>Error</code> spezifiziert, welche Variable die Messwiederholung anzeigt (<code>id</code>, da alle gleichen Ausprägungen zur gleichen Person gehören). Da es sich bei <code>age</code> allerdings um eine Innersubjektvariable (eine Within-Variable) handelt, müssen wir dies vermerken, indem wir in <code>Error(id/times)</code> noch “<code>id/times</code>” hinzufügen, was quasi sagt, dass innerhalb einer Person die Gruppen betrachtet werden. In den <code>aov</code>-Objekten werden uns ein paar zusätzliche Infos mit ausgegen, nämlich die Quadratsummenzerlegung in Effekt, Person und Fehler. Die Variation, die auf die Personen zurückzuführen ist, steht unter <code>Stratum 1: id</code>, während die Effekte der Zeit unter <code>Stratum 2: id:age</code> zu finden sind.</p>
<div id="polynomiale-kontraste-und-trendanalysen" class="section level3">
<h3>Polynomiale Kontraste und Trendanalysen</h3>
<p>In der <a href="/post/anova2/">letzten Sitzung</a> hatten wir den <code>contrast</code>-Befehl genutzt, um beliebige Kontraste zu definieren. Bei <em>messwiederholten</em> Designs mit dem Ziel, Veränderung über die Zeit zu untersuchen, ist es meist sinnvoll zu prüfen, ob die Veränderung über die Zeit durch eine einfache Funktion der Zeit beschrieben werden kann. Für den Zeitverlauf werden häufig Polynome genutzt, wie Sie sie in der <a href="/post/quadratische-und-moderierte-regression/">4. Regressionssitzung</a> gesehen haben. Hierbei ist zu beachten, dass herkömmliche Kontraste immer so aufgestellt werden, dass das <strong>Verwerfen der Null-Hypothese gegen den Kontrast spricht</strong>. Bspw. wenn wir annehmen, dass zwei bestimmte Mittelwerte gleich sind, dann verwerfen wir diese Hypothese bei einem signifikanten Hypothesentest und einer entsprechend großen Teststatistik.</p>
<p>Bei sogenannten <strong>Trendanalysen</strong>, bei denen wir Veränderungen über bspw. die Zeit bei Messwiederholungsdesigns untersuchen, ist dies anders. Hier wird in der Regel eine ganze Batterie an orthogonalen Kontrasten verwendet, die <em>sukzessive</em> verschiedene Verläufe testet, wobei hier die Null-Hypothese besagt, dass der jeweilige Verlauf <em><strong>nicht</strong></em> gilt. Dies bedeutet im Umkehrschluss, dass bei Trendanalysen die Signifikanz einer Hypothese besagt, dass mindestens dieser Verlauf gilt (auf das <em>“mindestens”</em> gehen wir noch näher ein).</p>
<p>In unserem Beispiel haben wir 3 Messzeitpunkte, also 3 Mittelwerte, die wir auf Trends testen können. Bei 3 Mittelwerten können wir <em>maximal einen quadratischen Verlauf</em> testen und es können <em>maximal zwei orthogonale Kontraste</em> aufgestellt werden (immer K - 1 viele, wobei K die Anzahl an Gruppen ist; hier Gruppen = Messzeitpunkte).
<strong>Welche Verläufe sind nun möglich?</strong> Die Null-Hypothese einer normalen ANOVA besagt, dass alle Mittelwerte gleich sind. Übersetzt in das Messwiederholungsdesign bedeutet dies, dass sich die Mittelwerte nicht über die Zeit verändern: <em>die Mittelwerte folgen einer <strong>horizontalen Linie</strong> (im Regressionssetting bedeutet dies, dass es keine Beziehung mit der Zeit/der Wiederholungsmessung gibt; die Steigung ist Null)</em>. Folgen die Mittelwerte keiner horziontalen Linie, sondern <em>verändern sich gleichmäßig über die Zeit</em>, so <strong>steigen sie linear an oder fallen linear ab</strong>. Zeigen die Mittelwerte hingegen ein <em>beschleunigtes Wachstum oder einen beschleunigten Abfall</em> oder steigen sie erst an und fallen dann ab oder fallen erst ab und steigen dann an, so folgen sie vermutlich keinem linearen Trend mehr. Hier wäre der <strong>quadratische Trend</strong> geeigneter, um dieses Verhalten zu erklären.</p>
<p>Folglich haben wir <strong>drei Trends</strong>, die wir untersuchen können: <strong>horizontal, linear und quadratisch</strong>. Entsprechend werden auch die Hypothesen aufgestellt. Die erste Kontrasthypothese in diesem Beispiel ist, dass ein horizontaler Verlauf gilt. Ist diese Hypothese signifikant, so wird sie verworfen und es gilt kein horizontaler Verlauf. Aus diesem Grund wird diese Hypothese auch häufig die <strong>Hypothese auf linearen Trend</strong> genannt; ist sie signifikant so gilt mindestens ein linearer Trend in den Daten (mit einer Irrtumswahrscheinlichkeit von <span class="math inline">\(5\%\)</span>). Das mindestens steht hier, weil auch ein quadratischer Trend dem horizontalen Verlauf widerspricht. Wir brauchen also noch einen weiteren Hypothesentest, der den <strong>linearen gegen den quadratischen Verlauf</strong> testet. Sie denken es sich vielleicht schon, die nächste Null-Hypothese testet auf <em>linearen Trend</em>. Wird diese verworfen, so gilt kein linearer Verlauf sondern ein quadratischer. Der quadratische Trend beschreibt die Daten signifikant besser als der lineare. Aus diesem Grund wird dieser Kontrast auch häufig der <strong>Kontrast auf quadratischen Trend</strong> genannt. Ist er signifikant, so können wir für die Daten einen quadratischen Trend annehmen. Diese Informationen sind in folgender Tabelle nochmals zusammengefasst:</p>
<table>
<thead>
<tr class="header">
<th>Kontrastnahme</th>
<th><span class="math inline">\(H_0\)</span></th>
<th><span class="math inline">\(H_1\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><em>linear</em></td>
<td>horizontal: <span class="math inline">\(y = c\)</span></td>
<td>linear: <span class="math inline">\(y = bx + c\)</span></td>
</tr>
<tr class="even">
<td><em>quadratisch</em></td>
<td>linear: <span class="math inline">\(y = bx + c\)</span></td>
<td>quadratisch: <span class="math inline">\(y = ax^2 +bx + c\)</span></td>
</tr>
</tbody>
</table>
<p>Der Tabelle entnehmen wir, dass quasi immer ein Term hinzukommt (von “<span class="math inline">\(c\)</span>” zu “<span class="math inline">\(bx + c\)</span>” zu “<span class="math inline">\(ax^2 + bx + c\)</span>”). Die Signifikanzentscheidung entspricht also dem inkrementellen Vorgehen, welches wir bereits aus der Regressionsanalyse kennen! Das bedeutet also, falls der lineare Trend signifikant ist, dann verbessert er gegenüber des horizontalen Trends die Vorhersage des Mittelwertsverlaufs. Genauso spricht ein signifikanter quadratischer Trend für eine Verbesserung der Vorhersage gegenüber des linearen Trends!</p>
<p>Die erste Funktion, die üblicherweise getestet wird, ist der <strong>lineare Verlauf</strong>. Dabei wird unterstellt, dass die Mittelwerte auf einer <em>geraden Linie</em> liegen, die eine uns vorerst unbekannte Steigung hat. Wie bei <a href="https://hds.hebis.de/ubffm/Record/HEB366849158">Eid et al. (2017</a>, S. 481) dargestellt, ergibt sich daraus die Linearkombination</p>
<p><span class="math display">\[\Lambda = K_1 \cdot \mu_1 + K_2 \cdot \mu_2 + \ldots + K_J \cdot \mu_J\]</span></p>
<p>wobei <span class="math inline">\(K_j\)</span> die jeweiligen Kontrastkoeffizienten sind. Wie in der <a href="/post/anova2/">letzten Sitzung</a> behandelt, wird für Kontrastkoeffizienten die Restriktion aufgestellt, dass <span class="math inline">\(\sum_{j=1}^{J} K_j = 0\)</span> (die Summe aller Kontrastkoeffizienten muss 0 sein). Für einen linearen Trend müssen die <span class="math inline">\(K_j\)</span> jetzt so gewählt werden, dass sie mit den Zeitabständen zwischen den wiederholten Messungen korrespondieren. In unserem Fall geht es um 3 aufeinanderfolgende Jahre - die Abstände zwischen den Wiederholungen sind also gleich (jeweils 1 Jahr) - sodass der lineare Vektor einfach ist:</p>
<pre class="r"><code>lin_cont &lt;- c(-1, 0, 1)</code></pre>
<p>Wie schon für die Kontraste in der <a href="/post/anova2/">letzten Sitzung</a> wird hierbei die Nullhypothese getestet, dass <span class="math inline">\(H_0 : -1 \cdot \mu_1 + 0 \cdot \mu_2 + 1 \cdot \mu_3 = 0\)</span>. Im Fall von drei Wiederholungen ist der lineare Trend also einfach die <strong>Differenz zwischen 1. und 3. Messung</strong>. Dies liegt daran, dass wir den linearen Verlauf gegen eine <em>horizontale Linie</em> absichern wollen. Das schaffen wir, indem wir annehmen, dass sich die Mittelwerte über die Zeit nicht verändern, also, dass der Abstand vom Mittelpunkt in beide Richtungen gleich groß ist und sich das Vorzeichen nicht verändert: <span class="math inline">\(\mu_2 - \mu_1 = \mu_2 - \mu_3\)</span>. Hier ist es extrem wichtig, dass wir das gleiche <span class="math inline">\(\mu\)</span> (hier <span class="math inline">\(\mu_2\)</span>) zuerst nennen, da wir sonst fälschlicherweise einen linearen Trend testen würden. Wenn wir diese kleine Gleichung nun umformen und auf beiden Seiten <span class="math inline">\(\mu_2\)</span> abziehen und anschließend beide Seiten mit <span class="math inline">\(\mu_3\)</span> addieren, dann erhalten wir: <span class="math inline">\(-\mu_1 + \mu_3 = 0\)</span> also die Kontrastkoeffizienten (-1, 0, 1), wie wir sie oben schon aufgeschrieben hatten.</p>
<p>Wir können uns anschauen, inwiefern der lineare Verlauf eine realistische Behauptung über den Mittelwertsverlauf ist. Wie in der <a href="/post/anova2/">letzten Sitzung</a> behandelt, erstellen wir mit <code>ezPlot</code> automatisch einen <code>ggplot</code> mit der gleichen Snytax wie bei <code>ezANOVA</code>. Der Grund, aus dem <code>ggplot2</code> als Paket so beliebt ist, ist, dass es modular funktioniert und wir unsere Abbildungen schichten können (wie in der <a href="/post/grafiken-mit-ggplot2/">2. Sitzung</a> behandelt). Wenn Pakete also <code>ggplot2</code>-Abbildungen erstellen, können wir diese einfach durch andere <code>ggplot2</code>-Komponenten ergänzen (wenn wir vorher <code>ggplot2</code> geladen haben):</p>
<pre class="r"><code>library(ggplot2)</code></pre>
<p>Zur Erinnerungen können Sie die Abbildung nach Ihren Wünschen umgestalten, wie in der <a href="/post/grafiken-mit-ggplot2/">2. Sitzung</a> besprochen:</p>
<pre class="r"><code># ezPlot siehe oben
ezPlot(alc_long, alcuse, id, within = age,
  x = age) +
# beliebige ggplot Erweiterungen anfügen
  theme_minimal() +
  xlab(&#39;Alter&#39;)</code></pre>
<p><img src="/post/2021-05-26_ANOVA-III_files/figure-html/ezplot_theme-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>Um Verläufe darzustellen, hatten wir in der <a href="/post/grafiken-mit-ggplot2/">2. Sitzung</a> und der <a href="/post/nichtlineare-regression/">8. Sitzung</a> <code>geom_smooth()</code> kennen gelernt. Weil diese Geometrie als Schicht auf den ursprünglichen Plot gelegt werden kann, können wir den linearen Verlauf veranschaulichen:</p>
<pre class="r"><code>ezPlot(alc_long, alcuse, id, within = age,
  x = age) +
  geom_smooth(aes(x = as.numeric(age)), method = &#39;lm&#39;, se = FALSE)</code></pre>
<pre><code>## `geom_smooth()` using formula &#39;y ~ x&#39;</code></pre>
<p><img src="/post/2021-05-26_ANOVA-III_files/figure-html/unnamed-chunk-22-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>Weil wir für <code>ezANOVA</code> das Alter in einen Faktor umgewandelt hatten, müssen wir es für <code>geom_smooth</code> erst noch in eine numerische Variable zurücküberführen (<code>as.numeric</code>). Dann wählen wir mit <code>method = 'lm'</code> das lineare Modell und unterdrücken mit <code>se = FALSE</code> das Konfidenzintervall um die Regressionsgerade. In unserem Kontrast für den linearen Effekt prüfen wir den Anstieg dieser Geraden (oben als <span class="math inline">\(\Lambda\)</span> notiert):</p>
<pre class="r"><code>contrast(em, list(lin_cont))</code></pre>
<pre><code>##  contrast    estimate   SE  df t.ratio p.value
##  c(-1, 0, 1)    0.541 0.11 162   4.935  &lt;.0001</code></pre>
<p>Wie wir an dem <code>p.value</code> erkennen können, ist der Kontrast signifikant, es liegt also mindestens ein linearer Trend vor. Im nächsten Schritt können wir prüfen, ob ein <strong>quadratischer Effekt</strong> vorliegt. Für diesen Effekt ist es eventuell nicht so direkt einleuchtend, wie der Kontrastvektor auszusehen hat. Auch hier gilt, dass <span class="math inline">\(\sum_{j=1}^{J} K_j = 0\)</span> sein muss. Gleichzeitig müssen wir drei Zahlen finden, die einen quadratischen Verlauf darstellen. Darüber hinaus müssen der quadratische Kontrast und der lineare Kontrast <strong>orthogonal</strong> sein, wenn wir sie gleichzeitig prüfen wollen (siehe <a href="https://hds.hebis.de/ubffm/Record/HEB366849158">Eid et al., 2017</a>, S. 426). Wir wissen, dass der Test auf den quadratischen Trend dem des linearen Trends widersprechen soll. Dies erreichen wir, indem wir tatsächlich einen Kontrast auf linearen Verlauf aufstellen. Das erscheint jetzt etwas paradox, da wir uns ja im zuvorigen Test bereits dafür entschlossen hatten, dass in den Daten <em>mindestens</em> ein linearer Trend verborgen ist. Wir wollen allerdings einen Kontrast erstellen, der, falls er signifikant ist, gegen einen linearen und für einen quadratischen Verlauf spricht. Folglich müssen wir <em>Linearität annehmen</em>, indem wir uns vorstellen, dass die Veränderung von <span class="math inline">\(\mu_1\)</span> zu <span class="math inline">\(\mu_2\)</span> genauso groß ist, wie von <span class="math inline">\(\mu_2\)</span> zu <span class="math inline">\(\mu_3\)</span>. Hier ist nun die Richtung (und damit das Vorzeichen) entscheidend, denn in Worten gesprochen klingt das zunächst sehr ähnlich zu dem, was wir oben getestet haben. Wenn wir allerdings die Richtung berücksichtigen, so erhalten wir bspw: <span class="math inline">\(\mu_2 - \mu_1 = \mu_3 - \mu_2\)</span>, was sich umformen lässt zu <span class="math inline">\(\mu_1 - 2\mu_2 + \mu_3 = 0\)</span>. Dieser Kontrast ist offensichtlich <em>orthogonal</em> zum Kontrast auf linearen Trend (also den, den wir zuvor getestet haben!), denn: <span class="math inline">\(-1*1 + 0*-2 + 1*1 = 0\)</span> (hier ist die erste Zahl pro Summand jeweils der Koeffizient des ersten Kontrasts und die zweite jeweils die vom zweiten: (-1, 0, 1) und (1, -2, 1)).</p>
<p>Um Ihnen das Leben ein wenig zu erleichtern, können Sie folgende Tabelle konsultieren, wenn Sie gleichabständige Messungen vorliegen haben und polynomiale Kontraste definieren wollen:</p>
<table>
<thead>
<tr class="header">
<th align="center">Zeitpunkte</th>
<th align="center">Polynom</th>
<th align="center">Vektor</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">2</td>
<td align="center">1 (linear)</td>
<td align="center"><span class="math inline">\([-1, 1]\)</span></td>
</tr>
<tr class="even">
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr class="odd">
<td align="center">3</td>
<td align="center">1 (linear)</td>
<td align="center"><span class="math inline">\([-1, 0, 1]\)</span></td>
</tr>
<tr class="even">
<td align="center"></td>
<td align="center">2 (quadratisch)</td>
<td align="center"><span class="math inline">\([1, -2, 1]\)</span></td>
</tr>
<tr class="odd">
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr class="even">
<td align="center">4</td>
<td align="center">1 (linear)</td>
<td align="center"><span class="math inline">\([-3, -1, 1, 3]\)</span></td>
</tr>
<tr class="odd">
<td align="center"></td>
<td align="center">2 (quadratisch)</td>
<td align="center"><span class="math inline">\([1, -1, -1, 1]\)</span></td>
</tr>
<tr class="even">
<td align="center"></td>
<td align="center">3 (kubisch)</td>
<td align="center"><span class="math inline">\([-1, 3, -3, 1]\)</span></td>
</tr>
</tbody>
</table>
<p>Diese Tabelle ist natürlich ziemlich lang erweiterbar. Wie Sie sehen, können Polynome immer für <span class="math inline">\(t-1\)</span> Grade bestimmt werden - für drei Messzeitpunkte, kann also bis zum quadratischen Trend geprüft werden. Abgebildet sieht der quadratische Verlauf der Mittelwerte (rote Linie) so aus:</p>
<pre class="r"><code>ezPlot(alc_long, alcuse, id, within = age,
  x = age) +
  geom_smooth(aes(x = as.numeric(age)), method = &#39;lm&#39;, se = FALSE) +
  geom_smooth(aes(x = as.numeric(age)), method = &#39;lm&#39;, se = FALSE,
    formula = y ~ x + I(x^2), color = &#39;red&#39;)</code></pre>
<pre><code>## `geom_smooth()` using formula &#39;y ~ x&#39;</code></pre>
<p><img src="/post/2021-05-26_ANOVA-III_files/figure-html/unnamed-chunk-24-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>Wir erkennen deutlich, dass alle Mittelwerte auf dem quadratischen Trend liegen. Das ist allerdings auch einleuchtend, da es immer so ist, dass für <span class="math inline">\(t\)</span> Zeitpunkte ein Polynom bis zum Grad <span class="math inline">\(t-1\)</span> (also: <span class="math inline">\(a_0 + a_1X + a_2X^2 + \dots + a_{t-1}X^{t-1}\)</span>) gefunden werden kann, dass alle Punkte trifft, solang nicht mehrere Punkte den gleichen <span class="math inline">\(x\)</span>-Wert haben. Die Frage ist nun, ob der quadratische Trend eine signifikante Verbesserung gegenüber dem linearen Trend ist!</p>
<p>Wir wollen nun also untersuchen, ob es in den Daten einen quadratischen Trend gibt, indem wir dafür den entsprechenden Kontrast definieren und die Kontrastprüfung gleichzeitig für den linearen und quadratischen Effekt durchführen! Wir sollten dabei nicht vergessen, die <span class="math inline">\(p\)</span>-Werte einer Bonferroni-Korrektur zu unterziehen!</p>
<pre class="r"><code>lin_cont &lt;- c(-1, 0, 1)
qua_cont &lt;- c(1, -2, 1)

contrast(em, list(lin_cont, qua_cont),
  adjust = &#39;bonferroni&#39;)</code></pre>
<pre><code>##  contrast    estimate   SE  df t.ratio p.value
##  c(-1, 0, 1)    0.541 0.11 162   4.935  &lt;.0001
##  c(1, -2, 1)   -0.125 0.19 162  -0.658  1.0000
## 
## P value adjustment: bonferroni method for 2 tests</code></pre>
<p>Wie Sie erkennen können, ist nur der lineare Trend-Kontrast signifikant! Wir gehen also nur von einem linearen und nicht von einem quadratischen Trend aus, denn der Test auf “Modellverbesserung” durch das Hinzufügen des quadratischen Trends brachte keine signifikante Verbesserung. Genauso kann man dies so interpretieren, dass die Datenlage zwar einem horizontalen (Gleichheit aller Mittelwerte) Verlauf widerspricht, nicht aber einem linearen Verlauf!</p>
<p>Hier muss allerdings aufgepasst werden. Diese Kontraste, die aus sogenannten orthognalen Polynomen entstehen, sollten immer gemeinsam getestet werden. Wenn beispielsweise der quadratische Verlauf der richtige wäre, er aber perfekt U-förmig verläuft, so könnte es passieren, dass der lineare Trend nicht signifikant wird, wir aber im quadratischen erkennen, dass tatsächlich die Daten einem quadratischen Trend folgen. <strong>Hier ist das beste Vorgehen immer alle möglichen Trends gleichzeitig zu prüfen</strong>. Es wird dann immer der <em>höchste signifikante Trend</em> angenommen. Falls z.B. der lineare und der quadratische signifikant sind, so entscheiden wir uns für den quadratischen. Falls Sie mehr dazu wissen wollen, schauen Sie doch in <a href="#AppendixA">Appendix A</a> vorbei.</p>
</div>
<div id="abkürzungen-für-typische-kontraste" class="section level3">
<h3>Abkürzungen für typische Kontraste</h3>
<p>Damit wir nicht für jede Datenkonstellation riesige Tabellen von orthogonalen Kontrasten parat haben müssen, können wir in der <code>contrast</code>-Funktion einige typische Kontraste in abgekürzter Fassung anfordern. Für polynomiale Kontraste, z.B.</p>
<pre class="r"><code>contrast(em, interaction = &#39;poly&#39;)</code></pre>
<pre><code>##  age_poly  estimate   SE  df t.ratio p.value
##  linear       0.541 0.11 162   4.935  &lt;.0001
##  quadratic   -0.125 0.19 162  -0.658  0.5114</code></pre>
<p>Es zeigt sich in diesem Fall also ein bedeutsamer linearer, aber kein bedeutsamer quadratischer Trend. Die Interpretation ist identisch zu oben — es ist ja auch die gleiche Analyse (alle Koeffizienten sind identisch zu oben)! Wie schon zuvor, können wir hier mit <code>adjust</code> eine Bonferroni-Korrektur vornehmen:</p>
<pre class="r"><code>contrast(em, interaction = &#39;poly&#39;,
  adjust = &#39;bonferroni&#39;)</code></pre>
<pre><code>##  age_poly  estimate   SE  df t.ratio p.value
##  linear       0.541 0.11 162   4.935  &lt;.0001
##  quadratic   -0.125 0.19 162  -0.658  1.0000
## 
## P value adjustment: bonferroni method for 2 tests</code></pre>
<p>Es ergibt sich die gleiche Tabelle wie zuvor.</p>
<p>Wollen wir einen herkömmlichen Kontrast prüfen (also keinen Trend), so müssen wir in unserer Interpretation wieder umschwenken! Der direkte Vergleich aller Zeitpunkte kann via <code>method = 'pairwise'</code> erreicht werden. Außerdem resultieren die Voreinstellungen in einem Vergleich aller Zeitpunkte mit dem globalen Mittel:</p>
<pre class="r"><code># Alle paarweisen Vergleiche
contrast(em, method = &#39;pairwise&#39;,
  adjust = &#39;bonferroni&#39;)</code></pre>
<pre><code>##  contrast estimate   SE  df t.ratio p.value
##  14 - 15    -0.333 0.11 162  -3.038  0.0083
##  14 - 16    -0.541 0.11 162  -4.935  &lt;.0001
##  15 - 16    -0.208 0.11 162  -1.898  0.1785
## 
## P value adjustment: bonferroni method for 3 tests</code></pre>
<p>Hier erkennt man, dass sich vor allem Unterschiede zwischen 14 und 15 Jahren (<span class="math inline">\(p = 0.0083\)</span>) sowie zwischen 14 und 16 Jahren (<span class="math inline">\(p &lt; .001\)</span>) ergeben, da hier die Mittelwertsvergleiche signifikant sind. Genauso könnten wir auch den jeweiligen Gruppenmittelwert gegen den globalen Mittelwert testen.</p>
<pre class="r"><code># Vergleiche mit dem Mittel
contrast(em,
  adjust = &#39;bonferroni&#39;)</code></pre>
<pre><code>##  contrast  estimate     SE  df t.ratio p.value
##  14 effect  -0.2915 0.0633 162  -4.603  &lt;.0001
##  15 effect   0.0417 0.0633 162   0.658  1.0000
##  16 effect   0.2498 0.0633 162   3.945  0.0004
## 
## P value adjustment: bonferroni method for 3 tests</code></pre>
<p>Der Vergleich mit dem Mittel ist dann nützlich, wenn man sehr viele Zeitpunkte (oder Gruppen) hat. Dann bietet es sich an zu prüfen, ob es spezifische Instanzen gibt, die <em>“auffällig”</em> vom Durchschnittswert abweichen, statt sehr viele Einzelvergleiche zu definieren. Dies gilt besonders dann, wenn man keine natürliche Referenzkategorie hat - wie z.B. einen Prätest oder eine Kontrollgruppe. In unserem Fall weichen das Alter 14 (<span class="math inline">\(p &lt; .001\)</span>) und 16 (<span class="math inline">\(p = .0004\)</span>) von Mittel ab.</p>
<p>Würden wir beispielsweise bei p Gruppen paarweise Vergleiche durchführen, so bräuchten wir insgesamt <span class="math inline">\(\frac{p(p-1)}{2}\)</span> Vergleiche, während wir beim Test gegen das globale Mittel nur <span class="math inline">\(p\)</span> Tests brauchen:</p>
<table>
<colgroup>
<col width="33%" />
<col width="33%" />
<col width="33%" />
</colgroup>
<thead>
<tr class="header">
<th>Anzahl Gruppen: <span class="math inline">\(p\)</span></th>
<th>Anzahl paarweise Vergleiche: <span class="math inline">\(\frac{p(p-1)}{2}\)</span></th>
<th>Anzahl Vergleiche zum Mittel: <span class="math inline">\(p\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>2</td>
<td>1</td>
<td>2</td>
</tr>
<tr class="even">
<td>3</td>
<td>3</td>
<td>3</td>
</tr>
<tr class="odd">
<td>4</td>
<td>6</td>
<td>4</td>
</tr>
<tr class="even">
<td>5</td>
<td>10</td>
<td>5</td>
</tr>
</tbody>
</table>
<p>Wir sehen also, dass die paarweisen Vergleiche extrem schnell anwachsen, was natürlich verherende Folgen im Hinblick auf die Irrtumswahrscheinlichkeit hat!</p>
</div>
</div>
<div id="split-plot-anova" class="section level2">
<h2>Split-Plot ANOVA</h2>
<p>Untersuchungen, in denen <em>mehrere Gruppen und mehrere Messungen gleichzeitig</em> betrachtet werden, werden häufig <strong>Split-Plot Designs</strong> genannt. Im aktuellen Datensatz können Jugendliche danach in Gruppen eingeteilt werden, ob ihre Eltern Alkoholiker sind (<code>coa</code>). Die entsprechende Syntax für das <code>ez</code>-Paket ist eine einfache Kombination aus der Syntax für die beiden Typen der ANOVA, die wir bereits behandelt haben:</p>
<pre class="r"><code># Deskriptive Statistiken
ezStats(alc_long, 
  dv = alcuse, 
  wid = id, 
  within = age,   #zwischen den jährlichen Messungen
  between = coa)  #zwischen den Jugendlichen Gruppen</code></pre>
<pre><code>## Warning: Data is unbalanced (unequal N per group). Make sure you specified a
## well-considered value for the type argument to ezANOVA().</code></pre>
<pre><code>## Warning in ezStats(alc_long, dv = alcuse, wid = id, within = age, between =
## coa): Unbalanced groups. Mean N will be used in computation of FLSD</code></pre>
<pre><code>##   coa age  N      Mean        SD      FLSD
## 1   0  14 45 0.2903221 0.6253560 0.3080161
## 2   0  15 45 0.6601661 0.8840523 0.3080161
## 3   0  16 45 0.8762325 1.1225959 0.3080161
## 4   1  14 37 1.0441549 1.0885821 0.3080161
## 5   1  15 37 1.3327066 1.1215570 0.3080161
## 6   1  16 37 1.5312054 1.0573837 0.3080161</code></pre>
<pre class="r"><code># Grafische Darstellung
ezPlot(alc_long, 
  dv = alcuse, 
  wid = id, 
  within = age, 
  between = coa,
  x = age, split = coa)</code></pre>
<pre><code>## Warning: Data is unbalanced (unequal N per group). Make sure you specified a
## well-considered value for the type argument to ezANOVA().</code></pre>
<pre><code>## Warning in ezStats(data = data, dv = dv, wid = wid, within = within, within_full
## = within_full, : Unbalanced groups. Mean N will be used in computation of FLSD</code></pre>
<p><img src="/post/2021-05-26_ANOVA-III_files/figure-html/unnamed-chunk-30-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>Der Plot verdeutlicht bereits, was in dieser Situation die drei zentralen Fragestellungen sind:</p>
<ul>
<li>Verändert sich der Alkoholkonsum über die Zeit? (<strong>Haupteffekt A</strong>)</li>
<li>Unterscheiden sich Jugendliche von Alkoholikern von Jugendlichen nicht alkoholabhängiger Eltern in ihrem mittleren Alkoholkonsum? (<strong>Haupteffekt B</strong>)</li>
<li>Unterscheidet sich die Veränderung mit der Zeit im Alkoholkonsum zwischen den beiden Gruppen von Jugendlichen? (<strong>Interaktionseffekt</strong>)</li>
</ul>
<p>Wir erkennen leicht, dass die ANOVA mit Messwiederholung mit einem between Faktor sehr viel mit der zweifaktoriellen ANOVA gemein hat! Allerdings müssen wir unbedingt die Ähnlichkeit der Messungen, die durch die wiederholten Messungen entsteht, berücksichtigen, was wir ja über das “Within”-Design getan haben!</p>
<p>In sehr vielen psychologischen Studien ist der Interaktionseffekt der relevante Effekt. Insbesondere wenn experimentelle Studien durchgeführt werden, ist die Annahme, dass die Gruppen sich zu Beginn nicht unterscheiden (randomisierte Gruppenzuweisung), dann aber durch eine Intervention eine Veränderung eintritt und diese in der Experimentalgruppe anders ist, als die Veränderung in der Kontrollgruppe.</p>
<p>Um diese Effekte zu untersuchen, können wir wieder die <code>ezANOVA</code> nutzen:</p>
<pre class="r"><code>ezANOVA(alc_long, 
  dv = alcuse, 
  wid = id, 
  within = age, 
  between = coa)</code></pre>
<pre><code>## Warning: Data is unbalanced (unequal N per group). Make sure you specified a
## well-considered value for the type argument to ezANOVA().</code></pre>
<pre><code>## $ANOVA
##    Effect DFn DFd          F            p p&lt;.05          ges
## 2     coa   1  80 15.0889366 2.101590e-04     * 0.1108265719
## 3     age   2 160 12.2596915 1.112344e-05     * 0.0494086230
## 4 coa:age   2 160  0.1132673 8.929835e-01       0.0004799824
## 
## $`Mauchly&#39;s Test for Sphericity`
##    Effect         W           p p&lt;.05
## 3     age 0.8859965 0.008386194     *
## 4 coa:age 0.8859965 0.008386194     *
## 
## $`Sphericity Corrections`
##    Effect       GGe        p[GG] p[GG]&lt;.05       HFe        p[HF] p[HF]&lt;.05
## 3     age 0.8976633 2.626605e-05         * 0.9169621 2.233274e-05         *
## 4 coa:age 0.8976633 8.726825e-01           0.9169621 8.768214e-01</code></pre>
<p>Obwohl <code>ez</code> den <em>Mauchly Test</em> für Sphärizität mitliefert, ist im Fall des Split-Plot Designs die <em>eigentliche</em> Annahme die <em>Gleichheit der Varianz-Kovarianz-Matrizen der messwiederholten Variablen über alle Gruppen hinweg</em>. Diese Annahme kann mithilfe des <strong>Box-M-Tests</strong> geprüft werden, welcher allerdings in nur wenigen Paketen implementiert ist, weil er in der Mehrheit aller empirischen Anwendungen statistisch bedeutsam ist. Wer ihn dennoch durchführen möchte, findet ihn z.B. im <code>heplots</code> Paket:</p>
<pre class="r"><code>heplots::boxM(alc[, c(&#39;alcuse.14&#39;, &#39;alcuse.15&#39;, &#39;alcuse.16&#39;)], group = alc$coa)</code></pre>
<pre><code>## 
##  Box&#39;s M-test for Homogeneity of Covariance Matrices
## 
## data:  alc[, c(&quot;alcuse.14&quot;, &quot;alcuse.15&quot;, &quot;alcuse.16&quot;)]
## Chi-Sq (approx.) = 21.486, df = 6, p-value = 0.0015</code></pre>
<p>Nach <a href="https://hds.hebis.de/ubffm/Record/HEB366849158">Eid et al. (2017</a>, S. 494) ist die ANOVA gegenüber der Verletzung der Homgenitätsannahme bezüglich der Kovarianzmatrizen dann robust, wenn die Sphärizitätsannahme nicht verworfen werden muss. Sollte diese ebenfalls verworfen werden müssen, können entweder die zuvor dargestellten Korrekturen genutzt werden oder eine “echte” robuste Variante (z.B. im <code>WRS2</code>-Paket) genutzt werden.</p>
<p>Bezüglich der Ergebnisse der ANOVA zeigt sich, dass das Alter und ob ein Elternteil Alkoholiker ist einen bedeutsamen Einfluss auf das Trinkverhalten von Jugendlichen haben. Dass die Interaktion nicht statistisch bedeutsam ist, deutet darauf hin, dass die Entwicklung über die Zeit zwischen beiden Gruppen von Jugendlichen parallel verläuft.</p>
<hr />
</div>
<div id="AppendixA" class="section level2">
<h2>Appendix A</h2>
<details>
<summary>
<strong>Trendanalysen</strong>
</summary>
<p>Wir schauen uns im Folgenden simulierte Daten an und betrachten nochmals die 3 Trends (horizontal, linear, quadratisch). Wir beginnen mit einem horiziontalen Trend in den Daten an. Die wahren Mittelwerte werden als (0, 0, 0) gewählt:</p>
<pre class="r"><code>set.seed(123) # für Vergleichbarkeit
Means &lt;- c(0, 0, 0) # wahren Mittelwerte pro Zeitpunkt
Y &lt;- Means[1] + rnorm(30)
Y &lt;- c(Y, Means[2] + rnorm(30))
Y &lt;- c(Y, Means[3] + rnorm(30))

times &lt;- c(rep(&quot;1&quot;, 30), rep(&quot;2&quot;, 30), rep(&quot;3&quot;, 30))
id &lt;- c(1:30, 1:30, 1:30)
df &lt;- data.frame(Y, times, id)
df$times &lt;- as.factor(times)
df$id &lt;- as.factor(df$id)
head(df)</code></pre>
<pre><code>##             Y times id
## 1 -0.56047565     1  1
## 2 -0.23017749     1  2
## 3  1.55870831     1  3
## 4  0.07050839     1  4
## 5  0.12928774     1  5
## 6  1.71506499     1  6</code></pre>
<pre class="r"><code>ezPlot(df, Y, id, within = times,
  x = times) +
  geom_smooth(aes(x = as.numeric(times)), method = &#39;lm&#39;, se = FALSE) +
  geom_smooth(aes(x = as.numeric(times)), method = &#39;lm&#39;, se = FALSE,
    formula = y ~ x + I(x^2), color = &#39;red&#39;)</code></pre>
<p><img src="/post/2021-05-26_ANOVA-III_files/figure-html/unnamed-chunk-33-1.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>whd_aov &lt;- aov(Y ~ times + Error(id/times), data = data.frame(df))
em &lt;- emmeans(whd_aov, ~ times)
contrast(em, interaction = &#39;poly&#39;)</code></pre>
<pre><code>##  times_poly estimate    SE df t.ratio p.value
##  linear       -0.635 0.475 84  -1.337  0.1848
##  quadratic    -0.531 0.823 84  -0.645  0.5205</code></pre>
<p>Sowohl der lineare als auch der quadratische Trend sind <strong>nicht</strong> signifikant! Die blau Linie stellt einen linearen Verlauf dar, die rote einen quadratischen.</p>
<p>Nun schauen wir uns einen linearen Trend mit Mittelwerten (0, 1, 2) an:</p>
<pre class="r"><code>set.seed(123) # für Vergleichbarkeit
Means &lt;- c(0, 1, 2) # wahren Mittelwerte pro Zeitpunkt
Y &lt;- Means[1] + rnorm(30)
Y &lt;- c(Y, Means[2] + rnorm(30))
Y &lt;- c(Y, Means[3] + rnorm(30))

times &lt;- c(rep(&quot;1&quot;, 30), rep(&quot;2&quot;, 30), rep(&quot;3&quot;, 30))
id &lt;- c(1:30, 1:30, 1:30)
df &lt;- data.frame(Y, times, id)
df$times &lt;- as.factor(times)
df$id &lt;- as.factor(df$id)
head(df)</code></pre>
<pre><code>##             Y times id
## 1 -0.56047565     1  1
## 2 -0.23017749     1  2
## 3  1.55870831     1  3
## 4  0.07050839     1  4
## 5  0.12928774     1  5
## 6  1.71506499     1  6</code></pre>
<pre class="r"><code>ezPlot(df, Y, id, within = times,
  x = times) +
  geom_smooth(aes(x = as.numeric(times)), method = &#39;lm&#39;, se = FALSE) +
  geom_smooth(aes(x = as.numeric(times)), method = &#39;lm&#39;, se = FALSE,
    formula = y ~ x + I(x^2), color = &#39;red&#39;)</code></pre>
<p><img src="/post/2021-05-26_ANOVA-III_files/figure-html/unnamed-chunk-34-1.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>whd_aov &lt;- aov(Y ~ times + Error(id/times), data = data.frame(df))
em &lt;- emmeans(whd_aov, ~ times)
contrast(em, interaction = &#39;poly&#39;)</code></pre>
<pre><code>##  times_poly estimate    SE df t.ratio p.value
##  linear        1.365 0.475 84   2.872  0.0052
##  quadratic    -0.531 0.823 84  -0.645  0.5205</code></pre>
<p>Diesmal ist nur der lineare Trend signifikant. Die Mittelwerte steigen mit jedem Zeitpunkt um 1 Einheit!</p>
<p>Nun schauen wir uns einen (umgekehrt) U-förmigen Verlauf an mit Mittelwerten: (0, 1, 0):</p>
<pre class="r"><code>set.seed(123) # für Vergleichbarkeit
Means &lt;- c(0, 1, 0) # wahren Mittelwerte pro Zeitpunkt
Y &lt;- Means[1] + rnorm(30)
Y &lt;- c(Y, Means[2] + rnorm(30))
Y &lt;- c(Y, Means[3] + rnorm(30))

times &lt;- c(rep(&quot;1&quot;, 30), rep(&quot;2&quot;, 30), rep(&quot;3&quot;, 30))
id &lt;- c(1:30, 1:30, 1:30)
df &lt;- data.frame(Y, times, id)
df$times &lt;- as.factor(times)
df$id &lt;- as.factor(df$id)
head(df)</code></pre>
<pre><code>##             Y times id
## 1 -0.56047565     1  1
## 2 -0.23017749     1  2
## 3  1.55870831     1  3
## 4  0.07050839     1  4
## 5  0.12928774     1  5
## 6  1.71506499     1  6</code></pre>
<pre class="r"><code>ezPlot(df, Y, id, within = times,
  x = times) +
  geom_smooth(aes(x = as.numeric(times)), method = &#39;lm&#39;, se = FALSE) +
  geom_smooth(aes(x = as.numeric(times)), method = &#39;lm&#39;, se = FALSE,
    formula = y ~ x + I(x^2), color = &#39;red&#39;)</code></pre>
<p><img src="/post/2021-05-26_ANOVA-III_files/figure-html/unnamed-chunk-35-1.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>whd_aov &lt;- aov(Y ~ times + Error(id/times), data = data.frame(df))
em &lt;- emmeans(whd_aov, ~ times)
contrast(em, interaction = &#39;poly&#39;)</code></pre>
<pre><code>##  times_poly estimate    SE df t.ratio p.value
##  linear       -0.635 0.475 84  -1.337  0.1848
##  quadratic    -2.531 0.823 84  -3.075  0.0028</code></pre>
<p>Es ist nur der quadratische Trend signifikant, da wir ja gesehen hatten, dass der Kontrast für den linearen Trend nur die beiden äußeren Mittelwerte gegeneinander testet (<span class="math inline">\(\mu_1\)</span> vs <span class="math inline">\(\mu_3\)</span>), welche sich aber nicht unterscheiden und somit auch die blau Gerade horizontal erscheint! Schauen wir uns doch einmal einen Verlauf an, in welchem sowohl der lineare als auch de quadratische Trend signifikant ist. Das ist der Fall, wenn die Mittelwerte bspw. “beschleunigt” steigen mit den Zeitpunkten. wir wählen die Mittelwerte als (1, 4, 9), also <span class="math inline">\(t^2\)</span>.</p>
<pre class="r"><code>set.seed(1234) # für Vergleichbarkeit
Means &lt;- c(1, 4, 9) # wahren Mittelwerte pro Zeitpunkt
Y &lt;- Means[1] + rnorm(30)
Y &lt;- c(Y, Means[2] + rnorm(30))
Y &lt;- c(Y, Means[3] + rnorm(30))

times &lt;- c(rep(&quot;1&quot;, 30), rep(&quot;2&quot;, 30), rep(&quot;3&quot;, 30))
id &lt;- c(1:30, 1:30, 1:30)
df &lt;- data.frame(Y, times, id)
df$times &lt;- as.factor(times)
df$id &lt;- as.factor(df$id)
head(df)</code></pre>
<pre><code>##            Y times id
## 1 -0.2070657     1  1
## 2  1.2774292     1  2
## 3  2.0844412     1  3
## 4 -1.3456977     1  4
## 5  1.4291247     1  5
## 6  1.5060559     1  6</code></pre>
<pre class="r"><code>ezPlot(df, Y, id, within = times,
  x = times) +
  geom_smooth(aes(x = as.numeric(times)), method = &#39;lm&#39;, se = FALSE) +
  geom_smooth(aes(x = as.numeric(times)), method = &#39;lm&#39;, se = FALSE,
    formula = y ~ x + I(x^2), color = &#39;red&#39;)</code></pre>
<p><img src="/post/2021-05-26_ANOVA-III_files/figure-html/unnamed-chunk-36-1.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>whd_aov &lt;- aov(Y ~ times + Error(id/times), data = data.frame(df))
em &lt;- emmeans(whd_aov, ~ times)
contrast(em, interaction = &#39;poly&#39;)</code></pre>
<pre><code>##  times_poly estimate    SE df t.ratio p.value
##  linear         9.04 0.497 84  18.194  &lt;.0001
##  quadratic      4.13 0.861 84   4.793  &lt;.0001</code></pre>
<p>Wir erkennen, dass sowohl der lineare als auch der quadratische Trend signifikant ist. Die blau Linie passt besser als einen horiziontale und die rote passt besser als die blau Linie! Hier entscheiden wir uns final für den quadratischen Trend!</p>
</details>
<hr />
</div>
<div id="r-skript" class="section level2">
<h2>R-Skript</h2>
<p>Den gesamten <code>R</code>-Code, der in dieser Sitzung genutzt wird, können Sie <a href="/post/PsyBSc7_R_Files/ANOVA-III.R"><svg aria-hidden="true" role="img" viewBox="0 0 512 512" style="height:1em;width:1em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:currentColor;overflow:visible;position:relative;"><path d="M216 0h80c13.3 0 24 10.7 24 24v168h87.7c17.8 0 26.7 21.5 14.1 34.1L269.7 378.3c-7.5 7.5-19.8 7.5-27.3 0L90.1 226.1c-12.6-12.6-3.7-34.1 14.1-34.1H192V24c0-13.3 10.7-24 24-24zm296 376v112c0 13.3-10.7 24-24 24H24c-13.3 0-24-10.7-24-24V376c0-13.3 10.7-24 24-24h146.7l49 49c20.1 20.1 52.5 20.1 72.6 0l49-49H488c13.3 0 24 10.7 24 24zm-124 88c0-11-9-20-20-20s-20 9-20 20 9 20 20 20 20-9 20-20zm64 0c0-11-9-20-20-20s-20 9-20 20 9 20 20 20 20-9 20-20z"/></svg>hier herunterladen</a>.</p>
<hr />
</div>
<div id="literatur" class="section level2">
<h2>Literatur</h2>
<p><a href="https://hds.hebis.de/ubffm/Record/HEB366849158">Eid, M., Gollwitzer, M., &amp; Schmitt, M. (2017).</a> <em>Statistik und Forschungsmethoden</em> (5. korrigierte Auflage, 1. Auflage: 2010). Weinheim: Beltz.</p>
<ul>
<li><small> <em>Blau hinterlegte Autorenangaben führen Sie direkt zur universitätsinternen Ressource.</em></li>
</ul>
</div>
