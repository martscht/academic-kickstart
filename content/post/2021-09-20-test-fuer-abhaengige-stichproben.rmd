---
title: Tests für abhängige Stichproben
date: '2021-09-20'
slug: gruppenvergleiche-abhaengig
categories:
  - BSc2
tags:
  - t-Test
  - abhängige Stichproben
subtitle: ''
summary: ''
authors: [koehler, buchholz, irmer]
lastmod: '2021-12-22T17:00:20+01:00'
featured: no
header:
  image: "/header/BSc2_test_abh_stpr.jpg"
  caption: "[Courtesy of pxhere](https://pxhere.com/en/photo/449195)"
projects: []
---

```{r setup, cache = FALSE, echo = FALSE, warning = FALSE, message = FALSE}
knitr::opts_chunk$set(error = TRUE,warning = FALSE, message = FALSE)
library(knitr)
```

<details><summary>Kernfragen der Lehreinheiten über Gruppenvergleiche </summary>
* Wie fertige ich Deskriptivstatistiken (Grafiken, Kennwerte) zur Veranschaulichung des Unterschieds zwischen zwei Gruppen an? 
     
**unabhängige Stichproben** ([letzte Sitzung](/post/gruppenvergleiche-unabhaengig)) $\rightarrow$ bereits erledigt!
     
* Was sind Voraussetzungen des _t_-Tests und wie prüfe ich sie? $\rightarrow$ bereits erledigt!
* Wie führe ich einen _t_-Test in R durch? $\rightarrow$ bereits erledigt!
* Wie berechne ich die Effektstärke Cohen's _d_? $\rightarrow$ bereits erledigt!
* Wie führe ich den Wilcoxon-Tests (auch "Mann-Whitney-Test", "U-Test", "Mann-Whitney-U-Test", "Wilcoxon-Rangsummentest") in R durch? $\rightarrow$ bereits erledigt!
* Wie führe ich den Vierfelder-Chi-Quadrat-Tests in R durch? $\rightarrow$ bereits erledigt!

**abhängige Stichproben** ([diese Sitzung](/post/gruppenvergleiche-abhaengig))

* Was sind Voraussetzungen des abhängigen _t_-Tests und wie prüfe ich sie?
* Wie führe ich einen abhängigen _t_-Test in R durch?  
* Wie berechne ich den standardisierten Populationseffekt für abhängige Stichproben?  
* Wie führe ich einen abhängigen Wilcoxon-Test in R durch?  


* Wie berichte ich statistische Ergebnisse formal? 
</details>

***
## Was erwartet Sie?
  
Nachdem wir uns die Woche vor der Weihnachtspause mit dem Unterschied zwischen dem Mittelwert einer Stichprobe und dem Mittelwert der dazugehörigen Population, aus der die Stichprobe stammt, auseinandergesetzt haben, fokussieren wir uns nun auf Unterschiede zwischen zwei Gruppen (also zwei Stichproben). Hierbei muss zwischen unabhängigen und abhängigen Stichproben unterschieden werden.

## Aufbau der Sitzungen zu Gruppenvergleichen

1. Fragestellung A: Unterscheidet sich die Anzahl erreichter Punkte in der Statistik-Klausur zwischen Personen, die das Tutorium regelmäßig besucht haben und denen, die nur unregelmäßig da waren? (_t-Test und Cohen's d für unabhängige Stichproben_) $\rightarrow$ bereits erledigt!
2. Fragestellung B: Sind Studentinnen verträglicher als Studenten? (_Wilcoxon-Test für unabhängige Stichproben_) $\rightarrow$ bereits erledigt!
3. Fragestellung C: Haben Studierende mit Wohnort in Uninähe (Frankfurt) mit gleicher Wahrscheinlichkeit einen Nebenjob wie Studierende, deren Wohnort außerhalb von Frankfurt liegt? (_Vierfelder-$\chi^2$-Test_) $\rightarrow$ bereits erledigt!
4. Fragestellung D: Sind jüngere Geschwister kooperativer als ältere? (_t-Test und Cohen's d für abhängige Stichproben_)
5. Fragestellung E: Sind jüngere Geschwister kooperativer als ältere? (_Wilcoxon-Test für abhängige Stichproben_)

Fragen 1.- 3. wurden in der letzte Sitzung behandelt. In dieser Sitzung schauen wir uns Fragestellung 4.- 5. an.


***

In dem Datensatz, den Sie am Anfang des Semesters ausgefüllt haben, gibt es keine sinnvollen abhängige Stichproben. Aus diesem Grund verwenden wir einen anderen Datensatz.

## 4. Fragestellung D: Sind jüngere Geschwister kooperativer als ältere?

Der Datensatz stammt aus Eid, Gollwitzer & Schmitt: "Statistik und Forschungsmethoden" (4. Auflage, S. 370). 

* Abhängige Variable (AV): Kooperationsbereitschaft (stetige Variable mit Werten von 0 [nicht kooperativ] bis 1 [maximal kooperativ])
* Gruppen: das jeweils ältere Geschwisterteil (Gruppe "Älter") vs. das jeweils jüngere Geschwisterteil (Gruppe "Jünger") 

```{r}
# Datensatz generieren
dataKooperation <- data.frame(Paar = 1:10,  Juenger = c(0.49,0.25,0.51,0.55,0.35,0.54,0.24,0.49,0.38,0.50), Aelter = c(0.4,0.25,0.31,0.44,0.25,0.33,0.26,0.38,0.23,0.35))
dataKooperation # überprüfen, ob alles geklappt hat
```

Ein Blick auf die Messwertpaare lässt bereits erkennen, dass die Stichproben (also die Messwerte in den beiden experimentellen Bedingungen) voneinander abhängig sind. Die Geschwisterpaare ähneln sich hinsichtlich ihrer kooperativen Verhaltenstendenzen. Auch inhaltlich sind sie von einander abhängig, da die meisten Geschwister miteinander verwandt sind, also ähnliche Gene aufweisen, und in der Regel im gleichen Zuhause aufwachsen und somit gleiche/sehr ähnliche Umwelteinflüsse genießen. 

Für unsere Analysen ist es jedoch unwichtig, welche Ursachen diese Ähnlichkeiten haben. Entscheidend ist, dass es sich um Faktoren handelt, die sowohl einen Teil der Varianz in der ersten Gruppe als auch einen Teil der Varianz in der zweiten Gruppe erzeugen.

Relevant ist nun die Frage, ob die Differenz zwischen den beiden Mittelwerten (also zwischen jüngeren und älteren Geschwistern) statistisch bedeutsam ist - also ob die mittlere Differenz zwischen den Paaren von Null verschieden ist.

### 4.1. Deskriptivstatistik

Wie immer beginnen wir mit der deskriptivstatistischen Analyse unserer Daten.

#### 4.1.1. grafisch
Mithilfe von Histogrammen
```{r}
# Je ein Histogramm pro Gruppe, untereinander dargestellt, vertikale Linie für den jeweiligen Mittelwert
par(mfrow=c(2,1), mar=c(3,3,2,0))
hist(dataKooperation[, "Juenger"], 
     xlim=c(0,1), 
     main="Kooperationsbereitschaft juengeres Geschwisterteil", 
     xlab="", 
     ylab="", 
     las=1)
abline(v=mean(dataKooperation[, "Juenger"]), 
       lty=2, 
       lwd=2)

hist(dataKooperation[, "Aelter"], 
     xlim=c(0,1), 
     main="Kooperationsbereitschaft aelteres Geschwisterteil", 
     xlab="", 
     ylab="", 
     las=1)
abline(v=mean(dataKooperation[, "Aelter"]), 
       lty=2, 
       lwd=2)

par(mfrow=c(1,1)) #Zurücksetzen des Plotfensters, zuvor hatten wir "dev.off()" kennengelernt
```

Die Histogramme sieht via `xlim` so gewählt, dass sie die gleiche x-Achse aufweisen und somit ausgesprochen gut vergleichbar sind. `abline` fügt eine Linie in eine Grafik ein. Mit dem Zusatzargument `v` geben wir eine vertikale Linie in den Plot (hier den Mittelwert). Insgesamt sehen die beiden Verteilungen etwas verschoben aus!  

#### 4.1.2. statistisch

Deskriptivstatistisch sehen die Ergebnisse so aus:

```{r}
summary(dataKooperation[, "Juenger"])
summary(dataKooperation[, "Aelter"])
#alternativ
library(psych)
describe(dataKooperation[, "Juenger"])
describe(dataKooperation[, "Aelter"])
```
```{r, echo=FALSE}
jung <- describe(dataKooperation[, "Juenger"])
alt <- describe(dataKooperation[, "Aelter"])
```
Achtung: Bei den hier berichteten SD handelt es sich (wie immer in R) um den Populationsschätzer. Die Mittelwerte der beiden Gruppen unterscheiden sich leicht. Die Frage ist nun, ob sich dieser Unterschied auf die Population verallgemeinern lässt.

### 4.2. Voraussetzungsprüfung

Um den Ergebnissen eines $t$-Test für abhängige Stichproben vertrauen zu können, müssen dessen Voraussetzungen erfüllt sein: 

**Voraussetzungen für die Durchführung des _t_-Tests für abhängige Stichproben:**  

1. Die abhängige Variable ist intervallskaliert $\rightarrow$ ok  
2. Die Messwerte innerhalb der Paare dürfen sich gegenseitig beeinflussen/voneinander abhängig sein; keine Abhängigkeiten zwischen den Messwertpaaren $\rightarrow$ ok  
3. Die Differenzvariable _d_ muss in der Population normalverteilt sein $\rightarrow$ ab _n_ => 30 meist gegeben (s. zentraler Grenzwertsatz), ggf. grafische Prüfung oder Hintergrundwissen  

**zu 3. Normalverteilung von _d_**

Da wir hier die Differenzvariable betrachten müssen, müssen wir diese zunächst erstellen. Das passiert vektorwertig. Anschließend schauen wir uns wie immer das Histogramm und den QQ-Plot an:

```{r}
difference <- dataKooperation[, "Juenger"]-dataKooperation[, "Aelter"]
hist(difference, 
     xlim=c(-.3,.3), 
     ylim = c(0,5.5),
     main="Verteilung der Differenzen", 
     xlab="Differenzen", 
     ylab="", 
     las=1)
curve(dnorm(x, mean=mean(difference), sd=sd(difference)), 
      col="blue", 
      lwd=2, 
      add=T)
qqnorm(difference)
qqline(difference, col="blue")
```

$\Rightarrow$ Differenzen sehen nicht normalverteilt aus! Allerdings steht in Eid, Gollwitzer & Schmitt: "Zur Messung zur Kooperationsbereitschaft verwendet [der Forscher] ein standardisiertes Instrument, das Messwerte auf Intervallskalenniveau liefert und in der Population normalverteilt ist."

$\Rightarrow$ Es wird also Normalverteilung angenommen, somit sind alle drei Voraussetzungen für die Durchführung des _t_-Tests für abhängige Stichproben erfüllt.


### 4.3. Inferenzstatistik: _t_-Test für abhängige Stichproben {#Hypothesen}

Zur Erinnerung:  

> Fragestellung D: "Sind jüngere Geschwister kooperativer als Ältere?"   

**Hypothesen:** 

* Art des Effekts: Unterschiedshypothese
* Richtung des Effekts: Gerichtet - positiver Effekt
* Grösse des Effekts: Unspezifisch

Hyothesenpaar (inhaltlich):  

* H0: Jüngere Geschwister sind genau so oder weniger kooperativ wie ältere Geschwister. 
* H1: Jüngere Geschwister sind kooperativer als ältere Geschwister.  

Hypothesenpaar (statistisch):  

* H0: $\mu_\text{jünger} \le \mu_\text{älter}$  bzw.  $\mu_{d} \le 0$  
* H1: $\mu_\text{jünger} > \mu_\text{älter}$    bzw.  $\mu_{d} > 0$

**Signifikanzniveau**  

Das Signifikanzniveau muss vor der Untersuchung festgelegt werden. Es soll hier 5% betragen. $\rightarrow$ $\alpha=.05$

**Durchfürhung des abhängigen _t_-Tests in R:**

Wir verwenden hier die Funktion `t.test`. Diesmal müssen wir allerdings die beiden Gruppen einzeln der Funktion übergeben. Dies geschieht über die Argumente `x` und `y`. Das Argument `paired = T` führt dazu, dass der _t_-Test für abhängige (gepaarte) Stichproben durchgeführt wird.

```{r}
t.test(x = dataKooperation[, "Juenger"], y  = dataKooperation[, "Aelter"], # die beiden abhängigen Gruppen
       paired = T,                                                         # Stichproben sind abhängig
       alternative = "greater",                                            # gerichtete Hypothese
       conf.level = .95)                                                   # alpha = .05

```
```{r, echo=FALSE}
ttest <- t.test(x = dataKooperation[, "Juenger"], y  = dataKooperation[, "Aelter"],
       paired = T, alternative = "greater", conf.level = .95)
```

_df_ bei _t_-test mit abhängigen Stichproben: $n - 1$ (wobei $n$ die Anzahl der Paare darstellt)  
$\rightarrow$ _t_(`r ttest$parameter`) = `r round(ttest$statistic, 2)`, _p_ < .001 $\rightarrow$ signifikant, H0 wird verworfen, H1 wird angenommen.


### 4.4. Schätzung des standardisierten Populationseffekts

Formel:  $$d_2'' = \frac{\bar{d}} {sd_{\hat{d}}}$$

wobei  

* $\bar{d}$: Mittelwert der Differenz aller Wertepaare  
* $sd_{\hat{d}}$: geschätzte SD der Differenzen  

```{r}
mean_d <- mean(difference)
sd.d.est <- sd(difference)
d_Kooperation <- mean_d/sd.d.est
d_Kooperation
```

Konventionen nach Cohen (1988) für _t_-Test für abhängige Stichproben 
(Achtung: Werte unterscheiden sich zw. abhängigem und unabhängigem _t_-Test):

_d''_ | Interpretation |
:-: | :------: |
~ .14 | kleiner Effekt |
~ .35 | mittlerer Effekt |
~ .57 | großer Effekt |

$\Rightarrow$ der standardisierte Populationseffekt beträgt $d_2''$ = `r round(d_Kooperation, 2)` und ist laut Konventionen groß. 


### 4.5. Ergebnisinterpretation
Es wurde an Geschwisterpaaren untersucht, ob jüngere Geschwister kooperativer sind als ältere Geschwister. Zunächst findet sich deskriptiv ein Unterschied: Jüngere Geschwister weisen einen durchschnittlichen Wert von `r round(jung$mean, 2)` (_SD_ = `r round(jung$sd, 2)`) auf, während die älteren Geschwister einen Wert von `r round(alt$mean, 2)` (_SD_ = `r round(alt$sd, 2)`) aufweisen. Zur Beantwortung der Fragestellung wurde ein gerichteter _t_-Test für abhängige Stichproben durchgeführt. Der Gruppenunterschied ist signifikant (_t_(`r ttest$parameter`) = `r round(ttest$statistic, 2)`, _p_ < .001), somit wird die Nullhypothese verworfen. Jüngere Geschwister sind kooperativer als ihre älteren Geschwister. Dieser Unterschied ist nach dem standardisierten Populationseffekt von $d_2''$ = `r round(d_Kooperation, 2)` groß.

***


## 5. Fragestellung E: Sind jüngere Geschwister kooperativer als ältere? $\rightarrow$ Wilcoxon-Test

Zuvor hatten wir bemerkt, dass die Normalverteilungsannahme der Differenzen eigentlich nicht gegeben war. Wir hatten dann trotzdem einen _t_-Test für abhängige Stichproben durchgeführt, da die verwendete Skala als normalverteilt angenommen werden kann. Wir wollen nun die Analyse mit Hilfe des Wilcoxon-Test wiederholen. Der Grund wäre, dass die Normalverteilungsannahme empirisch verletzt war und wir nur theoretisch dagegen argumentiert hatten.

**Signifikanzniveau**

Das Signifikanzniveau muss vor der Untersuchung festgelegt werden. Es soll hier 5% betragen. $\rightarrow$ $\alpha=.05$

Die Hypothesen sind identisch zu jenen des _t_-Tests (siehe [Hypothesen](#Hypothesen)). Sie werden nicht erneut aufgelistet.

**Durchführung des Wilcoxon-Tests für abhängige Stichproben in R:**

Der Wilcoxon-Test-Befehl für abhängige Stichproben sieht dem des _t_-Tests für abhängige Stichproben sehr ähnlich. 

```{r}
wilcox.test(x = dataKooperation[, "Juenger"], 
            y  = dataKooperation[, "Aelter"], # die beiden abhängigen Gruppen
            paired = T,      # Stichproben sind abhängig
            alternative = "greater", # gerichtete Hypothese
            conf.level = .95)                 # alpha = .05
```

```{r, echo=FALSE}
wilcox <- wilcox.test(x = dataKooperation[, "Juenger"], y  = dataKooperation[, "Aelter"], paired = T, alternative = "greater", conf.level = .95)
```

_V_ = `r wilcox$statistic`, _p_ < .01 $\rightarrow$ H0 wird verworfen, H1 wird angenommen.



### 5.1 Ergebnisinterpretation  


Es wurde an Geschwisterpaaren untersucht, ob jüngere Geschwister kooperativer sind als ältere Geschwister. Zunächst findet sich deskriptiv ein Unterschied: Jüngere Geschwister weisen einen durchschnittlichen Wert von `r round(jung$mean, 2)` (_SD_ = `r round(jung$sd, 2)`) auf, während die älteren Geschwister einen Wert von `r round(alt$mean, 2)` (_SD_ = `r round(alt$sd, 2)`) aufweisen. Da die Differenzen nicht normalverteilt waren, wurde ein Wilcoxon-Test für abhängige Stichproben durchgeführt. Der Unterschied wurde bei einem Signifikanzniveau von alpha = .05 signifikant (_V_ = `r wilcox$statistic`, _p_ < .01). Somit wird die Nullhypothese verworfen und die Alternativhypothese angenommen:  Jüngere Geschwister sind kooperativer als ihre älteren Geschwister.


### 5.2 Vergleich _t_-Test und Wilcoxon-Test
Der _t_-Test und der Wilcoxon-Test haben unterschiedliche Annahmen. Die des _t_-Tests sind strenger. Sind Annahmen verletzt, so kann es fälschlicherweise zu signifikanten Ergebnissen kommen. In unserem Beispiel ist es nun so, dass der _t_-Test _p_ < 0.001 und der Wilcoxon-Test _p_ < 0.01 sich hinsichtlich der p-Werte drastisch unterscheiden. Dies kann sich auf die Power der Tests auswirken. Dazu erfahren Sie in den Aufgaben zu Simulation und Poweranalysen am Ende des Semesters mehr!

***
