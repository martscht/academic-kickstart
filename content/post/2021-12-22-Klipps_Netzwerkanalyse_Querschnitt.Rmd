---
title: Netzwerkanalyse im Querschnitt
date: '2022-01-11'
slug: cross-sectional-networks
categories:
  - MSc5a
tags:
  - Querschnitt
  - Zusammenfassung
  - Netzwerkanalyse
subtitle: ''
summary: ''
authors: [nehler]
lastmod: '2022-01-10T15:21:58+02:00'
featured: no
header:
  image: "/header/klipps_network.jpg"
  caption: "[Courtesy of pxhere](https://pxhere.com/en/photo/1575603)"
projects: []
---



```{r setup, include=FALSE}
# Vorbereitungen
knitr::opts_chunk$set(echo = TRUE, fig.align = "center")
```



## Einführung

Netzwerkanalyse kommt aus einem eher technischen Feld. Sie wurde dafür genutzt, Systeme darzustellen, bei denen verschiedene Einheiten miteinander verbunden sind. Beispielsweise wurden Computer als Knotenpunkte gesehen und dann über Kanten deren Verbindung (oder eben auch Nicht-Verbindung) dargestellt. Den ersten Einzug in die Psychologie hatten Netzwerke in Gruppenanalysen. Dabei sind nun nicht mehr Computer die Knotenpunkte, sondern eben Menschen aus einer spezifischen Gruppe. Bestimmte Arten der Beziehung werden dabei durch eine Verbindung zwischen zwei Personen abgebildet.

```{r, echo = F, figure = T}
library(qgraph)
people <- matrix(data =
                   c(0,1,0,0,1,0,0,0,0,1,
                     1,0,1,1,0,1,1,0,0,0,
                     0,1,0,0,1,1,1,0,0,0,
                     0,1,0,0,0,0,0,1,1,0,
                     1,0,1,0,0,1,1,0,0,1,
                     0,1,1,0,1,0,1,0,0,0,
                     0,1,1,0,1,1,0,0,0,0,
                     0,0,0,1,0,0,0,0,1,0,
                     0,0,0,1,0,0,0,1,0,1,
                     1,0,0,0,1,0,0,0,1,0), 
            nrow = 10, ncol = 10)
rownames(people)<- c("Anna", "Chris","Rosa","Johanna","Lars","Uwe","Lina","Lucie","Stefan","Miriam")
colnames(people)<- c("Anna", "Chris","Rosa","Johanna","Lars","Uwe","Lina","Lucie","Stefan","Miriam")
labs <- c("Anna", "Chris","Rosa","Johanna","Lars","Uwe","Lina","Lucie","Stefan","Miriam")



qgraph(people,layout = "spring",color = "yellow", label.cex = c(1,1,1,1,0.9,1,1,1,1,1.1), labels = labs, edge.color="black")
```

In der neueren Literatur werden Netzwerke aber auch zur Darstellung von Psychologischen Konstrukten genutzt. Beispielsweise können die einzelne Symptome der Depression die Knotenpunkte darstellen und die Kanten deren Zusammenhang. Dies hat gegenüber einem globalen Skalenwert den Vorteil, dass die Dynamik zwischen verschiedenen Symptomen aufgezeigt werden kann. Dadurch könnten zentrale Symptome und mögliche Ansatzpunkte für die Intervision aufgefunden werden. Bevor wir diese Punkte im Netzwerk identifizieren können, müssen wir uns mit grundlegenden Begriffen und der Berechnung der Netzwerkstruktur auseinandersetzen.   

Psychologisches Netzwerk zur Veranschaulichung (aus Präsentation nehmen)

## Begriffsklärung und Netzwerktypen

Betrachten wir an dieser Stelle nochmal zwei grundlegende Begriffe der Netzwerkanalyse. Wie bereits angedeutet wurde, bestehen diese aus **Knoten** und **Kanten**. **Knoten** oder englisch **nodes** repräsentieren Unterschiedliche psychologische Variablen (z.B: Störungen Symptome oder Items), die über Messungen aus verschiedenen Skalen oder Subskalen werden können. **Edges** der englisch **edges** repräsentieren statistische Beziehungen zwischen den Nodes (z.B. zum Beispiel Korrelationen) die anhand der Daten geschätzt werden. Während Werte auf den Knoten also gemessen werden, muss deren Beziehung (also die Kanten) geschätzt werden.


Kanten können sowohl **gerichtet** als auch **ungerichtet** sein, wobei gerichtete Edges durch einen Pfeil gekennzeichnet werden, der einen einseitigen Effekt andeutet. 

gerichetes und ungerichtetes Netzwerk nebeneinader darstellen

Ungerichtete Kanten werden durch eine einfache Linie zwischen zwei Knoten abgebildet werden. Ein Netzwerk, das nur gerichtete Kanten enthält, bezeichnet man als **gerichtetes Netzwerk**. Netzwerke aus ungerichteten Kanten nennt man hingegen **ungerichtetes Netzwerk**. Im Querschnitt sind keine zeitlichen Abfolgen bekannt, weshalb wir heute zunächst nur ungerichtete Netzwerke betrachten werden.

Eine weitere interessante Eigenschaft eines Netzwerkes besteht darin, ob die Kanten ein Gewicht inne haben. Die Unterscheidung besteht darin zwischen **gewichteten** und **ungewichteten** Netzwerken. Für beide Arten haben wir in diesem Tutorial bereits Beispiele gesehen. Das soziale Netzwerk der 10 Personen zeigte nur an, ob zwischen diesen eine Beziehung besteht oder nicht. Der Beziehung wird kein Gewicht zugegeben, weshalb es sich um ein ungewichtetes Netzwerk handelt. Das präsentierte psychologische Netzwerk hingegen hat unterschiedliche Kantenformen. Diese sind unterschiedlich dick, wodurch die unterschiedliche Stärke des Zusammenhangs zwischen den Symptomen demonstriert wird. Dabei wird auch durch die Farbe dargestellt, ob eine positive oder negative Beziehung vorliegt. Ursprünglich wurde dies durch grüne und rote Kanten demonstriert, wobei jetzt eine Wahl von blau für positive Beziehung eine höhere Differenzierbarkeit garantiert.  

Nachdem nun die wichtigsten Basics über Netzwerke abgehandelt wurden, können wir uns mit den ersten kleinen Umsetzungen in `R` beschäftigen. Zunächst brauchen wir aber natürlich einen Datensatz.

## Daten

In dieser Sitzung wollen wir einen Datensatz von Rubin (2020). verwenden. Dieser steht auf [OSF zum Download](https://osf.io/awz3d/) zur Verfügung kann aber auch über den folgenden Befehl direkt ins Environment eingeladen werden. 

```{r, results = "hide"}
raw_data <- readRDS(url("https://osf.io/awz3d/download"))
```

Mit `head` können wir uns wie gewohnt die ersten 6 Zeilen des Datensatzes anschauen. 

```{r}
head(raw_data)
```

Dabei ist auffällig, dass der Datensatz schon auf rein inhaltliche Items reduziert wurde. Allerdings ist die Benennung durch das Erhebungsinstrument und ein Kürzel bzw. die dazu gehörige Nummer für die Interpretation noch etwas unschön, weshalb wir die Bedeutung im folgenden Code als Spaltenname zuordnen. In Voraussicht auf spätere Zeichnungen kürzen wir manche längeren Namen etwas ab.

```{r}
names(raw_data) <- c("observe", "describe", "awaren.", "nonjudg.",
                     "nonreact.", "interest",  "emotions",  "sleep",
                     "tired",  "appetite", "selfim.",
                     "concentr.", "speed")
```

Die Variablen *observe*, *describe*, *awareness*, *nonjudging* und *nonreactivity* bezeichnen die **fünf Facetten der Achtsamkeit** von Baer et al. (2006), über die [in diesem Paper](https://pubmed.ncbi.nlm.nih.gov/16443717/) mehr steht. Die 8 weiteren Variablen beschreiben eine dysfunktionale, meist negative Veränderung in dem bezeichneten Lebensaspekt im Zuge einer **Depression**; so steht *interest* beispielsweise für einen Interessensverlust, während *selfimage* ein negatives Selbstbild abbildet.

## Netzwerkschätzung

Es gibt in `R` einige Pakete, die sich mit der Netzwerkanalyse auseinandersetzen. In der Psychologie ist wohl das `bootnet`-Paket aktuell das meist verwendete. Dieses vereint einige vorher entwickelte Pakete und ist dadurch für verschiedene Fragestellungen einsetzbar. Vor der ersten Verwendung muss das Paket natürlich installiert werden - die vorher entwickelten Pakete werden als Dependencies automatisch mit installiert. 

```{r, eval = FALSE}
install.packages("bootnet")
```

Anschließend müssen wir das Paket zur Verwendung natürlich noch aktivieren.

```{r}
library(bootnet)
```

Die Schätzung von Netzwerken funktioniert in dem Paket fast ausschließlich durch die Sammelfunktion `estimateNetwork`. In ihr können durch Argumente verschiedene Netzwerkanalysen durchgeführt werden, wie wir im weiteren Verlauf sehen werden.

Starten wir zunächst mit der einfachsten Berechnung von Zusammenhänge, die wir für intervallskalierte Variablen kennen gelernt haben - die Produkt-Moment-Korrelation. Wenn wir eine Netzwerkstruktur erstellen wollen, indem das Gewicht der Kanten der Korrelation zwischen den zugehörigen Knoten entspricht, muss das Argument `default` mit `"cor"` gefüllt werden. Weiterhin muss natürlich der Datensatz mit aufgeführt werden, für den die Schätzung durchgeführt werden soll. Wir weisen dieses Netzerk dem Objekt `cor_net` zu und betrachten das `summary`. 

```{r}
cor_net <- estimateNetwork(raw_data, default = "cor")
summary(cor_net)
```
Bei der Schätzung erhalten wir zunächst eine Warning Message, die wir aber nicht weiter betrachten müssen. Im `summary` sind einige Informationen abgetraten. Über das Netzwerk wird dabei ausgesagt, dass es `r cor_net$nNode` Knoten gibt. Weiterhin wird angezeigt, dass alle Korrelationen (also die Gewichte der Kanten) nicht gleich 0 sind. Es wird das durchschnittliche Gewicht der Gewichte bestimmt. Wir erhalten zusätzliche einige Hinweise zum weiteren Vorgehen und der Zitation. Dabei konzentrieren wir uns jetzt zunächst erst einmal darauf, das Netzwerk zu zeichnen.

```{r}
plot(cor_net)
```

Das Paket zeichnet wie wir es bereits gesehen haben positive Beziehungen als blaue Striche. Je stärker das Gewicht einer Kante ist, desto dicker ist die zugehörige Linie . Die Erstellung der Struktur in der Grafik (also an welchem Ord, welcher Knoten passiert wird), wird durch einen Algorithmus berechnet. Das Ziel dabei ist es, Knoten mit starken Verbindungen möglichst eng zu platzieren, welche mit schwächeren Verbindungen weiter entfernt. Die dahinter liegende Mathematik werden wir an dieser Stelle nicht besprechen. Neben dieser Darstellung als Matrix mit Zahlen möglich (in diesem Fall also die Korrelationsmatrix). Diese wird im Objekt abgelegt und kann daher sehr simpel ausgegeben werden.

```{r}
cor_net$graph
```

Die Koeffizienten liegen wie immer bei der Korrelation zwischen -1 und 1. Wir können uns exemplarisch noch die Beziehung der ersten beiden Variablen in der Matrix und im Plot anschauen. Das Gewicht wird als `r cor_net$graph[1,2]` ausgegeben. Im Plot findet man beide Items am Rand rechts. Sie sind durch einen dünnen (weil kleinerer Wert), blauen (weil positiver Wert) Strich verbunden.

Aus einiger Arbeit mit Korrelationen in multivariaten Settings wissen wir, dass die Einzigartigkeit einer Beziehung durch einfache Korrelationen nicht abgebildet wird. Obwohl zwei Variablen in unserem Plot also verbunden sind, könnten sie eigentlich keinen eigenen Zusammenhang haben, sondern durch eine Drittvariable gesteuert sein. Deshalb betrachtet man für solche Darstellungen üblicherweise nicht Korrelationen. Stattdessen werden die Partialkorrelationen berechnet. Die Gewichte der Kanten sollen die Beziehungen zwischen den Knoten abbilden, nachdem auf alle anderen Informationen im Datensatz kontrolliert wurde. Im Bachelor haben wir Formeln für das herauspartialisieren einer Variable aus der Beziehung für die Berechnung der Partialkorrelation kennen gelernt. Dies würde viel rechnerischen Aufwand bedeuten. Zum Glück können Partialkorrelationen auch aus der inversen der Kovarianzmatrix  berechnet werden. 

$$ \Theta = \Sigma^{-1} $$
$\Sigma$ bezeichnet die Kovarianzmatrix, während $\Theta$ die Inverse dieser symbolosiert. Die Berechnung der Parialkorrelation $\rho$ zweier Variablen $j$ und $p$ anhand der Einträge aus $\Theta$ folgt dann folgender Formel:

$$ \rho(y_py_j) = -\frac{\Theta_{y_py_j}}{\sqrt{\Theta_{y_piy_j}}\sqrt{\Theta_{y_py_j}}}$$

Für das Vorgehen in `R` hat diese Verwendung eines anderen Maßes erstmal keine großen Konsequenzen. In `default` muss jetzt `"pcor"` angegeben werden. Wir nennen das resultierende Objekt `pcor_net` und lassen uns wieder das `summary` ausgeben.

```{r}
pcor_net <- estimateNetwork(raw_data, default = "pcor")
summary(pcor_net)
```
Der Output verändert seine Struktur dabei nicht, nur die Werte werden für die neue Berechnung angepasst. Weiterhin sind jedoch keine Gewichte von Kanten 0, wozu wir gleich nochmal kommen werden. Zunächst wollen wir uns aber das Netzwerk nochmal zeichnen lassen.

```{r}
plot(pcor_net)
```

Zunächst sehen wir, dass sich die Struktur geändert hat. Da der Algorithmus nun andere Werte verwendet, platziert er auch die Knoten an anderen Orten. 

### Regularisierung und Netzwerkauswahl

Ein Problem der Netzwerkanalyse ist es, dass durch die Fehlervarianz in der Messung eigentlich immer alle Knoten untereinander verbunden sind. Dies führt vor allem bei komplexen Netzwerken mit vielen Knoten dazu, dass die Visualisierung des Netzwerkes unübersichtlich wird und man sich mit Kanten beschäftigt, die keine relevante Beziehung zwischen zwei Knoten darstellen. Um dies zu vermeiden, wird  für das Netzwerk der Partialkorrelation eine Regularisierung durchgeführt.

Ein regularisiertes Partialkorrelations-Netzwerk ist eine visualisierte gewichtete Netzwerkstruktur, das durch Regulations-Techniken aus dem Feld des Machine-Learnings geschätzt wird. Daraus resultiert eine sogenannte **sparse network structure** (also eine spärlich besetzte Netzwerkstruktur). Das bedeutet, dass viele der Parameter auf den Kanten exakt 0 sind. Die theoretische Reichweite der bestraften Partialkorrelationen ist dabei weiter zwischen 0 und 1.  

Das aktuelle Mittel der Wahl ist die **Lasso-Regulation**. Diese hat wie beschrieben das Ziel, **falsche** Kanten in ihrer Anzahl zu verringern. Falsche Kanten bedeutet also, dass diese in der Population nicht existieren, aber in der Stichprobe trotzdem keine Partialkorrelationen von 0 vorliegen würden. Regularisierungsmethoden kommen zum Einsatz, da die übliche Signifikanztestung aufgrund der Vielzahl der Kanten problematisch wäre. Die Lasso-Regularisierung hat gegenüber anderen Regularisierungs-Techniken den Vorteil, dass Werte genau 0 sein können. Aufgrund der noch andauernden Entwicklung der Netzwerkanalyse für psychologische Konstrukte gibt es über die Anwendung noch Diskussionen. Jedoch ist das Verfahren mathematisch durchaus etabliert und wird großflächig eingesetzt, weshalb wir es an dieser Stelle präsentieren.

Lasso kommt ursprünglich aus der multiplen Regression und wurde zur Selektion von Prädiktoren genutzt. Friedman et al. (2008) haben eine Überleitung in die Analyse von Grapfen (Netzwerke sind eigentlich auch nur Graphen) gespannt - daher kommt auch die Bezeichnung als **graphical lasso** (**glasso**). Obwohl es um Werte von 0 in der Partialkorrelationsmatrix geht, wird mathematisch die Bestrafung und Schätzung in der inversen Kovarianzmatrix $\Theta$. Wenn dort ein Eintrag 0 ist, folgt daraus nach der bereits dargestellten  Form der Berechnung der Partialkorrelation aber auch, dass diese den Wert 0 annimmt. Für die Schätzung der regularisierten inversen Kovarianzmatrix wird die folgende Gleichung maximiert.

$$\log \det(\Theta) - trace(S\Theta) - \lambda \|\Theta\|_1$$
Dabei steht $S$ für die empirisch gefundene Kovarianzmatrix. $\|\Theta\|_1$ bezeichnet die absolute Summe aller Einträge in $\Theta$. Da der Maximierungsprozess unter anderem duale Räumen verwendet, werden wir uns damit nicht näher befassen. Anhand der Gleichung sehen wir aber, dass hohe Werte in der inversen Matrix einen niedrigeren Gesamtwert ergeben, weshalb diese runter regularisiert werden. Weiterhin sehen wir, dass das Ergebnis der Maximierung abhängig von der Wahl eines $\lambda$-Wertes, den man auch als Bestrafungsparameters bezeichnet. Für eine gute Auwahl wird die Schätzung standardmäßig mit verschiedenen Bestrafungsparametern durchgeführt. Üblich sind dabei 100 $\lambda$-Werte. Als obere Grenze $\lambda_{max}$ wird der Wert gewählt, der alle Einträge auf 0 regularisieren würde. Bis zu einer gewählten unteren Grenze (meist $\lambda_{max} \cdot 0.01 $) werden die andere Werte in einer logarithmischen Verteilung festgelegt.

Nachdem 100 verschiedene inverse Kovarianzmatrizen geschätzt wurden, muss noch eine Auswahl der besten Werte geschehen. Üblicherweise wird dabei die Minimierung des Informationskriteriums **EBIC** nach Foygel und Drton (2010) genutzt.

$$ EBIC = -2LL + E \cdot \log(n) + 4 \cdot \gamma \cdot E \cdot \log(p) $$
$p$ Größe des Netzwerkes - also Zeilen und auch Spaltenanzahl der Matrix
$n$ Größe der Stichprobe   
$E$: Anzahl der Elemente der Matrix, die nicht null sind
 $\gamma$: Hyperparameter der Auswahl - üblicherweise auf 0.5 für moderate Bestrafung größerer Modell 0 wäre explorativer

Nachdem die beiden wichtigen Schritte (Regularisierung und Auswahl) nun theoretisch dargestellt wurden, können wir uns mit der praktischen Umsetzung befassen. `bootnet` bietet natürlich eine Möglichkeit, beide Schritte in einem durchzuführen. Die Kombination der Bestrafung anhand des grafischen Lasso mit der Auswahl des besten Netzwerkes durch EBIC führt zu der Benennung als `"EBICglasso` in dem Argument `default` in der bereits bekannten Funktion. Wir legen das Objekt unter `reg_net` als Netzwerk mit regularisierten Werten ab. Die Anzahl der geschätzten Werte, die anhand ihres EBICs anschließend bewertet werden, kann mit `nlambda` festgelegt werden. Weiterhin interessant ist das Argument `tuning`, in dem $\gamma$ als Bestrafungsparameter für Netzwerke mit vielen Edges festgelegt werden kann. Die hier gewählten Werte sind dabei die Standardeinstellungen des Paketes, aber eine Variation ist (wie zum Teil auch beschrieben) durchaus situativ nötig.

```{r}
reg_net <- estimateNetwork(raw_data, default = "EBICglasso",
                           nlambda = 100, tuning = 0.5)
summary(reg_net)
```

Der Aufbau des `summary` verändert sich auch im Fall der Regularisierung nicht. Wir sehen allerdings, dass nun nicht mehr alle Gewichte der Kanten ungleich null sind - nur 54 der ursrünglichen 78 haben noch ein solches. Anscheinend wurde ein Netzwerk ausgewählt, in dem manche Kanten als falsch identifiziert wurden. Im abgelegten Objekt `reg_net` kann man sich unter `results` diese auch noch genauer anschauen. Unter `optnet` sind die Gewichte der Kanten abgelegt, die später zum aufzeichnen der Struktur verwendet werden.

```{r}
reg_net$results$optnet
```

Im Endeffekte ist das aber die selbe Information, die in `reg_net$graph` abgelegt wird. `results` ist als Unterpunkt besonders interessant, wenn man sich den Ablauf der Berechnung nochmal klar machen möchte. 

Zunächst hat die Funktion 100 Bestrafungsparameter bestimmt. Diese sind unter `lambda` abgelegt.

```{r}
reg_net$results$lambda
```

Der größte Bestrafungsparameter ist der letzte Eintrag in der Matrix. Für diesen sollten alle Gewichte der Kanten auf 0 herunter regularisiert worden sein.

Die Werte aller 100 bestraften inversen Kovarianzmatrizen sind unter `reg_net$results$results$wi`. Beispielsweise ist das komplett leere Netzwerke (also mit dem größten Bestrafungsparameter $\lambda$) als 100. Objekt abgelegt.

```{r}
reg_net$results$results$wi[,,100]
```

Für jede dieser Strukturen hat die Funktion dann automatisch den EBIC mitbestimmt. Diese sind unter `ebic` abgelegt.

```{r}
reg_net$results$ebic
```

Der niedrigste dieser Werte hat für die Funktion den Ausschlag gegeben, welche Matrix als Struktur für das optimale Netzwerk ausgewählt wurde. Das Paket nutzt also genau das vorgehen, dass zu Beginn dieses Abschnitts theoretisch beschrieben wurde. 

Zur Veranschaulichung des Einfluss von $\gamma$ ziehen wir hier nochmal einen Verlgeich mit einem größeren Parameter in `tuning` von 2. 

```{r}
reg_net2 <- estimateNetwork(raw_data, default = "EBICglasso",
                           nlambda = 100, tuning = 2)
summary(reg_net2)
```

Das gewählte Netzwerk hätte jetzt noch 48 Kanten, die ein Gewicht ungleich 0 aufweisen würden. Natürlich ist `tuning = 2` ein unrealitisch hoher Wert, da dieser wie empfohlen stets zwischen 0 und 0.5 liegen sollte. Mathematisch macht dies jedoch keinen Unterschied und das Beispiel demonstriert seinen Zweck sehr gut: Ein höherer  Bestrafungsparameter führt dazu, dass ein Netzwerk mit weniger Gewichten unterschiedlich von 0 ausgewählt wird. Bei anderen Netzwerkkonstellationen wird dort auch ein Unterschied zwischen der Wahl von 0 oder 0.5 vorliegen.

Zum Abschluss dieses Abschnitts wollen wir natürlich das geschätzte Netzwerk auch nochmal zeichnen
```{r}
plot(reg_net)
```


## Zentralitätsindizes

Nachdem durch die eben durchgeführte Analyse ein Netzwerk für die Präsentation ausgewählt und auch gezeichnet wurde, stellt sich die Frage, welche weiteren Aussagen durch die Netzwerkanalyse durchführbar sind. In den technischen und sozialen Netzwerken wurde dafür die Zentralität der Knoten untersucht. Darin wird durch verschiedene Facetten aufgezeigt, welcher Knoten im Netzwerk am meisten Einfluss hat. Die Aktivierung dieser Knoten sollte zu einer (De-)Aktivierung anderer, verbundener Knoten im Netzwerk führen. Die Herangehensweise wurde mit kleinen Anpassungen für die Psychologischen Netzwerke übernommen. Die Anwendung steht aktuell in der Kritik aufgrund von instabiler Schätzung und der Frage der inhaltlichen Relevanz. Da diese Diskussion jedoch nicht abgeschlossen ist und die Indizes noch breitflächig zum Einsatz kommen, werden wir die wichtigen Werte auch an dieser Stelle besprechen und berechnen.

Die Zentralität eines Knoten ist hoch, wenn er starke oder viele Verbindungen hat, alle anderen Knoten schnell erreichbar sind oder durch ihn viele Verbindungen zwischen anderen Knoten gehen. Im Folgenden werden die **Zentralitäts-Indices** beschrieben und berechnet, die diese Eigenschaften repräsentieren. Während `bootnet` später wieder zum Einsatz kommt, ist es für die einfache Berechnung der Indizes nicht geeignet, weshalb wir das Paket `qgraph` aktivieren müssen. Dieses ist bei der Installation von `bootnet` mitinstalliert worden. 

```{r}
library(qgraph)
```

Die Anzahl von Verbindungen eines Knoten zu anderen Knoten im Netzwerk wird üblicherweise als **Grad der Zentralität** *(eng: degree)* bezeichnet. Dieser Wert ist besonders in ungewichteten Netzwerken von Interesse. Wenn Gewichte mit im Spiel sind, wird häufig die **Stärke** des Knoten *(eng: strength)* betrachtet. Diese wird durch die aufsummierten und gewichteten Werte aller Kanten eines Knoten zu allen anderen im Netzwerk vorhandenen Knoten dargestellt. 

Bezeichnung nicht komplett konsistent

Die folgenden Zentralitäts-Indizes werden über die Funktion `centrality` gemeinsam berechnet. Als `graph` Argument braucht man die Struktur des Graphen, die wie besprochen in `reg_net$graph` vorhanden ist.  Wir legen die Resultate erstmal in ein Objekt `centrality_indices` an und konzentrieren und auf den Unterpunkt `OutDegree`. 

```{r}
centrality_indices <- centrality(graph = reg_net$graph)
centrality_indices$OutDegree
```

Die Unterpunkte `InDegree` und `OutDegree` im Objekt `centrality_indices` sind gleich, da es sich um ein ungerichtetes Netzwerk handelt.

 Durch Kenntnis über die Stärke einer Node können weitere Informationen über die Zentralität der Node ausgesagt werden, zum Beispiel: Eine Node mit einem hohen Grad der Zentralität und einer niedrigen Stärke kann weniger zentral in einem Netzwerk sein als eine Node mit einem niedrigeren Grad der Zentralität und einer hohen Stärke.



Die **Verbundenheit** *(eng: closeness)* eines Knote quantifiziert ihre Beziehungen im Netzwerk anhand ihrer indirekten Verbindungen mit anderen Knoten. Hohe Verbundenheit charakterisiert im Mittel eine kurze Distanz von einem Knoten zu allen anderen Knoten. Knoten mit hoher Verbundenheit sind leicht von Veränderungen in einem beliebigen Part des Netzwerks betroffen und beeinflussen im Gegenzug leicht andere Knoten.

```{r}
centrality_indices$Closeness
```


Die **Dazwischenheit** *(eng: betweenness)* eines Knoten gibt Informationen über die Wichtigkeit einer Node im Rahmen der durchschnittlich zurückgelegten Weges zwischen ihr und anderen Nodes im Netzwerk. Die Node mit dem kürzesten Weg zwischen zwei anderen Nodes, also einer hohen "Dazwischenheit", hat beispielsweise besonderen Einfluss auf die Verbindung jener anderen Nodes.

```{r}
centrality_indices$Betweenness
```


## Fazit

Die Netzwerkanalyse für psychologisch Konstrukte ist ein sich noch entwickelndes Gebiet. Sie wird kein Ersatz der typischen latenten Modelle sein können, für die Visualisierung und spezifischere Betrachtung der Dynamik zwischen Symptomen aber in jedem Fall hilfreich sein. Die genaue Vorgehensweise der Schätzung und Interpretation sind aktuell ein Thema der methodischen Forschung. Im Paket `bootnet` sind dabei stets aktuelle Ansätze auffindbar. Es ist dabei auch sehr verständlich geschrieben und dient einem nutzerfreundlichen Einstieg.

*** 

## Literatur

[Epskamp, S., & Fried, E. I. (2018).](https://hds.hebis.de/ubffm/EBSCO/Record?id=edsarx.1607.01367|edsarx) A tutorial on regularized partial correlation networks. _Psychological Methods, 23_(4), 617-634.  [https://doi.org/10.1037/met0000167](https://doi.org/10.1037/met0000167)

[Foygel, R., & Drton, M.  (2010).](https://hds.hebis.de/ubffm/EBSCO/Record?id=edsarx.1011.6640|edsarx) Extended Bayesian information criteria for Gaussian graphical models. *Advances in Neural Information Processing Systems*, *23*, 604–612.

[Friedman, J., Hastie, T., & Tibshirani, R. (2008).](https://hds.hebis.de/ubffm/EBSCO/Record?id=RN231666321|edsbl) Sparse inverse covariance estimation with the graphical lasso. _Biostatistics, 9_(3), 432-441.  [https://doi.org/10.1093/biostatistics/kxm045](https://doi.org/10.1093/biostatistics/kxm045)



* <small> *Blau hinterlegte Autorenangaben führen Sie direkt zur universitätsinternen Ressource.*

