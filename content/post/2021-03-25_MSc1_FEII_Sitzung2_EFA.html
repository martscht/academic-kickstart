---
title: Exploratorische Faktorenanalyse
date: '2020-03-25'
slug: efa
categories:
  - MSc1
tags:
  - EFA
  - exploratorisch
  - Rotation
  - Datenreduktion
  - latent
  - Normalverteilung
  - Hauptachsenanalyse
subtitle: 'EFA'
summary: ''
authors: [irmer, schultze]
lastmod: '2021-04-13T08:32:21+02:00'
featured: no
header:
  image: "/header/FEII_Sitzung_2.png"
  caption: "[Courtesy of pxhere](https://pxhere.com/en/photo/1370218)"
projects: []
---

<script src="/rmarkdown-libs/header-attrs/header-attrs.js"></script>


<p>Forscher der Psychologie oder anderer Natur-, Sozial- und Geisteswissenschaften interessieren sich häufig dafür, wie sich Daten auf einige wenige entscheidende Faktoren herunterbrechen lassen, welche ein theoretisches Erklärungsmodell für die Variation in einem Datensatz liefern. Die Annahme ist hierbei, dass die beobachtbaren Messungen eine Linearkombination (also eine Summe) aus einem systematischen (wahren) und einem unsystematischen (Fehler-) Anteil bilden. Die dahinterliegenden Faktoren sind nicht messbare (latente) Variablen, auf welche, unter gewissen Annahmen, nur anhand der Kovariation zwischen den beobachtbaren Items geschlossen werden kann. Durch diese Zusammenhänge zwischen den Messungen können schließlich Hypothesen für die latenten Variablen untersucht werden. Ein theoriegenerierendes Verfahren, das hierzu häufig verwendet wird, ist die <strong>exploratorische Faktorenanalyse</strong> (im Folgenden EFA, engl. <strong>E</strong>xploratory <strong>F</strong>actor <strong>A</strong>nalysis, vgl. <a href="https://hds.hebis.de/ubffm/Record/HEB366849158">Eid, Gollwitzer &amp; Schmitt, 2017</a>, Kapitel 25; außerdem können Sie sich <a href="https://hds.hebis.de/ubffm/Record/HEB468515836">Brandt, 2020</a>, Kapitel 23 genauer ansehen, wenn Sie weitere Informationen, bzw. eine zusätzliche Erklärung wünschen).</p>
<p>Wir wollen die <strong>EFA</strong> zur Auswertung von Beziehungen zwischen Variablen in <code>R</code> näher kennenlernen. Die EFA ist manchen Gesichtspunkten, sowie im Output in <code>R</code>, recht verwandt mit der <a href="/post/PCA">Hauptkomponentenanalyse (PCA)</a> aus dem vergangenen Semester. Allerdings konnten wir bei der PCA kein Erklärungsmodell aufstellen (“wir konnten den Hauptkomponenten nicht so einfach eine inhaltliche Bedeutung zuschreiben”) und auch keine Messfehler (unsystematische Fehleranteile) mitmodellieren. Zudem waren die Hauptkomponenten der PCA Linearkombinationen (also Zusammensetzungen) aus den beobachteten Variablen, bei der EFA hingegen sind die Messungen (beobachteten Variablen) Linearkombinationen aus systematischen (latenten) Variablen sowie Messfehlern.</p>
<p>Bevor wir mit den Analysen beginnen können, laden wir zunächst alle Pakete, welche wir im Folgenden benötigen werden.</p>
<pre class="r"><code>library(corrplot) # Korrelationsmatrix grafisch darstellen
library(psych) # EFA durchführen
library(GPArotation) # EFA Lösung rotieren</code></pre>
<div id="datensatz" class="section level2">
<h2>Datensatz</h2>
<p>Wir wollen uns die Faktorenstruktur der <em>Big-5</em> eines entsprechenden Fragebogens ansehen. Der Originaldatensatz ist ein Onlinedatensatz, wird seit 2012 erfasst und ist auf <a href="https://openpsychometrics.org/_rawdata/"><svg style="height:0.8em;top:.04em;position:relative;" viewBox="0 0 512 512"><path d="M216 0h80c13.3 0 24 10.7 24 24v168h87.7c17.8 0 26.7 21.5 14.1 34.1L269.7 378.3c-7.5 7.5-19.8 7.5-27.3 0L90.1 226.1c-12.6-12.6-3.7-34.1 14.1-34.1H192V24c0-13.3 10.7-24 24-24zm296 376v112c0 13.3-10.7 24-24 24H24c-13.3 0-24-10.7-24-24V376c0-13.3 10.7-24 24-24h146.7l49 49c20.1 20.1 52.5 20.1 72.6 0l49-49H488c13.3 0 24 10.7 24 24zm-124 88c0-11-9-20-20-20s-20 9-20 20 9 20 20 20 20-9 20-20zm64 0c0-11-9-20-20-20s-20 9-20 20 9 20 20 20 20-9 20-20z"/></svg> openpsychometrics.org</a> als <em>.zip</em> downloadbar. Bisher haben über <strong>19700</strong> Probanden aus der ganzen Welt teilgenommen. Zu jeder der fünf Facetten gibt es 10 Fragen. Der Fragebogen ist auf <a href="http://personality-testing.info/tests/BIG5.php">personality-testing.info</a> einzusehen.
Um das Ganze etwas übersichtlicher zu gestalten, betrachten wir einen gekürzten Datensatz. Im Datensatz <em>Big5_EFA.rda</em> (wir kennen diesen Datensatz, allerdings in anderer Zusammensetzung, bereits aus den <a href="/post/MSc1-Daten">Übungen zum vergangenen Semester</a> zum Themenblock <a href="/post/manova">MANOVA</a>, weswegen wir hier das Kürzel “EFA” angehängt haben) befinden sich 15 Items aus dem Big-5 Persönlichkeitsfragebogen. Hier werden von diesen 10 Items jeweils die ersten drei verwendet. Der Itemwortlaut der verwendeten Items ist</p>
<table class="gmisc_table" style="border-collapse: collapse; margin-top: 1em; margin-bottom: 1em;">
<thead>
<tr>
<td colspan="2" style="text-align: left;">
Itemwortlaut
</td>
</tr>
<tr>
<th style="font-weight: 900; border-bottom: 1px solid grey; border-top: 2px solid grey; text-align: center;">
Item Nr.
</th>
<th style="font-weight: 900; border-bottom: 1px solid grey; border-top: 2px solid grey; text-align: center;">
Item
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">
E1
</td>
<td style="text-align: left;">
I am the life of the party.
</td>
</tr>
<tr>
<td style="text-align: center;">
E2
</td>
<td style="text-align: left;">
I don’t talk a lot.
</td>
</tr>
<tr>
<td style="text-align: center;">
E3
</td>
<td style="text-align: left;">
I feel comfortable around people.
</td>
</tr>
<tr>
<td style="text-align: center;">
N1
</td>
<td style="text-align: left;">
I get stressed out easily.
</td>
</tr>
<tr>
<td style="text-align: center;">
N2
</td>
<td style="text-align: left;">
I am relaxed most of the time.
</td>
</tr>
<tr>
<td style="text-align: center;">
N3
</td>
<td style="text-align: left;">
I worry about things.
</td>
</tr>
<tr>
<td style="text-align: center;">
A1
</td>
<td style="text-align: left;">
I feel little concern for others.
</td>
</tr>
<tr>
<td style="text-align: center;">
A2
</td>
<td style="text-align: left;">
I am interested in people.
</td>
</tr>
<tr>
<td style="text-align: center;">
A3
</td>
<td style="text-align: left;">
I insult people.
</td>
</tr>
<tr>
<td style="text-align: center;">
C1
</td>
<td style="text-align: left;">
I am always prepared.
</td>
</tr>
<tr>
<td style="text-align: center;">
C2
</td>
<td style="text-align: left;">
I leave my belongings around.
</td>
</tr>
<tr>
<td style="text-align: center;">
C3
</td>
<td style="text-align: left;">
I pay attention to details.
</td>
</tr>
<tr>
<td style="text-align: center;">
O1
</td>
<td style="text-align: left;">
I have a rich vocabulary.
</td>
</tr>
<tr>
<td style="text-align: center;">
O2
</td>
<td style="text-align: left;">
I have difficulty understanding abstract ideas.
</td>
</tr>
<tr>
<td style="border-bottom: 2px solid grey; text-align: center;">
O3
</td>
<td style="border-bottom: 2px solid grey; text-align: left;">
I have a vivid imagination.
</td>
</tr>
</tbody>
</table>
<p>Die Kürzung des vollen Datensatzes lässt sich im <a href="#AppendixA">Appendix A</a> nachvollziehen. Zusätzlich zu den Persönlichkeitsitems wurden demografische Daten, die mögliche Unterschiede zwischen Personen beschreiben, erfasst.</p>
<div id="daten-laden" class="section level3">
<h3>Daten laden</h3>
<p>Wir laden zunächst die Daten: entweder lokal von Ihrem Rechner:</p>
<pre class="r"><code>load(&quot;C:/Users/Musterfrau/Desktop/Big5_EFA.rda&quot;)</code></pre>
<p>oder wir laden sie direkt über die Website:</p>
<pre class="r"><code>load(url(&quot;https://pandar.netlify.app/post/Big5_EFA.rda&quot;))</code></pre>
<p>Nun sollte in <code>R</code>-Studio oben rechts in dem Fenster unter der Rubrik “Data” unser Datensatz mit dem Namen “<em>Big5</em>” erscheinen. Der Datensatz heißt also genauso wie der Datensatz für die <a href="/post/manova">MANOVA</a>, enthält aber andere Variablen (also <em>Achtung!</em>).</p>
</div>
<div id="übersicht-über-die-daten" class="section level3">
<h3>Übersicht über die Daten</h3>
<pre class="r"><code>head(Big5, n = 10) # gebe die ersten 10 Zeilen aus</code></pre>
<pre><code>##    age engnat gender country E1 E2 E3 N1 N2 N3 A1 A2 A3 C1 C2 C3 O1 O2 O3
## 1   53      1      1      US  4  2  5  1  5  2  1  5  1  4  1  5  4  1  3
## 2   46      1      2      US  2  2  3  2  3  4  1  3  3  4  1  3  3  3  3
## 3   14      2      2      PK  5  1  1  5  1  5  5  1  5  4  1  5  4  5  5
## 4   19      2      2      RO  2  5  2  5  4  4  2  5  4  3  3  4  4  3  5
## 5   25      2      2      US  3  1  3  3  3  3  5  5  3  3  1  5  3  1  1
## 6   31      1      2      US  1  5  2  1  5  4  2  2  3  2  5  4  4  2  1
## 7   20      1      2      US  5  1  5  2  4  2  5  5  1  2  4  3  3  1  5
## 8   23      2      1      IN  4  3  5  1  4  4  2  5  1  4  2  5  3  1  5
## 9   39      1      2      US  3  1  5  2  4  5  1  5  1  4  3  5  3  3  5
## 10  18      1      2      US  1  4  2  5  2  5  2  3  1  5  2  4  4  2  5</code></pre>
<p>Wir sehen, dass in den ersten 4 Spalten die demografischen Daten wie etwa <em>Alter (“age”)</em>, <em>Englisch als Muttersprache (“engant”, 1=yes, 2=no, 0=missed)</em>, <em>Geschlecht (“gender”, 1=Male, 2=Female, 3=Other, 0=missed)</em> und <em>Herkunftsland (“country”, ISO-kodiert, bspw. “DE” = Deutschland, “FR” = Frankreich, “EM” = Vereinigte Arabische Emirate, “US” = Vereinigten Staaten von Amerika)</em> eingetragen wurden. In den darauf folgenden Spalten sind die Items der Extraversion (engl. <em>extraversion</em>, Items: <em>E1</em>, <em>E2</em>, <em>E3</em>), des Neurotizismus (engl. <em>neuroticism</em>, Items: <em>N1</em>, <em>N2</em>, <em>N3</em>), der Verträglichkeit (engl. <em>agreeableness</em>, Items: <em>A1</em>, <em>A2</em>, <em>A3</em>), der Gewissenhaftigkeit (engl. <em>conscientiousness</em>, Items: <em>C1</em>, <em>C2</em>, <em>C3</em>) und der Offenheit für Erfahrungen (engl. <em>openness</em>, Items: <em>O1</em>, <em>O2</em>, <em>O3</em>) eingetragen. Beispielsweise ist die erste Person des Datensatzes ein 53-jähriger Mann, der Englisch als Muttersprache spricht und in den USA lebt.</p>
<p>Da wir uns in der Praxis nur sehr selten in der glücklichen Lage befinden, einen solch riesigen Datensatz zu haben, wollen wir uns innerhalb des Datensatzes auf Subgruppen beschränken: wir wollen uns zunächst nur Daten von Personen aus <em>Frankreich</em> ansehen. Dazu wählen wir nur diejenigen Zeilen aus, in denen <code>country == "FR"</code> gilt. Das erreichen wir wie folgt: Mit <code>Big5$country</code> haben wir Zugriff auf die “Country”-Spalte im Datensatz und können mit <code>== "FR"</code> prüfen, an welchen Stellen hier <em>“FR”</em> steht, also Personen, die in Frankreich leben. <code>dim</code> gibt die Dimensionen des Datensatzes wieder.</p>
<pre class="r"><code>dim(Big5)</code></pre>
<pre><code>## [1] 19711    19</code></pre>
<pre class="r"><code>data_France &lt;- Big5[Big5$country == &quot;FR&quot;, ]
dim(data_France)</code></pre>
<pre><code>## [1] 129  19</code></pre>
<p>Dem Output sollte zu entnehmen sein, dass <code>data_France</code> 129 Zeilen (also Probanden, die in Frankreich leben) und 19 Spalten (also Variablen) enthält. Für die weiteren Analysen brauchen wir die demografischen Variablen in dem Datensatz der in Frankreich lebenden Teilnehmer nicht mehr. Aus diesem Grund speichern wir den Datensatz noch einmal ohne die ersten 4 Spalten ab. Anschließend stellen wir die Korrelationsmatrix dieser Daten grafisch dar (den Befehl <code>corrplot</code> aus dem gleichnamigen Paket kennen wir bereits aus der <a href="/post/PCA">PCA</a> Sitzung des vergangenen Semesters).</p>
<pre class="r"><code>dataFR &lt;- data_France[, -c(1:4)] # entferne demografische Daten und speichere als &quot;dataFR&quot;

#### Visualisierte Korrelationsmatrix in dataFR
corrplot(corr = cor(dataFR), # Korrelationsmatrix (Datengrundlage)
         method = &quot;color&quot;, # zeichne die Ausprägung der Korrelation farblich kodiert
         addCoef.col = &quot;black&quot;, # schreibe die Korrelationskoeffizienten in schwarz in die Grafik
         number.cex = 0.7) # stelle die Schriftgröße der Koeffizienten ein</code></pre>
<p><img src="/post/2021-03-25_MSc1_FEII_Sitzung2_EFA_files/figure-html/unnamed-chunk-6-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>Auf den ersten Blick scheinen die Items der gleichen Skala (ausgedrückt durch gleiche Buchstaben pro Item) stärker (betragsmäßig höher) miteinander zu korrelieren. Allerdings sind hier sehr viele Korrelationen abgetragen. Wir wollen uns zunächst nur auf Extraversion und Neurotizismus beschränken.</p>
<pre class="r"><code>dataFR2 &lt;- dataFR[,1:6] # Zunächst wählen wir die ersten 6 Items: E1 bis E3 und N1 bis N3
head(dataFR2)</code></pre>
<pre><code>##     E1 E2 E3 N1 N2 N3
## 17   1  3  2  4  2  3
## 398  3  3  3  4  3  4
## 488  1  5  2  4  4  5
## 545  1  2  1  4  1  5
## 551  1  4  1  5  1  5
## 656  1  4  2  5  1  5</code></pre>
<pre class="r"><code># zum gleichen Ergebnis würde auch Folgendes kommen (besonders von Relevanz,
# wenn wir bspw. nicht die Position sondern nur die Namen der Variablen kennen!):
head(dataFR[, c(&quot;E1&quot;, &quot;E2&quot;, &quot;E3&quot;, &quot;N1&quot;, &quot;N2&quot;, &quot;N3&quot;)])</code></pre>
<pre><code>##     E1 E2 E3 N1 N2 N3
## 17   1  3  2  4  2  3
## 398  3  3  3  4  3  4
## 488  1  5  2  4  4  5
## 545  1  2  1  4  1  5
## 551  1  4  1  5  1  5
## 656  1  4  2  5  1  5</code></pre>
<p>Wenn wir uns die Korrelationmatrix des gekürzten Datensatzes <code>dataFR2</code> ansehen…</p>
<pre class="r"><code># Visualisierte Korrelationsmatrix
corrplot(corr = cor(dataFR2), # Korrelationsmatrix (Datengrundlage)
         method = &quot;color&quot;, # Zeichne die Ausprägung der Korrelation farblich kodiert
         addCoef.col = &quot;black&quot;, # schreibe die Korrelationskoeffizienten in schwarz in die Grafik
         number.cex = 1) # Stelle die Schriftgröße der Koeffizienten ein</code></pre>
<p><img src="/post/2021-03-25_MSc1_FEII_Sitzung2_EFA_files/figure-html/unnamed-chunk-8-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>…erkennen wir deutlich, dass die Extraversionsitems und die Neurotizismusitems untereinander jeweils stärker zusammenhängen als zwischen den Konstrukten. Dennoch ist der Grafik zu entnehmen, dass die beiden Konstrukte nicht unabhängig voneinander sind (es gibt Beziehungen zwischen Items der beiden Konstrukte).</p>
</div>
</div>
<div id="ziel-efa" class="section level2">
<h2>Ziel: EFA</h2>
<p>Unser Ziel ist es, mit den gegebenen Items eine exploratorische Faktorenanalyse durchzuführen. Wir wollen hierbei die Anzahl der Faktoren mittels einer Parallelanalyse bestimmen und anschließend dieses Modell mit dem <span class="math inline">\(\chi^2\)</span>-Test (<em>Likelihood-Quotiententest (Likelihood-Ratio-Test)/ Likelihood-Differenzentest</em>/ <span class="math inline">\(\chi^2\)</span>-<em>Differenzentest</em>) gegen konkurrierende Modelle testen.
Hierbei wollen wir die oblique rotierte und die orthogonal rotierte Lösung vergleichen und hinsichtlich unserer Daten interpretieren. Das Modell, was wir an unsere Daten anpassen wollen, sieht für 6 Variablen (<span class="math inline">\(V_1,\dots,V_6\)</span>) im Allgemeinen erst einmal so aus (hier sind nur die Beziehungen, nicht aber die Stärken der Beziehungen zwischen den Variablen abgetragen), wobei hier schon die implizite Annahme drin steckt, dass es nur zwei zugrundeliegende latente Variablen gibt:</p>
<center>
<img src="https://raw.githubusercontent.com/martscht/PsyMSc1/master/inst/tutorials/EFA/images/EFA_Modell.png" width="70%"/>
</center>
<p>Auf unseren Datensatz angepasst, wollen wir folgendes Modell anpassen:</p>
<center>
<img src="https://raw.githubusercontent.com/martscht/PsyMSc1/master/inst/tutorials/EFA/images/specific_model.png" width="70%"/>
</center>
<p>Natürlich erwarten wir, dass insgesamt 2 Faktoren die Daten am besten beschreiben und dass die konstruktkongruenten Items jeweils auf dem gleichen Faktor am stärksten laden. Aber stützen die Daten diese Hypothese?</p>
<p>Wir wollen im Folgenden</p>
<ul>
<li>eine Parallelanalyse durchführen, um in Erfahrung zu bringen, wie viele Faktoren sinnvoll zu den Daten passen</li>
<li>eine Hauptachsenanalyse mit orthogonaler und obliquer Rotation durchführen</li>
<li>eine exploratorische Maximum-Likelihood-Faktorenanalyse durchführen und die Passung zu den Daten untersuchen</li>
<li>im Rahmen der exploratorischen Maximum-Likelihood-Faktorenanalyse die Passung zu den Daten im Vergleich zu konkurrierenden Modellen untersuchen.</li>
</ul>
<div id="Parallelanalyse_1" class="section level3">
<h3>Parallelanalyse und Auswahl an Faktoren</h3>
<p>Zur Auswahl der Anzahl an Faktoren in der EFA kann auf die Eigenwerte zurückgegriffen werden. Diese Eigenwerte entstehen beispielsweise durch Lösen des Eigenwerteproblems und entsprechen den Varianzen der Faktoren. Hier gilt es, nur solche Faktoren zu wählen, die auch große Varianzen haben.
Die Parallelanalyse hatten wir im Zusammenhang mit der <a href="/post/PCA">Hauptkomponentenanalyse</a> kennengelernt. Hier werden vielfach (z.B. 1000 Mal, für Vergleichbarkeit sogar besser mehr!) unabhängige Daten in dem gleichen Format des ursprünglichen Datensatzes gezogen und eine PCA oder EFA durchgeführt. Die entstehenden Eigenwerte werden der Größe nach sortiert und dann über die Wiederholungen gemittelt. So entsteht ein auf die Stichprobe und Anzahl der Variablen genormter, zufälliger, durchschnittlicher Eigenwerteverlauf. Sind Eigenwerte der tatsächlich beobachteten Daten größer als die der Parallelanalyse, so spricht dies für eine/n bedeutsame/n Komponente/Faktor. Weitere Kriterien zur Auswahl von zu extrahierenden Faktoren im Rahmen der PCA waren das <em>Eigenwerte-größer-1 Kriterium (Kaiser-Guttman-Kriterium)</em> sowie der <em>Scree-Test (Ellbow-Criterion, Knick im Eigenwerteverlauf)</em>. Weitere Informationen zur EFA sowie zu Wiederholungen der PCA und der Auswahlkriterien können beispielsweise in <a href="https://hds.hebis.de/ubffm/Record/HEB366849158">Eid, Gollwitzer und Schmitt (2017)</a> in Kapitel 25 (Seite 919 und folgend) nachgelesen werden.</p>
<p>Der wesentliche Unterschied zwischen einer EFA und einer PCA ist, dass bei der EFA angenommen wird, dass die beobachteten Variablen systematische (wahre) und unsystematische (Fehler-) Anteile enthalten. Es wird somit ein Erklärungsmodell, welches die Variation zwischen den Variablen erzeugt, postuliert. Bei der PCA werden die beobachteten Variablen als messfehlerfrei angenommen. Eine wichtige Folge aus der (Nicht-) Modellierung der Fehler ist, dass in der Regel die Faktorladungen bei der PCA höher ausfallen als bei der EFA. Dies liegt daran, dass bei der PCA die Variablen mit ihren eigenen Messfehlern, aus welchen auch die Hauptkomponenten unter anderem zusammengesetzt sind, korrelieren. Die Faktorladungen/ Komponentenladungen stehen hierbei (im orthogonalen Fall) für die Korrelation zwischen Item und Faktor/ Komponente; im obliquen Fall sind die Faktorladungen als Regressionkoeffizienten zu interpretieren. Wird eine ML-EFA an die Daten angepasst, so wird zusätzlich noch ein Erklärungsmodell basierend auf Verteilungsannahmen (multivariate Normalverteilung der Faktoren und Fehler — und als Konsequenz daraus auch der Items) herangezogen. Bei der PCA sind die Hauptkomponenten lediglich Linearkombinationen aus den beobachteten Variablen ohne jegliche Verteilungsannahmen (die Hauptkomponenten bestehen aus gewichteten Summen der beobachteten Variablen). Entsprechend ist es bei der PCA auch nicht möglich, konkurierende Modelle gegeneinander zu testen. Es bleiben dort nur die deskriptiven und recht subjektiven Auswahlkriterien für die Anzahl der Komponenten.</p>
<p>Mit Hilfe des <code>fa.parallel</code> Befehls aus dem <code>psych</code>-Paket, welchen wir im Rahmen der PCA bereits kennengelernt hatten, lässt sich ganz einfach der Eigenwerteverlauf inklusive Parallelanalyse grafisch darstellen.</p>
<pre class="r"><code>fa.parallel(dataFR2)</code></pre>
<p><img src="/post/2021-03-25_MSc1_FEII_Sitzung2_EFA_files/figure-html/unnamed-chunk-9-1.png" width="672" style="display: block; margin: auto;" /></p>
<pre><code>## Parallel analysis suggests that the number of factors =  2  and the number of components =  2</code></pre>
<p>Ohne weitere Einstellungen wird der Eigenwerteverlauf der PCA und der EFA ausgegeben. Deutlich zu sehen ist, dass die Eigenwerte der PCA größer ausfallen als die der EFA. Dies liegt erneut daran, dass die Faktoren der EFA lediglich die systematischen Anteile der Variablen enthalten, während die Komponenten der PCA Kompositionen sind - also Zusammensetzungen aus den Variablen; inklusive der Messfehler. Wählen wir <code>fa = "fa"</code>, so wird uns nur der Verlauf der Eigenwerte auf Basis einer EFA aufgeführt.</p>
<pre class="r"><code>fa.parallel(dataFR2, fa = &quot;fa&quot;)</code></pre>
<p><img src="/post/2021-03-25_MSc1_FEII_Sitzung2_EFA_files/figure-html/unnamed-chunk-10-1.png" width="672" style="display: block; margin: auto;" /></p>
<pre><code>## Parallel analysis suggests that the number of factors =  2  and the number of components =  NA</code></pre>
<p>Die Grafik zeigt drei Eigenwerteverläufe. <em>FA Actual Data</em> ist der Eigenwerteverlauf unseres Datensatzes. <em>FA Simulated Data</em> ist der Eigenwerteverlauf basierend auf den 1000 simulierten Datensätzen. <em>FA Resampled Data</em> ist der Eigenwerteverlauf von Datensätzen, der durch <em>Resampling</em>, also neues Verteilen unseres Datensatzes entsteht (das ist im Grunde <a href="/post/sem/#Bootstrapping">Bootstrapping</a>, was im Rahmen der Sitzung zu <a href="/post/sem">SEM</a> näher erläutert wird).</p>
<p>Der Parallelanalyse der EFA ist zu entnehmen, dass voraussichtlich 2 Faktoren genügen, um die Variation im Datensatz zu erklären. Auch die Parallelanalyse der PCA (Grafik zuvor) lässt dies vermuten. Des Weiteren sprechen beide Scree-Tests für einen Knick um den 3. Faktor/die 3. Komponente, was auch für eine Dimensionalität von 2 spricht. Zu guter Letzt zeigt auch das Kaiser-Guttman-Kriterium kein anderes Ergebnis. Allerdings ist dieses Kriterium nur sinnvoll auf den Eigenwerteverlauf der PCA anwendbar, weswegen wir es auch nur im Bezug auf den PCA-Eigenwerteverlauf interpretieren.</p>
</div>
<div id="Hauptachsenanalyse" class="section level3">
<h3>Orthogonale und oblique Hauptachsenanalyse</h3>
<p>Da unsere Auswahlkriterien einstimmig für 2 Faktoren sprechen und dies auch unsere Hypothese war, modellieren wir zunächst eine orthogonale Hauptachsenanalyse. Dazu nutzen wir den <code>fa</code> (Factor Analysis) Befehl des <code>psych</code> Paketes. Mit Hilfe der Argumente <code>nfactors</code> und <code>rotate</code> lässt sich die Anzahl an Faktoren sowie die Rotation auswählen (genauso wie bei der <code>pca</code> Funktion für die PCA!). Wir wollen hier orthogonal varianzmaximierend (also <em>varimax</em>) rotieren.</p>
<pre class="r"><code>fa(dataFR2, nfactors = 2, rotate = &quot;varimax&quot;)</code></pre>
<pre><code>## Factor Analysis using method =  minres
## Call: fa(r = dataFR2, nfactors = 2, rotate = &quot;varimax&quot;)
## Standardized loadings (pattern matrix) based upon correlation matrix
##      MR1   MR2   h2   u2 com
## E1  0.69 -0.06 0.48 0.52 1.0
## E2 -0.65  0.00 0.42 0.58 1.0
## E3  0.82 -0.19 0.70 0.30 1.1
## N1 -0.01  0.84 0.70 0.30 1.0
## N2  0.10 -0.58 0.35 0.65 1.1
## N3 -0.05  0.59 0.34 0.66 1.0
## 
##                        MR1  MR2
## SS loadings           1.58 1.42
## Proportion Var        0.26 0.24
## Cumulative Var        0.26 0.50
## Proportion Explained  0.53 0.47
## Cumulative Proportion 0.53 1.00
## 
## Mean item complexity =  1
## Test of the hypothesis that 2 factors are sufficient.
## 
## The degrees of freedom for the null model are  15  and the objective function was  1.47 with Chi Square of  183.82
## The degrees of freedom for the model are 4  and the objective function was  0.07 
## 
## The root mean square of the residuals (RMSR) is  0.04 
## The df corrected root mean square of the residuals is  0.07 
## 
## The harmonic number of observations is  129 with the empirical chi square  4.98  with prob &lt;  0.29 
## The total number of observations was  129  with Likelihood Chi Square =  9.06  with prob &lt;  0.06 
## 
## Tucker Lewis Index of factoring reliability =  0.886
## RMSEA index =  0.099  and the 90 % confidence intervals are  0 0.187
## BIC =  -10.38
## Fit based upon off diagonal values = 0.99
## Measures of factor score adequacy             
##                                                    MR1  MR2
## Correlation of (regression) scores with factors   0.89 0.88
## Multiple R square of scores with factors          0.79 0.77
## Minimum correlation of possible factor scores     0.58 0.55</code></pre>
<p>Im Output ganz oben erkennen wir die Schätzmethode (hier: <code>minres</code>, also Minimierung der Residuen). Aus diesem Grund heißen die Faktoren in diesem Output auch <em>MR1</em> und <em>MR2</em>; für <em>Minimale-Residuen-Faktor 1</em> und <em>2</em> (diese Benennung war uns auch bereits bei der PCA aufgefallen, wo diese je nach Rotation entweder PC1 oder RC1, etc., hießen). Die Faktorladungen zu den zugehörigen Faktoren sind unter <code>Standardized loadings (pattern matrix) based upon correlation matrix</code> zu sehen. <code>h2</code> steht für die Kommunalität (<span class="math inline">\(h^2\)</span>), also den Anteil an systematischer Variation, die auf die 2 Faktoren zurückzuführen ist (diese kann ähnlich der Reliabilität interpretiert werden). <code>u2</code> ist die “uniqueness” (<span class="math inline">\(u^2\)</span>), also der unerklärte Anteil. Offensichtlich gilt <span class="math inline">\(u^2 = 1-h^2\)</span> oder <span class="math inline">\(h^2 + u^2 = 1\)</span>. Unter den Faktorladungen erhalten wir Informationen über die Faktoren. <code>SS loadings</code> steht für “Sum of Squares loadings”, also die Quadratsumme der Faktorladungen. Diese ist gleich dem Eigenwert: <span class="math inline">\(\theta_j = \Sigma_{i=1}^p\lambda_{ij}^2 = \lambda_{1j}^2+\dots+\lambda_{pj}^2\)</span> (Spaltenquadratsumme der Faktorladungen), mit <span class="math inline">\(p=\)</span> Anzahl an Variablen (hier <span class="math inline">\(p=6\)</span>). Allerdings gilt dies nur für den orthogonalen Fall. Sind die Faktoren korreliert, muss diese Korrelation berücksichtigt werden. Dazu später mehr! <code>Proportion Var</code> betitelt den Anteil der Variation, der durch die jeweiligen Faktoren erklärt werden kann. <code>Cumulative Var</code> kumuliert, also summiert, diese Anteile bis zum jeweiligen Faktor auf (<span class="math inline">\(\text{CumVar}_j = \sum_{k=1}^j\theta_k = \theta_1+\dots+\theta_j\)</span>, also <span class="math inline">\(\text{CumVar}_1=\theta_1\)</span> und <span class="math inline">\(\text{CumVar}_2=\theta_1+\theta_2\)</span>). <code>Proportion Explained</code> setzt die Variation, die durch die Faktoren erklärt wird, in Relation zur gesamten erklärten Varianz (d.h. hier summiert sich die erklärte Varianz immer zu 1, während sich die proportionale Varianz nur zu 1 aufsummiert, wenn die gesamte Variation im Datensatz auf die beiden Variablen zurückzuführen ist). <code>Cumulative Proportion</code> beschreibt das gleiche wie <code>Cumulative Var</code>, nur bezieht sie sich hier auf die <code>Proportion Explained</code>. Bei der Interpretation dieser Kennwerte ist zu bedenken, dass bei der EFA angenommen wird, dass die beobachteten Variablen Messfehler enthalten (also die Reliabilität nicht als 1 angenommen werden kann). Folglich ist die Kommunalität <span class="math inline">\(h^2\)</span> nicht 1 und wir können nicht unbedingt davon ausgehen, dass die Faktoren die gesamte Variation der Daten erklären. All diese Koeffizienten kennen wir bereits aus der Sitzung zur <a href="/post/PCA">PCA</a>, wo wir diese im Hinblick auf eine PCA interpretierten. Dabei fiel uns auch auf, dass einige Koeffizienten in dieser Übersicht nicht mit allen Dezimalstellen angezeigt werden und es ggf. zu seltsamen Rundungsverfälschungen kommen kann. Aus diesem Grund hatten wir uns entschieden, die jeweiligen Koeffizienten und Informationen dem Objekt selbst zu entlocken, um diese Rundungsverfälschungen zu umgehen.</p>
<p>Außerdem werden durch diesen Befehl sehr viele Informationen ausgegeben. Aus diesen Gründen speichern wir uns diese Analyse als ein Objekt ab, welchem wir dann gezielt Informationen mit Hilfe von <code>...$...</code> entlocken können. Welche Argumente entlockt werden können, kann beispielsweise mit <code>names</code> herausgefunden werden. Wir speichern das Objekt unter dem Namen <em>two_factor</em> ab.</p>
<pre class="r"><code>two_factor &lt;- fa(dataFR2, nfactors = 2, rotate = &quot;varimax&quot;)
names(two_factor) # mögliche Informationen</code></pre>
<pre><code>##  [1] &quot;residual&quot;      &quot;dof&quot;           &quot;chi&quot;           &quot;nh&quot;           
##  [5] &quot;rms&quot;           &quot;EPVAL&quot;         &quot;crms&quot;          &quot;EBIC&quot;         
##  [9] &quot;ESABIC&quot;        &quot;fit&quot;           &quot;fit.off&quot;       &quot;sd&quot;           
## [13] &quot;factors&quot;       &quot;complexity&quot;    &quot;n.obs&quot;         &quot;objective&quot;    
## [17] &quot;criteria&quot;      &quot;STATISTIC&quot;     &quot;PVAL&quot;          &quot;Call&quot;         
## [21] &quot;null.model&quot;    &quot;null.dof&quot;      &quot;null.chisq&quot;    &quot;TLI&quot;          
## [25] &quot;RMSEA&quot;         &quot;BIC&quot;           &quot;SABIC&quot;         &quot;r.scores&quot;     
## [29] &quot;R2&quot;            &quot;valid&quot;         &quot;score.cor&quot;     &quot;weights&quot;      
## [33] &quot;rotation&quot;      &quot;communality&quot;   &quot;communalities&quot; &quot;uniquenesses&quot; 
## [37] &quot;values&quot;        &quot;e.values&quot;      &quot;loadings&quot;      &quot;model&quot;        
## [41] &quot;fm&quot;            &quot;rot.mat&quot;       &quot;Structure&quot;     &quot;method&quot;       
## [45] &quot;scores&quot;        &quot;R2.scores&quot;     &quot;r&quot;             &quot;np.obs&quot;       
## [49] &quot;fn&quot;            &quot;Vaccounted&quot;</code></pre>
<p>Beispielsweise erhalten wir mit <code>$loadings</code> die Faktorladungsmatrix sowie Informationen über die Eigenwerte. (<em>Wichtig für später</em>: Die richtigen Kommunalitäten werden mit <code>$communality</code> angefordert.)</p>
<pre class="r"><code>two_factor$loadings</code></pre>
<pre><code>## 
## Loadings:
##    MR1    MR2   
## E1  0.692       
## E2 -0.646       
## E3  0.819 -0.186
## N1         0.837
## N2        -0.580
## N3         0.585
## 
##                  MR1   MR2
## SS loadings    1.578 1.419
## Proportion Var 0.263 0.236
## Cumulative Var 0.263 0.499</code></pre>
<p>Hier ist relativ deutlich die Zuordnung zu den jeweiligen Faktoren zu sehen. Faktor 1 (<em>MR1</em>) entspräche <em>post-hoc</em> interpretiert (die Theorie wird also aus den Daten generiert; es sind auch andere Interpretationsansätze zulässig) der Extraversion, während der zweite Faktor (<em>MR2</em>) dem Neurotizismus entspräche. Indem wir hinter <code>loadings</code> eckige Klammern mit einem Komma setzten (<code>[,]</code>), bekommen wir alle Nachkommastellen ohne Runden angzeigt (hätten wir bspw. <code>round</code> auf die Ladungsmatrix oben angewendet, würden sich auch die Eigenwerte ändern, weswegen diese Ansicht sich nicht wirklich zur genauen Interpretation der Eigenwerte eignet! Hier hatten wir das Argument <code>Vaccounted</code> bereits im Rahmen der <a href="/post/PCA">PCA</a> kennengelernt):</p>
<pre class="r"><code>two_factor$loadings[,] # ohne seltsames Runden</code></pre>
<pre><code>##            MR1          MR2
## E1  0.69189323 -0.058067393
## E2 -0.64577474  0.004122088
## E3  0.81858640 -0.185912523
## N1 -0.01345489  0.837407770
## N2  0.09879742 -0.580348020
## N3 -0.04734674  0.585385819</code></pre>
<p>Die Faktorladungsmatrix wird auch manchmal <em>Mustermatrix</em> genannt. Die <em>Strukturmatrix</em> enthält Informationen über die Korrelation der Items mit den jeweiligen Faktoren. Sie heißt <code>Structure</code>. Auch hier ist der Zusatz <code>[,]</code> sinnvoll!</p>
<pre class="r"><code>two_factor$Structure[,]</code></pre>
<pre><code>##            MR1          MR2
## E1  0.69189323 -0.058067393
## E2 -0.64577474  0.004122088
## E3  0.81858640 -0.185912523
## N1 -0.01345489  0.837407770
## N2  0.09879742 -0.580348020
## N3 -0.04734674  0.585385819</code></pre>
<p>Wir sehen deutlich, dass die Strukturmatrix sich nicht von der Faktorladungsmatrix unterscheidet. Das liegt daran, dass die Faktoren noch als unkorreliert angenommen werden: somit ist die Faktorladungsmatrix gleich der Strukturmatrix. Genau aus diesem Grund hatten wir uns die Strukturmatrix auch nicht im Rahmen der PCA angesehen — dort hatten wir nur orthogonal rotiert.</p>
<p>Da wir nicht davon ausgehen können, dass die Faktoren unkorreliert sind, wollen wir die gleiche Analyse nun für <em>oblique</em> (“oblimin” in <code>R</code>) rotierte Faktoren durchführen.</p>
<pre class="r"><code>two_factor_oblimin &lt;- fa(dataFR2, nfactors = 2, rotate = &quot;oblimin&quot;)</code></pre>
<p>Die einzig neue Information können wir unter <code>With factor correlations of</code> ablesen: die Korrelation zwischen den Faktoren. Im Output der obliquen Rotation ist zu erkennen, dass sich die Kommunalitäten nicht ändern. Wir können also nicht mehr Variation im Datensatz erklären. Die Varianz wird nur umverteilt, wie den veränderten Eigenwerten neben <code>SS loadings</code> zu entnehmen ist. Hier hat der erste Faktor einen etwas größeren Eigenwert als im orthogonalen Fall (entsprechend ist der 2. Eigenwert kleiner, da nicht mehr Variation erklärt wird):</p>
<pre class="r"><code>two_factor$Vaccounted</code></pre>
<pre><code>##                             MR1       MR2
## SS loadings           1.5780086 1.4186844
## Proportion Var        0.2630014 0.2364474
## Cumulative Var        0.2630014 0.4994488
## Proportion Explained  0.5265833 0.4734167
## Cumulative Proportion 0.5265833 1.0000000</code></pre>
<pre class="r"><code>two_factor_oblimin$Vaccounted</code></pre>
<pre><code>##                             MR1       MR2
## SS loadings           1.6065736 1.3901195
## Proportion Var        0.2677623 0.2316866
## Cumulative Var        0.2677623 0.4994488
## Proportion Explained  0.5361155 0.4638845
## Cumulative Proportion 0.5361155 1.0000000</code></pre>
<p>Schauen wir uns die Ladungsmatrix an, …</p>
<pre class="r"><code>two_factor_oblimin$loadings[,] # Ladungsmatrix</code></pre>
<pre><code>##            MR1         MR2
## E1  0.70055173  0.03946625
## E2 -0.65623412 -0.08729631
## E3  0.82326401 -0.07142273
## N1  0.02609114  0.84195602
## N2  0.07286715 -0.57082957
## N3 -0.02032830  0.58319228</code></pre>
<p>… so ist <em>post-hoc</em> interpretiert anzunehmen, dass der erste Faktor die Extraversion abbildet und der zweite den Neurotizismus.</p>
<p>Entlocken Sie doch mal dem Objekt <code>two_factor_oblimin</code> die latente Kovarianzmatrix, also die Kovarianzmatrix der latenten Variablen. Tipp, der griechische Buchstabe in diesem Zusammenhang ist häufig <span class="math inline">\(\Phi\)</span>. Die resultierende Matrix sieht so aus:</p>
<pre><code>##            MR1        MR2
## MR1  1.0000000 -0.1852246
## MR2 -0.1852246  1.0000000</code></pre>
<p>Als neue Information entnehmen wir der Korrelationsmatrix der Faktoren, dass die beiden Faktoren negativ korreliert sind zu -0.19. Nun wollen wir nachschauen, ob sich tatsächlich die Strukurmatrix im oblique-rotierten Fall von der Faktorladungsmatrix unterscheidet:</p>
<pre class="r"><code>two_factor_oblimin$loadings[,]</code></pre>
<pre><code>##            MR1         MR2
## E1  0.70055173  0.03946625
## E2 -0.65623412 -0.08729631
## E3  0.82326401 -0.07142273
## N1  0.02609114  0.84195602
## N2  0.07286715 -0.57082957
## N3 -0.02032830  0.58319228</code></pre>
<pre class="r"><code>two_factor_oblimin$Structure[,]</code></pre>
<pre><code>##           MR1         MR2
## E1  0.6932416 -0.09029319
## E2 -0.6400647  0.03425442
## E3  0.8364933 -0.22391151
## N1 -0.1298599  0.83712330
## N2  0.1785989 -0.58432636
## N3 -0.1283499  0.58695759</code></pre>
<p>Sie sehen, dass sich nun die Strukturmatrix von der Faktorladungsmatrix unterscheidet. Die Unterschiede sind allerdings nicht sehr groß, da die Korrelation zwischen den beiden Faktoren mit -0.19 betragsmäßig nicht sonderlich groß ausfällt. Weitere Informationen und wie die beiden Matrizen ineinander überführbar sind, erfahren Sie im <a href="#AppendixB">Appendix B</a>. In <a href="#AppendixC">Appendix C</a> erfahren Sie, wie sie Kommunalitäten und Eigenwerte im Rahmen der EFA nur mit Hilfe der <code>loadings</code> und der Faktorkorrelation <code>Phi</code> bestimmen.</p>
<p>Die Frage ist nun, ob unser Modell überhaupt zu den Daten passt.</p>
</div>
<div id="exploratorische-maximum-likelihood-faktorenanalyse-ml-efa" class="section level3">
<h3>Exploratorische Maximum-Likelihood-Faktorenanalyse (ML-EFA)</h3>
<p>Wir möchten unsere Analysen nun gegen andere konkurrierende Modelle absichern sowie untersuchen, ob unser zweifaktorielles Modell überhaupt zu den Daten passt. Hierzu müssen wir annehmen, dass unsere Daten multivariat normalverteilt sind. Wie man diese Annahme zumindest deskriptiv untersucht, hatten wir im Zusammenhang mit den Voraussetzungen von statistischen Verfahren kennengelernt (Mahalanobis-Distanz sollte approximativ <span class="math inline">\(\chi^2\)</span>-verteilt sein, siehe hierzu im <a href="#AppendixD">Appendix D</a> nach, auch weitere Tests sind möglich: bspw. Mardia’s Test). Mit Hilfe dieser Verteilungsannahme können wir die Maximum-Likelihood-Schätzmethode nutzen, um die Parameter in unserem Modell zu schätzen. Die <em>Likelihood</em> ist die Wahrscheinlichkeit unserer Daten gegeben das Modell. Sie hängt somit von den beobachteten Daten ab (den Ausprägungen der Personen auf den Variablen), hat die Gestalt unseres Modells und wird parametrisiert durch die Parameter in unserem Modell. Die durch das Modell implizierte Kovarianz oder Korrelationsmatrix der beobacheten Variablen wird mit <span class="math inline">\(\Sigma\)</span> betitelt und setzt sich folgendermaßen zusammen:</p>
<p><span class="math display">\[\Sigma := \Lambda\Phi \Lambda&#39; + \Theta.\]</span>
Dabei ist <span class="math inline">\(\Lambda\)</span> die Matrix der Faktorladungen, <span class="math inline">\(\Phi\)</span> die Kovarianz- oder Korrelationsmatrix der Faktoren und <span class="math inline">\(\Theta\)</span> die Kovarianzmatrix der Fehler.</p>
<p>Im unkorrelierten/orthogonalen Fall sähe die Matrix so aus: <span class="math inline">\(\Sigma := \Lambda \Lambda&#39; + \Theta\)</span>, da hier <span class="math inline">\(\Phi\)</span> die Einheitsmatrix ist und <span class="math inline">\(\Lambda\)</span> demzufolge einfach mit 1 multipliziert wird! Diese ist somit sehr nah an der implizierten Matrix im Rahmen der PCA, welche sich durch <span class="math inline">\(\Lambda \Lambda&#39;\)</span> ergab. Wir erkennen erneut, dass bei der PCA die Messfehler nicht mitmodelliert werden (deren Varianzen stecken in <span class="math inline">\(\Theta\)</span>).</p>
<p>Unter der Normalverteilungsannahme brauchen wir nur (Ko-)Varianzen und Mittelwerte, um unsere Variablen vollständig zu beschreiben. In der Schätzung der ML-EFA geht es uns darum, die Parameter in <span class="math inline">\(\Lambda\)</span>, <span class="math inline">\(\Phi\)</span> und <span class="math inline">\(\Theta\)</span> so zu bestimmen, dass sich die behauptete Kovarianzmatrix <span class="math inline">\(\Sigma\)</span> von unserer beobachteten Kovarianzmatrix <span class="math inline">\(S\)</span> so wenig unterscheidet wie möglich. Dazu bestimmen wir mit der Maximum-Likelihood-Schätzung die Werte für z.B. Faktorladungen, die es <em>maximal wahrscheinlich</em> machen, dass unsere Daten enstehen würden, wenn unsere EFA das richtige Modell wäre.</p>
<p>Um mit Hilfe von <code>fa</code> eine ML-EFA durchzuführen, muss dem Argument <code>fm</code> die entsprechende Bezeichnung <code>"ml"</code> übergeben werden.</p>
<pre class="r"><code>two_factor_ML &lt;- fa(dataFR2, nfactors = 2, rotate = &quot;oblimin&quot;, fm = &quot;ml&quot;)
two_factor_ML</code></pre>
<pre><code>## Factor Analysis using method =  ml
## Call: fa(r = dataFR2, nfactors = 2, rotate = &quot;oblimin&quot;, fm = &quot;ml&quot;)
## Standardized loadings (pattern matrix) based upon correlation matrix
##      ML1   ML2   h2   u2 com
## E1  0.69  0.04 0.47 0.53 1.0
## E2 -0.65 -0.06 0.41 0.59 1.0
## E3  0.83 -0.06 0.71 0.29 1.0
## N1  0.03  0.84 0.70 0.30 1.0
## N2  0.10 -0.57 0.35 0.65 1.1
## N3 -0.01  0.59 0.36 0.64 1.0
## 
##                        ML1  ML2
## SS loadings           1.61 1.39
## Proportion Var        0.27 0.23
## Cumulative Var        0.27 0.50
## Proportion Explained  0.54 0.46
## Cumulative Proportion 0.54 1.00
## 
##  With factor correlations of 
##       ML1   ML2
## ML1  1.00 -0.18
## ML2 -0.18  1.00
## 
## Mean item complexity =  1
## Test of the hypothesis that 2 factors are sufficient.
## 
## The degrees of freedom for the null model are  15  and the objective function was  1.47 with Chi Square of  183.82
## The degrees of freedom for the model are 4  and the objective function was  0.07 
## 
## The root mean square of the residuals (RMSR) is  0.04 
## The df corrected root mean square of the residuals is  0.07 
## 
## The harmonic number of observations is  129 with the empirical chi square  5.6  with prob &lt;  0.23 
## The total number of observations was  129  with Likelihood Chi Square =  8.75  with prob &lt;  0.068 
## 
## Tucker Lewis Index of factoring reliability =  0.893
## RMSEA index =  0.096  and the 90 % confidence intervals are  0 0.184
## BIC =  -10.69
## Fit based upon off diagonal values = 0.99
## Measures of factor score adequacy             
##                                                    ML1  ML2
## Correlation of (regression) scores with factors   0.90 0.88
## Multiple R square of scores with factors          0.80 0.77
## Minimum correlation of possible factor scores     0.61 0.55</code></pre>
<p>Wir sehen, dass diesmal die Schätzmethode “ml” ist. Auch die Faktoren heißen nun <em>ML1</em> und <em>ML2</em>. Die Faktorladungen im ML-EFA Modell mit <em>obliquer</em> Rotation sehen den Faktorladungen aus unserer vorigen Analyse sehr ähnlich.</p>
<p>Uns interessiert nun die Modellpassung, also inwiefern unsere Daten von unserem behaupteten Modell abweichen. <code>$STATISTIC</code> und <code>$PVAL</code> entlocken der Analyse (abgespeichert als Objekt) den <span class="math inline">\(\chi^2\)</span> Wert und den zugehörigen p-Wert bei 4 Freiheitsgraden. Verwirrenderweise gibt es zusätzlich <code>$chi</code>, was den empirisch und nicht likelihoodbasierten <span class="math inline">\(\chi^2\)</span>-Wert ausgibt, welcher sinnvoll ist, wenn Modellvoraussetzungen nicht erfüllt sind.</p>
<pre class="r"><code>two_factor_ML$STATISTIC # Likelihood basierter Chi^2-Wert</code></pre>
<pre><code>## [1] 8.749298</code></pre>
<pre class="r"><code>two_factor_ML$PVAL # p-Wert</code></pre>
<pre><code>## [1] 0.06768059</code></pre>
<p>Dem ist zu entnehmen, dass auf dem Signifikanzniveau von 5% die Hypothese auf Passung der Kovarianz unserer Daten mit der modellimplizierten Kovarianz in der Population nicht verworfen wird. Die Daten widersprechen dem zweifaktoriellen Modell nicht (die untersuchte Null-Hypothese ist: <span class="math inline">\(H_0: \Sigma_{Daten}=\Sigma_{2-fakt.}\)</span>, also, dass die Datenkovarianzmatrix sich durch die Kovarianzmatrix eines 2-faktoriellen EFA-Modells darstellen lässt). Vielleicht reicht auch ein Faktor aus, um die Variation in unserem Datensatz zu beschreiben? Wir wollen unser Modell mit zwei Faktoren gegen eines mit einem und eines mit drei Faktoren absichern.</p>
</div>
<div id="modellvergleich-ml-efa" class="section level3">
<h3>Modellvergleich: ML-EFA</h3>
<p>Das einfaktorielle Modell erhalten wir ganz einfach via:</p>
<pre class="r"><code>one_factor_ML &lt;- fa(dataFR2, nfactors = 1, rotate = &quot;oblimin&quot;, fm = &quot;ml&quot;)
one_factor_ML$STATISTIC # Chi-Quadratwert</code></pre>
<pre><code>## [1] 76.76935</code></pre>
<pre class="r"><code>one_factor_ML$PVAL # p-Wert</code></pre>
<pre><code>## [1] 7.063217e-13</code></pre>
<p>Das einfaktorielle Modell scheint nicht zu den Daten zu passen (<em>Mit einer Irrtumswahrscheinlichkeit von 5% ist davon auszugehen, dass in der Population die Differenz zwischen der Populationskovarianzmatrix und der modellimplizierten Kovarianzmatrix, bzw. der daraus folgenden Likelihoods, nicht 0 ist.</em>). Dennoch wollen wir dies genau wissen und vergleichen die beiden Modelle direkt miteinander. Für einen solchen Vergleich ist es notwendig, dass es sich bei den beiden Modellen um <em>geschachtelte Modelle</em> handelt. Das bedeutet, dass ein Modell durch Restriktionen von Modellparametern aus dem anderen Modell erzeugt werden kann. Das einfaktorielle Modell lässt sich aus dem zweifaktoriellen Modell durch die Restriktion gewinnen, dass alle Ladungen auf dem Faktor 0 sind und die Varianz dieses Faktors dementsprechend ebenfalls 0 ist.</p>
<p>Mit Hilfe des <code>anova</code> Befehls, welchen wir schon bei einigen anderen Modellvergleichen im Rahmen der <a href="/post/regression-und-ausreisserdiagnostik">Regression</a>, der <a href="/post/logistische-regression">logistischen Regression</a> sowie der <a href="/post/multi-level-modeling">Multi-Level Modelle</a> kennengelernt haben, lässt sich nun das einfaktorielle mit dem zweifaktoriellen Modell vergleichen.</p>
<pre class="r"><code>anova(one_factor_ML, two_factor_ML)</code></pre>
<pre><code>## Model 1 = fa(r = dataFR2, nfactors = 1, rotate = &quot;oblimin&quot;, fm = &quot;ml&quot;)
## Model 2 = fa(r = dataFR2, nfactors = 2, rotate = &quot;oblimin&quot;, fm = &quot;ml&quot;)</code></pre>
<table>
<thead>
<tr class="header">
<th align="left"></th>
<th align="right">df</th>
<th align="right">d.df</th>
<th align="right">chiSq</th>
<th align="right">d.chiSq</th>
<th align="right">PR</th>
<th align="right">test</th>
<th align="right">empirical</th>
<th align="right">d.empirical</th>
<th align="right">test.echi</th>
<th align="right">BIC</th>
<th align="right">d.BIC</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">1</td>
<td align="right">9</td>
<td align="right">NA</td>
<td align="right">76.77</td>
<td align="right">NA</td>
<td align="right">NA</td>
<td align="right">NA</td>
<td align="right">142.43</td>
<td align="right">NA</td>
<td align="right">NA</td>
<td align="right">33.03</td>
<td align="right">NA</td>
</tr>
<tr class="even">
<td align="left">2</td>
<td align="right">4</td>
<td align="right">5</td>
<td align="right">8.75</td>
<td align="right">68.02</td>
<td align="right">0</td>
<td align="right">13.6</td>
<td align="right">5.60</td>
<td align="right">136.83</td>
<td align="right">27.37</td>
<td align="right">-10.69</td>
<td align="right">-43.72</td>
</tr>
</tbody>
</table>
<p>Zunächst bekommen wir in angezeigt, welche Modelle unter welchem Kürzel gegeneinander getestet werden. Die Modellnummer steht im ANOVA-Output entsprechend für das jeweilige Modell. In der Zeile <code>2</code> steht also der Output für das 2-faktorielle Modelle und am Ende dieser Zeile steht auch der Modellvergleich.</p>
<p>In der ersten Spalte stehen beispielsweise die Freiheitsgrade der Modelle (<code>df</code>). Daneben steht die Differenz der Freiheitsgrade (<code>d.df</code>) und dahinter stehen verschiedene Fit-Maße, bzw. Modellvergleiche. Wir müssen im Bereich des <em>chiSq</em> und nicht bei <em>empirical</em> (eine Näherung des <span class="math inline">\(\chi^2\)</span> Wertes, wenn Annahmen verletzt sind) nachsehen. Der Output ist immer so aufgebaut, dass zunächst der Wert pro Modell angezeigt (<code>chiSq</code> oder <code>empirical</code>) wird und anschließend die Differenz (<code>d.chiSq</code> oder <code>d.empirical</code>) sowie die Signifikanzentscheidung berichtet wird (<code>PR test</code>, welche allerdings nicht bei der Näherung angezeigt wird). Außerdem wird noch eine Rubrik <code>test</code>, bzw. <code>test.echi</code> angezeigt, welche noch einmal die <span class="math inline">\(\chi^2\)</span>-Differenz geteilt durch die Freiheitsgrade repräsentiert. Der <span class="math inline">\(\chi^2\)</span>-Differenzwert liegt bei 68.02 mit einem zugehörigen p-Wert von de facto 0. <code>d.df</code> (häufig <span class="math inline">\(\Delta df\)</span>) gibt die Anzahl an Freiheitsgraden der <span class="math inline">\(\chi^2\)</span>-Differenz (hier: df = 5) des Differenzentests an (hier wurden die Freiheitsgrade der beiden Modelle voneinander abgezogen). Ganz hinten wird noch das Bayes Information Criterion <code>BIC</code>, sowie dessen Differenz <code>d.BIC</code> aufgeführt. Dieses Informationskriterium werden wir bei der <a href="/post/cfa">CFA</a> und deren Modellpassung noch einmal genauer betrachten.</p>
<p>Insgesamt wird die Null-Hypothese, dass beide Modell die Daten gleich gut beschreiben, verworfen. Wir entscheiden uns — Ockhams Rasiermesser folgend (siehe <a href="https://hds.hebis.de/ubffm/Record/HEB366849158">Eid et al., 2017, p. 787</a>) — somit für das Modell mit mehr Parametern, das weniger restriktive Modell, welches die Daten besser beschreibt: hier das zweifaktorielle Modell. Nun ist die Frage, ob wir das Modell noch weiter verbessern können, indem wir drei anstatt zwei Faktoren verwenden, um die Kovariation zwischen den Variablen zu beschreiben.</p>
<pre class="r"><code># Passt auch eines mit 3 Faktor?
three_factor_ML &lt;- fa(dataFR2, nfactors = 3, rotate = &quot;oblimin&quot;, fm = &quot;ml&quot;)
three_factor_ML$STATISTIC # Chi-Quadratwert</code></pre>
<pre><code>## [1] 0.0328432</code></pre>
<pre class="r"><code>three_factor_ML$PVAL # p-Wert</code></pre>
<pre><code>## [1] NA</code></pre>
<p>Das dreifaktorielle Modell beschreibt die Daten perfekt. Das liegt daran, dass es im dreifaktoriellen Modell genauso viele Parameter gibt, wie es empirische Informationen im Datensatz gibt. Demnach lässt sich die empirische Korrelationsmatrix perfekt durch die modelltheoretische Korrelationsmatrix (diejenige Korrelationsmatrix, die sich ergibt, wenn nur die Beziehungen zwischen den Variablen bestehen, die durch das Modell angenommen werden) darstellen. Ein Test auf Modellpassung ist in diesem Fall nicht möglich und auch nicht nötig (deshalb wird beim <code>$PVAL</code> nichts bzw. <code>NA</code> ausgegeben). Nun vergleichen wir die beiden Modelle (es ist sehr sinnvoll, das komplexere Modell rechts hin zuschreiben, da es ansonsten bei manchen Analysemethoden zu negativen <span class="math inline">\(\chi^2\)</span>-Werten kommen kann, außerdem zeigt man damit auf, wie die Schachtelung der Modelle funktioniert [allerdings sichert dies nicht die Schachtelung, dies ist eine theoretische Überlegung, die die Software leider in den meisten Fällen nicht für uns übernehmen kann]. Hier: das 2-faktorielle Modell ist ein Spezialfall des 3-faktoriellen Modells):</p>
<pre class="r"><code>anova(two_factor_ML, three_factor_ML)</code></pre>
<pre><code>## Model 1 = fa(r = dataFR2, nfactors = 2, rotate = &quot;oblimin&quot;, fm = &quot;ml&quot;)
## Model 2 = fa(r = dataFR2, nfactors = 3, rotate = &quot;oblimin&quot;, fm = &quot;ml&quot;)</code></pre>
<table>
<thead>
<tr class="header">
<th align="left"></th>
<th align="right">df</th>
<th align="right">d.df</th>
<th align="right">chiSq</th>
<th align="right">d.chiSq</th>
<th align="right">PR</th>
<th align="right">test</th>
<th align="right">empirical</th>
<th align="right">d.empirical</th>
<th align="right">test.echi</th>
<th align="right">BIC</th>
<th align="right">d.BIC</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">1</td>
<td align="right">4</td>
<td align="right">NA</td>
<td align="right">8.75</td>
<td align="right">NA</td>
<td align="right">NA</td>
<td align="right">NA</td>
<td align="right">5.60</td>
<td align="right">NA</td>
<td align="right">NA</td>
<td align="right">-10.69</td>
<td align="right">NA</td>
</tr>
<tr class="even">
<td align="left">2</td>
<td align="right">0</td>
<td align="right">4</td>
<td align="right">0.03</td>
<td align="right">8.72</td>
<td align="right">0.07</td>
<td align="right">2.18</td>
<td align="right">0.02</td>
<td align="right">5.58</td>
<td align="right">1.4</td>
<td align="right">-10.69</td>
<td align="right">NA</td>
</tr>
</tbody>
</table>
<p>Der <span class="math inline">\(\chi^2\)</span>-Differenzwert liegt hier bei 8.72 mit einen zugehörigen p-Wert von 0.07. <code>d.df</code> liegt bei 4 (<span class="math inline">\(\Delta df\)</span> = 4). Somit wird die Null-Hypothese, dass beide Modell die Daten gleich gut beschreiben, bzw. dass das sparsamere Modell die Daten genauso gut beschreiben kann, wie das komplexere Modell (<span class="math inline">\(H_0:\Sigma_{3-Fakt.} = \Sigma_{2-Fakt.}\)</span>; im Gegensatz zum <code>anova</code>-Befehl, steht hier das komplexere Modell links), nicht verworfen. Aus diesem Grund entscheiden wir uns - Ockhams Rasiermesser folgend (siehe <a href="https://hds.hebis.de/ubffm/Record/HEB366849158">Eid et al., 2017, p. 787</a>) - für das sparsamere Modell, also jenes, welches weniger Parameter enthält und somit restriktiver ist, hier: das <em>zweifaktorielle</em> Modell. Denn in der Wissenschaft streben wir danach, Modelle möglichst einfach zu halten!</p>
<p>Wenn Sie davon noch nicht genug haben, so können Sie in <a href="#fivefactorML">Appendix B</a> nachlesen, wie eine EFA am gesamten (gekürzten) Datensatz durchgeführt wird. Dort stehen keine neuen Informationen zur Durchführung, Sie sollten es folglich eher als Übung ansehen, falls Sie sich entschließen, <a href="#fivefactorML">Appendix B</a> durchzuarbeiten!</p>
<p>Die Zuordnung, die wir hier gefunden haben, entspringt der spezifischen Stichprobe, die wir untersucht haben. Wenn wir a priori aufgestellte Theorien über die Faktorstruktur prüfen wollen, können wir uns der <a href="/post/cfa"><strong>konfirmatorischen Faktorenanalyse</strong></a> bedienen, die wir in der nächsten Sitzung betrachten.</p>
<p>Den gesamten R-Code, der in dieser Sitzung genutzt wird, können Sie <a href="/post/FEII_efa.R"><svg style="height:0.8em;top:.04em;position:relative;" viewBox="0 0 512 512"><path d="M216 0h80c13.3 0 24 10.7 24 24v168h87.7c17.8 0 26.7 21.5 14.1 34.1L269.7 378.3c-7.5 7.5-19.8 7.5-27.3 0L90.1 226.1c-12.6-12.6-3.7-34.1 14.1-34.1H192V24c0-13.3 10.7-24 24-24zm296 376v112c0 13.3-10.7 24-24 24H24c-13.3 0-24-10.7-24-24V376c0-13.3 10.7-24 24-24h146.7l49 49c20.1 20.1 52.5 20.1 72.6 0l49-49H488c13.3 0 24 10.7 24 24zm-124 88c0-11-9-20-20-20s-20 9-20 20 9 20 20 20 20-9 20-20zm64 0c0-11-9-20-20-20s-20 9-20 20 9 20 20 20 20-9 20-20z"/></svg> hier herunterladen</a>.</p>
<hr />
</div>
</div>
<div id="AppendixA" class="section level2">
<h2>Appendix A</h2>
<details>
<summary>
<strong>Kürzen des Datensatzes</strong>
</summary>
<p>Falls Sie die Originaldaten auf <a href="https://openpsychometrics.org/_rawdata/"><svg style="height:0.8em;top:.04em;position:relative;" viewBox="0 0 512 512"><path d="M216 0h80c13.3 0 24 10.7 24 24v168h87.7c17.8 0 26.7 21.5 14.1 34.1L269.7 378.3c-7.5 7.5-19.8 7.5-27.3 0L90.1 226.1c-12.6-12.6-3.7-34.1 14.1-34.1H192V24c0-13.3 10.7-24 24-24zm296 376v112c0 13.3-10.7 24-24 24H24c-13.3 0-24-10.7-24-24V376c0-13.3 10.7-24 24-24h146.7l49 49c20.1 20.1 52.5 20.1 72.6 0l49-49H488c13.3 0 24 10.7 24 24zm-124 88c0-11-9-20-20-20s-20 9-20 20 9 20 20 20 20-9 20-20zm64 0c0-11-9-20-20-20s-20 9-20 20 9 20 20 20 20-9 20-20z"/></svg> openpsychometrics.org</a> als <em>.zip</em> herunterladen wollen, so können Sie diesen auf die hier verwendeten Daten wie folgt kürzen:</p>
<pre class="r"><code>data_full &lt;- read.table(&quot;BIG5/data.csv&quot;, header = T, sep = &quot;\t&quot;) # nach entpacken des .zip liegen die Daten in einem Ordner namens Big5

### Entferne leere Zeilen und Zeilen mit Missings aus dem Datensatz
ind &lt;- apply(data_full, 1, FUN = function(x) any(is.na(x))) # erzeuge eine Variable, welche TRUE ist, wenn mindestens ein Eintrag pro Zeile fehlt und ansonsten FALSE anzeigt
data_full &lt;- data_full[!ind, ] # Wähle nur diejenigen Zeilen, in denen unsere Indikatorvariable &quot;ind&quot; NICHT TRUE anzeigt, also wo alle Einträge vorhanden sind
# !ind (Ausrufezeichen vor ind) negiert die Einträge in ind (Prüfe bspw. !FALSE == TRUE, nicht false ist gleich true)

### Shorten Data Set
Big5 &lt;- data_full[, c(2:4,7,7+rep(1:3,5)+sort(rep(seq(0,40,10),3)))]
 # Verwende nur 3 Items pro Skala plus einige demografische Items
Big5 &lt;- data.frame(Big5) # Schreibe Datensatz als data.frame
save(list = c(&quot;Big5&quot;), file = &quot;Big5.rda&quot;)
# Speichere gekürzten Datensatz in .rda file (dem R-internen Datenformat)
## --&gt; Das ist auch der Datensatz, den wir weiter verwendet haben!</code></pre>
</details>
</div>
<div id="fivefactorML" class="section level2">
<h2>Appendix B</h2>
<details>
<summary>
<strong>ML-EFA für den gesamten (gekürzten) Datensatz</strong>
</summary>
<p>Für den vollen Datensatz mit jeweils drei Items pro Persönlichkeitsfacette, nehmen wir zunächst an, dass es 5 Faktoren gibt. Dies wird hier allerdings nicht durch die Parallelanalyse gestützt. Wir müssen die Funktion <code>fa.parallel</code> diesmal auf den vollen (gekürzten) Datensatz anwenden; nämlich auf <code>dataFR</code>.</p>
<pre class="r"><code>fa.parallel(x = dataFR,fa = &quot;fa&quot;)</code></pre>
<p><img src="/post/2021-03-25_MSc1_FEII_Sitzung2_EFA_files/figure-html/unnamed-chunk-30-1.png" width="672" style="display: block; margin: auto;" /></p>
<pre><code>## Parallel analysis suggests that the number of factors =  4  and the number of components =  NA</code></pre>
<p>Hier scheinen eher 4 Faktoren sinnvoll. Wir prüfen dennoch erstmal unsere inhaltliche Hypothese, dass es 5 Faktoren gibt, mit Hilfe der <em>oblique</em> Rotierten ML-EFA.</p>
<pre class="r"><code>five_factor_ML &lt;- fa(dataFR, nfactors = 5, rotate = &quot;oblimin&quot;, fm = &quot;ml&quot;)
five_factor_ML$STATISTIC</code></pre>
<pre><code>## [1] 44.07717</code></pre>
<pre class="r"><code>five_factor_ML$PVAL # Modell wird durch die Daten nicht verworfen</code></pre>
<pre><code>## [1] 0.3031972</code></pre>
<p>Die Daten scheinen unserem Modell mit 5 Faktoren nicht zu widersprechen. Schauen wir uns die Faktorladungen an, um die Faktoren inhaltlich zu interpretieren.</p>
<pre class="r"><code>five_factor_ML$loadings # auch nochmal ohne [,] um die Ausblendehilfe von psych als Unterstützung für die Zuordnung zu nutzen</code></pre>
<pre><code>## 
## Loadings:
##    ML4    ML3    ML1    ML2    ML5   
## E1  0.688                            
## E2 -0.643         0.155              
## E3  0.813         0.117              
## N1         0.433 -0.340              
## N2                0.986              
## N3         0.920                     
## A1 -0.227  0.160  0.203        -0.276
## A2  0.655  0.242                     
## A3 -0.186  0.159         0.197       
## C1         0.170  0.208  0.179 -0.355
## C2                              0.730
## C3         0.177  0.140  0.145 -0.278
## O1                       0.998       
## O2  0.126  0.247        -0.214 -0.106
## O3         0.229  0.163  0.189       
## 
##                  ML4   ML3   ML1   ML2   ML5
## SS loadings    2.091 1.328 1.274 1.194 0.869
## Proportion Var 0.139 0.089 0.085 0.080 0.058
## Cumulative Var 0.139 0.228 0.313 0.392 0.450</code></pre>
<pre class="r"><code>five_factor_ML$loadings[,] # alle Dezimalstellen anzeigen</code></pre>
<pre><code>##             ML4         ML3          ML1         ML2          ML5
## E1  0.688468319 -0.03665453 -0.012193249  0.02787857  0.071260642
## E2 -0.643272367  0.08577303  0.155240994  0.09656023  0.065735002
## E3  0.812764373 -0.05121616  0.116888237  0.01806219 -0.076129365
## N1 -0.022613674  0.43257679 -0.339987402 -0.07415779  0.069005051
## N2  0.017710987 -0.02860957  0.985613730 -0.02537580  0.026025668
## N3 -0.004230572  0.91962125 -0.026913718 -0.00657639 -0.013229825
## A1 -0.227423669  0.15957275  0.203222904 -0.08704521 -0.275728683
## A2  0.655281001  0.24198774  0.006033115  0.01175666  0.092166503
## A3 -0.186178370  0.15918711  0.095110929  0.19652141  0.097407381
## C1  0.056714149  0.16981702  0.207576065  0.17890272 -0.354809510
## C2 -0.015398173  0.01818279  0.084998138  0.01776008  0.729941525
## C3  0.014355504  0.17741965  0.140061799  0.14464044 -0.278431363
## O1  0.002352582 -0.01037494 -0.023817340  0.99812410 -0.001488256
## O2  0.125971083  0.24681060  0.029753625 -0.21358237 -0.106264287
## O3 -0.080478366  0.22862665  0.163239313  0.18923154  0.082298847</code></pre>
<p>Durch die Rotation sind auch hier die Faktoren anders nummeriert. Der erste Faktor ist hier <em>ML4</em> (dieser Faktor ist der erste in der Liste, da hier der Eigenwerte nach Rotation maximal ist; vor Rotation hatte <em>ML4</em> den viert größten Eigenwert). Die höchsten Faktorladungen mit diesem Faktor haben die Items <span class="math inline">\(E_1\)</span>, <span class="math inline">\(E_2\)</span>, <span class="math inline">\(E_3\)</span> und <span class="math inline">\(A_2\)</span>. Somit könnte man diesen am ehesten <em>post-hoc</em> (die Theorie wird also aus den Daten generiert; es sind auch andere Interpretationsansätze zulässig) als Extraversion interpretieren. Allerdings scheinen die Items der Extraversion einiges mit jenen der Verträglichkeit (<span class="math inline">\(A_{...}\)</span>) gemeinsam zu haben.
Dies könnte mit unter damit zusammen hängen, dass diese beiden Items am ehesten etwas mit sozialer Erwünschtheit zu tun haben.
Auf dem Faktor <em>ML3</em> laden vor allem die Items <span class="math inline">\(N_1\)</span> und <span class="math inline">\(N_3\)</span>. Allerdings lädt <span class="math inline">\(N_2\)</span> besonders auf <em>ML1</em>.<br />
Dies könnte durchaus daran liegen, dass <span class="math inline">\(N_1\)</span> (<em>“I get stressed out easily.”</em>) und <span class="math inline">\(N_3\)</span> (<em>“I worry about things.”</em>) negativ kodiert sind, während <span class="math inline">\(N_2\)</span> (<em>“I am relaxed most of the time.”</em>) positiv kodiert ist und die erstgenannten Items somit mehr gemeinsam haben als die inhaltliche Zuordnung zum Neurotizismus. Somit scheint <em>ML3</em> ein Faktor der Sorgen, also des Neurotizismus zu sein, während <em>ML1</em> eher für einen Faktor der Gelassenheit spricht; beispielsweise laden hier auch positiv Items der Extraversion und Verträglichkeit. Das die Items des Neurotizismus auf unterschiedlichen Faktoren laden und unterschiedliche Vorzeichen aufweisen, kann für Methodeneffekte sprechen (<em>Unterschiede die zustande kommen, da unterschiedliche Methoden, hier: Itemformulierungen [positiv vs. negativ], verwendet werden.</em>). Auch auf <em>ML2</em> und <em>ML5</em> laden jeweils nur ein Item besonders stark: <span class="math inline">\(O_1\)</span> auf <em>ML2</em> und <span class="math inline">\(C_2\)</span> auf <em>ML5</em>. Insgesamt muss geschlussfolgert werden, dass zwar die fünffaktorielle Struktur durch die Daten nicht verworfen wird, aber dass die oblique rotierte Lösung keine eindeutige Zuordnung der Items aufweist. Allerdings bringt auch eine <em>varimax</em>-rotierte Lösung keine Verbesserung der Interpretierbarkeit, da diese neben der Einfachstruktur in der Faktorladungsmatrix noch die Unkorreliertheit der Faktoren berücksichtigen muss (in der <em>varimax</em>-rotierten Lösung sind dafür die Konstrukte nicht überlappend, was allerdings auch eine strenge Annahme ist):</p>
<pre class="r"><code>fa(dataFR, nfactors = 5, rotate = &quot;varimax&quot;, fm = &quot;ml&quot;)$loadings[,]</code></pre>
<pre><code>##             ML4           ML3         ML1         ML2          ML5
## E1  0.679741350 -0.0298612003  0.04717727 -0.06209588 -0.025294029
## E2 -0.616269745 -0.0009785951  0.07502041  0.24020664 -0.043100326
## E3  0.812929628 -0.0734949752  0.16420656 -0.12171911  0.134579147
## N1 -0.060232149  0.5043444919 -0.37548744  0.06060518 -0.063964536
## N2  0.101251528 -0.2329637937  0.95295799  0.10457873  0.106824247
## N3 -0.016430443  0.8479850127 -0.18607020  0.29295427  0.151708177
## A1 -0.213443248  0.1199149173  0.13194526 -0.04987855  0.278471636
## A2  0.644794316  0.2278750098  0.01990198  0.03032774 -0.004249186
## A3 -0.165880085  0.0456542742  0.02042712  0.28908281 -0.018069436
## C1  0.081940401  0.0183155255  0.08750067  0.11679630  0.435079003
## C2 -0.006651558  0.0264955123  0.16832618  0.26419496 -0.667066743
## C3  0.032388740  0.0576353789  0.03621164  0.11108025  0.344258937
## O1  0.056711714 -0.4160253195 -0.23367971  0.84296969  0.231306357
## O2  0.112086056  0.3032964635  0.02602280 -0.14672358  0.100453282
## O3 -0.056937114  0.0975755222  0.08029510  0.29567696  0.021600591</code></pre>
<p>was wahrscheinlich daran liegt, dass die Kovariation zwischen den Faktoren nicht sehr groß ist:</p>
<pre class="r"><code>round(five_factor_ML$Phi, 2) # runde auf 2 Nachkommastellen</code></pre>
<pre><code>##       ML4   ML3   ML1   ML2   ML5
## ML4  1.00 -0.05  0.14 -0.07 -0.09
## ML3 -0.05  1.00 -0.30 -0.02 -0.02
## ML1  0.14 -0.30  1.00  0.04  0.02
## ML2 -0.07 -0.02  0.04  1.00  0.00
## ML5 -0.09 -0.02  0.02  0.00  1.00</code></pre>
<pre class="r"><code>fa(dataFR, nfactors = 5, rotate = &quot;varimax&quot;, fm = &quot;ml&quot;)$Phi</code></pre>
<pre><code>## NULL</code></pre>
<p><code>NULL</code> zeigt hierbei an, dass es das <code>$Phi</code> -Objekt nicht gibt. Tatsächlich ist die Kovarianzmatrix im orthogonalen Fall die Einheitsmatrix der Dimension <span class="math inline">\(5\times5\)</span>:
<span class="math display">\[\begin{pmatrix} 1&amp; 0&amp;0&amp;0&amp;0 \\ 0&amp; 1&amp;0&amp;0&amp;0 \\ 0&amp; 0&amp;1&amp;0&amp;0\\ 0&amp; 0&amp;0&amp;1&amp;0 \\ 0&amp; 0&amp;0&amp;0&amp;1 \end{pmatrix}\]</span>
In <code>R</code>:</p>
<pre class="r"><code>diag(5) # Einheitsmatrix der Dimension 5x5.</code></pre>
<pre><code>##      [,1] [,2] [,3] [,4] [,5]
## [1,]    1    0    0    0    0
## [2,]    0    1    0    0    0
## [3,]    0    0    1    0    0
## [4,]    0    0    0    1    0
## [5,]    0    0    0    0    1</code></pre>
<div id="modellvergleich-ml-efa-1" class="section level3">
<h3>Modellvergleich: ML-EFA</h3>
<p>Wir schauen uns nun die Passung unseres Modells im Vergleich zu einem vier- und einem sechsfaktoriellen Modell an.</p>
<pre class="r"><code>four_factor_ML &lt;- fa(dataFR, nfactors = 4, rotate = &quot;oblimin&quot;, fm = &quot;ml&quot;)
four_factor_ML$STATISTIC</code></pre>
<pre><code>## [1] 73.04596</code></pre>
<pre class="r"><code>four_factor_ML$PVAL</code></pre>
<pre><code>## [1] 0.023097</code></pre>
<p>Das vierfaktorielle Modell wird durch die Daten verworfen (<span class="math inline">\(p&lt;0.05\)</span>). Nun zum Modellvergleich:</p>
<pre class="r"><code>anova(four_factor_ML, five_factor_ML)</code></pre>
<pre><code>## Model 1 = fa(r = dataFR, nfactors = 4, rotate = &quot;oblimin&quot;, fm = &quot;ml&quot;)
## Model 2 = fa(r = dataFR, nfactors = 5, rotate = &quot;oblimin&quot;, fm = &quot;ml&quot;)</code></pre>
<table>
<thead>
<tr class="header">
<th align="left"></th>
<th align="right">df</th>
<th align="right">d.df</th>
<th align="right">chiSq</th>
<th align="right">d.chiSq</th>
<th align="right">PR</th>
<th align="right">test</th>
<th align="right">empirical</th>
<th align="right">d.empirical</th>
<th align="right">test.echi</th>
<th align="right">BIC</th>
<th align="right">d.BIC</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">1</td>
<td align="right">51</td>
<td align="right">NA</td>
<td align="right">73.05</td>
<td align="right">NA</td>
<td align="right">NA</td>
<td align="right">NA</td>
<td align="right">105.81</td>
<td align="right">NA</td>
<td align="right">NA</td>
<td align="right">-174.80</td>
<td align="right">NA</td>
</tr>
<tr class="even">
<td align="left">2</td>
<td align="right">40</td>
<td align="right">11</td>
<td align="right">44.08</td>
<td align="right">28.97</td>
<td align="right">0</td>
<td align="right">2.63</td>
<td align="right">47.94</td>
<td align="right">57.87</td>
<td align="right">5.26</td>
<td align="right">-150.32</td>
<td align="right">24.49</td>
</tr>
</tbody>
</table>
<p>Wir entscheiden uns hier nun für das fünffaktorielle Modell. Nun wollen wir uns das fünffaktoirelle Modell noch im Vergleich zum sechsfaktoriellen Modell ansehen.</p>
<pre class="r"><code>six_factor_ML &lt;- fa(dataFR, nfactors = 6, rotate = &quot;oblimin&quot;, fm = &quot;ml&quot;)
six_factor_ML$STATISTIC</code></pre>
<pre><code>## [1] 29.19415</code></pre>
<pre class="r"><code>six_factor_ML$PVAL # Modell wird durch die Daten nicht verworfen</code></pre>
<pre><code>## [1] 0.5074152</code></pre>
<p>Dem sechsfaktoriellen Modell widersprechen die Daten genauso wenig, wie dem Fünffakoriellen (beide <span class="math inline">\(p&gt;0.05\)</span>). Dies war zu erwarten, da wir durch Hinzunahme des sechsten Faktors die Komplexität des Modell erhöht haben, wodurch sich das Modell stärker der konkreten Datenlage annähern kann. <em>Mehr Faktoren bedeuten immer eine detailgetreuere Abbildung der ursprünglichen Datenlage (siehe auch <a href="https://hds.hebis.de/ubffm/Record/HEB366849158">Eid et al., 2017, Kapitel 25</a>).</em></p>
<pre class="r"><code>anova(five_factor_ML, six_factor_ML)</code></pre>
<pre><code>## Model 1 = fa(r = dataFR, nfactors = 5, rotate = &quot;oblimin&quot;, fm = &quot;ml&quot;)
## Model 2 = fa(r = dataFR, nfactors = 6, rotate = &quot;oblimin&quot;, fm = &quot;ml&quot;)</code></pre>
<table>
<thead>
<tr class="header">
<th align="left"></th>
<th align="right">df</th>
<th align="right">d.df</th>
<th align="right">chiSq</th>
<th align="right">d.chiSq</th>
<th align="right">PR</th>
<th align="right">test</th>
<th align="right">empirical</th>
<th align="right">d.empirical</th>
<th align="right">test.echi</th>
<th align="right">BIC</th>
<th align="right">d.BIC</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">1</td>
<td align="right">40</td>
<td align="right">NA</td>
<td align="right">44.08</td>
<td align="right">NA</td>
<td align="right">NA</td>
<td align="right">NA</td>
<td align="right">47.94</td>
<td align="right">NA</td>
<td align="right">NA</td>
<td align="right">-150.32</td>
<td align="right">NA</td>
</tr>
<tr class="even">
<td align="left">2</td>
<td align="right">30</td>
<td align="right">10</td>
<td align="right">29.19</td>
<td align="right">14.88</td>
<td align="right">0.14</td>
<td align="right">1.49</td>
<td align="right">28.63</td>
<td align="right">19.31</td>
<td align="right">1.93</td>
<td align="right">-116.60</td>
<td align="right">33.72</td>
</tr>
</tbody>
</table>
<p>Der <span class="math inline">\(\chi^2\)</span>-Differenzwert liegt hier bei 14.88 mit einen zugehörigen p-Wert von 0.14 mit <span class="math inline">\(\Delta df\)</span> = 10. Mit diesem Test wird geprüft, ob das sparsamere Modell die Daten schlechter abbildet. Die Nullhypothese ist also, dass das sparsamere Modell die Daten genauso gut beschreiben kann, wie das komplexere Modell (<span class="math inline">\(H_0:\Sigma_{6-Fakt.} = \Sigma_{5-Fakt.}\)</span>). Da in diesem Fall der p-Wert größer als <span class="math inline">\(.05\)</span> ist, wird diese Nullhypothese nicht verworfen und wir entscheiden uns — Ockhams Rasiermesser folgend (siehe <a href="https://hds.hebis.de/ubffm/Record/HEB366849158">Eid et al., 2017, p. 787</a>) — für das sparsamere Modell.</p>
<p>Wir hätten auch mehrere Tests gleichzeitig durchführen können. Allerdings sollten nicht beliebig konkurriende Theorien getestet werden — Stichwort <em>Alpha-Inflation</em>!</p>
<pre class="r"><code>anova(four_factor_ML, five_factor_ML, six_factor_ML)</code></pre>
<pre><code>## Model 1 = fa(r = dataFR, nfactors = 4, rotate = &quot;oblimin&quot;, fm = &quot;ml&quot;)
## Model 2 = fa(r = dataFR, nfactors = 5, rotate = &quot;oblimin&quot;, fm = &quot;ml&quot;)
## Model 3 = fa(r = dataFR, nfactors = 6, rotate = &quot;oblimin&quot;, fm = &quot;ml&quot;)</code></pre>
<table>
<thead>
<tr class="header">
<th align="left"></th>
<th align="right">df</th>
<th align="right">d.df</th>
<th align="right">chiSq</th>
<th align="right">d.chiSq</th>
<th align="right">PR</th>
<th align="right">test</th>
<th align="right">empirical</th>
<th align="right">d.empirical</th>
<th align="right">test.echi</th>
<th align="right">BIC</th>
<th align="right">d.BIC</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">1</td>
<td align="right">51</td>
<td align="right">NA</td>
<td align="right">73.05</td>
<td align="right">NA</td>
<td align="right">NA</td>
<td align="right">NA</td>
<td align="right">105.81</td>
<td align="right">NA</td>
<td align="right">NA</td>
<td align="right">-174.80</td>
<td align="right">NA</td>
</tr>
<tr class="even">
<td align="left">2</td>
<td align="right">40</td>
<td align="right">11</td>
<td align="right">44.08</td>
<td align="right">28.97</td>
<td align="right">0.00</td>
<td align="right">2.63</td>
<td align="right">47.94</td>
<td align="right">57.87</td>
<td align="right">5.26</td>
<td align="right">-150.32</td>
<td align="right">24.49</td>
</tr>
<tr class="odd">
<td align="left">3</td>
<td align="right">30</td>
<td align="right">10</td>
<td align="right">29.19</td>
<td align="right">14.88</td>
<td align="right">0.14</td>
<td align="right">1.49</td>
<td align="right">28.63</td>
<td align="right">19.31</td>
<td align="right">1.93</td>
<td align="right">-116.60</td>
<td align="right">33.72</td>
</tr>
</tbody>
</table>
</details>
</div>
</div>
<div id="AppendixC" class="section level2">
<h2>Appendix C</h2>
<details>
<summary>
<strong>Faktorladungsmatrix vs. Strukturmatrix</strong>
</summary>
<p>Um die Beziehung zwischen der Faktorladungsmatrix und der Strukturmatrix genauer zu verstehen, schauen wir uns das zweifaktorielle Modell für den (<em>standardisierten</em>) Datensatz <code>dataFR2</code> genauer an (<em>standardisiert</em> ist hier wichtig, da dies bedeutet, dass die Mittelwerte alle <span class="math inline">\(0\)</span> sind und wir somit diese ignorieren können):
<span class="math display">\[\begin{pmatrix}E_1\\E_2\\E_3\\N_1\\N_2\\N_3 \end{pmatrix} = \begin{pmatrix}
\lambda_{11} &amp; \lambda_{12}\\
\lambda_{21} &amp; \lambda_{22}\\
\lambda_{31} &amp; \lambda_{32}\\
\lambda_{41} &amp; \lambda_{42}\\
\lambda_{51} &amp; \lambda_{52}\\
\lambda_{61} &amp; \lambda_{62} \end{pmatrix}  \begin{pmatrix}\xi_1\\\xi_2 \end{pmatrix} +  \begin{pmatrix}\varepsilon_{E_1}\\\varepsilon_{E_2}\\\varepsilon_{E_3}\\\varepsilon_{N_1}\\\varepsilon_{N_2}\\\varepsilon_{N_3} \end{pmatrix}\]</span></p>
<p>Dies ist die Messmodellsgleichung, welche die Beziehung zwischen den latenten Variablen und den Messfehlern mit den beobachtbaren Variablen beschreibt. Die Faktorladungsmatrix <span class="math inline">\(\Lambda\)</span> enthält hier die Gewichtung der latenten Variablen und bestimmt somit, wie groß der Anteil jeder latenten Variable an der Messung ist (dies ist ähnlich der Reliabilität zu bewerten). Die Strukturmatrix beschreibt die Korrelation/Kovariation zwischen Messung und latenter Variable und enthält somit zusätzliche Informationen über die Beziehungen der latenten Variablen untereinander.</p>
<p><a href="#Hauptachsenanalyse">Im Abschnitt zur Hauptachsenanalyse</a> hatten wir erkannt, dass der erste Faktor wahrscheinlich der Extraversion und der zweite wahrscheinlich dem Neurotizismus entspricht. Demnach könnten wir <span class="math inline">\(\xi_1=\xi_\text{Extraversion}\)</span> und <span class="math inline">\(\xi_2=\xi_\text{Neurotizismus}\)</span> nennen. Bennen wir nun die Faktorladungsmatrix als <span class="math inline">\(\Lambda\)</span> und die Korrelationsmatrix der latenten Variablen <span class="math inline">\(\Phi\)</span> (die Diagonaleinträge sind <span class="math inline">\(1\)</span>).
Die Kovarianz zwischen dem ersten Extraversionitem und dem Extraversionfaktor ist folgendermaßen zu berechnen (wir rechnen hier mit Kovarianzen, da dies im Allgemeinen deutlich einfacher ist als mit Korrelationen zu rechen. Außerdem sind hier alle Variablen standardisiert und somit sind Korrelation und Kovarianz identisch; über die Rechenregeln und die Beziehungen zwischen Korrelation und Kovarianz können sie in <a href="https://hds.hebis.de/ubffm/Record/HEB366849158">Eid, et al. (2017)</a> S. 195-196 und folgend und S.570-571 und folgend nachlesen):
<span class="math display">\[\begin{align}\mathbf{C}ov[E_1, &amp;\xi_1]\\&amp;= \mathbf{C}ov[\lambda_{11}\xi_1 + \lambda_{12}\xi_2+\varepsilon_{E_1}, \xi_1]\\ &amp;= \lambda_{11}\mathbf{C}ov[\xi_1, \xi_1] + \lambda_{12}\mathbf{C}ov[\xi_2, \xi_1] +\mathbf{C}ov[\varepsilon_{E_1}, \xi_1]\\ &amp;= \lambda_{11}\mathbb{V}ar[\xi_1] + \lambda_{12}\mathbf{C}ov[\xi_2, \xi_1]\\ &amp;= \lambda_{11}\phi_{11} + \lambda_{12}\phi_{21}\\&amp;= \lambda_{11} + \lambda_{12}\phi_{21}\end{align}\]</span>
<span class="math inline">\(\mathbf{C}ov[\varepsilon_{E_1}, \xi_1]=0\)</span> gilt, da die Fehler als unabhängig von allen weiteren Variablen im Modell angenommen werden. Außerdem sind <span class="math inline">\(\phi_{11}=1\)</span> und <span class="math inline">\(\mathbb{C}ov[\xi_1,\xi_2]=\phi_{21}=\phi_{12}=\mathbb{C}ov[\xi_2,\xi_1]\)</span> die Varianz von <span class="math inline">\(\xi_1\)</span> und die Kovarianz/Korrelation zwischen <span class="math inline">\(\xi_1\)</span> und <span class="math inline">\(\xi_2\)</span> und entsprechend Einträge von <span class="math inline">\(\Phi\)</span>. Aus dieser Rechnung folgt, dass der erste Eintrag in der Strukturmatrix (an der Stelle 1. Zeile, 1. Spalte) <span class="math inline">\(\lambda_{11} + \lambda_{12}\phi_{21}\)</span> sein muss. Hier ist zu erkennen, dass falls die Korrelation zwischen den latenten Variablen als <span class="math inline">\(0\)</span> angenommen wird (im orthogonalen Fall gilt dann <span class="math inline">\(\phi_{21}=\phi_{12}=0\)</span>), dann ist die Strukurmatrix gleich der Faktorladungsmatrix und der erste Eintrag lautet <span class="math inline">\(\lambda_{11}\)</span>. Wir schauen uns dies empirisch für das orthogonale Modell (bereits geschätzt in <code>two_factor</code>) und das oblique-rotiert geschätzte Modell (bereits geschätzt in <code>two_factor_oblimin</code>) an.
Im orthogonalen Fall ist dies etwas unspannend:</p>
<pre class="r"><code>two_factor$loadings[1, 1] # volle Formel für ersten Eintrag in Strukutrmatrix, da Kovarianz der Faktoren = 0</code></pre>
<pre><code>## [1] 0.6918932</code></pre>
<pre class="r"><code>two_factor$Structure[1, 1] # erster Eintrag in der Strukturmatrix</code></pre>
<pre><code>## [1] 0.6918932</code></pre>
<p>Offensichtlich sind beide Einträge gleich, was daran liegt, dass die Faktoren als unkorreliert angenommen werden. Nun zum oblique rotierten Fall:</p>
<pre class="r"><code>two_factor_oblimin$loadings[1, 1] # erste Faktorladung im obliquen Modell (unterscheidet sich von dem ersten Eintrag der Strukturmatrix)</code></pre>
<pre><code>## [1] 0.7005517</code></pre>
<pre class="r"><code>two_factor_oblimin$loadings[1, 1] + two_factor_oblimin$loadings[1, 2]*two_factor_oblimin$Phi[2, 1] # volle Formel für ersten Eintrag in Strukutrmatrix</code></pre>
<pre><code>## [1] 0.6932416</code></pre>
<pre class="r"><code>two_factor_oblimin$Structure[1, 1] # erster Eintrag in der Strukturmatrix</code></pre>
<pre><code>## [1] 0.6932416</code></pre>
<p>Hier ist zu sehen, dass sich Faktorladungsmatrix und Strukturmatrix unterscheiden. Der Unterschied ist nicht sehr hoch, da die Korrelation zwischen den beiden Faktoren lediglich bei <span class="math inline">\(\hat{\phi}_{21}\)</span>=-0.1852 liegt und somit <span class="math inline">\(\hat{\lambda}_{12}\hat{\phi}_{21}=\)</span> -0.0073 keine große Veränderung zu <span class="math inline">\(\hat{\lambda}_{11}\)</span> mit sich bringt. In Matrixschreibweise lässt sich die Strukturmatrix unkompliziert bestimmen. Sie wird durch folgenden Ausdruck berechnet:
<span class="math display">\[\Lambda\Phi\]</span>
Dies können wir in <code>R</code> leicht empirisch überprüfen. Einen Überblick über die Befehle für Matrix-Algebra in <code>R</code> finden Sie auf der <a href="https://www.statmethods.net/advstats/matrix.html">Quick-R Website</a>, auf welche bereits in der Sitzung zu <a href="/post/einführung-in-lavaan">Einführung in <code>lavaan</code></a> aufmerksam gemacht wurde. Außerdem ist im <a href="/post/einleitung-und-wiederholung/#EinleitungAppendixBMatrixalgebra">Appendix B</a> der <a href="/post/einleitung-und-wiederholung">Einführungssitzung zu PsyMSc1</a> bereits eine Einführung in Matrixalgebra gegeben worden. Wir berechnen nun das Matrixprodukt für den oblique rotieren Fall:</p>
<pre class="r"><code>two_factor_oblimin$loadings[,] %*% two_factor_oblimin$Phi[,] # Matrixprodukt</code></pre>
<pre><code>##           MR1         MR2
## E1  0.6932416 -0.09029319
## E2 -0.6400647  0.03425442
## E3  0.8364933 -0.22391151
## N1 -0.1298599  0.83712330
## N2  0.1785989 -0.58432636
## N3 -0.1283499  0.58695759</code></pre>
<pre class="r"><code>two_factor_oblimin$Structure[,] # Strukturmatrix</code></pre>
<pre><code>##           MR1         MR2
## E1  0.6932416 -0.09029319
## E2 -0.6400647  0.03425442
## E3  0.8364933 -0.22391151
## N1 -0.1298599  0.83712330
## N2  0.1785989 -0.58432636
## N3 -0.1283499  0.58695759</code></pre>
<p><code>%*%</code> signalisiert <code>R</code>, dass ein Matrixprodukt und <em>keine</em> komponentenweise Mulitplikation durchzuführen ist. <code>[,]</code> sorgt dafür, dass nur die Matrizen verwendet werden und nicht der zusätzliche Output, der ggf. durch das <code>psych</code>-Paket mit ausgegeben wird.</p>
<p>Das ganze funktioniert selbstverständlich auch für den fünffaktoriellen oblique rotierten ML-EFA Fall, den wir uns später angesehen haben, als es darum ging den <a href="#fivefactorML">gesamten (gekürzten) Datensatz mit Hilfe der ML-EFA</a> zu untersuchen. Das zugehörige Objekt, welches das geschätzte Modell enthält, heißt <code>five_factor_ML</code>:</p>
<pre class="r"><code>five_factor_ML$loadings[,] %*% five_factor_ML$Phi[,] # Matrixprodukt</code></pre>
<pre><code>##            ML4         ML3         ML1         ML2          ML5
## E1  0.68012693 -0.06717103  0.09828653 -0.01822411  0.009260453
## E2 -0.63791259  0.06552915  0.04403530  0.14413074  0.125484598
## E3  0.83728352 -0.12337423  0.24576500 -0.03084187 -0.146382973
## N1 -0.09189974  0.53663293 -0.47561225 -0.09483930  0.055041769
## N2  0.15694831 -0.32787315  0.99631061  0.01289071  0.045752916
## N3 -0.04934588  0.92837355 -0.30647378 -0.02583979 -0.032437499
## A1 -0.17544108  0.11612973  0.11370804 -0.06663641 -0.254026633
## A2  0.63566748  0.20739547  0.02728767 -0.03702446  0.027811781
## A3 -0.20229561  0.13312175  0.03054772  0.20947982  0.112785431
## C1  0.09812869  0.10806476  0.16374057  0.18026600 -0.359308148
## C2 -0.07172742 -0.02229676  0.09337011  0.02096820  0.732728884
## C3  0.04129630  0.13719615  0.08822234  0.14594730 -0.280624296
## O1 -0.06746981 -0.02332237  0.01902778  0.99723607 -0.003104410
## O2  0.14261965  0.23841159 -0.03792795 -0.22572173 -0.121938771
## O3 -0.08840219  0.17745445  0.09190619  0.19639438  0.088088488</code></pre>
<pre class="r"><code>five_factor_ML$Structure[,] # Strukturmatrix</code></pre>
<pre><code>##            ML4         ML3         ML1         ML2          ML5
## E1  0.68012693 -0.06717103  0.09828653 -0.01822411  0.009260453
## E2 -0.63791259  0.06552915  0.04403530  0.14413074  0.125484598
## E3  0.83728352 -0.12337423  0.24576500 -0.03084187 -0.146382973
## N1 -0.09189974  0.53663293 -0.47561225 -0.09483930  0.055041769
## N2  0.15694831 -0.32787315  0.99631061  0.01289071  0.045752916
## N3 -0.04934588  0.92837355 -0.30647378 -0.02583979 -0.032437499
## A1 -0.17544108  0.11612973  0.11370804 -0.06663641 -0.254026633
## A2  0.63566748  0.20739547  0.02728767 -0.03702446  0.027811781
## A3 -0.20229561  0.13312175  0.03054772  0.20947982  0.112785431
## C1  0.09812869  0.10806476  0.16374057  0.18026600 -0.359308148
## C2 -0.07172742 -0.02229676  0.09337011  0.02096820  0.732728884
## C3  0.04129630  0.13719615  0.08822234  0.14594730 -0.280624296
## O1 -0.06746981 -0.02332237  0.01902778  0.99723607 -0.003104410
## O2  0.14261965  0.23841159 -0.03792795 -0.22572173 -0.121938771
## O3 -0.08840219  0.17745445  0.09190619  0.19639438  0.088088488</code></pre>
<p>Hier alle Einträge auf Gleichheit zu untersuchen, ist sehr mühsam. Wir können dies viel einfacher mit einer Differenz tun:</p>
<pre class="r"><code>five_factor_ML$loadings[,] %*% five_factor_ML$Phi[,] - five_factor_ML$Structure[,]</code></pre>
<pre><code>##    ML4 ML3 ML1 ML2 ML5
## E1   0   0   0   0   0
## E2   0   0   0   0   0
## E3   0   0   0   0   0
## N1   0   0   0   0   0
## N2   0   0   0   0   0
## N3   0   0   0   0   0
## A1   0   0   0   0   0
## A2   0   0   0   0   0
## A3   0   0   0   0   0
## C1   0   0   0   0   0
## C2   0   0   0   0   0
## C3   0   0   0   0   0
## O1   0   0   0   0   0
## O2   0   0   0   0   0
## O3   0   0   0   0   0</code></pre>
<p>Da hier nur Nullen herauskommen, scheinen die Ausdrücke identisch zu sein!</p>
</details>
</div>
<div id="AppendixD" class="section level2">
<h2>Appendix D</h2>
<details>
<summary>
<strong>Berechnen von Eigenwerten und Kommunalitäten mit Hilfe von <span class="math inline">\(\Lambda\)</span> und <span class="math inline">\(\Phi\)</span></strong>
</summary>
<p>Im vorigen Abschnitt hatten wir bemerkt, wie leicht die Strukturmatrix aus der Faktorladungsmatrix <span class="math inline">\(\Lambda\)</span> hervorgeht, indem einfach nur die Beziehung der latenten Variablen untereinander berücksichtigt wird. Es ist folglich nur logisch, dass bei der Bestimmung der Eigenwerte und der Kommunalitäten diese Beziehung ebenfalls eine Rolle spielt. Im Rahmen der <a href="/post/PCA">PCA</a> hatten wir uns bereits die Beziehungen dieser Größen untereinander angesehen. Dort war es so, dass die Diagonalelemente von <span class="math inline">\(\Lambda\Lambda&#39;\)</span> gerade die Kommunalitäten waren und die Diagonalelemente von <span class="math inline">\(\Lambda&#39;\Lambda\)</span> gerade die Eigenwerte der rotierten Lösung. Es kam also lediglich darauf an, in welcher Reihenfolge <span class="math inline">\(\Lambda\)</span> und transponiertes <span class="math inline">\(\Lambda\)</span> miteinander verrechnet werden! Für oblique rotierte EFAs müssen wir nun noch die Korrelation der Faktoren untereinander berücksichtigen. Die implizierte Korrelationsmatrix war einfach
<span class="math display">\[\Lambda\Phi\Lambda&#39; + \Theta,\]</span>
wobei die Elemente von <span class="math inline">\(\Theta\)</span> im Grunde nur dafür sorgen, dass die Hauptdiagonale wieder bei 1 landet. Lassen wir <span class="math inline">\(\Theta\)</span> weg, erhalten wir die Korrelationsmatrix mit den Kommunalitäten auf der Hauptdiagonale. Damit ist klar, dass
<span class="math display">\[\text{diag}(\Lambda\Phi\Lambda&#39;) = \text{Kommunalitäten}\]</span>
gilt. Da wir bereits wissen, dass <span class="math inline">\(\Lambda\Phi\)</span> die Strukturmatrix ist, könnten wir auch einfach sagen, dass das Matrixprodukt <em>Strukturmatrix Faktorladungsmatrix’</em> die Kommunalitäten auf der Hauptdiagonale enthält. Probieren wir dies doch einmal aus:</p>
<pre class="r"><code>two_factor_ML$communality</code></pre>
<pre><code>##        E1        E2        E3        N1        N2        N3 
## 0.4715292 0.4068085 0.7128628 0.6964745 0.3520527 0.3565427</code></pre>
<pre class="r"><code>diag(two_factor_ML$loadings[,] %*% two_factor_ML$Phi[,] %*% t(two_factor_ML$loadings[,]))</code></pre>
<pre><code>##        E1        E2        E3        N1        N2        N3 
## 0.4715292 0.4068085 0.7128628 0.6964745 0.3520527 0.3565427</code></pre>
<pre class="r"><code>diag(two_factor_ML$Structure[,] %*% t(two_factor_ML$loadings[,]))</code></pre>
<pre><code>##        E1        E2        E3        N1        N2        N3 
## 0.4715292 0.4068085 0.7128628 0.6964745 0.3520527 0.3565427</code></pre>
<p>In allen 3 Fällen kommen die Kommunalitäten heraus. <code>diag</code> fordert hierbei die Diagonalelemente einer quadratischen Matrix an. Um nun die Eigenwerte zu erhalten, müssen wir das Matrixprodukt nur umdrehen: <em>Faktorladungsmatrix’ Strukturmatrix</em>, bzw. das Transponierungszeichen tauschen (<em>Strukturmatrix’ Faktorladungsmatrix</em> ginge auch!):</p>
<p><span class="math display">\[\text{diag}(\Phi\Lambda&#39;\Lambda) = \text{Eigenwerte}\]</span>
Wer genau aufpasst, fragt sich jetzt vielleicht, wieso <span class="math inline">\(\Phi\)</span> kein Transponierungszeichen trägt. Das liegt daran, dass eine Kovarianz/Korrelationsmatrix immer symmetrisch ist — die Definition einer symmetrischen quadratischen Matrix <span class="math inline">\(A\)</span> ist: <span class="math inline">\(A = A&#39;\)</span>.</p>
<pre class="r"><code>two_factor_ML$Vaccounted # Eigenwerte nach Rotation und Extraktion in SS loadings</code></pre>
<pre><code>##                             ML1       ML2
## SS loadings           1.6053881 1.3908823
## Proportion Var        0.2675647 0.2318137
## Cumulative Var        0.2675647 0.4993784
## Proportion Explained  0.5357955 0.4642045
## Cumulative Proportion 0.5357955 1.0000000</code></pre>
<pre class="r"><code>diag(two_factor_ML$Phi[,] %*% t(two_factor_ML$loadings[,])  %*% two_factor_ML$loadings[,])</code></pre>
<pre><code>##      ML1      ML2 
## 1.605388 1.390882</code></pre>
<pre class="r"><code>diag(t(two_factor_ML$Structure[,]) %*% two_factor_ML$loadings[,])</code></pre>
<pre><code>##      ML1      ML2 
## 1.605388 1.390882</code></pre>
<p>In der ersten Zeile von <code>two_factor_ML$Vaccounted</code> stehen die Eigenwerte nach Rotation und Extraktion. Diese sind identisch zur Diagonale der beiden Matrixprodukte!</p>
</details>
</div>
<div id="AppendixE" class="section level2">
<h2>Appendix E</h2>
<details>
<summary>
<strong>Prüfen der Voraussetzungen mit der Mahalanobisdistanz</strong>
</summary>
<p>Auf multivariate Normalverteilung können wir beispeilsweise <strong>deskriptiv</strong> prüfen, indem wir die Mahalanobisdistanz (die Distanz vom gemeinsame Zentroiden; dem Mittelwert über alle Variablen; unter Berücksichtigung der Kovariation im Datensatz) plotten und sie mit einer <span class="math inline">\(\chi^2\)</span>-Verteilung vergleichen; wobei <span class="math inline">\(df=p\)</span> und <span class="math inline">\(p=\)</span> Anzahl an Variablen (hier <span class="math inline">\(df=p=15\)</span>).</p>
<pre class="r"><code>Mahalanobis_Distanz &lt;- mahalanobis(x = dataFR, cov = cov(dataFR), center = colMeans(dataFR)) # Berechnen der Mahalanobisdistanz
hist(Mahalanobis_Distanz, col = &quot;skyblue&quot;, border = &quot;blue&quot;, freq = F, breaks = 15) # Histogramm
lines(x = seq(0, max(Mahalanobis_Distanz), 0.01), y = dchisq(x = seq(0, max(Mahalanobis_Distanz), 0.01), df = 15), col = &quot;darkblue&quot;, lwd = 4) # Einzeichnen der Dichte</code></pre>
<p><img src="/post/2021-03-25_MSc1_FEII_Sitzung2_EFA_files/figure-html/unnamed-chunk-51-1.png" width="672" style="display: block; margin: auto;" /></p>
<p><em>Sie können ja mal Einstellungen verändern und sich deren Konsequenz für die Grafik ansehen!</em></p>
<p>Das Histogramm scheint nicht perfekt zur <span class="math inline">\(\chi^2\)</span> Verteilung zu passen. Allerdings sind die Abweichungen auch nicht enorm. Wir verwerfen auf Basis des Histogramms die Normalverteilungsannahme nicht, sollten die Ergebnisse aber trotzdem unter Vorbehalt interpretiert werden.</p>
<p>Die Funktion <code>mahalanobis</code> berechnet die Mahalanobisdistanz pro Proband. Als Datenargument braucht sie eine Matrix <code>x</code>. Die Mahalanobisdistanz ist ein Distanzmaß, welches die korrelative Struktur in den Daten berücksichtigt. Wir übergeben daher mit <code>cov = cov(dataFR)</code> der Funktion <code>mahalanobis</code> die empirische Kovarianzmatrix unserer Daten (<code>cov(dataFR)</code>), um diese Struktur mit zuberücksichtigen. Außerdem müssen die Variablen und deren Variation relativ zu einem Zentroiden angegeben werden. Der Zentroid wird dem <code>center</code> Argument übergeben. Wir brauchen also für jede Variable deren Mittelwert. Dies machen wir mit <code>colMeans</code>.</p>
<pre class="r"><code>colMeans(dataFR)</code></pre>
<pre><code>##       E1       E2       E3       N1       N2       N3       A1       A2 
## 2.558140 2.968992 3.217054 3.372093 3.131783 3.852713 2.620155 3.596899 
##       A3       C1       C2       C3       O1       O2       O3 
## 2.286822 3.100775 3.131783 4.000000 3.945736 2.077519 4.240310</code></pre>
<p>Der <code>hist</code> Befehl erzeugt schließlich ein Histogramm der Mahalanobisdistanzen. Mit den Argumenten <code>col = "skyblue"</code> und <code>border = "blue"</code> setzten wir die Farben des Histogramms fest. Mit <code>freq = F</code> sagen wir, dass wir nicht die absoluten sondern die relativen Häufigkeiten angezeigt haben wollen (dies brauchen wir um anschließend die Dichte der <span class="math inline">\(\chi^2\)</span>-Verteilung einzuzeichnen). Mit <code>breaks = 15</code> beschließen wir, dass insgesamt ca. 15 Balken gezeichnet werden sollen.</p>
<p>Schließlich zeichnen wir mit <code>lines</code> eine Line, welche als x-Argument <code>x = seq(0, max(Mahalanobis_Distanz), 0.01)</code> eine Sequenz von Zahlen von 0 bis zur maximalen Mahalanobisdistanz erhält und in 0.01 Schritten wächst. Gegen diese x-Werte zeichnen wir die Dichte der <span class="math inline">\(\chi^2(df=15)\)</span>-Verteilung ein: <code>y = dchisq(x = seq(0, max(Mahalanobis_Distanz), 0.01), df = 15)</code>. <code>col = "darkblue"</code> und <code>lwd = 4</code> setzten jeweils die Linienfarbe und Liniendicke fest. Weitere Informationen zu Verteilungen und wie man diese in <code>R</code> umsetzt, können im <a href="https://en.wikibooks.org/wiki/R_Programming/Probability_Distributions">R-Wiki zu Verteilungen</a>, in <a href="https://de.wikipedia.org/wiki/Wahrscheinlichkeitsdichtefunktion">Wikipedia zu Verteilungen und Dichten</a> oder in einer <a href="https://www.statmethods.net/advgraphs/probability.html">Kurzzusammenfassung auf statmethods</a> nachgelesen werden. Grundlagen hierzu können außerdem in <a href="https://hds.hebis.de/ubffm/Record/HEB366849158">Eid et al. (2017)</a> in Kapitel 7 ab Seite 171 gefunden werden.</p>
<p>Außerdem können wir auch noch Mardia’s Test auf multivariate Normalverteilung verwenden. Diesen gibt es bspw. im <code>R</code>-Paket <code>MVN</code> (für <strong>M</strong>ulti-<strong>V</strong>ariate <strong>N</strong>ormal-distribution). In diesem Paket verwenden wir die <code>mvn</code>-Funktion, um Mardia’s Test zu verwenden:</p>
<pre class="r"><code>library(MVN)
mvn(data = dataFR, mvnTest = &quot;mardia&quot;)</code></pre>
<pre><code>## $multivariateNormality
##              Test        Statistic              p value Result
## 1 Mardia Skewness 814.236119391994 0.000288124299329737     NO
## 2 Mardia Kurtosis 1.53049602635342    0.125893996300673    YES
## 3             MVN             &lt;NA&gt;                 &lt;NA&gt;     NO
## 
## $univariateNormality
##            Test  Variable Statistic   p value Normality
## 1  Shapiro-Wilk    E1        0.8846  &lt;0.001      NO    
## 2  Shapiro-Wilk    E2        0.9099  &lt;0.001      NO    
## 3  Shapiro-Wilk    E3        0.9062  &lt;0.001      NO    
## 4  Shapiro-Wilk    N1        0.8844  &lt;0.001      NO    
## 5  Shapiro-Wilk    N2        0.9109  &lt;0.001      NO    
## 6  Shapiro-Wilk    N3        0.8291  &lt;0.001      NO    
## 7  Shapiro-Wilk    A1        0.8772  &lt;0.001      NO    
## 8  Shapiro-Wilk    A2        0.8785  &lt;0.001      NO    
## 9  Shapiro-Wilk    A3        0.8083  &lt;0.001      NO    
## 10 Shapiro-Wilk    C1        0.9097  &lt;0.001      NO    
## 11 Shapiro-Wilk    C2        0.9067  &lt;0.001      NO    
## 12 Shapiro-Wilk    C3        0.8288  &lt;0.001      NO    
## 13 Shapiro-Wilk    O1        0.8395  &lt;0.001      NO    
## 14 Shapiro-Wilk    O2        0.8386  &lt;0.001      NO    
## 15 Shapiro-Wilk    O3        0.7745  &lt;0.001      NO    
## 
## $Descriptives
##      n     Mean   Std.Dev Median Min Max 25th 75th        Skew    Kurtosis
## E1 129 2.558140 1.3044813      3   1   5    1    3  0.32427985 -1.03222800
## E2 129 2.968992 1.2433447      3   1   5    2    4  0.13071545 -0.98604106
## E3 129 3.217054 1.2683727      3   1   5    2    4 -0.20289793 -0.99959701
## N1 129 3.372093 1.3232876      4   1   5    2    4 -0.31730421 -1.14311645
## N2 129 3.131783 1.1550152      3   1   5    2    4 -0.01411112 -0.95870960
## N3 129 3.852713 1.0975881      4   1   5    3    5 -0.87031995 -0.10813842
## A1 129 2.620155 1.3761007      2   1   5    1    4  0.33995849 -1.17089544
## A2 129 3.596899 1.1693974      4   1   5    3    5 -0.37750788 -0.99209594
## A3 129 2.286822 1.3761007      2   1   5    1    4  0.55150074 -1.20186405
## C1 129 3.100775 1.1239228      3   1   5    2    4 -0.16388511 -0.85645458
## C2 129 3.131783 1.2770807      3   1   5    2    4 -0.17800768 -1.01121119
## C3 129 4.000000 1.0231691      4   1   5    3    5 -0.86845894 -0.01507734
## O1 129 3.945736 1.0178875      4   1   5    3    5 -0.90696625  0.43639201
## O2 129 2.077519 1.1012238      2   1   5    1    3  0.75369527 -0.39530983
## O3 129 4.240310 0.9080817      4   1   5    4    5 -1.16861246  0.88182592</code></pre>
<p>Hier bekommen wir einiges an Output. Der erste Block enthält den Test auf multivariate Normalität (unter <code>$multivariateNormality</code>). Der nächste Unterpunkt enthält Informationen zur univariate Normalität (unter <code>$univariateNormality</code>) sowie einen Block zu Deskriptivstatistiken (unter <code>$Descriptives</code>). Wir konzentrieren uns nur auf den multivariaten Test:</p>
<pre><code>## ## $multivariateNormality
## ##              Test        Statistic              p value Result
## ## 1 Mardia Skewness 814.236119391994 0.000288124299329737     NO
## ## 2 Mardia Kurtosis 1.53049602635342    0.125893996300673    YES
## ## 3             MVN             &lt;NA&gt;                 &lt;NA&gt;     NO
## ##</code></pre>
<p>In der ersten Spalte steht der Test <code>Mardia Skewness</code> oder <code>Mardia Kurtosis</code> womit mutlivariate Schiefe (Skewness) und Kurtosis (Wölbung) untersucht wird, ob diese von der Normalverteilung abweicht. <code>Statistic</code> enthält Informationen zu Mardia’s Teststatistik, welche auch einen zugehörigen <code>p value</code> hat. Unter <code>Result</code> steht eine Entscheidung, ob die Schiefe oder Wölbung jeweils von einer Normalverteilung stammen könnte. Ganz unten steht <code>MVN</code>, also eine globale Entscheidung. Hier steht leider <code>NO</code>, also kann nicht von multivariater Normalverteilung gesprochen werden, denn die Null-Hypothese, dass die Daten die selbe multivariate Schiefe und Wölbung wie die einer Normalverteilung aufzeigen, musste auf dem <span class="math inline">\(\alpha=5\%\)</span> Niveau verworfen werden. Dieser Test wird auch kurz in <a href="https://hds.hebis.de/ubffm/Record/HEB366849158">Eid et al. (2017, pp. 516-517)</a> beschrieben. Für unsere Ergebnisse bedeutet dies, dass Parameter ggf. verzerrt sind und der Likelihood Ratio Test ggf. zu falschen Schlüssen kommt! Die Ergebnisse diese Sitzung sind also nur unter Vorbehalt zu interpretieren.</p>
</details>
</div>
<div id="literatur" class="section level2">
<h2>Literatur</h2>
<p><a href="https://hds.hebis.de/ubffm/Record/HEB468515836">Brandt H. (2020).</a> Exploratorische Faktorenanalyse (EFA). In <a href="https://hds.hebis.de/ubffm/Record/HEB468515836">Moosbrugger H., Kelava A.</a> (eds) Testtheorie und Fragebogenkonstruktion. Berlin, Heidelberg: Springer. <a href="https://doi.org/10.1007/978-3-662-61532-4_23">https://doi.org/10.1007/978-3-662-61532-4_23</a></p>
<p><a href="https://hds.hebis.de/ubffm/Record/HEB366849158">Eid, M., Gollwitzer, M., &amp; Schmitt, M. (2017).</a> <em>Statistik und Forschungsmethoden</em> (5. Auflage, 1. Auflage: 2010). Weinheim: Beltz.</p>
<ul>
<li><small> <em>Blau hinterlegte Autorenangaben führen Sie direkt zur universitätsinternen Ressource.</em></li>
</ul>
</div>
