---
title: Metaanalysen in R
date: '2021-12-22'
slug: metaanalysen-mw
categories:
  - MSc5a
tags:
  - Metaanalyse
  - Zusammenfassung
  - Summary
  - Mittelwerte
  - Effektstärken
  - Gruppenvergleiche
subtitle: 'Mittelwertsunterschiede'
summary: ''
authors: [irmer]
lastmod: '2022-01-13T15:21:58+02:00'
featured: no
header:
  image: "/header/Klipps_Meta-Analyse_MW.jpg"
  caption: "[Courtesy of pxhere](https://pxhere.com/en/photo/1075945)"
projects: []
---

<script src="/rmarkdown-libs/header-attrs/header-attrs.js"></script>


<div id="einführung" class="section level2">
<h2>Einführung</h2>
<p>Metaanalysen sind empirische Zusammenfassungen von Studien unter Verwendung mathematischer/statistischer Modelle. Auf diese Weise können Ergebnisse aus jahrelanger Forschung integriert und zusammengefasst werden, was oft Aufschluss darüber liefert, ob Effekte im Mittel vorhanden sind oder nicht. Somit können Metaanalysen lange Debatten beenden und Licht in das Dunkel von sich widersprechenden Studienergebnissen bringen.</p>
<p>Mit Hilfe des <code>metafor</code>-Paketes (<em><strong>meta</strong><em>-analysis </em><strong>fo</strong><em>r </em><strong>r</strong></em>) von Viechtbauer (2010) lassen sich eindimensionale und mehrdiemensionale Metaanalysen (in welchen ein oder mehrere Koeffizient über mehrere Studien “gemittelt” werden soll) leicht berechnen. Zunächst müssen wir dazu das <code>R</code>-Paket installieren.</p>
<pre class="r"><code>library(metafor)</code></pre>
<pre><code>## Warning: Paket &#39;metafor&#39; wurde unter R Version 4.1.2 erstellt</code></pre>
<pre><code>## Lade nötiges Paket: Matrix</code></pre>
<pre><code>## 
## Loading the &#39;metafor&#39; package (version 3.0-2). For an
## introduction to the package please type: help(metafor)</code></pre>
<p>Wie auch beim Laden des Paketes schon erwähnt wird (<code>For an overview and introduction to the package please type: help(metafor)</code>), können wir uns mit der sehr nützlichen <code>R</code>-internen Hilfe-Funktion einen Überblick über das Paket verschaffen.</p>
<pre class="r"><code>help(&quot;metafor&quot;)</code></pre>
<p>Wenn wir diesen Befehl ausführen, so geht in <code>R</code>-Studio ein Fenster mit der Überschrift “metafor: A Meta-Analysis Package for R” auf, in welchem die grundlegenden Funktionen erklärt werden.</p>
<div id="effekte-bestimmen" class="section level3">
<h3>Effekte bestimmen</h3>
<p>Im Datensatz, den wir in dieser Sitzung betrachten wollen, wurden die Effektstärken (standardisierte Mittelwertsdifferenzen) bereits bestimmt. Mit Hilfe der <code>escalc</code>-Funktion hätten wir diese auch selbst erstellen können, angenommen wir hätten einen Datensatz, welcher zwei unabhängige Gruppen in einer Variable untersucht hatte. Wir nehmen mal folgende Mittelwerte, Standardabweichungen und Stichprobengrößen an: <span class="math inline">\(\bar{X}_1 = 1.5, SD_1=0.7,n_1=35\)</span> und <span class="math inline">\(\bar{X}_2 = 2.7, SD_2=1.3,n_2=27\)</span>. Wir fügen diese Daten kurz in einen <code>data.frame</code>, um dann die <code>escalc</code>-Funktion schöner darauf anwenden zu können:</p>
<pre class="r"><code>df &lt;- data.frame(&quot;X1&quot; = 1.5, &quot;SD1&quot; = 0.7, &quot;n1&quot; = 35,
                 &quot;X2&quot; = 2.7, &quot;SD2&quot; = 1.3, &quot;n2&quot; = 27)
df</code></pre>
<pre><code>##    X1 SD1 n1  X2 SD2 n2
## 1 1.5 0.7 35 2.7 1.3 27</code></pre>
<p>Der <code>escalc</code> Funktion müssen wir zunächst sagen, welche Transformation wir wünschen <code>measure = "SMD"</code> für <strong>S</strong>tandardized <strong>M</strong>ean <strong>D</strong>ifference. Anschließend brauch die Funktion alle Informationen, die wir auch selbst zum bestimmen der Effektstärke brauchen: Mittelwerte (<code>m1i</code>, <code>m2i</code>), Standardabweichungen (<code>sd1i</code>, <code>sd2i</code>) und Stichprobengrößen (<code>n1i</code>, <code>n2i</code>).</p>
<pre class="r"><code>escalc(measure = &quot;SMD&quot;, m1i = X1, m2i = X2, sd1i = SD1, sd2i = SD2,
       n1i = n1, n2i = n2,
       data = df)</code></pre>
<pre><code>##    X1 SD1 n1  X2 SD2 n2      yi     vi 
## 1 1.5 0.7 35 2.7 1.3 27 -1.1790 0.0768</code></pre>
<p>Zurückgegeben wird uns ein Datensatz, der um die beiden Variablen <code>yi</code> (Standardized Mean Difference) und <code>vi</code> (Standardfehler der SMD) erweitert wurde. Hätten wir mehrere Studien übergeben, würden hier entsprechened mehrere Zeilen stehen. Zum Glück liegen die Daten schon vor, sodass wir das nicht für unsere Metaanalyse tun müssen!</p>
</div>
</div>
<div id="daten" class="section level2">
<h2>Daten</h2>
<p>In dieser Sitzung wollen wir einen Datensatz von López-López et al. (2019), der mit dem <code>metafor</code>-Paket mitgeliefert wird, verwenden. Dieser heißt <code>dat.lopez2019</code>. Die Autorinnen und Autoren haben die Effektivität der CBT (cognitive behavioural therapy [kognitive Verhaltenstherapie]) bei Depression untersucht und diese mit verschiedenen Kontrollbedingungen und unterschiedlichen Arten der CBT verglichen. Weitere Informationen zum Datensatz erhalten Sie bspw. mit <code>?dat.lopez2019</code> (das <code>metafor</code>-Paket muss natürlich vorher geladen sein).</p>
<pre class="r"><code>head(dat.lopez2019)</code></pre>
<table style="width:100%;">
<colgroup>
<col width="12%" />
<col width="9%" />
<col width="3%" />
<col width="1%" />
<col width="5%" />
<col width="4%" />
<col width="3%" />
<col width="5%" />
<col width="5%" />
<col width="4%" />
<col width="6%" />
<col width="3%" />
<col width="2%" />
<col width="1%" />
<col width="3%" />
<col width="3%" />
<col width="3%" />
<col width="2%" />
<col width="3%" />
<col width="3%" />
<col width="3%" />
<col width="3%" />
<col width="2%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">study</th>
<th align="left">treatment</th>
<th align="left">scale</th>
<th align="right">n</th>
<th align="right">diff</th>
<th align="right">se</th>
<th align="right">group</th>
<th align="right">tailored</th>
<th align="right">sessions</th>
<th align="right">length</th>
<th align="right">intensity</th>
<th align="right">multi</th>
<th align="right">cog</th>
<th align="right">ba</th>
<th align="right">psed</th>
<th align="right">home</th>
<th align="right">prob</th>
<th align="right">soc</th>
<th align="right">relax</th>
<th align="right">goal</th>
<th align="right">final</th>
<th align="right">mind</th>
<th align="right">act</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Andersson (2005)</td>
<td align="left">Placebo</td>
<td align="left">BDI</td>
<td align="right">49</td>
<td align="right">-0.2140</td>
<td align="right">0.0208</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">NA</td>
<td align="right">NA</td>
<td align="right">NA</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="left">Andersson (2005)</td>
<td align="left">Multimedia CBT</td>
<td align="left">BDI</td>
<td align="right">36</td>
<td align="right">-1.5529</td>
<td align="right">0.0425</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="right">5</td>
<td align="right">NA</td>
<td align="right">NA</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="right">0</td>
</tr>
<tr class="odd">
<td align="left">Arean (1993)</td>
<td align="left">Wait list</td>
<td align="left">BDI</td>
<td align="right">20</td>
<td align="right">-0.4032</td>
<td align="right">0.0531</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">NA</td>
<td align="right">NA</td>
<td align="right">NA</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="left">Arean (1993)</td>
<td align="left">F2F CBT</td>
<td align="left">BDI</td>
<td align="right">19</td>
<td align="right">-1.5505</td>
<td align="right">0.0831</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">12</td>
<td align="right">90</td>
<td align="right">10.8</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
</tr>
<tr class="odd">
<td align="left">Beckenridge (1985)</td>
<td align="left">Wait list</td>
<td align="left">BDI</td>
<td align="right">19</td>
<td align="right">0.2131</td>
<td align="right">0.0542</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">NA</td>
<td align="right">NA</td>
<td align="right">NA</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="left">Beckenridge (1985)</td>
<td align="left">F2F CBT</td>
<td align="left">BDI</td>
<td align="right">17</td>
<td align="right">-1.5438</td>
<td align="right">0.0934</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">18</td>
<td align="right">NA</td>
<td align="right">NA</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
</tr>
</tbody>
</table>
<p>In <code>study</code> steht die verwendete Studie, <code>treatment</code> zeigt an, welche Art der Therapie oder Kontrollgruppe in der jeweiligen Studie verwendet wurde (“F2F CBT” = “Angesicht zu Angesicht” CBT, “Multimedia CBT” = Online-CBT, “Placebo” = Placebo-Kontrollgruppe, “Wait list” = Wartelistenkontrollgruppe, “Hybrid CBT” = Mischung aus F2F und Multimedia, “No treatment” = klassische Kontrollgruppw, “TAU” = Treatment as Usual [Standardtherapie]), <code>scale</code> gibt an, wie die Depression erfasst wurde, <code>n</code> ist die Stichprobengröße der Studie, <code>diff</code> ist die standardisierte Differenz (Cohen’s <span class="math inline">\(d\)</span>) zwischen vor und nach der Intervention, <code>se</code> ist der Standardfehler von <code>diff</code>, <code>group</code> [Dummy-Variable] zeigt an, ob es sich um eine Einzel (0) oder Gruppentherapie (1) gehandelt hat, <code>tailored</code> gibt an, ob die Therapie auf den jeweiligen Patienten/die jeweilige Patientin zugeschnitten wurde, <code>sessions</code> ist die Anzahl an Therapiesitzungen, <code>length</code> ist die durchschnittliche Sitzungslänge, <code>intensity</code> ist das Produkt aus <code>session</code> und <code>length</code>. Außerdem werden noch weitere mögliche Moderatorvariablen aufgeführt, die sich jeweils auf die Therapie beziehen. Für mehr Informationen siehe bspw. <code>?dat.lopez2019</code>. Wir schauen uns die Moderatoren genauer an, wenn es um die Moderatoranalysen im Rahmen von Metaanalysen geht.</p>
<p>Wir wollen uns zunächst nur auf die klassische “Face-to-Face” CBT konzentrieren und kürzen daher den Datensatz. Wir kopieren den Originaldatensatz in <code>F2F_CBT</code>, damit <code>dat.lopez2019</code> erhalten bleibt.</p>
<pre class="r"><code>F2F_CBT &lt;- dat.lopez2019[dat.lopez2019$treatment == &quot;F2F CBT&quot;,] # wähle nur Fälle mit F2F CBT</code></pre>
<div id="fragestellungen" class="section level3">
<h3>Fragestellungen</h3>
<p>Insgesamt wollen wir nun untersuchen, ob</p>
<ol style="list-style-type: decimal">
<li>die CBT zu einem Therapieerfolg bei Depression führt</li>
<li>ob die CBT über Studien hinweg zu einer homogenen Verbesserung der Depressivität führt</li>
<li>ob Heterogenität durch Moderatoren (Therapiemerkmale) erklärt werden kann</li>
</ol>
<p>Um die erste Fragestellung zu beantworten müssen wir eine durchschnittliche Differenz von Prä-Post bestimmen. Ist diese bedeutsam negativ, so gibt es eine Symptomverbesserung der CBT für die Depressivität auch in der Population.</p>
</div>
</div>
<div id="fixed-effects-modell" class="section level2">
<h2>Fixed Effects Modell</h2>
<p>Das simpelste Vorgehen wäre es, die Differenzen der Studien einfach zu mitteln. Allerdings sind die Studien unterschiedlich groß. Somit müssen wir zumindest ein gewichtetes Mittel bestimmen. Von nun an nennen wir die Effektgrößen (also die standardisierte Prä-Post-Differenz) <span class="math inline">\(Y_i\)</span>.</p>
<div id="fixed-effects-modell-händisch" class="section level3">
<h3>Fixed Effects Modell: händisch</h3>
<p>Wir mitteln (gewichtet) zunächst händisch via:
<span class="math display">\[\sum_{i=1}^k\frac{n_iY_i}{\sum_{i=1}^kn_i}\]</span>
Für die <span class="math inline">\(k\)</span> Stichproben wird hier jede standardisierte Prä-Post-Differenz mit der Stichprobengröße multipliziert <span class="math inline">\(n_iY_i\)</span> und dann werden diese Werte aufsummiert (eine gewichtete Summe entsteht). Teilen wir diese Summe anschließend durch die Gesamtstichprobe <span class="math inline">\(\sum_{i=1}^kn_i\)</span> so erhalten wir einen gewichteten Mittelwert, der berücksichtigt, dass einige Stichproben größer sind und dort die geschätzte standardisierte Differenz präziser ist. Dies sieht in <code>R</code> so aus:</p>
<pre class="r"><code>sum(F2F_CBT$n*F2F_CBT$diff)/sum(F2F_CBT$n)</code></pre>
<pre><code>## [1] -1.744116</code></pre>
</div>
<div id="fixed-effects-modell-modellgleichung" class="section level3">
<h3>Fixed Effects Modell: Modellgleichung</h3>
<p>Wir haben hier, ohne es zu wissen, das sogenannte “Fixed Effects”-Modell bestimmt, wobei wir die Stichprobengröße als als Gewichtung verwendet haben. Das Fixed-Effects-Modell besagt, dass</p>
<p><span class="math display">\[Y_i = \theta + \varepsilon_i\]</span></p>
<p>die Effektstärken <span class="math inline">\(Y_i\)</span> zufällig um den wahren Wert <span class="math inline">\(\theta\)</span> streuen. <span class="math inline">\(\varepsilon_i\)</span> ist hierbei die zufällige Abweichung vom wahren Effekt, quasi das Residuum, welches als Normalverteilt angenommen wird.</p>
</div>
<div id="fixed-effects-modell-metafor" class="section level3">
<h3>Fixed Effects Modell: <code>metafor</code></h3>
<p>Ein Fixed-Effects-Modell lässt sich leicht mit dem <code>metafor</code>-Paket schätzen. Die Funktion dazu heißt <code>rma</code> (für <code>R</code> und Metaanalyse). Da bei Metaanalysen die Effekte in den Studien die abhängigen Variablen sind, werden sie im Paket als <code>yi</code> bezeichnet. Wir brauchen dann noch ein Streumaß <code>vi</code>, den Datensatz in <code>data</code> und wir müssen die Methode als Fixed Effects <code>method = "FE"</code> festlegen. Das Modell nennen wir <code>FEM_n</code> für Fixed-Effects Modell gewichtet mit Stichprobengrößen.</p>
<pre class="r"><code>FEM_n &lt;- rma(yi = diff, vi =  1/n, data = F2F_CBT, method = &quot;FE&quot;)
summary(FEM_n)</code></pre>
<pre><code>## 
## Fixed-Effects Model (k = 71)
## 
##     logLik    deviance         AIC         BIC        AICc 
## -1561.4161   3206.6098   3124.8321   3127.0948   3124.8901   
## 
## I^2 (total heterogeneity / total variability):   97.82%
## H^2 (total variability / sampling variability):  45.81
## 
## Test for Heterogeneity:
## Q(df = 70) = 3206.6098, p-val &lt; .0001
## 
## Model Results:
## 
## estimate      se      zval    pval    ci.lb    ci.ub 
##  -1.7441  0.0217  -80.3430  &lt;.0001  -1.7867  -1.7016  *** 
## 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>Die <code>summary</code> gibt uns, wie immer, eine Übersicht über die Ergebnisse.</p>
<p>In der Summary sehen wir Folgendes:</p>
<pre><code>## Fixed-Effects Model (k = 71)</code></pre>
<p>zeigt uns, dass ein Fixed Effects Modell mit <span class="math inline">\(k\)</span>=71 Studien gerechnet wurde.</p>
<pre><code>##     logLik    deviance         AIC         BIC        AICc 
## -1561.4161   3206.6098   3124.8321   3127.0948   3124.8901</code></pre>
<p>sind Modell-Fit Ergebnisse. Das Modell wurde mit der Maximum-Likelihood (ML) Methode geschätzt, weswegen uns die Log-Liklihood (<code>logLik</code>), die Devianz (<code>deviance</code>), sowie weitere Informationskriterien (<code>AIC</code>, <code>BIC</code>, <code>AICc</code>) ausgegeben werden. Das zeigt uns, dass wenn Modelle mit ML geschätzt werden, auch Modellvergleiche möglich sind.</p>
<pre><code>## I^2 (total heterogeneity / total variability):   97.82%
## H^2 (total variability / sampling variability):  45.81</code></pre>
<p>sind Heterogenitätsmaße. Sie beschreiben, wie viel der Variation der Studienergebnisse durch mögliche Subpopulationen zu Stande gekommen sind. <span class="math inline">\(I^2\)</span> ist ein häufig berichtetes Maß, welches den Anteil an der Gesamtvariation der Effektstärken schätzt, die durch Heterogenität zwischen den Studien resultiert.</p>
<p>Diese Heterogenität wird hier auf Signifikanz geprüft mit Hilfe von Cochran’s <span class="math inline">\(Q\)</span>.</p>
<pre><code>## Test for Heterogeneity:
## Q(df = 70) = 3206.6098, p-val &lt; .0001</code></pre>
<p>Das signifikante Ergebnis zeigt uns, dass die Heterogenität statistisch bedeutsam ist, es also Unterschiede zwischen den Stichproben gibt. Diese Heterogenitätsvarianz, die hier de facto auf Signifikanz geprüft wurde, lässt sich vergleichen mit der Between-Varianz in HLM-Modellen. Die Sampling-Varianz enstpricht der Within-Varianz.</p>
<p>Wie immer wird unter <code>Model Results</code> eine Übersicht über die Parameterschätzung gegeben (<code>estimate</code> = Schätzung, <code>se</code> = SE, <code>zval</code> = zugehöriger <span class="math inline">\(z\)</span>-Wert, <code>pval</code> = zugehöriger <span class="math inline">\(p\)</span>-Wert). Da wir hier nur einen einzigen Parameter schätzen, wird hier nicht viel angezeigt. <code>ci.lb</code> und <code>ci.ub</code> ist das Konfidenzinterval der Schätzung, wobei <code>lb</code> für lower-bound (untere Grenze) und <code>ub</code> für upper-bound (obere Grenze) steht.</p>
<pre><code>## Model Results:
## 
## estimate      se      zval    pval    ci.lb    ci.ub 
##  -1.7441  0.0217  -80.3430  &lt;.0001  -1.7867  -1.7016  *** 
## 
## ---
## Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1</code></pre>
<p>Wir kommen zum selben Ergebnis, wie mit unserer händischen Berechnung. Im “Fixed Effects” Modell wird <span class="math inline">\(w_i:=\frac{1}{v_i}\)</span> als Gewicht verwendet (<span class="math inline">\(v_i\)</span> ist die Varianz des Schätzer; beim Mittelwert ist dies dessen Standardfehler im Quadrat). Wenn wir der <code>R</code>-Funktion <code>v_i= 1/n_i</code> übergeben, so ist das Gewicht <span class="math inline">\(w_i:=\frac{1}{\frac{1}{n_i}}=n_i\)</span> einfach die Stichprobengröße (Studien mit größeren Stichproben erhalten mehr Gewicht).</p>
<p>Wir haben nun eine relativ einfache Zusammenfassung der Studienergebnisse durchgeführt. Die Stichprobengröße wird als Gewichtung verwendet, weil sie uns Informationen über die Präzision der Effektstärken gibt: je größer die Stichprobe, desto präziser der Effekt, desto mehr Gewicht sollte diese Stichprobe haben. Nun ist es so, dass wir über Mittelwertsdifferenzen noch zusätzliche Informationen haben. Der Standardfehler enthält sowohl Informationen über die Variabilität innerhalb der Stichprobe, als auch Informationen über die Stichprobengröße. Die lässt sich leicht einsehen, wenn wir uns zurückerinnern, dass der Standardfehler des Mittelwerts gerade durch <span class="math inline">\(SE=\frac{SD}{\sqrt{n}}\)</span> gegeben ist. In gleicher Weise enthält der <span class="math inline">\(SE\)</span> der Effektstärken auch Informationen über Variabilität und Stichprobengröße, also insgesamt über die Präzision der Effektstärken. Aus diesem Grund wiederholen wir das Fixed-Effects-Modell nochmals und verwenden diesmal den <code>se</code> von <code>diff</code> als Gewicht. Das nötige Argument heißt <code>sei</code>. Wir können aber auch <code>vi</code> verwenden. Dafür müssen wir den SE nur quadrieren.</p>
<pre class="r"><code>FEM &lt;- rma(yi = diff, vi =  se^2, data = F2F_CBT, method = &quot;FE&quot;)
summary(FEM)</code></pre>
<pre><code>## 
## Fixed-Effects Model (k = 71)
## 
##     logLik    deviance         AIC         BIC        AICc 
## -8468.9399  17146.2694  16939.8798  16942.1425  16939.9377   
## 
## I^2 (total heterogeneity / total variability):   99.59%
## H^2 (total variability / sampling variability):  244.95
## 
## Test for Heterogeneity:
## Q(df = 70) = 17146.2694, p-val &lt; .0001
## 
## Model Results:
## 
## estimate      se       zval    pval    ci.lb    ci.ub 
##  -1.1130  0.0035  -319.7116  &lt;.0001  -1.1198  -1.1062  *** 
## 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code>FEM2 &lt;- rma(yi = diff, sei =  se, data = F2F_CBT, method = &quot;FE&quot;)
summary(FEM2)</code></pre>
<pre><code>## 
## Fixed-Effects Model (k = 71)
## 
##     logLik    deviance         AIC         BIC        AICc 
## -8468.9399  17146.2694  16939.8798  16942.1425  16939.9377   
## 
## I^2 (total heterogeneity / total variability):   99.59%
## H^2 (total variability / sampling variability):  244.95
## 
## Test for Heterogeneity:
## Q(df = 70) = 17146.2694, p-val &lt; .0001
## 
## Model Results:
## 
## estimate      se       zval    pval    ci.lb    ci.ub 
##  -1.1130  0.0035  -319.7116  &lt;.0001  -1.1198  -1.1062  *** 
## 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>Das Ergebnis ist komplett identisch. Der mittlere Effekt unterscheidet sich deutlich vom mittleren Effekt, den wir mit Stichprobengewichten bestimmt haben. Dies liegt vermutlich an der Heterogenität, die sich vermutlich auch auf unterschiedliche Streuungen innerhalb der Studien bezieht.</p>
<p>Würden wir selbst eine Metaanalyse durchführen wollen, und würden wir bspw. Mittelwerte zusammenfassen wollen, dann können wir den SE über die oben genannte Formel selbst bestimmen. <em>Dies ist ein guter Tipp, da in Studien sehr häufig nur Mittelwert und SD berichtet werden.</em></p>
</div>
</div>
<div id="random-effects-modell" class="section level2">
<h2>Random Effects Modell</h2>
<p>Da wir nun bereits wissen, dass es signifikante Heterogenität zwischen den Studien gibt, sollten wir diese auch in unserem Modell berücksichtigen. Dies schaffen wir mit dem Random Effects Modell.</p>
<div id="random-effects-modell-modellgleichung" class="section level3">
<h3>Random Effects Modell: Modellgleichung</h3>
<p>Im Random Effects Modell wird, wie bei Hierarchischen Regressionsmodellen, eine zusätzliche Variable aufgenommen, die die Heterogenität abbildet:</p>
<p><span class="math display">\[Y_i = \theta + \vartheta_i + \varepsilon_i,\]</span></p>
<p>wobei <span class="math inline">\(\theta\)</span> und <span class="math inline">\(\varepsilon_i\)</span> die selbe Bedeutung haben, wie beim Fixed Effects Modell. <span class="math inline">\(\vartheta_i\)</span> ist die systematische Abweichung vom durchschnittlichen Effekt <span class="math inline">\(\theta\)</span>, der auf Charakteristika der Studie <span class="math inline">\(i\)</span> zurückzuführen ist. Die Varianz von <span class="math inline">\(\vartheta_i\)</span> wird als Heterogenitätsvarianz bezeichnet und häufig mit <span class="math inline">\(\tau^2\)</span> bezeichnet. Die Varianz von <span class="math inline">\(\varepsilon_i\)</span> und <span class="math inline">\(\vartheta_i\)</span> lassen sich mit der Within- und der Between-Varianz von HLM Modell vergleichen.</p>
<p>Um nun das Modell zu schätzen, muss die Heterogenität zwischen Studien berücksichtigt werden. Im “Random Effects” Modell wird die Heterogenitätsvarianz <span class="math inline">\(\tau^2\)</span> als Gewichtung mitverwendet: <span class="math inline">\(w_i:=\frac{1}{v_i+\tau^2}\)</span>. Das Mitteln funktioniert für beide Modelle gleich, nämlich genau so wie der gewichtete Mittelwert, den wir uns zuvor angesehen haben:
<span class="math display">\[\sum_{i=1}^k\frac{w_iy_i}{\sum_{i=1}^kw_i}.\]</span>
Verwenden wir nun das “Random Effects” Modell, so ergibt sich ein etwas anderer Mittelwert (offensichtlich scheinen die Effektstärken heterogen zu sein, denn das Wählen des “Random Effects” Modells hat einen Einfluss auf den geschätzten Mittelwert und die Heterogenitätsvarianz <span class="math inline">\(\tau^2\)</span> ist auch statistisch signifikant). Das Modell nennen wir <code>REM</code> für Random-Effects-Modell:</p>
<pre class="r"><code>REM &lt;- rma(yi = diff, sei =  se, data = F2F_CBT)
summary(REM)</code></pre>
<pre><code>## 
## Random-Effects Model (k = 71; tau^2 estimator: REML)
## 
##    logLik   deviance        AIC        BIC       AICc 
## -113.9313   227.8626   231.8626   236.3596   232.0417   
## 
## tau^2 (estimated amount of total heterogeneity): 1.4347 (SE = 0.2480)
## tau (square root of estimated tau^2 value):      1.1978
## I^2 (total heterogeneity / total variability):   99.93%
## H^2 (total variability / sampling variability):  1454.46
## 
## Test for Heterogeneity:
## Q(df = 70) = 17146.2694, p-val &lt; .0001
## 
## Model Results:
## 
## estimate      se      zval    pval    ci.lb    ci.ub 
##  -2.0523  0.1438  -14.2714  &lt;.0001  -2.3342  -1.7705  *** 
## 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>Der Output des Random Effects Modells unterscheidet sich kaum vom Fixed Effects Modell. Gleich am Anfang der <code>summary</code> fällt uns auf, dass das Modell mit REML anstatt mit ML geschätzt wurde. Dies ist wichtig für folgende Modellvergleiche! Außerdem wird uns jetzt ein Maß für die Herterogenitätsvarianz <span class="math inline">\(\tau^2\)</span> (<code>tau^2</code>) angegeben. In Klammern dahinter steht sein Standardfehler.</p>
<pre><code>## Random-Effects Model (k = 71; tau^2 estimator: REML)
## 
##    logLik   deviance        AIC        BIC       AICc 
## -113.9313   227.8626   231.8626   236.3596   232.0417   
## 
## tau^2 (estimated amount of total heterogeneity): 1.4347 (SE = 0.2480)
## tau (square root of estimated tau^2 value):      1.1978
## I^2 (total heterogeneity / total variability):   99.93%
## H^2 (total variability / sampling variability):  1454.46</code></pre>
<p>Der mittlere Effekt liegt beim “Random Effects” Modell deutlich höher (-2.052) als beim “Fixed Effects” Modell (-1.113). Dem Random-Effects Modell ist hier stärker zu vertrauen, da es die systematische Variation zwischen den Studien in die Modellierung integriert.</p>
<p>In beiden Analysen ist die mittlere Differenz negativ und signifikant von 0 verschieden. Niedrigere Mittelwertsdifferenzen sprechen für ein höhere Reduktion der Depressionssymptomatik.</p>
</div>
<div id="homogenität-annehmen" class="section level3">
<h3>Homogenität “annehmen”</h3>
<p>Wollen wir von Homogenität sprechen, schlagen Döring und Bortz (2016) zwei Kriterien vor: 1) der p-Wert der Q-Statistik sollte größer als 0.1 sein (<span class="math inline">\(p&gt;0.1\)</span>) und die Power des Homogenitätstests sollte hoch sein. Die Power können wir recht leicht mit folgendem Code bestimmen:</p>
<pre class="r"><code>power &lt;- 1 - pchisq(q = qchisq(p = .95, df = REM$k.all - 1), df = REM$k.all - 1, ncp = REM$QE)
power</code></pre>
<pre><code>## [1] 1</code></pre>
<p><code>ncp</code> ist der Non-centrality-parameter der <span class="math inline">\(\chi^2\)</span>-Verteilung. Er beschreibt im Grunde die <span class="math inline">\(\chi^2\)</span>-Verteilung unter einer spezifischen Alternativ-Hypothese. In diesem Beispiel liegt die Power bei 1 (also bei <span class="math inline">\(100\%\)</span>). Das ist wenig verwunderlich, da viele Studien eingegangen sind und der Q-Wert sehr groß ausfällt. Die Power sollte bei <span class="math inline">\(0.8\)</span> also (<span class="math inline">\(80\%\)</span>) liegen.</p>
</div>
</div>
<div id="analyse-plots" class="section level2">
<h2>Analyse Plots</h2>
<p>Das <code>metafor</code> Paket bietet außerdem noch einige grafischen Veranschaulichungen der Daten. Beispielsweise lässt sich ganz leicht ein Funnel-Plot erstellen mit der <code>funnel</code> Funktion, welche lediglich unser Metaanalyse Objekt <code>REM</code> entgegen nehmen muss.</p>
<div id="funnel-plot-und-trim-and-fill-methode" class="section level4">
<h4>Funnel Plot und Trim-and-Fill Methode</h4>
<p>Der Funnel-Plot wird verwendet, um auf das bekannte Problem des Publication-Bias zu untersuchen. Hier wird der gefundene Effekt (hier Effektstärken von Prä-Post Veränderungen) gegen den Standardfehler jeder Studie geplottet. Es wird die Annahme zugrunde gelegt, dass alle Studien in der Metaanalyse eine gewisse, zufällige Schwankung um den wahren Effekt haben, und dabei diese zufällige Schwankung größer ist, je größer der Standardfehler in einer Studie ist und je kleiner die Stichprobe war. Sofern eine Studie unabhängig von der Effektgröße sowie der Streuung (und damit auch der Signifikanz) publiziert wurde, sollte so das typische symmetrische Dreieck (Funnel = Trichter) entstehen.</p>
<pre class="r"><code># funnel plot
funnel(REM)</code></pre>
<p><img src="/post/2021-12-22-Klipps_Meta-Analyse-in-R_MW_files/figure-html/unnamed-chunk-19-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>Der Grafik ist zu entnehmen, dass sich fast alle Effektstärken im negativen Bereich tummeln. Je kleiner der Effekt desto präziser die Schätzung (desto kleiner der SE - höher dargestellt im Funnel-Plot). Dies könnte Indizien auf einen Publication Bias zeigen. Außerdem gibt es wenige Studien mit sehr großen Standardfehlern (und damit geringen Stichprobengrößen). Der Funnel (Trichter) ist kaum befüllt. Dies liegt vermutlich an den wenigen extremen Ergebnissen, die links im Plot dargestellt sind. Allerdings ist die Punktewolke, auch wenn etwas schief, im oberen rechten Bereich recht gut ausgefüllt. Es gibt keine einzige Studie mit positiven Effektstärken. Insgesamt spricht dies dann doch dagegen, dass die Signifikanz des Effekts durch einen Bias in Veröffentlichungen entstanden ist. Allerdings könnte die ausgesprochen große Effektstärke verzerrt sein.</p>
<p>Die Trim-and-Fill Methode wird verwendet, um zu bestimmen, wie viel Studien hinzugenommen (fill) oder entfernt werden (Trim) müssten werden müssten, damit der Funnel-Plot symmetrisch ist. Die Methoden kann auch verwendet werden, um einen (um einen möglichen Publication-Bias) bereinigten Effekt zu schätzen.</p>
<pre class="r"><code>trimfill(REM)</code></pre>
<pre><code>## 
## Estimated number of missing studies on the right side: 0 (SE = 4.0143)
## 
## Random-Effects Model (k = 71; tau^2 estimator: REML)
## 
## tau^2 (estimated amount of total heterogeneity): 1.4347 (SE = 0.2480)
## tau (square root of estimated tau^2 value):      1.1978
## I^2 (total heterogeneity / total variability):   99.93%
## H^2 (total variability / sampling variability):  1454.46
## 
## Test for Heterogeneity:
## Q(df = 70) = 17146.2694, p-val &lt; .0001
## 
## Model Results:
## 
## estimate      se      zval    pval    ci.lb    ci.ub 
##  -2.0523  0.1438  -14.2714  &lt;.0001  -2.3342  -1.7705  *** 
## 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>Die Funktion bestimmt selbst, auf welche Seite mögliche fehlende (nicht publizierte) Werte ergänzt werden sollten. Der Output sieht dem <code>REM</code> sehr ähnlich. In der ersten Zeile steht, dass keine Studie auf der rechten Seite des geschätzten durchschnittlichen Effekts ergänzt wurde. Das ist etwas schade, weil wir möchten gerne sehen, was dann passieren würde. Deshalb stellen wir aus didaktischen Gründen ein, dass Effekte auch auf der linken Seite ergänzt werden sollen (auch wenn das keinen Sinn macht, da der Effekt ja negativ ist!).</p>
<pre class="r"><code>trimfill(REM, side = &quot;left&quot;)</code></pre>
<pre><code>## 
## Estimated number of missing studies on the left side: 18 (SE = 5.5063)
## 
## Random-Effects Model (k = 89; tau^2 estimator: REML)
## 
## tau^2 (estimated amount of total heterogeneity): 1.7369 (SE = 0.2660)
## tau (square root of estimated tau^2 value):      1.3179
## I^2 (total heterogeneity / total variability):   99.96%
## H^2 (total variability / sampling variability):  2796.32
## 
## Test for Heterogeneity:
## Q(df = 88) = 311883.7263, p-val &lt; .0001
## 
## Model Results:
## 
## estimate      se      zval    pval    ci.lb    ci.ub 
##  -2.4362  0.1408  -17.2967  &lt;.0001  -2.7122  -2.1601  *** 
## 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>Nun sehen wir, dass insgesamt 18 Studien ersetzt wurden. Der Output hat sich deutlich verändert. Der mittlere Effekt ist deutlich stärker negativ (-2.05 vs -2.44). Wenn wir nun wieder die <code>funnel</code> Funktion darauf anwenden, sehen wir auch, welche Studien hinzugefügt wurden:</p>
<pre class="r"><code>funnel(trimfill(REM, side = &quot;left&quot;))</code></pre>
<p><img src="/post/2021-12-22-Klipps_Meta-Analyse-in-R_MW_files/figure-html/unnamed-chunk-22-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>Wir sehen, dass die 18 Studien nicht sinnvoll hinzugefügt wurden. Wir gehen somit insgesamt davon aus, dass kein Publication Bias vorliegt und verwerfen die eben betrachteten Trim-and-Fill Ergebnisse.</p>
</div>
<div id="forest-plot" class="section level4">
<h4>Forest-Plot</h4>
<p>Auch Forest-Plots funktionieren auf die gleiche Weise mit der <code>forest</code> Funktion. Der Forest-Plot stellt die unterschiedlichen Studien hinsichtlich ihrer Parameterschätzung (Effektstärken) und die zugehörige Streuung grafisch dar. So können beispielsweise Studien identifiziert werden, welche besonders hohe oder niedrige Werte aufweisen oder solche, die eine besonders große oder kleine Streuung zeigen.</p>
<pre class="r"><code># forest plot
forest(REM)</code></pre>
<p><img src="/post/2021-12-22-Klipps_Meta-Analyse-in-R_MW_files/figure-html/unnamed-chunk-23-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>Wir sehen sehr deutlich, dass alle Studien Konfidenzintervalle aufweisen, die die Null nicht einschließen. Auch ein kumulativer Forest-Plot wäre möglich. Dazu müssen wir auf unser <code>REM</code>-Objekt noch die Funktion <code>cumul.rma.uni</code> anwenden:</p>
<pre class="r"><code># kumulativer Forest Plot
forest(cumul.rma.uni(REM))</code></pre>
<p><img src="/post/2021-12-22-Klipps_Meta-Analyse-in-R_MW_files/figure-html/unnamed-chunk-24-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>Die Funktion <code>cumul.rma.uni</code> führt skuzessive immer wieder eine Metaanalyse durch, wobei nach und nach eine Studie hinzugefügt wird. Anders als beim ersten Forest-Plot wird immer das Ergebnis der jeweiligen Metaanalyse dargestellt und nicht jede Studie einzeln. Wir sehen, dass sich sowohl mittlere Effektstärke als auch Streuung von oben nach unten einpendeln. Das finale Ergebnis ist identisch mit unsere Metaanalyse. Die gestrichelte Linie der Forest-Plots symbolisiert die 0, da in den meisten Fällen gegen 0 getestet wird und es daher von Interesse ist, wie viele Studien sich von 0 unterscheiden und ob sich der mittlere Effekt von 0 unterscheidet. Die Achsenbeschriftung unterscheidet sich, sodass die beiden Forest-Plots nicht ideal vergleichbar sind. Mit dem Zusatzargument <code>xlim</code> können wir die x-Achse explizit einstellen:</p>
<pre class="r"><code># kumulativer Forest Plot
forest(cumul.rma.uni(REM), xlim = c(-10, 2))</code></pre>
<p><img src="/post/2021-12-22-Klipps_Meta-Analyse-in-R_MW_files/figure-html/unnamed-chunk-25-1.png" width="672" style="display: block; margin: auto;" />
Nun sehen wir schöner, wie gut sich die Ergebnisse um den mittleren Wert einpendeln.</p>
<p>Insgesamt zeigen uns die Plots, dass von einem stabilen Effekt ausgegangen werden kann.</p>
</div>
</div>
<div id="moderatormodell" class="section level2">
<h2>Moderatormodell</h2>
<p>Im Random Effects Modell hatten wir bemerkt, dass erhebliche Heterogenität in den Daten herrscht. Diese Heterogenität zwischen den Studien lässt sich mit einem Moderatormodell untersuchen. Hier wird quasi eine Regressionsgleichung zwischen Studien aufgestellt, um die Heterogenitätsvarianz zu erklären.</p>
<p>Hingegen würde es keinen Sinn machen ein Moderatormodell aufzustellen, wenn es keine von Null verschiedene Heterogenitätsvariabilität gibt!</p>
<div id="moderatormodell-modellgleichung" class="section level3">
<h3>Moderatormodell: Modellgleichung</h3>
<p>Die Modellgleichung wird um die Moderatoren (Variablen die die Variation zwischen Studien erklären sollen) erweitert.</p>
<p><span class="math display">\[Y_i = \theta + \beta_1 Z_{1i} + \beta_2 Z_{2i} + \dots + \beta_l Z_{li} + \vartheta_i + \varepsilon_i,\]</span>
wobei <span class="math inline">\(\theta\)</span> der durchschnittliche Effekt ist, wenn alle Moderatoren den Wert 0 annehmen (also das Interzept - Zentrierung der Moderatoren ist sehr wichtig für die Interpretation!), <span class="math inline">\(\beta_j\)</span> ist der Moderatoreffekt des <span class="math inline">\(j\)</span>-ten Moderators <span class="math inline">\(Z_j\)</span>, <span class="math inline">\(\vartheta_i\)</span> ist wieder eine Variable die die verbleibende Heterogenitätsvarianz beschreibt und <span class="math inline">\(\varepsilon_i\)</span> ist das Residuum.</p>
</div>
<div id="moderatormodell-metafor" class="section level3">
<h3>Moderatormodell: <code>metafor</code></h3>
<p>Augenscheinlich würde die <code>intensity</code> der Therapie Sinn machen, dass sie für Heterogenität zwischen den Studien sorgt. Zunächst muss diese Variable zentriert werden, damit der durchschnittliche bedingte Effekt sinnvoll interpretierbar bleibt. Wir überschreiben die Ursprungsvariable.</p>
<pre class="r"><code>F2F_CBT$intensity &lt;- scale(F2F_CBT$intensity, center = T, scale = F) # nur zentrieren</code></pre>
<p>Wir stellen ein Modell auf (hierbei müssen die Moderatoren, wie in einer normalen Regressionsanlyse mit einer Formel eingegben werden; diese Formel wird dem Argument <code>mods</code> übergeben) und lassen dieses diesmal mit “ML” schätzen, um später einen geeigneten Modellvergleich durchführen zu können:</p>
<pre class="r"><code>MEM1 &lt;- rma(yi = diff, sei =  se, data = F2F_CBT, 
            mods =~ intensity, 
            method = &quot;ML&quot;)</code></pre>
<pre><code>## Warning: Studies with NAs omitted from model fitting.</code></pre>
<pre class="r"><code>summary(MEM1)</code></pre>
<pre><code>## 
## Mixed-Effects Model (k = 61; tau^2 estimator: ML)
## 
##   logLik  deviance       AIC       BIC      AICc 
## -99.6787  375.9617  205.3574  211.6901  205.7785   
## 
## tau^2 (estimated amount of residual heterogeneity):     1.4485 (SE = 0.2686)
## tau (square root of estimated tau^2 value):             1.2035
## I^2 (residual heterogeneity / unaccounted variability): 99.91%
## H^2 (unaccounted variability / sampling variability):   1135.43
## R^2 (amount of heterogeneity accounted for):            3.05%
## 
## Test for Residual Heterogeneity:
## QE(df = 59) = 10944.1843, p-val &lt; .0001
## 
## Test of Moderators (coefficient 2):
## QM(df = 1) = 1.6842, p-val = 0.1944
## 
## Model Results:
## 
##            estimate      se      zval    pval    ci.lb    ci.ub 
## intrcpt     -2.1560  0.1560  -13.8172  &lt;.0001  -2.4618  -1.8501  *** 
## intensity   -0.0517  0.0398   -1.2978  0.1944  -0.1298   0.0264      
## 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>Uns wird eine “Warning” ausgegeben: <code>Warning: Studies with NAs omitted from model fitting.</code> Diese bedeutet, dass nicht alle Studien zu allen Moderatoren Angaben haben. Für jetzt ignorieren wir diesen Sachverhalt gekonnt.</p>
<p>Die <code>summary</code> wird um einen erklärten Varianzanteil</p>
<pre class="r"><code>cat(&quot;R^2 (amount of heterogeneity accounted for):            3.05%&quot;)</code></pre>
<pre><code>## R^2 (amount of heterogeneity accounted for):            3.05%</code></pre>
<p>sowie um einen Omnibustest der Moderatoren erweitert (quasi F-Test des gesamten Modells aus der Regression, nur das <span class="math inline">\(Q_M\)</span> hier <span class="math inline">\(\chi^2\)</span>-verteilt ist)</p>
<pre><code>## Test of Moderators (coefficient 2):
## QM(df = 1) = 1.6842, p-val = 0.1944</code></pre>
<p>Der Moderator scheint keinen signifikanten Heterogenitätsvarianzanteile zu erklären (<span class="math inline">\(Q_M(df=1)=\)</span> 1.68, <span class="math inline">\(p=\)</span>, 0.1944). Insgesamt werden nur <span class="math inline">\(3.05\%\)</span> Heterogenitätsvariation durch die Intensität erklärt. Unter</p>
<pre><code>## Model Results:</code></pre>
<p>findet sich ein Output, der einem Regressionsoutput sehr ähnlich sieht. <code>intrcpt</code> ist das Interzept und damit der durchschnittliche Effekt, wenn die <code>intensity</code> den Wert 0 annimmt. Der Effekt von <code>intensity</code> ist nicht statistisch bedeutsam. Wir nehmen zusätzlich die Moderatoren Psychoedukation (<code>psed</code>, Dummy-Variable, 0 = nein, 1 = ja), soziales Kompetenztraining (<code>soc</code>, Dummy-Variable, 0 = nein, 1 = ja), Verhaltensaktivierung (<code>ba</code>, Dummy-Variable, 0 = nein, 1 = ja) und Hausaufgaben (<code>home</code>, Dummy-Variable, 0 = nein, 1 = ja) in das Modell mit auf.</p>
<pre class="r"><code>MEM2 &lt;- rma(yi = diff, sei =  se, data = F2F_CBT, 
            mods =~ intensity + psed + soc + ba + home, 
            method = &quot;ML&quot;)</code></pre>
<pre><code>## Warning: Studies with NAs omitted from model fitting.</code></pre>
<pre class="r"><code>summary(MEM2)</code></pre>
<pre><code>## 
## Mixed-Effects Model (k = 61; tau^2 estimator: ML)
## 
##   logLik  deviance       AIC       BIC      AICc 
## -89.7698  356.1439  193.5397  208.3158  195.6529   
## 
## tau^2 (estimated amount of residual heterogeneity):     1.0327 (SE = 0.1931)
## tau (square root of estimated tau^2 value):             1.0162
## I^2 (residual heterogeneity / unaccounted variability): 99.75%
## H^2 (unaccounted variability / sampling variability):   407.62
## R^2 (amount of heterogeneity accounted for):            30.88%
## 
## Test for Residual Heterogeneity:
## QE(df = 55) = 7042.6184, p-val &lt; .0001
## 
## Test of Moderators (coefficients 2:6):
## QM(df = 5) = 25.6159, p-val = 0.0001
## 
## Model Results:
## 
##            estimate      se      zval    pval    ci.lb    ci.ub 
## intrcpt     -2.8435  0.2350  -12.0980  &lt;.0001  -3.3042  -2.3829  *** 
## intensity   -0.0879  0.0352   -2.5002  0.0124  -0.1568  -0.0190    * 
## psed         0.7806  0.2941    2.6543  0.0079   0.2042   1.3570   ** 
## soc          0.0341  0.3883    0.0878  0.9301  -0.7270   0.7952      
## ba           0.8994  0.3016    2.9823  0.0029   0.3083   1.4905   ** 
## home        -0.5052  0.3124   -1.6173  0.1058  -1.1174   0.1070      
## 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>Das Ergebnis sieht nun anders aus. Der Omnibustest zeigt an, dass die 5 Prädiktoren gemeinsam signifikante Varianzanteile erklären (<span class="math inline">\(Q_M(df=5)=\)</span> 25.62, <span class="math inline">\(p=\)</span>, 10^{-4}). Insgesamt können 30.88% der Heterogenitätsvariation durch die Prädiktoren erklärt werden. Der Effekt der Intensität ist nun bedeutsam (<span class="math inline">\(\beta_1=\)</span> -0.09, <span class="math inline">\(SE=\)</span> 0.04, <span class="math inline">\(p=\)</span> 0.0124). Auch die Psychoedukation (<span class="math inline">\(\beta_2=\)</span> 0.78, <span class="math inline">\(SE=\)</span> 0.29, <span class="math inline">\(p=\)</span> 0.0079) und Verhaltensaktivierung (<span class="math inline">\(\beta_4=\)</span> 0.9, <span class="math inline">\(SE=\)</span> 0.3, <span class="math inline">\(p=\)</span> 0.0029) trugen zu Unterschieden zwischen den Studien bei. Ob soziale Kompetenztrainings durchgeführt (<span class="math inline">\(\beta_3=\)</span> 0.03, <span class="math inline">\(SE=\)</span> 0.39, <span class="math inline">\(p=\)</span> 0.9301) oder ob Hausaufgaben aufgeben wurden (<span class="math inline">\(\beta_5=\)</span> -0.51, <span class="math inline">\(SE=\)</span> 0.31, <span class="math inline">\(p=\)</span> 0.1058), führte zu keiner Heterogenität zwischen Studien.</p>
<p>Der Effekt der Intensität erscheint plausibel. Je intensiver die Betreuung, desto besser das Ergebnis. Erstaunlich ist, dass Verhaltensaktivierung und Psychoedukation zu einer niedrigeren Verbesserung von Prä zu Post führte. Dies könnte (<em>Achtung Interpretation!</em>) allerdings daran liegen, dass Studien, die so ins Detail gehen, vielleicht grundsätzlich “sauberer” durchgeführt wurden, was zu ggf. kleineren Effekten geführt haben könnte.</p>
<p>Zwei Moderatormodelle lassen sich leicht mit der <code>anova</code>-Funktion inferenzstatistisch vergleichen: Wir führen wie folgt einen Likelihood-Ratio-Test durch</p>
<pre class="r"><code>anova(MEM1, MEM2, test = &quot;LRT&quot;)</code></pre>
<pre><code>## 
##         df      AIC      BIC     AICc   logLik     LRT   pval         QE  tau^2 
## Full     7 193.5397 208.3158 195.6529 -89.7698                 7042.6184 1.0327 
## Reduced  3 205.3574 211.6901 205.7785 -99.6787 19.8178 0.0005 10944.1843 1.4485 
##              R^2 
## Full 
## Reduced 28.7015%</code></pre>
<p>Der Modellvergleich ist statistisch bedeutsam (<span class="math inline">\(\Delta\chi^2(df=4)=\)</span> 19.82, <span class="math inline">\(p=\)</span> 0.0005). Somit passt das restriktivere Modell mit nur einem Prädiktor signifikant schlechter zu den Daten. Wir entscheiden uns für das Modell mit 5 Prädiktoren, welches insgesamt <span class="math inline">\(28.7015\%\)</span> mehr Heterogenitätsvariation erklärt als das Modell mit nur der Intensität als Moderator. Die Heterogenitätvarianz <span class="math inline">\(\tau^2\)</span> reduziert sich von <span class="math inline">\(1.44\)</span> auf <span class="math inline">\(1.03\)</span> durch Hinzunahme der vier Prädiktoren.</p>
<p>Mit Hilfe der <code>reporter</code>-Funktion lässt sich ein Mini-Report anfordern, der die Analyse beschreibt. Natürlich kann dieser nicht komplett übernommen werden, er hilft aber bei der Einordnung mancher Effekte. Außerdem können wir so prüfen, ob alles so ist, wie wir es erwarten würden.</p>
<pre class="r"><code>reporter(REM)</code></pre>
<p>Für MEM (Moderator-Analysen) ist diese Funktion leider noch nicht ausgebaut.</p>
<hr />
</div>
</div>
<div id="literatur" class="section level2">
<h2>Literatur</h2>
<p><a href="https://hds.hebis.de/ubffm/Record/HEB36808809X">Döring, N., &amp; Bortz, J. (2016)</a>. Meta-Analyse. In <em>Forschungsmethoden und Evaluation in den Sozial- und Humanwissenschaften</em> (pp. 893-943). Springer, Berlin, Heidelberg.</p>
<p><a href="https://hds.hebis.de/ubffm/EBSCO/Record?id=edsbas.37032030%7Cedsbas">López-López, J. A., Davies, S. R., Caldwell, D. M., Churchill, R., Peters, T. J., Tallon, D., Dawson, S., Wu, Q., Li, J., Taylor, A., Lewis, G., Kessler, D. S., Wiles, N., &amp; Welton, N. J. (2019).</a> The process and delivery of CBT for depression in adults: A systematic review and network meta-analysis. <em>Psychological Medicine, 49</em>(12), 1937–1947. <a href="https://doi.org/10.1017/S003329171900120X">https://doi.org/10.1017/S003329171900120X</a></p>
<p><a href="https://hds.hebis.de/ubffm/EBSCO/Record?id=edsbas.B90C267A%7Cedsbas">Viechtbauer, W. (2010).</a> Conducting meta-analyses in R with the metafor package. <em>Journal of Statistical Software</em>, <em>36</em>(3), 1–48. <a href="https://www.jstatsoft.org/v036/i03" class="uri">https://www.jstatsoft.org/v036/i03</a>.</p>
<ul>
<li><small> <em>Blau hinterlegte Autorenangaben führen Sie direkt zur universitätsinternen Ressource.</em></li>
</ul>
</div>
