---
title: "Partial- & Semipartialkorrelation"
date: '2021-04-22'
slug: partial
categories:
     - BSc7
tags:
- Partialkorrelation
- Semipartialkorrelation
- geteilte Varianz
- Zusammenhangsanalyse
subtitle: ''
summary: ''
authors: [schroeder, gruetzmacher, nehler]
lastmod: '2023-05-10 12:00:12 CEST'
featured: no
header:
     image: "/header/PsyBSc7_Partial.jpg"
     caption: "[Courtesy of pexels](https://www.pexels.com/photo/optical-glass-triangular-prism-3845162/)"
projects: []
---

```{r setup, include=FALSE, purl=FALSE}
options(knitr.duplicate.label = "allow") #Muss gesetzt werden, Setup-Chunk blockiert sonst Durchführung da er zeitweise doppelt existiert
options(knitr.purl.inline = FALSE) #Inline-Code wird hiermit entweder mit ins Skript übernommen (TRUE) oder ausgelassen (FALSE)
knitr::purl("2021-04-21-Partialkorrelation.Rmd", documentation = 0) #Legt fest das Purl nur die Chunkinhalte(0) in ein R-Skript umwandelt!; NAME DES RMD MUSS EINGESTELLT WERDEN!
file.rename("2021-04-21-Partialkorrelation.R","PsyBSc7_R_Files/03_partial.R") #NAME DER R-DATEI MUSS ANGEPASST WERDEN AN RMD-NAMEN!UNTERORDNER SOLLTE MIT KURS ÜBEREINSTIMMEN! (Siehe Ordner in /post)
```

```{r Info, purl=TRUE, echo=FALSE}
# ---- Partial- & Semipartialkorrelation ----
#Dieses Skript stammt von https://pandar.netlify.app/post/PsyBSc7_R_Files/03_partial.R, von der PandaR-Website der Goethe Universität Frankfurt.
#Die Autoren dieses Skripts sind Marvin Schröder, Luisa Grützmacher & Kai J. Nehler. Skriptkompilierung von Kevin Pommeranz.
```



## Einleitung

Sicher haben Sie in der Welt der Verschwörungstheorien mal gehört, dass die Anzahl der COVID-Erkrankungen mit der Anzahl der 5G-Tower zusammenhängt. Aber wussten Sie, dass auch der Konsum von Eiscreme und die Anzahl der Morde in New York oder die Anzahl von Nicolas-Cage-Filmauftritten mit der Anzahl weiblicher Redakteure beim Harvard Law Review positiv korreliert sind?^1^ 

Die Frage ist jedoch, ob mit den korrelativen Zusammenhängen der Beweis erbracht wurde, dass 5G-Strahlungen für COVID-Erkrankungen verantwortlich sind, der Eiskonsum zu einer erhöhten Mordrate führt oder die Anzahl der Filme, in denen Nicolas Cage mitspielt, einen Effekt auf die Frauenquote bei der Harvard Law Review hat. Die Antwort ist, wie Sie in Statistik I und Ihrer Einführung in die Versuchsplanung bereits wissen: **_Nein!_** 

Korrelationen liefern keine Belege für Kausalität. Zum einen gibt eine Korrelation keine Auskunft darüber, ob eine Variable *x* eine Variable *y* beeinflusst oder umgekehrt. Die meisten Korrelationsanalysen werden in der Psychologie für (relativ) gleichzeitig erhobene Konstrukte durchgeführt. Dies liegt besonders an der hohen Prävalenz von Fragebogenstudien. Den Einfluss des zeitlichen Aspekt auf die Kausalität werden wir jetzt nicht genauer betrachten, sondern eine andere notwendige Bedingung in Frage stellen. 

Der Zusammenhang zwischen zwei Variablen kann nämlich durch eine Drittvariable beeinflusst sein, was wir für Kausalität ausschließen müssten. So wird z.B. die Korrelation zwischen 5G-Towern mit den COVID-Erkrankungen durch die Ballungsgebiete erklärt, in denen die Leute enger beieinander leben. In dieser Sitzung beschäftigen wir uns daher mit der Partial- und der Semipartialkorrelation, d.h. Methoden mit denen der Einfluss einer oder mehrerer Drittvariablen kontrolliert werden kann, um hierdurch Scheinkorrelationen, redundante oder maskierte Zusammenhänge aufzudecken.



*Anmerkungen:*

^1^ Es gibt einen ganzen Blog, der sich mit solchen Scheinkorrelationen (bzw. [*spurious Correlations*](http://tylervigen.com/spurious-correlations)) befasst.


## Wiederholung Korrelationen
In der Psychologie werden häufig statistische Zusammenhänge (bzw. stochastische Abhängigkeiten)  zwischen Variablen ermittelt. Der statistische Zusammenhang kann mithilfe verschiedener Zusammenhangsmaße gemessen werden, z.B. mit der bivariaten Produkt-Moment-Korrelation, die die Beziehung zwischen zwei metrischen Variablen (bzw. einer metrischen und einer dichotomen Variable) berechnet.

$$r_{xy} = corr(X,Y) = \dfrac {\sum\limits_{i=1}^n (X_i - \bar{X})(Y_i - \bar{Y})}{\sqrt{\sum\limits_{i=1}^n (X_i - \bar{X})^2 \cdot \sum\limits_{i=1}^n (Y_i - \bar{Y})^2}}\hat{=}\frac{\mathbb{C}ov[X,Y]}{\sqrt{\mathbb{V}ar[X]\mathbb{V}ar[Y]}}$$

Der Korrelationskoeffizient r~xy~ misst die Stärke und Richtung einer linearen Beziehung zwischen zwei Variablen *x* und *y*. Der Wert von r~xy~ liegt dabei immer im Wertebereich zwischen +1 und -1. Man kann auch sagen, dass die Kovarianz "skaliert" wird, um diese besser  interpretieren zu können, deshalb steht in obiger Formel auch, $\mathbb{C}ov[X,Y]$ (Kovarianz zwischen $X$ und $Y$) geteilt durch das Produkt aus der Wurzel der Varianzen $\mathbb{V}ar[X]$ und $\mathbb{V}ar[Y]$. Eine Korrelation von 1 bedeutet ein perfekter positiver Zusammenhang, d.h. mit der Zunahme der eine Variablen, nimmt auch die anderen Variable zu und umgekehrt. Eine Korrelation von -1 bedeutet ein perfekter negativer Zusammenhang bei dem die Zunahme der einen Variablen mit der Abnahme der anderen Variablen einhergeht. Eine Korrelation von 0 hingegen bedeutet, dass es keinen Zusammenhang zwischen den Variablen gibt. Je höher der absolute Wert einer Korrelation zweier Variablen ist, desto mehr Varianz teilen die beiden Variablen miteinander.     

![](/post/VisualisierungderKorrelation.png){width="90%"}

Der Zusammenhang zwischen zwei Variablen *x* und *y* kann aber auch durch eine Drittvariable *z* beeinflusst werden. Methoden zur Kontrolle von Drittvariablen und zur Aufdeckung von Scheinkorrelationen, redundanten oder maskierten Zusammenhängen, sind die Partial- und Semipartialkorrelation.  

![](/post/Partial1.png){width="50%"}


## Partialkorrelation

Die Partialkorrelation ist die bivariate Korrelation zweier Variablen *x* und *y*, die bestehen würde, wenn zuvor der Einfluss einer weiteren Variable *z* statistisch kontrolliert (d.h. "auspartialisiert" oder "herausgerechnet") wird. Die Partialkorrelation r~xy.z~ kann gebildet werden als Korrelation der Regressionsresiduen von *x* bei Vorhersage durch *z* und *y* bei Vorhersage durch *z*. Denn dann bleibt jeweils der Anteil an *x* und *y* übrig, der nichts mit *z* zu tun hat.
![](/post/Partial2.png){width="50%"}


### Anwendungsbeispiel und Vorbereitung

Sie arbeiten an einer Schule und sind dafür zuständig, das Lernkonzept der Schule mit psychologischen Erkenntnissen zu unterstützen und zu verbessern. Die Schulleitung hat die erfahrungsbasierte Meinung, dass die Schüler:innen, die gut in Mathematik sind, auch gut in Lesetests abschneiden. Die Schulleitung möchte daher die Didaktik der beiden Fächer vereinen, um mehr von dieser Synergie zu profitieren. Sie als Psycholog:in vermuten jedoch, dass der Zusamenhang nur besteht, da Schüler:innen mit einem hohen IQ gut in beiden Bereichen sind. 

Um die Fragestellung zu klären, bevor ein neues Didaktikkonzept entwickelt werden muss, hat eine Stichprobe von 100 Schüler:innen einen Lesetest (`reading`, *x*), Mathematiktest (`math`, *y*) und allgemeinen Intelligenztest (`IQ`, *z*) beantwortet. Der resultierende Datensatz ist direkt von PandaR einlesbar. Mit `head()` schauen wir uns die obersten sechs Zeilen direkt an, um eine Übersicht zu erhalten. 

```{r include=TRUE}
#Daten abrufen
load(url("https://pandar.netlify.app/post/Schulleistungen.rda"))
head(Schulleistungen)
```

Wir sehen, dass in jeder Zeile eine Schülerin oder ein Schüler der aufgeführt ist. Neben den 3 schon beschriebenen Variablen wurde nur noch eine vierte erhoben: `female` als Angabe des Geschlechts (hier nur Männer und Frauen im Datensatz).

Zur Vorbereitung müssen wir außerdem noch `ggplot2` aktivieren, das wir im Verlauf des Tutorials benutzen werden.

```{r include=TRUE}
#Pakete laden
library(ggplot2)       # für Graphiken
```


Sie möchten in einem ersten Schritt wissen, ob die Leistung im Lesetest generell mit der Leistung im Mathematiktest zusammenhängt, um die erfahrungsbedingte Meinung der Schulleitung zu überprüfen

#### Korrelation zwischen Lese- und Mathematikleistung

Zur Berechnung und gleichzeitig inferenzstatistischen Absicherung einer einfachen bivariaten Korrelation, kann der `cor.test()`-Befehl genutzt werden, den wir im letzten Semester kennen gelernt haben. Um die reinen Zahlen noch zu unterstützen, zeichnen wir mit der Funktion `ggplot()` einen Scatterplot (`geom_point()`).

```{r}
# grafische Darstellung mittels Scatterplot
ggplot(Schulleistungen, aes(x=reading, y=math)) + 
  geom_point() + 
  labs(x= "Leseleistung", y= "Mathematikleistung")

# Korrelationstest
cor.test(Schulleistungen$reading, Schulleistungen$math)
```

Der Output zeigt einen Korrelationskoeffiziert von `r cor(Schulleistungen$reading, Schulleistungen$math)|>round(3)`, was bedeutet dass die beiden fachspezifischen Tests für Lesen und Mathematik positiv miteinander korrelieren. Der p-Wert beträgt `r cor.test(Schulleistungen$reading, Schulleistungen$math)$p.value|>round(3)|>format(nsmall=3)`. Der Zusammenhang, den die Schulleitung beobachtet hat, nehmen wir also mit einer Irrtumswahrscheinlichkeit von 5%  an. Schüler:innen, die gute Mathematikleistungen erbringen, zeigen eine bessere Leseleistung.

Nun heißt es näher zu betrachten, wie der IQ mit den einzelnen Leistungsbereichen zusammenhängt. 

#### Untersuchung zum Zusammenhang der allgemeinen Intelligenz zu der Lese- und Mathematikleistung

Als nächstes sollten wir uns eine Übersicht verschaffen, ob unsere Drittvariable, wie wir es annehmen, überhaupt einen Zusammenhang zu den beiden ursprünglichen variablen hat. Für einen ersten Eindruck berechnen wir den Zusammenhang der allgemeinen Intelligenz zu der Lese- und Mathematikleistung durch die Korrelation und sichern diese auch inferenzstatistisch ab.

```{r}
# Korrelation der Drittvariablen mit den beiden ursprünglichen Variablen
cor.test(Schulleistungen$IQ, Schulleistungen$reading)
cor.test(Schulleistungen$IQ, Schulleistungen$math)

```

Die Ergebnisse zeigen, dass die allgemeine Intelligenz sowohl mit der Lese-, als auch mit der Mathematikleistung signifikant zusammenhängt. Sie stellt daher eine mögliche konfundierende Drittvariable dar. Diese Vermutung können wir nun mit einer Partialkorrelation überprüfen, für die wir die Residuen brauchen.

Um die Residuen zu erhalten bestimmen wir die bivariate Regression zwischen der dritten Variable und der ursprünglichen beiden Variablen. Die Residuen repräsentieren den Teil der Variablen, der von der Drittvariable unabhängig ist. Das kann man also äquivalent dazu sehen, dass dieser Anteil von der Drittvariablen nicht erklärt werden kann (also dem Fehler in der Regression)

```{r}
# Regression 
reg_math_IQ <- lm(math ~ IQ, data = Schulleistungen)
reg_reading_IQ <- lm(reading ~ IQ, data = Schulleistungen)
```

```{r}
# Residuen in Objekt ablegen (Residuen x)
res_reading_IQ <- residuals(reg_reading_IQ)

# Residuen in Objekt ablegen (Residuen y)
res_math_IQ <- residuals(reg_math_IQ)
```

Wir haben die Residuen nun in Objekten abgelegt und können die Partialkorrelation bestimmen.

#### Partialkorrelation (Korrelation zwischen den Residuen)

Die bivariate Korrelation kann durch die Funktion `cor()` bestimmt werden. Als Argumente brauchen wir die beiden Objekte mit den Residuen. Beachten Sie, dass wir hier NICHT `cor.test()` verwenden, da die inferenzstatistische Absicherung die falschen Freiheitsgrade nutzen würde. Für interessierte Lesende findet sich [hier](#AppendixA) eine genauere Erläuterung der Problematik.

```{r}
# Partialkorrelation durch Residuen
cor(res_reading_IQ, res_math_IQ)
```

Es zeigt sich also, dass der ursprüngliche Zusammenhang zwischen der Lese- und Mathematikleistung (*r~xy~*= `r cor(Schulleistungen$reading, Schulleistungen$math)|>round(2)`) unter Kontrolle der allgemeinen Intelligenz verschwindet. 

#### Paket-Nutzung

Neben diesem Umweg über die Bestimmung der Residuen, die uns die Logik der Partialkorrelation nochmal näher bringen sollte, gibt es natürlich auch eine Funktion zur direkten Bestimmung. Diese ist aber nicht in den Basis-Paketen erhalten, weshalb wir erstmal `ppcor` installieren müssen. 

```{r, eval = F}
# Paket für Partial- und Semipartialkorrelation
install.packages("ppcor")
```

Anschließends muss das Paket natürlich noch aktiviert werden.

```{r}
library(ppcor)
```

Mit der Funktion `pcor.test()` lässt sich die Partialkorrelation direkt ermitteln:

```{r}
# Partialkorrelation mit Funktion

pcor.test(x=Schulleistungen$reading, y=Schulleistungen$math, z=Schulleistungen$IQ)
```
Die Partialkorrelation (r~xy.z~) beträgt `r cor(res_reading_IQ, res_math_IQ)|> round(2)` und ist nicht signifikant von 0 verschieden (p= `r pcor.test(x=Schulleistungen$reading, y=Schulleistungen$math, z=Schulleistungen$IQ)$p.value |> round(2)`). Es zeigt sich also, dass der ursprüngliche Zusammenhang zwischen der Lese- und Mathematikleistung (*r~xy~*=`r cor(Schulleistungen$reading, Schulleistungen$math)|> round(2)`) unter Kontrolle der allgemeinen Intelligenz verschwindet. Es handelt sich also um eine Scheinkorrelation.
    
### Mögliche Veränderung der ursprünglichen Korrelation bei Bestimmung der Partialkorrelation

Wird eine Partialkorrelation berechnet, kann die ursprüngliche Korrelation sich auf drei Arten verhalten:

1. Partialkorrelation ist kleiner als die ursprüngliche Korrelation

Wie in unserem Bespiel teilen alle drei Variablen miteinander Varianz. Partialisiert man nun eine Variable aus dem Zusammenhang der beiden anderen Variablen heraus, wird die geteilte Varianz weniger, womit die Korrelation sinkt. Dieser Fall ist der am häufigsten eintretende, da in der Forschung oft Variablen auspartialisiert werden, weil es theoretische Annahme gibt, warum die Variablen Varianz teilen sollten, man aber einen isolierten Effekt von *x* auf *y* betrachten möchte. Der im Tutorial dargestellte Effekt ist die extremste Form der Veränderung, bei der die Partialkorrelation dann fast bei 0 liegt.

2. Partialkorrelation ist gleich der ursprünglichen Korrelation

Ist die Partialkorrelation r~xy.z~ genauso groß (nicht signifikant unterschiedlich) wie die Ausgangskorrelation r~xy~, ist *z* mit *x* und *y* unkorreliert. Die Drittvariable *z* würde also keinen Zusammenhang und damit keine geteilte Varianz mit *x* und *y* haben.


3. Partialkorrelation ist größer als die ursprüngliche Korrelation

In einem solchen Fall liegt meist ein Suppressoreffekt vor (ein Teil der Varianz in *x* wird durch die Drittvariable unterdrückt bzw. supprimiert, der für den Zusammenhang mit *y* irrelevant ist). Der klassische Suppressoreffekt tritt dann auf, wenn *z* mit *y* zu 0 korreliert (was nicht immer der Fall sein muss), mit *x* aber eine bedeutende Korrelation aufweist (Sonderformen eines Suppressoreffekts finden Interessierte in Eid & Gollwitzer 2017, Kap.18,19). In solch einem Fall wird der für *y* irrelevante Varianzanteil in *x* durch den Supressor *z* gebunden, wodurch der relative Anteil an geteilter Varianz zwischen *x* und *y* größer wird. Ein Beispiel: Sie untersuchen den Zusammenhang von Sport (x), Kalorienzufuhr(z) und Gewichtsverlust (y). Sporttreiben korreliert positiv mit Gewichtsverlust und Kalorienzufuhr, Kalorienzufuhr aber nicht mit Gewichtsverlust. In einer Partialkorrelation wird die Korrelation von Sporttreiben mit Gewichtsverlust unter der Kontrolle von Kalorienzufuhr größer. Sie können daraus schließen, dass die Kalorienzuführ in diesem Beispiel als Suppressor agiert. Die Inhaltliche Begründung dafür wäre, dass mit einer erhöhten sportlichen Aktivität eine erhöhte Kalorienzufuhr einhergeht. Dieser Zusammenhang hat den positiven Effekt von Sport supprimiert. 

## Semipartialkorrelation

Wird aus inhaltlichen Gründen angenommen, dass die Drittvariable nur eine der Variablen *x* oder *y* beeinflusst, kann auf eine weitere Methode zur Aufdeckung von Scheinkorrelationen, redundanten oder maskierten Zusammenhängen zurückgegriffen werden; die Semipartialkorrelation. Bei dieser Methode wird der Einfluss der Drittvariablen nur aus einer der beiden Variablen herausgerechnet. Die Semipartialkorrelation r~x(y.z)~ entspricht der Korrelation zwischen x und dem Residuum von y bei Vorhersage durch z.

![](/post/Partial3.png){width="50%"}


```{r}
# Semipartialkorrelation durch Nutzung des Residuums
cor(Schulleistungen$reading, res_math_IQ)

```

Auch hier verwenden wir absichtlich die Funktion `cor()` statt `cor.test()`, da die inferenzstatistische Absicherung nicht korrekt durchgeführt werden würde aufgrund der Freiheitsgrade. 

Mit der Funktion `spcor.test()` aus dem zuvor installierten Paket `ppcor` lässt sich die Semipartialkorrelation direkt ermitteln und die inferenzstatistische Absicherung gelingt.

```{r}
# Semipartialkorrelation mit Funktion
spcor.test(x=Schulleistungen$reading, y=Schulleistungen$math, z=Schulleistungen$IQ)

```

Der Koeffizient der Semipartialkorrelation (r~x(y.z)~) beträgt `r spcor.test(x=Schulleistungen$reading, y=Schulleistungen$math, z=Schulleistungen$IQ)$estimate |> round(2)` und ist nicht signifikant (p=`r spcor.test(x=Schulleistungen$reading, y=Schulleistungen$math, z=Schulleistungen$IQ)$estimate |> round()`). Es zeigt sich also, dass der ursprüngliche Zusammenhang zwische Lese- und Mathematikleistung (*r~xy~*= `r cor(Schulleistungen$reading, Schulleistungen$math) |> round()`) verschwindet, wenn der Einfluss der allgemeinen Intelligenz auf die Mathematikleistung kontrolliert wird.

## Wann wähle ich die Partial- und wann die Semipartialkorrelation?

Ob Sie in Ihren Untersuchungen die Partial- oder Semipartialkorrelation zur Kontrolle von Drittvariablen verwenden, begründet sich primär in theoretischen Annahmen. Bei der Partialkorrelation nehmen Sie an, dass die Drittvariable *z* beide Variablen *x* und *y* ursächlich beeinflusst. In unserem Beispiel stellen wir uns den IQ als Ursache für die Leistungen in Mathematik und Lesen vor, daher wäre eine Partialkorrelation angebracht. 
Die Semipartialkorrelation ist dann das Mittel der Wahl, wenn die Drittvariable nur eine der beiden Variablen *x* oder *y* theoretisch kausal bedingt und zwischen den anderen Variablen lediglich ein ungerichteter Zusammenhang angenommen wird. In unserem Beispiel würde dies bedeuten, dass wir beispielsweise lediglich annehmen, dass der IQ die Matehmatikleistung bedingt, jedoch nicht die Leseleitung. Eine mögliche Begründung könnte sein, dass Mathematik stark von der abstrakten Vorstellungkraft profitiert, die im IQ abgebildet ist, die Leseleistung hingegen eine Fertigkeit ist, die vorallem erlernt wird. Da diese Annahme schwer empirisch zu stützen ist, eignet sich die Semipartialkorrelation in unserem Beispiel weniger als die Partialkorrelaton.



# Zusammenfassung

Wir haben in dem Tutorial die Partial- und Semipartialkorrelation als Erweiterungen der Korrelation kennengelernt. Die Zusammenhänge zwischen den drei Größen soll der folgende Plot nochmal zusammenfassen.

![](/post/Partial4.png){width="90%"}
***

## Appendix A {#AppendixA .anchorhead}

<details><summary>**Inferenzstatistik der Partialkorrelation**</summary>
**WORK IN PROGRESS**
```{r, purl=FALSE}
# Partial
```
</details>


***

## R-Skript
Den gesamten `R`-Code, der in dieser Sitzung genutzt wird, können Sie [`r fontawesome::fa("download")`hier herunterladen](/post/PsyBSc7_R_Files/03_partial.R).

