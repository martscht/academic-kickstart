---
title: "Partial- & Semipartialkorrelation"
date: '2021-04-22'
slug: partial
categories:
     - BSc7
tags:
- Partialkorrelation
- Semipartialkorrelation
- geteilte Varianz
- Zusammenhangsanalyse
subtitle: ''
summary: ''
authors: [schroeder, gruetzmacher, nehler]
lastmod: '2023-04-25 12:00:12 CEST'
featured: no
header:
     image: "/header/PsyBSc7_Partial.jpg"
     caption: "[Courtesy of pexels](https://www.pexels.com/photo/optical-glass-triangular-prism-3845162/)"
projects: []
---

```{r setup, include=FALSE, purl=FALSE}
options(knitr.duplicate.label = "allow") #Muss gesetzt werden, Setup-Chunk blockiert sonst Durchführung da er zeitweise doppelt existiert
options(knitr.purl.inline = FALSE) #Inline-Code wird hiermit entweder mit ins Skript übernommen (TRUE) oder ausgelassen (FALSE)
knitr::purl("2021-04-21-Partialkorrelation.Rmd", documentation = 0) #Legt fest das Purl nur die Chunkinhalte(0) in ein R-Skript umwandelt!; NAME DES RMD MUSS EINGESTELLT WERDEN!
file.rename("2021-04-21-Partialkorrelation.R","PsyBSc7_R_Files/03_partial.R") #NAME DER R-DATEI MUSS ANGEPASST WERDEN AN RMD-NAMEN!UNTERORDNER SOLLTE MIT KURS ÜBEREINSTIMMEN! (Siehe Ordner in /post)
```

```{r Info, purl=TRUE, echo=FALSE}
# ---- Partial- & Semipartialkorrelation ----
#Dieses Skript stammt von https://pandar.netlify.app/post/PsyBsc7_R_Files/03_partial.R, von der PandaR-Website der Goethe Universität Frankfurt.
#Die Autoren dieses Skripts sind Marvin Schröder, Luisa Grützmacher & Kai J. Nehler. Skriptkompilierung von Kevin Pommeranz.
```



## Einleitung

Sicher haben Sie in der Welt der Verschwörungstheorien mal gehört, dass die Anzahl der COVID-Erkrankungen mit der Anzahl der 5G-Tower zusammenhängt. Aber wussten Sie, dass auch der Konsum von Eiscreme und die Anzahl der Morde in New York oder die Anzahl von Nicolas-Cage-Filmauftritten mit der Anzahl weiblicher Redakteure beim Harvard Law Review positiv korreliert sind?^1^ 

Die Frage ist jedoch, ob mit den korrelativen Zusammenhängen der Beweis erbracht wurde, dass 5G-Strahlungen für COVID-Erkrankungen verantwortlich sind, der Eiskonsum zu einer erhöhten Mordrate führt oder die Anzahl der Filme, in denen Nicolas Cage mitspielt, einen Effekt auf die Frauenquote bei der Harvard Law Review hat. Die Antwort ist, wie Sie in Statistik I und Ihrer Einführung in die Versuchsplanung bereits wissen: **_Nein!_** 

Korrelationen liefern keine Belege für Kausalität. Zum einen gibt eine Korrelation keine Auskunft darüber, ob eine Variable *x* eine Variable *y* beeinflusst oder umgekehrt. Die meisten Korrelationsanalysen werden in der Psychologie für (relativ) gleichzeitig erhobene Konstrukte durchgeführt. Dies liegt besonders an der hohen Prävalenz von Fragebogenstudien. Den Einfluss des zeitlichen Aspekt auf die Kausalität werden wir jetzt nicht genauer betrachten, sondern eine andere notwendige Bedingung in Frage stellen. 

Der Zusammenhang zwischen zwei Variablen kann nämlich durch eine Drittvariable beeinflusst sein, was wir für Kausalität ausschließen müssten. So wird z.B. die Korrelation zwischen 5G-Towern mit den COVID-Erkrankungen durch die Ballungsgebiete erklärt, in denen die Leute enger beieinander leben. In dieser Sitzung beschäftigen wir uns daher mit der Partial- und der Semipartialkorrelation, d.h. Methoden mit denen der Einfluss einer oder mehrerer Drittvariablen kontrolliert werden kann, um hierdurch Scheinkorrelationen, redundante oder maskierte Zusammenhänge aufzudecken.



*Anmerkungen:*

^1^ Es gibt einen ganzen Blog, der sich mit solchen Scheinkorrelationen (bzw. [*spurious Correlations*](http://tylervigen.com/spurious-correlations)) befasst.


## Wiederholung Korrelationen
In der Psychologie werden häufig statistische Zusammenhänge (bzw. stochastische Abhängigkeiten)  zwischen Variablen ermittelt. Der statistische Zusammenhang kann mithilfe verschiedener Zusammenhangsmaße gemessen werden, z.B. mit der bivariaten Produkt-Moment-Korrelation, die die Beziehung zwischen zwei metrischen Variablen (bzw. einer metrischen und einer dichotomen Variable) berechnet.

$$r_{xy} = corr(X,Y) = \dfrac {\sum\limits_{i=1}^n (X_i - \bar{X})(Y_i - \bar{Y})}{\sqrt{\sum\limits_{i=1}^n (X_i - \bar{X})^2 \cdot \sum\limits_{i=1}^n (Y_i - \bar{Y})^2}}\hat{=}\frac{\mathbb{C}ov[X,Y]}{\sqrt{\mathbb{V}ar[X]\mathbb{V}ar[Y]}}$$

Der Korrelationskoeffizient r~xy~ misst die Stärke und Richtung einer linearen Beziehung zwischen zwei Variablen *x* und *y*. Der Wert von r~xy~ liegt dabei immer im Wertebereich zwischen +1 und -1. Man kann auch sagen, dass die Kovarianz "skaliert" wird, um diese besser  interpretieren zu können, deshalb steht in obiger Formel auch, $\mathbb{C}ov[X,Y]$ (Kovarianz zwischen $X$ und $Y$) geteilt durch das Produkt aus der Wurzel der Varianzen $\mathbb{V}ar[X]$ und $\mathbb{V}ar[Y]$. Eine Korrelation von 1 bedeutet ein perfekter positiver Zusammenhang, d.h. mit der Zunahme der eine Variablen, nimmt auch die anderen Variable zu und umgekehrt. Eine Korrelation von -1 bedeutet ein perfekter negativer Zusammenhang bei dem die Zunahme der einen Variablen mit der Abnahme der anderen Variablen einhergeht. Eine Korrelation von 0 hingegen bedeutet, dass es keinen Zusammenhang zwischen den Variablen gibt. Je höher der absolute Wert einer Korrelation zweier Variablen ist, desto mehr Varianz teilen die beiden Variablen miteinander.     

![](/post/VisualisierungderKorrelation.png){width="90%"}

Der Zusammenhang zwischen zwei Variablen *x* und *y* kann aber auch durch eine Drittvariable *z* beeinflusst werden. Methoden zur Kontrolle von Drittvariablen und zur Aufdeckung von Scheinkorrelationen, redundanten oder maskierten Zusammenhängen, sind die Partial- und Semipartialkorrelation.  

![](/post/Partial1.png){width="50%"}


## Partialkorrelation

Die Partialkorrelation ist die bivariate Korrelation zweier Variablen *x* und *y*, die bestehen würde, wenn zuvor der Einfluss einer weiteren Variable *z* statistisch kontrolliert (d.h. "auspartialisiert" oder "herausgerechnet") wird. Die Partialkorrelation r~xy.z~ kann gebildet werden als Korrelation der Regressionsresiduen von *x* bei Vorhersage durch *z* und *y* bei Vorhersage durch *z*.  
![](/post/Partial2.png){width="50%"}


## Anwendungsbeispiel und Vorbereitung

Sie arbeiten an einer Schule und sind dafür zuständig, das Lernkonzept der Schule mit psychologischen Erkenntnissen zu unterstützen und zu verbessern. Die Schulleitung hat die erfahrungsbasierte Meinung, dass die Schüler:innen, die gut in Mathematik sind, auch gut in Lesetests abschneiden. Die Schulleitung möchte daher die Didaktik der beiden Fächer vereinen, um mehr von dieser Synergie zu profitieren. Sie als Psycholog:in vermuten jedoch, dass der Zusamenhang nur besteht, da Schüler:innen mit einem hohen IQ gut in beiden Bereichen sind. 

Um die Fragestellung zu klären, bevor ein neues Didaktikkonzept entwickelt werden muss, hat eine Stichprobe von 100 Schüler:innen einen Lesetest (`reading`, *x*), Mathematiktest (`math`, *y*) und allgemeinen Intelligenztest (`IQ`, *z*) beantwortet. Der resultierende Datensatz ist direkt von PandaR einlesbar. Mit `head()` schauen wir uns die obersten sechs Zeilen direkt an, um eine Übersicht zu erhalten. 

```{r include=TRUE}
#Daten abrufen
load(url("https://pandar.netlify.app/post/Schulleistungen.rda"))
head(Schulleistungen)
```

Wir sehen, dass in jeder Zeile eine Schülerin oder ein Schüler der aufgeführt ist. Neben den 3 schon beschriebenen Variablen wurde nur noch eine vierte erhoben: `female` als Angabe des Geschlechts (hier nur Männer und Frauen im Datensatz).

Zur Vorbereitung müssen wir außerdem noch `ggplot2` aktivieren, das wir im Verlauf des Tutorials benutzen werden.

```{r include=TRUE}
#Pakete laden
library(ggplot2)       # für Graphiken
```


Sie möchten in einem ersten Schritt wissen, ob die Leistung im Lesetest generell mit der Leistung im Mathematiktest zusammenhängt, um die erfahrungsbedingte Meinung der Schulleitung zu überprüfen

**1) Korrelation zwischen Lese- und Mathematikleistung**

Zur Berechnung einer einfachen bivariaten Korrelation, nutzen Sie den `cor.test()`-Befehl, den wir im letzten Semester kennen gelernt haben. Um die reinen Zahlen noch zu unterstützen, zeichnen wir mit der Funktion `ggplot()` einen Scatterplot (`geom_point()`).

```{r}
# grafische Darstellung mittels Scatterplot
ggplot(Schulleistungen, aes(x=reading, y=math)) + 
  geom_point() + 
  labs(x= "Leseleistung", y= "Mathematikleistung")

# Korrelationstest
cor.test(Schulleistungen$reading, Schulleistungen$math)

```

**Interpretation der Ergebnisse:**

* der Korrelationskoeffiziert von  `r cor(Schulleistungen$reading, Schulleistungen$math)|>round(3)` zeigt, dass die
  beiden fachspezifischen Tests für Lesen und Mathematik
  positiv miteinander korrelieren
* der p-Wert beträgt `r cor.test(Schulleistungen$reading, Schulleistungen$math)$p.value|>round(3)|>format(nsmall=3)`, ist also kleiner als .05 und zeigt somit, dass die
  Korrelation signifikant ist
  + bzw. die formal korrekte Interpretation: Der p-Wert ist  $<.000$, ist also kleiner als
    .05 , und somit signifikant auf einem Alpha-Fehlerniveau von 5 %. Damit wird die Nullhypothese, dass es keine Beziehung zwischen den beiden Variablen in der Population gibt, auf dem Signifikanzniveau von 5% verworfen.
* Der Zusammenhang, den die Schulleitung beobachtet hat, existiert tatsächlich (mit einer Irrtumswahrscheinlichkeit von 5%). Schüler:innen, die gute Mathematikleistungen erbringen, zeigen ebenfalls eine bessere Leseleistung.

Nun heißt es näher zu betrachten, wie der IQ mit den einzelnen Leistungsbereichen zusammenhängt. Dazu nutzen wir die Regression (siehe nächstes Pandar Kapitel), da wir so ebenfalls die Residuen abspeichern können, die wir für die Berechnung der Partialkorrelation benötigen.

**2) Regression zur Vorhersage von                                                               (a) der Leseleistung durch die allgemeine Intelligenz und                                   (b) der Mathematikleistung durch die allgemeine Intelligenz**

```{r}
# Regression Leseleistung durch allgemeine Intelligenz
reg.reading.IQ <- lm(reading ~ IQ, data = Schulleistungen)
summary(reg.reading.IQ)

# Residuen in Objekt ablegen (Residuen x)
res.reading.IQ <- reg.reading.IQ$residuals
```

```{r}
# Regression Mathematikleistung durch allgemeine Intelligenz
reg.math.IQ <- lm(math ~ IQ, data = Schulleistungen)
summary(reg.math.IQ)

# Residuen in Objekt ablegen (Residuen y)
res.math.IQ <- reg.math.IQ$residuals
```

**Interpretation der Ergebnisse:**

* Regression zur Vorhersage der Leseleistung (Rechnung 2a) durch die allgemeine Intelligenz:
  + der Steigungsparameter (β~1~) beträgt `r coef(reg.reading.IQ)[2] |> round(2)`, demzufolge steigt pro IQ-Punkt die
    Leseleistung um ca. `r coef(reg.reading.IQ)[2] |> round(2)` Punkte  
* Regression zur Vorhersage der Mathematikleistung (Rechnung 2b) durch die allgemeine Intelligenz:
  + der Steigungsparameter (β~1~) beträgt `r coef(reg.math.IQ)[2] |> round(2)`, demzufolge steigt pro IQ-Punkt die
    Mathematikleistung um ca. `r coef(reg.math.IQ)[2] |> round(2)` Punkte

--> die allgemeine Intelligenz hat demzufolge einen Effekt auf die Lese- und
   Mathematikleistung und stellt daher eine mögliche konfundierende Drittvariable dar. Diese Vermutung können wir nun mit einer Partialkorrelation überprüfen.


**3) Partialkorrelation (Korrelation zwischen den Residuen)**

```{r}
# Partialkorrelation durch Residuen
cor.test(res.reading.IQ, res.math.IQ)

```


Neben diesem Umweg über die Bestimmung der Residuen, die uns die Logik der Partialkorrelation nochmal näher bringen sollte, gibt es natürlich auch eine Funktion zur direkten Bestimmung. Diese ist aber nicht in den Basis-Paketen erhalten, weshalb wir erstmal `ppcor` installieren müssen. 

```{r, eval = F}
# Paket für Partial- und Semipartialkorrelation
install.packages("ppcor")
```

Anschließends muss das Paket natürlich noch aktiviert werden.

```{r}
library(ppcor)
```

Mit der Funktion `pcor.test()` lässt sich die Partialkorrelation direkt ermitteln:

```{r}
# Partialkorrelation mit Funktion

pcor.test(x=Schulleistungen$reading, y=Schulleistungen$math, z=Schulleistungen$IQ)
```

**Interpretation der Ergebnisse:**

* Partialkorrelation:
  + der Korrelationskoeffizient (r~xy.z~) beträgt `r cor(res.reading.IQ, res.math.IQ)|> round(2)`, ist jedoch nicht
    signifikant (p= `r cor.test(res.reading.IQ, res.math.IQ)$p.value |> round(2)`)
  + es zeigt sich also, dass der ursprüngliche Zusammenhang zwischen der Lese-
    und Mathematikleistung (*r~xy~*=.37) unter Kontrolle der allgemeinen Intelligenz verschwindet. Es handelt sich also um eine Scheinkorrelation.
    
**Auswirkungen auf die ursprüngliche Korrelation**

Wird eine Partialkorrelation berechnet, kann die ursprüngliche Korrelation sich auf drei Arten verhalten:

1. Sie wird kleiner

Wie in unserem Bespiel teilen alle drei Variablen miteinander Varianz. Partialisiert man nun eine Variable aus dem Zusammenhang der beiden anderen Variablen heraus, wird die geteilte Varianz weniger, womit die Korrelation sinkt. Dieser Fall ist der am häufigsten eintretende, da in der Forschung oft Variablen auspartialisiert werden, weil es theoretische Annahme gibt, warum die Variablen Varianz teilen sollten, man aber einen isolierten Effekt von *x* auf *y* betrachten möchte.

2. Sie bleibt gleich

Ist die Partialkorrelation r~xy.z~ genauso groß (nicht signifikant unterschiedlich) wie die Ausgangskorrelation r~xy~, ist *z* mit *x* und *y* unkorreliert. Die Drittvariable *z* würde also keinen Zusammenhang und damit keine geteilte Varianz mit *x* und *y* haben.


3. Sie wird größer

In einem solchen Fall liegt meist ein Suppressoreffekt vor (ein Teil der Varianz in *x* wird durch die Drittvariable unterdrückt bzw. supprimiert, der für den Zusammenhang mit *y* irrelevant ist). Der klassische Suppressoreffekt tritt dann auf, wenn *z* mit *y* zu 0 korreliert (was nicht immer der Fall sein muss), mit *x* aber eine bedeutende Korrelation aufweist (Sonderformen eines Suppressoreffekts finden Interessierte in Eid & Gollwitzer 2017, Kap.18,19). In solch einem Fall wird der für *y* irrelevante Varianzanteil in *x* durch den Supressor *z* gebunden, wodurch der relative Anteil an geteilter Varianz zwischen *x* und *y* größer wird. Ein Beispiel: Sie untersuchen den Zusammenhang von Sport (x), Kalorienzufuhr(z) und Gewichtsverlust (y). Sporttreiben korreliert positiv mit Gewichtsverlust und Kalorienzufuhr, Kalorienzufuhr aber nicht mit Gewichtsverlust. In einer Partialkorrelation wird die Korrelation von Sporttreiben mit Gewichtsverlust unter der Kontrolle von Kalorienzufuhr größer. Sie können daraus schließen, dass die Kalorienzuführ in diesem Beispiel als Suppressor agiert. Die Inhaltliche Begründung dafür wäre, dass mit einer erhöhten sportlichen Aktivität eine erhöhte Kalorienzufuhr einhergeht. Dieser Zusammenhang hat den positiven Effekt von Sport supprimiert. 

## Semipartialkorrelation

Wird aus inhaltlichen Gründen angenommen, dass die Drittvariable nur eine der Variablen *x* oder *y* beeinflusst, kann auf eine weitere Methode zur Aufdeckung von Scheinkorrelationen, redundanten oder maskierten Zusammenhängen zurückgegriffen werden; die Semipartialkorrelation. Bei dieser Methode wird der Einfluss der Drittvariablen nur aus einer der beiden Variablen herausgerechnet. Die Semipartialkorrelation r~x(y.z)~ entspricht der Korrelation zwischen x und dem Residuum von y bei Vorhersage durch z.

![](/post/Partial3.png){width="50%"}


```{r}
# Semipartialkorrelation durch Nutzung des Residuums
cor.test(Schulleistungen$reading, res.math.IQ)

```

Mit der Funktion `spcor.test()` lässt sich die Semipartialkorrelation direkt ermitteln:

```{r}
# Semipartialkorrelation mit Funktion
spcor.test(x=Schulleistungen$reading, y=Schulleistungen$math, z=Schulleistungen$IQ)

```

**Interpretation der Ergebnisse:**

* der Korrelationskoeffizient (r~x(y.z)~) beträgt -.031 ist jedoch nicht
  signifikant (p=.762)
* es zeigt sich also, dass der ursprüngliche Zusammenhang zwische Lese- und
  Mathematikleistung (*r~xy~*= .37) verschwindet, wenn der Einfluss der
  allgemeinen Intelligenz auf die Mathematikleistung kontrolliert wird
* Auch hier wird die Scheinkorrelation ersichtlich

**Wann wähle ich die Partial- und wann die Semipartialkorrelation**

Ob Sie in Ihren Untersuchungen die Partial- oder Semipartialkorrelation zur Kontrolle von Drittvariablen verwenden, begründet sich primär in theoretischen Annahmen. Bei der Partialkorrelation nehmen Sie an, dass die Drittvariable *z* beide Variablen *x* und *y* ursächlich beeinflusst. In unserem Beispiel stellen wir uns den IQ als Ursache für die Leistungen in Mathematik und Lesen vor, daher wäre eine Partialkorrelation angebracht. 
Die Semipartialkorrelation ist dann das Mittel der Wahl, wenn die Drittvariable nur eine der beiden Variablen *x* oder *y* theoretisch kausal bedingt und zwischen den anderen Variablen lediglich ein ungerichteter Zusammenhang angenommen wird. In unserem Beispiel würde dies bedeuten, dass wir beispielsweise lediglich annehmen, dass der IQ die Matehmatikleistung bedingt, jedoch nicht die Leseleitung. Eine mögliche Begründung könnte sein, dass Mathematik stark von der abstrakten Vorstellungkraft profitiert, die im IQ abgebildet ist, die Leseleistung hingegen eine Fertigkeit ist, die vorallem erlernt wird. Da diese Annahme schwer empirisch zu stützen ist, eignet sich die Semipartialkorrelation in unserem Beispiel weniger als die Partialkorrelaton.



## Zusammenfassung

Wir haben in dem Tutorial die Partial- und Semipartialkorrelation als Erweiterungen der Korrelation kennengelernt. Die Zusammenhänge zwischen den drei Größen soll der folgende Plot nochmal zusammenfassen.

![](/post/Partial4.png){width="90%"}

***

## R-Skript
Den gesamten `R`-Code, der in dieser Sitzung genutzt wird, können Sie [`r fontawesome::fa("download")`hier herunterladen](/post/PsyBSc7_R_Files/03_partial.R).

