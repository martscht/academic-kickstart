---
title: Modelle für Gruppenvergleiche 
author: ''
date: '2021-04-13'
slug: msa
categories: 
  - MSc1
tags: 
  - lavaan
  - SEM
  - MSA
  - Invarianztestung
  - Strukturgleichungsmodelle
  - Regression
subtitle: 'Multi Sample Analysis'
summary: ''
authors: [irmer, schultze]
lastmod: '2021-05-25T10:30:02+02:00'
featured: no
header:
  image: "/header/FEII_MSA.jpg"
  caption: "[Courtesy of pxhere](https://pxhere.com/en/photo/644378)"
---



<p>In einer Multi-Sample-Analysis wird in mehreren Gruppen gleichzeitig ein Strukturgleichungsmodell geschätzt. Wir könnten uns bspw. fragen, ob die gleichen Beziehungen zwischen Zeitdruck, Emotionaler Erschöpfung und psychosomatischen Beschwerden, wie wir sie in der letzten Sitzung zu <a href="/post/sem">SEM</a> beobachtet haben, gleichermaßen für Männer und Frauen gelten. Im Datensatz <code>StressAtWork</code> der <a href="/post/sem">SEM</a> Sitzung ist die Variable <code>sex</code> enthalten. Hier sind Frauen mit <code>1</code> und Männer mit <code>2</code> kodiert. Wir können diesen wie gewohnt laden:
Sie können den im Folgenden verwendeten <a href="https://pandar.netlify.app/post/StressAtWork.rda"><svg style="height:0.8em;top:.04em;position:relative;" viewBox="0 0 512 512"><path d="M216 0h80c13.3 0 24 10.7 24 24v168h87.7c17.8 0 26.7 21.5 14.1 34.1L269.7 378.3c-7.5 7.5-19.8 7.5-27.3 0L90.1 226.1c-12.6-12.6-3.7-34.1 14.1-34.1H192V24c0-13.3 10.7-24 24-24zm296 376v112c0 13.3-10.7 24-24 24H24c-13.3 0-24-10.7-24-24V376c0-13.3 10.7-24 24-24h146.7l49 49c20.1 20.1 52.5 20.1 72.6 0l49-49H488c13.3 0 24 10.7 24 24zm-124 88c0-11-9-20-20-20s-20 9-20 20 9 20 20 20 20-9 20-20zm64 0c0-11-9-20-20-20s-20 9-20 20 9 20 20 20 20-9 20-20z"/></svg> Datensatz “StressAtWork.rda” hier herunterladen</a>.</p>
<p>Wir laden zunächst die Daten: entweder lokal von Ihrem Rechner:</p>
<pre class="r"><code>load(&quot;C:/Users/Musterfrau/Desktop/StressAtWork.rda&quot;)</code></pre>
<p>oder wir laden sie direkt über die Website:</p>
<pre class="r"><code>load(url(&quot;https://pandar.netlify.app/post/StressAtWork.rda&quot;))</code></pre>
<p>Als Paket brauchen wir erneut <code>lavaan</code> und <code>semPlot</code>:</p>
<pre class="r"><code>library(lavaan)
library(semPlot)</code></pre>
<p>Wir verwenden das gleiche Modell wie in der vorherigen Sitzung zu <a href="/post/sem">SEM</a> für die Variablen Zeitdruck, emotionale Erschöpfung und psychosomatische Beschwerden (als manifesten Skalenmittelwert, siehe dazu die <a href="/post/sem/#formvsreflMessmodell">Diskussion zu reflexiven vs. formativen Messmodellen</a> in der Sitzung zu SEM), welches so aussah (für Details, wie etwa das erstellen der Skalenmittelwerte für <code>BFs</code> schaue gerne nochmal in der vorherigen Sitzung zu <a href="/post/sem">SEM</a> vorbei):</p>
<pre class="r"><code>StressAtWork$BFs &lt;- rowMeans(StressAtWork[,paste0(&quot;bf&quot;,1:20)])

model_sem &lt;- &#39;
# Messmodelle
ZD =~ zd1 + zd2 + zd6
BOEE =~ bo1 + bo6 + bo12 + bo19

# Strukturmodell
BOEE ~ ZD
BFs ~  BOEE + ZD
&#39;

fit_sem &lt;- sem(model_sem, StressAtWork)

semPaths(object = fit_sem,  what = &quot;model&quot;, layout = &quot;tree2&quot;,
         rotation = 2, curve = T, col = list(man = &quot;skyblue&quot;, lat = &quot;yellow&quot;),
         curvePivot = T,  edge.label.cex=1.2, sizeMan = 5, sizeLat = 8)</code></pre>
<p><img src="/post/2021-04-13-MSA_files/figure-html/exercise_graph_sem1-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>Wenn wir die Variable Geschlecht als Gruppierung verwenden, können wir die Invarianz der Parameter über das Geschlecht untersuchen. Um die Gruppierung in das Modell mit aufzunehmen, können wir in <code>sem</code> einfach dem Argument <code>group</code> den Namen der Gruppierungsvariable übergeben (hierbei sind die “Gänsefüßchen” wichtig!).</p>
<pre class="r"><code>fit_sem_MSA &lt;- sem(model_sem, data = StressAtWork, group = &quot;sex&quot;)
summary(fit_sem_MSA)</code></pre>
<p>Wir sehen, dass im Output nun für jede Gruppe das Modell einzeln geschätzt wurde. Alle Parameter werden sowohl für Frauen, als auch für Männer geschätzt. Wir entnehmen,</p>
<pre><code>## [...]
##    Number of observations per group:                   
##     1                                              225
##     2                                               80 
## [...]</code></pre>
<p>… dass insgesamt 225 der Probanden Frauen und 80 Männer waren. Auch erhalten wir einen globalen sowie einen substichprobenspezifischen Modellfitwert:</p>
<pre><code>## [...]
##  Model Test User Model:
##                                                       
##   Test statistic                                35.803
##   Degrees of freedom                                36
##   P-value (Chi-square)                           0.478
##   Test statistic for each group:
##     1                                           21.400
##     2                                           14.403 
## [...]</code></pre>
<p>Der <span class="math inline">\(\chi^2\)</span>-Wert für das gesamte Modell liegt bei 35.803 bei <span class="math inline">\(df=\)</span> 36 mit zugehörigem <span class="math inline">\(p\)</span>-Wert von 0.478. Demnach verwerfen unsere Daten das Modell nicht. Die Freiheitsgrade sind doppelt so hoch, wie im Ein-Stichprobenfall, da wir alle Parameter für beide Stichproben schätzen müssen. Die <span class="math inline">\(\chi^2\)</span>-Werte der beiden Stichproben waren 21.400 für die Frauen und 14.403 für die Männer. Der <span class="math inline">\(\chi^2\)</span>-Wert für das gesamte Modell ist also einfach die Summe der subpopulationsspezifischen <span class="math inline">\(\chi_g^2\)</span>-Werte (wobei <span class="math inline">\(g=1\)</span> und <span class="math inline">\(g=2\)</span> für die erste und zweite Gruppe steht):
<span class="math display">\[\chi^2=\chi^2_{1}+\chi^2_{2}.\]</span>
Wenn wir uns jetzt die Ergebnisse des Modells etwas genauer ansehen, erhalten wir für jede Gruppe eine detaillierte Ausgabe:</p>
<pre><code>## [...]
##  Group 1 [1]:
## 
## Latent Variables:
##                    Estimate  Std.Err  z-value  P(&gt;|z|)
##   ZD =~                                               
##     zd1               1.000                           
##     zd2               0.861    0.073   11.853    0.000
##     zd6               0.830    0.068   12.214    0.000
##   BOEE =~                                             
##     bo1               1.000                           
##     bo6               0.900    0.063   14.356    0.000
##     bo12              0.936    0.067   14.011    0.000
##     bo19              1.033    0.070   14.667    0.000
## 
## Regressions:
##                    Estimate  Std.Err  z-value  P(&gt;|z|)
##   BOEE ~                                              
##     ZD                0.499    0.087    5.751    0.000
##   BFs ~                                               
##     BOEE              0.348    0.041    8.548    0.000
##     ZD                0.049    0.046    1.072    0.284
## 
## Intercepts:
##                    Estimate  Std.Err  z-value  P(&gt;|z|)
##    .zd1               3.622    0.083   43.758    0.000
##    .zd2               3.093    0.083   37.148    0.000
##    .zd6               3.849    0.078   49.598    0.000
##    .bo1               2.991    0.099   30.280    0.000
##    .bo6               2.258    0.095   23.659    0.000
##    .bo12              2.262    0.101   22.418    0.000
##    .bo19              2.582    0.108   23.905    0.000
##    .BFs               2.486    0.050   49.238    0.000
##     ZD                0.000                           
##    .BOEE              0.000                            
## [...]</code></pre>
<pre><code>## [...]
##  Group 2 [2]:
## 
## Latent Variables:
##                    Estimate  Std.Err  z-value  P(&gt;|z|)
##   ZD =~                                               
##     zd1               1.000                           
##     zd2               0.682    0.123    5.555    0.000
##     zd6               0.725    0.129    5.637    0.000
##   BOEE =~                                             
##     bo1               1.000                           
##     bo6               0.941    0.099    9.472    0.000
##     bo12              1.011    0.106    9.525    0.000
##     bo19              1.082    0.108   10.041    0.000
## 
## Regressions:
##                    Estimate  Std.Err  z-value  P(&gt;|z|)
##   BOEE ~                                              
##     ZD                0.519    0.145    3.580    0.000
##   BFs ~                                               
##     BOEE              0.418    0.059    7.108    0.000
##     ZD                0.023    0.062    0.367    0.714
## 
## Intercepts:
##                    Estimate  Std.Err  z-value  P(&gt;|z|)
##    .zd1               3.413    0.128   26.593    0.000
##    .zd2               2.788    0.122   22.833    0.000
##    .zd6               3.487    0.127   27.360    0.000
##    .bo1               3.000    0.157   19.093    0.000
##    .bo6               2.138    0.155   13.803    0.000
##    .bo12              2.188    0.166   13.184    0.000
##    .bo19              2.475    0.172   14.366    0.000
##    .BFs               2.176    0.078   28.072    0.000
##     ZD                0.000                           
##    .BOEE              0.000                            
## [...]</code></pre>
<p>Uns fällt auf, dass sowohl die Faktorladungen, als auch die Pfadkoeffizienten sich kaum über die Gruppen hinweg unterscheiden. Da sich die Subpopulationen auch hinsichtlich der Mittelwerte unterscheiden können, werden diese nun per Default im Output mit ausgegeben (es ist also nicht mehr notwendig, mit <code>meanstructure = TRUE</code> zu arbeiten). Natürlich können sich die Subpopulationen auch in allen weiteren Koeffizienten unterscheiden.</p>
<p>Im <a href="/post/sem">Beitrag zu den Strukturgleichungsmodellen</a> hatten wir Parameterlabel benutzt, um den indirekten Effekt als neuen Modellparameter bestimmen zu können. Da wir nun zwei Gruppen haben, müssen wir die Labels als Vektor schreiben, also bspw. <code>BOEE ~ c(a1, a2)*ZD</code>, um den Effekt der unabhängigen Variable auf den Mediator in den Gruppen jeweils <code>a1</code> und <code>a2</code> zu nennen.</p>
<p>Wir nutzen diese Schreibweise, um den indirekten Effekt sowohl für Frauen, als auch für Männer zu berechnen und erweitern unser Modell entsprechend:</p>
<pre class="r"><code>model_sem_IE_TE_MSA &lt;- &#39;
# Messmodelle
ZD =~ zd1 + zd2 + zd6
BOEE =~ bo1 + bo6 + bo12 + bo19

# Strukturmodell
BOEE ~ c(a1, a2)*ZD
BFs ~  c(b1, b2)*BOEE + c(c1,c2)*ZD

# Neue Parameter
IE1 := a1*b1
TE1 := IE1 + c1

IE2 := a2*b2
TE2 := IE2 + c2
&#39;
fit_sem_IE_TE_MSA &lt;- sem(model_sem_IE_TE_MSA, StressAtWork, group = &quot;sex&quot;)
summary(fit_sem_IE_TE_MSA)</code></pre>
<p>Nun sind alle Pfadkoeffizienten benannt. In Gruppe 1 (Frauen):</p>
<pre><code>## [...]
##  Regressions:
##                    Estimate  Std.Err  z-value  P(&gt;|z|)
##   BOEE ~                                              
##     ZD        (a1)    0.499    0.087    5.751    0.000
##   BFs ~                                               
##     BOEE      (b1)    0.348    0.041    8.548    0.000
##     ZD        (c1)    0.049    0.046    1.072    0.284 
## [...]</code></pre>
<p>Und in Gruppe 2 (Männer):</p>
<pre><code>## [...]
##  Regressions:
##                    Estimate  Std.Err  z-value  P(&gt;|z|)
##   BOEE ~                                              
##     ZD        (a2)    0.519    0.145    3.580    0.000
##   BFs ~                                               
##     BOEE      (b2)    0.418    0.059    7.108    0.000
##     ZD        (c2)    0.023    0.062    0.367    0.714 
## [...]</code></pre>
<p>Bis auf die hinzukommenden indirekten und totalen Effekte:</p>
<pre><code>## [...]
##  Defined Parameters:
##                    Estimate  Std.Err  z-value  P(&gt;|z|)
##     IE1               0.174    0.035    4.938    0.000
##     TE1               0.223    0.048    4.611    0.000
##     IE2               0.217    0.065    3.320    0.001
##     TE2               0.240    0.077    3.114    0.002 
## [...]</code></pre>
<p>… hat sich nichts am Output geändert. Wir haben ja auch nur Labels vergeben und neu definierte Parameter hinzugefügt, die allerdings, wie im <a href="/post/sem">Beitrag zu SEM</a> schon erwähnt, die Modellstruktur (und somit auch die <span class="math inline">\(df\)</span>) nicht tangieren. Auch können wir die Modelle in den beiden Gruppen darstellen via (die Dreiecke haben eine 1 in der Mitte stehen und stellen die Mittelwertsstruktur dar, die Kante/das Gewicht eines Dreiecks auf bspw die manifesten Variablen stellt dann den Mittelwert dieser manifesten Variable dar):</p>
<pre class="r"><code>semPaths(object = fit_sem_IE_TE_MSA, what = &quot;est&quot;, layout = &quot;tree2&quot;,
         rotation = 2, curve = T, col = list(man = &quot;skyblue&quot;, lat = &quot;yellow&quot;),
         curvePivot = T,  edge.label.cex=1, sizeMan = 5, sizeLat = 8, fade = F)</code></pre>
<p><img src="/post/2021-04-13-MSA_files/figure-html/unnamed-chunk-12-1.png" width="672" style="display: block; margin: auto;" /><img src="/post/2021-04-13-MSA_files/figure-html/unnamed-chunk-12-2.png" width="672" style="display: block; margin: auto;" /></p>
<p>Die totalen und die indirekten Effekte müssten in einer wissenschaftlichen Untersuchung erneut mithilfe von Bootstrapping inferenzstatistisch geprüft werden. Diesen Schritt überlassen wir an dieser Stelle dem/der aufmerksamen Leser/in. Auch können die indirekten Effekte bspw. gegeneinander untersucht werden via Bootstrapping, indem die Differenz der Effekte als neuer Parameter definiert wird. Allerdings können wir auch mittels des <span class="math inline">\(\chi^2\)</span>-Tests einen “richtigen” Invarianztest durchführen. Das schauen wir uns im Folgenden genauer an.</p>
<div id="invarianzstufen" class="section level3">
<h3>Invarianzstufen</h3>
<p>Mit Invarianz meinen wir die Gleichheit von Parametern über Gruppen hinweg, also bspw., dass es keine Unterschiede über das Geschlecht hinweg gibt. Ein ähnliches Konzept hatten wir im <a href="/post/cfa">Beitrag zur CFA</a> schon einmal gesehen, als es im Appendix um die Hierarchie der Messmodelle ging. Welche Stufen der Invarianz es in der MSA gibt, was diese bedeuten und wie wir diese spezifizieren, gucken wir uns im Folgenden nochmal kurz an.</p>
<p>So wie wir die indirekten Effekte bestimmt und die Koeffizienten für beide Gruppen benannt haben, lassen sich auch Invarianzen händisch prüfen. Wenn zwei Koeffizienten das selbe Label tragen, werden diese Parameter in den Gruppen auf den gleichen Wert gesetzt. Wir könnten nun für die jeweiligen Invarianzstufen die Parameter händisch gleichsetzen. Dieses ganze Prozedere erscheint recht aufwendig. Allerdings kann so in jedem Schritt überprüft werden, dass die Parameter richtig restringiert wurden. Zudem lassen sich so auch leicht partielle Invarianzen einbauen, in welchen bspw. nicht alle Faktorladungen über die Gruppen hinweg gleich sind. Außerdem könnten Invarianzen nur für bestimmte Variablen angenommen werden. Diesen kompletten, händischen Prozess sehen Sie in <a href="#AppendixA">Appendix A</a>. Glücklicherweise enthält das <code>lavaan</code>-Paket aber Möglichkeiten, Invarianzen global zu definieren. Dazu müssen wir lediglich in der Schätzung unserer Modelle in <code>sem</code> das Zusatzargument <code>group.equal</code> spezifizieren. Für partielle Invarianzen gibt es zusätzlich <code>group.partial</code>. Bevor wir mit den Analysen beginnen, sehen Sie in der folgenden Tabelle noch einmal eine Übersicht über die Invarianzstufen. Eine detaillierte Wiederholung dessen, was auch in den inhaltlichen Sitzungen zu den Invarianzstufen behandelt wurde, finden Sie im <a href="/post/exkurs-invarianzstufen">Exkurs zu Invarianzstufen</a>. Die beiden Spalten “Annahme” und “Implikation” sind kumulativ: Invarianzstufen, die weiter unten stehen, enthalten immer auch alle vorherigen Annahmen und erlauben auch immer alle vorherigen Aussagen. Die jeweiligen Einträge einer Zeile sind lediglich für diese Stufe <strong><em>zusätzlich</em></strong>.</p>
<table>
<colgroup>
<col width="21%" />
<col width="36%" />
<col width="42%" />
</colgroup>
<thead>
<tr class="header">
<th>Invarianzstufe</th>
<th>Annahme</th>
<th>Implikation</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>konfigural</td>
<td>gleiche Modellstruktur</td>
<td>gleiche Konstruktdefinition</td>
</tr>
<tr class="even">
<td>metrisch (schwach)</td>
<td>gleiche Faktorladungen</td>
<td>latente Variablen haben gleiche Bedeutung; Beziehungen zwischen latenten Variablen vergleichbar</td>
</tr>
<tr class="odd">
<td>skalar (stark)</td>
<td>gleiche Interzepte</td>
<td>mittlere Gruppenunterschiede in manifesten Variablen auf Unterschiede in latenten Mittelwerten zurückführbar; latente Mittelwerte vergleichbar</td>
</tr>
<tr class="even">
<td>strikt</td>
<td>gleiche Residualvarianzen</td>
<td>Varianzunterschiede in manifesten Variablen auf Varianzunterschiede in latenten Varianzen zurückführbar</td>
</tr>
</tbody>
</table>
<p>Die zwei verschiedenen Bezeichnungstypen für die beiden mittleren Invarianzstufen (entweder schwach und stark oder metrisch und skalar) kommen aus unterschiedlichen Traditionen in der MSA Literatur und können austauschbar benutzt werden.</p>
<p>Probieren wir dies doch gleich einmal aus (das Modell sollte hierzu keine Parameterbenennungen haben, da diese die gloablen Invarianzeinstellungen in <code>sem</code> überschreiben könnten):</p>
<pre class="r"><code>model_sem &lt;- &#39;
# Messmodelle
ZD =~ zd1 + zd2 + zd6
BOEE =~ bo1 + bo6 + bo12 + bo19

# Strukturmodell
BOEE ~ ZD
BFs ~  BOEE + ZD
&#39;</code></pre>
<p>Um <code>BFs</code> hier wie eine latente Variable zu behandeln, müssen wir bestimmen, dass das Interzept und die Residualvarianz nicht mit den manifesten Variablen zusammen gleichgesetzt werden, sondern erst mit den latenten Variablen über die Gruppen restringiert werden (bei der Testung der vollständigen Invarianz). Dazu müssen wir zusätzlich die partielle Invarianzeinstellung verwenden: <code>group.partial = c("BFs~1", "BFs~~BFs")</code>. Hiermit wird bestimmt, welche Koeffizienten <strong>nicht</strong> von den Invarianzeinstellungen betroffen sein sollen. Auch wenn diese Einstellungen erst bei der skalaren/starken Invarianz (<code>"BFs~1"</code>) und bei der strikten Invarianz (<code>"BFs~~BFs"</code>) zum Tragen kommen, stellen wir diese auch beim konfigural-invarianten und beim metrisch-invarianten (schwach-invarianten) Modell mit ein, um aufzuzeigen, dass wir in jedem Punkt genau wissen, was wir tun. Fangen wir mit dem Fitten des konfigural-invarianten Modells an.</p>
</div>
<div id="konfigurale-invarianz" class="section level3">
<h3>Konfigurale Invarianz</h3>
<p>Bei der konfiguralen Invarianz geht es darum, dass in beiden Gruppen die gleichen Modelle aufgestellt werden. Gilt diese Annahme bereits nicht, so macht es keinen Sinn, das Modell weiter einzuschränken und Parameter über die Gruppen zu restringieren. Glücklicherweise passt das Modell zu den Daten, in welchem das Modell für das Geschlecht jeweils geschätzt wurde. Hier schauen wir uns dies noch einmal zur Wiederholung und zum Umbenennen des geschätzten Modells an und spezifizieren mit <code>group.equal = c("")</code>, dass keine Parameter über die Gruppen als identisch angenommen werden sollen:</p>
<pre class="r"><code>fit_sem_sex_konfigural &lt;- sem(model_sem, data = StressAtWork, 
                              group = &quot;sex&quot;,
                              group.equal = c(&quot;&quot;), 
                              group.partial = c(&quot;BFs~1&quot;, &quot;BFs~~BFs&quot;))
summary(fit_sem_sex_konfigural, fit.measures = T)</code></pre>
<p>Dem Modell-Fit Teil der Summary entnehmen wir, dass das Modell gut zu den Daten passt:</p>
<pre><code>## [...]
##  Model Test User Model:
##                                                       
##   Test statistic                                35.803
##   Degrees of freedom                                36
##   P-value (Chi-square)                           0.478
##   Test statistic for each group:
##     1                                           21.400
##     2                                           14.403
## 
## Model Test Baseline Model:
## 
##   Test statistic                              1325.901
##   Degrees of freedom                                56
##   P-value                                        0.000
## 
## User Model versus Baseline Model:
## 
##   Comparative Fit Index (CFI)                    1.000
##   Tucker-Lewis Index (TLI)                       1.000
## 
## Loglikelihood and Information Criteria:
## 
##   Loglikelihood user model (H0)              -3377.320
##   Loglikelihood unrestricted model (H1)      -3359.418
##                                                       
##   Akaike (AIC)                                6858.639
##   Bayesian (BIC)                              7052.095
##   Sample-size adjusted Bayesian (BIC)         6887.176
## 
## Root Mean Square Error of Approximation:
## 
##   RMSEA                                          0.000
##   90 Percent confidence interval - lower         0.000
##   90 Percent confidence interval - upper         0.057
##   P-value RMSEA &lt;= 0.05                          0.902
## 
## Standardized Root Mean Square Residual:
## 
##   SRMR                                           0.031 
## [...]</code></pre>
<p>Der <span class="math inline">\(\chi^2\)</span>-Wert ist nicht signifikant und auch die Fit-Indizes CFI, TLI, RMSEA und SRMR sind unauffällig und deuten auf guten Modell-Fit hin. Dies bedeutet, dass wir frohen Mutes das Modell einschränken können, um zu prüfen, welche Invarianz über das Geschlecht hinweg gilt.</p>
</div>
<div id="metrische-invarianz" class="section level3">
<h3>Metrische Invarianz</h3>
<p>Unter metrischer oder schwacher Invarianz verstehen wir, dass die Faktorladungen (<span class="math inline">\(\lambda\)</span>, bzw. <span class="math inline">\(\Lambda\)</span>) über die Gruppen hinweg gleich sind. Somit ist der Anteil jedes Items, der auf die latenten Variablen zurückzuführen ist, über die Gruppen hinweg gleich. Dies ist wichtig, um zu prüfen, ob die Konstrukte über die beiden Gruppen hinweg die gleiche Bedeutung haben. Wir erreichen dies, indem wir <code>group.equal = c("loadings")</code> spezifizieren.</p>
<pre class="r"><code>fit_sem_sex_metrisch &lt;- sem(model_sem, data = StressAtWork, 
                            group = &quot;sex&quot;,
                            group.equal = c(&quot;loadings&quot;), 
                            group.partial = c(&quot;BFs~1&quot;, &quot;BFs~~BFs&quot;))
summary(fit_sem_sex_metrisch, fit.measures = T)</code></pre>
<p>Wir entnehmen,</p>
<pre><code>## [...]
##  Model Test User Model:
##                                                       
##   Test statistic                                37.543
##   Degrees of freedom                                41
##   P-value (Chi-square)                           0.625
##   Test statistic for each group:
##     1                                           21.770
##     2                                           15.773
## 
## Model Test Baseline Model:
## 
##   Test statistic                              1325.901
##   Degrees of freedom                                56
##   P-value                                        0.000
## 
## User Model versus Baseline Model:
## 
##   Comparative Fit Index (CFI)                    1.000
##   Tucker-Lewis Index (TLI)                       1.004
## 
## Loglikelihood and Information Criteria:
## 
##   Loglikelihood user model (H0)              -3378.190
##   Loglikelihood unrestricted model (H1)      -3359.418
##                                                       
##   Akaike (AIC)                                6850.380
##   Bayesian (BIC)                              7025.234
##   Sample-size adjusted Bayesian (BIC)         6876.173
## 
## Root Mean Square Error of Approximation:
## 
##   RMSEA                                          0.000
##   90 Percent confidence interval - lower         0.000
##   90 Percent confidence interval - upper         0.048
##   P-value RMSEA &lt;= 0.05                          0.958
## 
## Standardized Root Mean Square Residual:
## 
##   SRMR                                           0.035 
## [...]</code></pre>
<p>… dass das Modell immer noch gut zu den Daten passt. Die Frage ist nur, ob das metrisch-invariante Modell nicht doch vielleicht signifikant schlechter zu den Daten passt als das konfigural-invariante Modell. Bevor wir dieser Frage nachgehen, schauen wir uns noch schnell an, wie Parameter hier per Default benannt werden:</p>
<pre><code>## [...]
##  Group 1 [1]:
## 
## Latent Variables:
##                    Estimate  Std.Err  z-value  P(&gt;|z|)
##   ZD =~                                               
##     zd1               1.000                           
##     zd2     (.p2.)    0.826    0.063   13.119    0.000
##     zd6     (.p3.)    0.813    0.060   13.496    0.000
##   BOEE =~                                             
##     bo1               1.000                           
##     bo6     (.p5.)    0.912    0.053   17.191    0.000
##     bo12    (.p6.)    0.959    0.057   16.955    0.000
##     bo19    (.p7.)    1.048    0.059   17.780    0.000
## 
## Regressions:
##                    Estimate  Std.Err  z-value  P(&gt;|z|)
##   BOEE ~                                              
##     ZD                0.481    0.084    5.764    0.000
##   BFs ~                                               
##     BOEE              0.353    0.041    8.703    0.000
##     ZD                0.048    0.045    1.073    0.283 
## [...]</code></pre>
<pre><code>## [...]
##  Group 2 [2]:
## 
## Latent Variables:
##                    Estimate  Std.Err  z-value  P(&gt;|z|)
##   ZD =~                                               
##     zd1               1.000                           
##     zd2     (.p2.)    0.826    0.063   13.119    0.000
##     zd6     (.p3.)    0.813    0.060   13.496    0.000
##   BOEE =~                                             
##     bo1               1.000                           
##     bo6     (.p5.)    0.912    0.053   17.191    0.000
##     bo12    (.p6.)    0.959    0.057   16.955    0.000
##     bo19    (.p7.)    1.048    0.059   17.780    0.000
## 
## Regressions:
##                    Estimate  Std.Err  z-value  P(&gt;|z|)
##   BOEE ~                                              
##     ZD                0.581    0.153    3.795    0.000
##   BFs ~                                               
##     BOEE              0.412    0.054    7.576    0.000
##     ZD                0.013    0.069    0.193    0.847 
## [...]</code></pre>
<p>Wir erkennen, dass “einfach” nur die Parameter durchnummeriert werden, wobei Parameter, die auf 1 restringiert sind, mitgezählt werden, aber nicht ihr eigenes Label erhalten. So heißt <span class="math inline">\(\lambda_{21}^x\)</span>, der Ladungskoeffizient von <code>zd2</code>, hier <code>.p2.</code>, wobei das <code>p</code> für Parameter steht und die Punkte andeuten, dass es sich hierbei um ein intern vergebenes (also ein durch die Funktion selbst vergebenes) Label handelt. Wollen wir nun wissen, ob sich die Modelle statistisch signifikant voneinander unterscheiden, können wir wieder den Likelihood-Ratio-Test (<span class="math inline">\(\chi^2\)</span>-Differenzentest) heranziehen.</p>
<pre class="r"><code>lavTestLRT(fit_sem_sex_metrisch, fit_sem_sex_konfigural)</code></pre>
<pre><code>## Chi-Squared Difference Test
## 
##                        Df    AIC    BIC  Chisq Chisq diff Df diff Pr(&gt;Chisq)
## fit_sem_sex_konfigural 36 6858.6 7052.1 35.803                              
## fit_sem_sex_metrisch   41 6850.4 7025.2 37.543     1.7405       5     0.8838</code></pre>
<p>Die <span class="math inline">\(\chi^2\)</span>-Differenz liegt bei 1.7405 bei <span class="math inline">\(\Delta df=\)</span> 5 mit dem zugehörigen <span class="math inline">\(p\)</span>-Wert von 0.8838 (die Null-Hypothese war: <span class="math inline">\(H_0: \Sigma_{konfigural}=\Sigma_{metrisch}\)</span>). Das metrische Modell ist hier das restriktivere, da Koeffizienten gleichgesetzt wurden. Weil es keine signifikanten Unterschiede zwischen den Modellen gibt, entscheiden wir uns — Ockhams Rasiermesser folgend (siehe <a href="https://hds.hebis.de/ubffm/Record/HEB366849158">Eid et al., 2017, p. 787</a>) — für das sparsamere Modell, also jenes, welches weniger Parameter enthält und somit restriktiver ist, hier: das <em>metrisch-invariante</em> Modell. Somit können wir weiter von metrischer Invarianz ausgehen. Dies bedeutet, dass sich Unterschiede zwischen Frauen auf der latenten Variable in gleicher Weise in den beobachtbaren Variablen niederschlagen, wie sie es bei Männern tun.</p>
</div>
<div id="skalare-invarianz" class="section level3">
<h3>Skalare Invarianz</h3>
<p>Als nächstes wollen wir prüfen, ob zusätzlich zu den Faktorladungen auch die Interzepte (<span class="math inline">\(\tau\)</span>) über die Gruppen hinweg gleich sind (insgesamt also <span class="math inline">\(\lambda\)</span>s und <span class="math inline">\(\tau\)</span>s gleich über die Gruppen hinweg). Dazu passen wir erneut unser Modell an. Hierbei ist zu beachten, dass wir nicht das Interzept von <code>BFs</code> über die Gruppen hinweg gleichsetzen, da sich die Interzepte auf die manifesten Variablen beziehen, wir <code>BFs</code> hier allerdings wie eine latente Variable behandeln wollen, bzw. diese zu einer der Variablen der Strukturgleichung zählen wollen. Dazu haben wir die <code>group.partial = c("BFs~1", "BFs~~BFs")</code> Einstellungen verwendet. Eine Besonderheit der skalaren Invarianz ist, dass wir, sobald wir die Interzepte über die Gruppen hinweg gleichsetzen, die Freiheitsgrade haben, mit welchen wir die latenten Interzepte von <code>ZD</code> und <code>BOEE</code> schätzen können. Dies ist dann eine Art Effektkodierung, wobei der Mittelwert der einen Gruppe auf 0 gesetzt und in der anderen Gruppe dann die Abweichung zu dieser Gruppe mitgeführt wird. Andernfalls würden wir fälschlicherweise Invarianz der latenten Mittelwerte annehmen, was wir hier noch gar nicht prüfen wollen! Wir schauen uns dies im Output an.</p>
<pre class="r"><code>fit_sem_sex_skalar &lt;- sem(model_sem, data = StressAtWork, 
                          group = &quot;sex&quot;,
                          group.equal = c(&quot;loadings&quot;, &quot;intercepts&quot;), 
                          group.partial = c(&quot;BFs~1&quot;, &quot;BFs~~BFs&quot;))
summary(fit_sem_sex_skalar, fit.measures = T)</code></pre>
<pre><code>## [...]
##  Group 1 [1]:
## 
## Latent Variables:
##                    Estimate  Std.Err  z-value  P(&gt;|z|)
##   ZD =~                                               
##     zd1               1.000                           
##     zd2     (.p2.)    0.841    0.063   13.321    0.000
##     zd6     (.p3.)    0.829    0.061   13.682    0.000
##   BOEE =~                                             
##     bo1               1.000                           
##     bo6     (.p5.)    0.913    0.053   17.171    0.000
##     bo12    (.p6.)    0.961    0.057   16.943    0.000
##     bo19    (.p7.)    1.050    0.059   17.764    0.000
## 
## Regressions:
##                    Estimate  Std.Err  z-value  P(&gt;|z|)
##   BOEE ~                                              
##     ZD                0.488    0.084    5.792    0.000
##   BFs ~                                               
##     BOEE              0.353    0.041    8.683    0.000
##     ZD                0.048    0.045    1.070    0.284
## 
## Intercepts:
##                    Estimate  Std.Err  z-value  P(&gt;|z|)
##    .zd1     (.21.)    3.644    0.082   44.440    0.000
##    .zd2     (.22.)    3.075    0.079   39.155    0.000
##    .zd6     (.23.)    3.822    0.075   50.822    0.000
##    .bo1     (.24.)    3.014    0.095   31.582    0.000
##    .bo6     (.25.)    2.240    0.092   24.481    0.000
##    .bo12    (.26.)    2.259    0.097   23.304    0.000
##    .bo19    (.27.)    2.570    0.104   24.790    0.000
##    .BFs               2.486    0.050   49.238    0.000
##     ZD                0.000                           
##    .BOEE              0.000                            
## [...]</code></pre>
<pre><code>## [...]
##  Group 2 [2]:
## 
## Latent Variables:
##                    Estimate  Std.Err  z-value  P(&gt;|z|)
##   ZD =~                                               
##     zd1               1.000                           
##     zd2     (.p2.)    0.841    0.063   13.321    0.000
##     zd6     (.p3.)    0.829    0.061   13.682    0.000
##   BOEE =~                                             
##     bo1               1.000                           
##     bo6     (.p5.)    0.913    0.053   17.171    0.000
##     bo12    (.p6.)    0.961    0.057   16.943    0.000
##     bo19    (.p7.)    1.050    0.059   17.764    0.000
## 
## Regressions:
##                    Estimate  Std.Err  z-value  P(&gt;|z|)
##   BOEE ~                                              
##     ZD                0.590    0.156    3.782    0.000
##   BFs ~                                               
##     BOEE              0.413    0.055    7.564    0.000
##     ZD                0.012    0.071    0.166    0.868
## 
## Intercepts:
##                    Estimate  Std.Err  z-value  P(&gt;|z|)
##    .zd1     (.21.)    3.644    0.082   44.440    0.000
##    .zd2     (.22.)    3.075    0.079   39.155    0.000
##    .zd6     (.23.)    3.822    0.075   50.822    0.000
##    .bo1     (.24.)    3.014    0.095   31.582    0.000
##    .bo6     (.25.)    2.240    0.092   24.481    0.000
##    .bo12    (.26.)    2.259    0.097   23.304    0.000
##    .bo19    (.27.)    2.570    0.104   24.790    0.000
##    .BFs               2.207    0.068   32.380    0.000
##     ZD               -0.288    0.143   -2.013    0.044
##    .BOEE              0.103    0.165    0.624    0.533 
## [...]</code></pre>
<p>In dieser Ausgabe tauchen jetzt mitunter nur Zahlen zwischen den Punkten auf, dabei handelt es sich aber lediglich um eine Abkürzung im Output. In <code>lavaan</code> werden konsistent alle diese Label als <code>.p</code>[Parameternummer]<code>.</code> vergeben. (Wenn Sie sich davon selbst überzeugen möchten, nutzen Sie z.B. die <code>parameterEstimates</code>-Funktion, um eine detaillierte Ausgabe über die Parameter zu erhalten.)</p>
<p>Hier greift nun tatsächlich die Einstellung <code>"BFs~1"</code> in <code>group.partial</code>. <code>BFs</code> hat zwei unterschiedliche Interzepte. Bei <code>ZD</code> und <code>BOEE</code> fällt auf, dass diese in Gruppe 1 auf 0 gesetzt sind (ohne Unsicherheit) und in Gruppe 2 hier eine Effektkodierung durchgeführt wurde: hier wurden die Interzepte geschätzt. Unterscheidet sich dieser Interzept nun von 0, so unterscheiden sich die Gruppe in ihren Interzepten ([möglicherweise bedingten] Mittelwerten). Dazu später mehr!</p>
<p>Nun wollen wir untersuchen, ob das metrisch- und das skalar-invariante Modell sich signifikant in der Modellbeschreibung unterscheiden.</p>
<pre class="r"><code>lavTestLRT(fit_sem_sex_skalar, fit_sem_sex_metrisch)</code></pre>
<pre><code>## Chi-Squared Difference Test
## 
##                      Df    AIC    BIC  Chisq Chisq diff Df diff Pr(&gt;Chisq)
## fit_sem_sex_metrisch 41 6850.4 7025.2 37.543                              
## fit_sem_sex_skalar   46 6844.5 7000.8 41.694     4.1504       5      0.528</code></pre>
<p>Die <span class="math inline">\(\chi^2\)</span>-Differenz ist erneut klein (4.15) und der p-Wert zeigt auch hier an, dass es sich um keine signifikante Verschlechterung des Modells handelt (p = 0.528). Die Null-Hypothese, dass die Interzepte über die Faktorladungen hinaus über das Geschlecht hinweg gleich sind, wird somit nicht verworfen (die Null-Hypothese war: <span class="math inline">\(H_0: \Sigma_{metrisch}=\Sigma_{skalar}\)</span>). Dies bedeutet nun, dass Unterschiede im Mittelwert der Items zwischen den beiden Gruppen tatsächlich auch auf Unterschiede der Mittelwerte der latenten Variablen zurückzuführen sind. Das heißt, dass es erst ab dieser Invarianzstufe zulässig ist, Mittelwerte zwischen den Gruppen zu vergleichen.</p>
</div>
<div id="strikte-invarianz" class="section level3">
<h3>Strikte Invarianz</h3>
<p>Unter strikter Invarianz verstehen wir, dass zusätzlich zu den Faktorladungen und den Interzepten auch die Residualvarianzen (<span class="math inline">\(\theta\)</span>) gleich sind (insgesamt also <span class="math inline">\(\lambda\)</span>s, <span class="math inline">\(\tau\)</span>s und <span class="math inline">\(\theta\)</span>s gleich über die Gruppen hinweg). Wir passen entsprechend das Modell an:</p>
<pre class="r"><code>fit_sem_sex_strikt &lt;- sem(model_sem, data = StressAtWork, 
                          group = &quot;sex&quot;,
                          group.equal = c(&quot;loadings&quot;, &quot;intercepts&quot;, &quot;residuals&quot;), 
                          group.partial = c(&quot;BFs~1&quot;, &quot;BFs~~BFs&quot;))</code></pre>
<p>Hier greift nun tatsächlich die Einstellung <code>"BFs~~BFs"</code> in <code>group.partial</code>. Wir vergleichen das skalar- und das strikt-invariante Modell hinsichtlich der Modellbeschreibung.</p>
<pre class="r"><code>lavTestLRT(fit_sem_sex_strikt, fit_sem_sex_skalar)</code></pre>
<pre><code>## Chi-Squared Difference Test
## 
##                    Df    AIC    BIC  Chisq Chisq diff Df diff Pr(&gt;Chisq)
## fit_sem_sex_skalar 46 6844.5 7000.8 41.694                              
## fit_sem_sex_strikt 53 6836.7 6966.9 47.850     6.1563       7     0.5216</code></pre>
<p>Die <span class="math inline">\(\chi^2\)</span>-Differenz ist erneut klein (6.156) und der p-Wert zeigt auch hier an, dass es sich um keine signifikante Verschlechterung des Modells handelt (p = 0.522). Die Null-Hypothese, dass die Fehlervarianzen über die Faktorladungen und Interzepte hinaus über das Geschlecht hinweg gleich sind, wird somit nicht verworfen (die Null-Hypothese war: <span class="math inline">\(H_0: \Sigma_{skalar}=\Sigma_{strikt}\)</span>).
Dies bedeutet nun, dass Unterschiede in der Varianz der manifesten Variablen tatsächlich auf Unterschiede in den Varianzen der latenten Variablen zurückzuführen sind. In anderen Worten, wenn wir z.B. beobachten, dass Männer in den beobachtbaren Verhaltensweisen homogener sind als Frauen, können wir bei dieser Varianzstufe davon ausgehen, dass dies daher kommt, dass Männer im Konstrukt ähnlicher sind und nicht nur daher, dass sie z.B. aufgrund der Formulierung der Fragen genauer gemessen werden konnten.</p>
</div>
<div id="vollständige-invarianz" class="section level3">
<h3>Vollständige Invarianz</h3>
<p>Unter vollständiger Invarianz verstehen wir das Gleichsetzen aller Strukturparameter. Hier werden nun alle Varianzen, Residualvarianzen, ungerichtete und gerichtete Effekte des Strukturmodells über die Gruppen hinweg gleichgesetzt (insgesamt also <span class="math inline">\(\lambda\)</span>s, <span class="math inline">\(\tau\)</span>s, <span class="math inline">\(\theta\)</span>s, <span class="math inline">\(\gamma\)</span>s, <span class="math inline">\(\beta\)</span>s, <span class="math inline">\(\kappa\)</span>s, <span class="math inline">\(\phi\)</span>s und <span class="math inline">\(\psi\)</span>s gleich über die Gruppen hinweg). Wir passen entsprechend das Modell an. Außerdem müssen wir nun das Interzept und die Residualvarianz von <code>BFs</code> invariant zwischen den Gruppen setzen, was wir erreichen, indem wir die <code>group.partial</code> Option rausnehmen.</p>
<pre class="r"><code>fit_sem_sex_voll &lt;- sem(model_sem, data = StressAtWork, 
                        group = &quot;sex&quot;,
                        group.equal = c(&quot;loadings&quot;, &quot;intercepts&quot;, &quot;residuals&quot;,
                                        &quot;means&quot;,          # latente Mittelwerte
                                        &quot;lv.variances&quot;,   # latente Varianzen
                                        &quot;lv.covariances&quot;, # latente Kovarianzen
                                        &quot;regressions&quot;))   # Strukturparameter (Regressionsgewichte)</code></pre>
<p>Wenn wir nun den Modellvergleich zwischen dem strikt invarianten und dem vollständig invarianten Modell durchführen,</p>
<pre class="r"><code>lavTestLRT(fit_sem_sex_voll, fit_sem_sex_strikt)</code></pre>
<pre><code>## Chi-Squared Difference Test
## 
##                    Df    AIC    BIC Chisq Chisq diff Df diff Pr(&gt;Chisq)   
## fit_sem_sex_strikt 53 6836.7 6966.9 47.85                                 
## fit_sem_sex_voll   62 6844.0 6940.7 73.14      25.29       9   0.002667 **
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>… erhalten wir diesmal eine große <span class="math inline">\(\chi^2\)</span>-Differenz (25.29) und der p-Wert zeigt an, dass es sich um eine signifikante Verschlechterung des Modells handelt <span class="math inline">\(p = 0.003 &lt; 0.05\)</span>, wenn wir die Restriktion der vollständigen Invarianz in das Modell aufnehmen. Die Null-Hypothese, dass alle Parameter im Modell über das Geschlecht hinweg gleich sind, wird somit verworfen (die Null-Hypothese war: <span class="math inline">\(H_0: \Sigma_{strikt}=\Sigma_{vollständig}\)</span>). Dies bedeutet also, dass es Geschlechtsunterschiede in den Beziehungen zwischen den latenten Variablen gibt.</p>
<p>Natürlich ist es nun interessant, wo diese Unterschiede liegen. Deshalb schauen wir uns dies an, indem wir uns den Output der Summary des strikt-invarianten Modells ansehen, da sich hier Pfadkoeffizienten, sowie die Mittelwerte und Varianzen der latenten Variablen (bzw. von <code>BFs</code>, was wir als latente Variable mitführen) noch unterscheiden:</p>
<pre class="r"><code>summary(fit_sem_sex_strikt)</code></pre>
<pre><code>## [...]
##  Group 1 [1]:
## 
## Latent Variables:
##                    Estimate  Std.Err  z-value  P(&gt;|z|)
##   ZD =~                                               
##     zd1               1.000                           
##     zd2     (.p2.)    0.842    0.063   13.351    0.000
##     zd6     (.p3.)    0.828    0.061   13.632    0.000
##   BOEE =~                                             
##     bo1               1.000                           
##     bo6     (.p5.)    0.909    0.053   17.127    0.000
##     bo12    (.p6.)    0.955    0.057   16.871    0.000
##     bo19    (.p7.)    1.046    0.059   17.681    0.000
## 
## Regressions:
##                    Estimate  Std.Err  z-value  P(&gt;|z|)
##   BOEE ~                                              
##     ZD                0.490    0.084    5.805    0.000
##   BFs ~                                               
##     BOEE              0.349    0.040    8.688    0.000
##     ZD                0.050    0.045    1.115    0.265
## 
## Intercepts:
##                    Estimate  Std.Err  z-value  P(&gt;|z|)
##    .zd1     (.21.)    3.644    0.082   44.513    0.000
##    .zd2     (.22.)    3.078    0.078   39.236    0.000
##    .zd6     (.23.)    3.818    0.076   50.443    0.000
##    .bo1     (.24.)    3.011    0.096   31.468    0.000
##    .bo6     (.25.)    2.242    0.092   24.477    0.000
##    .bo12    (.26.)    2.259    0.097   23.306    0.000
##    .bo19    (.27.)    2.572    0.104   24.811    0.000
##    .BFs               2.486    0.050   49.238    0.000
##     ZD                0.000                           
##    .BOEE              0.000                            
## [...]</code></pre>
<pre><code>## [...]
##  Group 2 [2]:
## 
## Latent Variables:
##                    Estimate  Std.Err  z-value  P(&gt;|z|)
##   ZD =~                                               
##     zd1               1.000                           
##     zd2     (.p2.)    0.842    0.063   13.351    0.000
##     zd6     (.p3.)    0.828    0.061   13.632    0.000
##   BOEE =~                                             
##     bo1               1.000                           
##     bo6     (.p5.)    0.909    0.053   17.127    0.000
##     bo12    (.p6.)    0.955    0.057   16.871    0.000
##     bo19    (.p7.)    1.046    0.059   17.681    0.000
## 
## Regressions:
##                    Estimate  Std.Err  z-value  P(&gt;|z|)
##   BOEE ~                                              
##     ZD                0.583    0.155    3.752    0.000
##   BFs ~                                               
##     BOEE              0.423    0.056    7.606    0.000
##     ZD                0.004    0.071    0.060    0.952
## 
## Intercepts:
##                    Estimate  Std.Err  z-value  P(&gt;|z|)
##    .zd1     (.21.)    3.644    0.082   44.513    0.000
##    .zd2     (.22.)    3.078    0.078   39.236    0.000
##    .zd6     (.23.)    3.818    0.076   50.443    0.000
##    .bo1     (.24.)    3.011    0.096   31.468    0.000
##    .bo6     (.25.)    2.242    0.092   24.477    0.000
##    .bo12    (.26.)    2.259    0.097   23.306    0.000
##    .bo19    (.27.)    2.572    0.104   24.811    0.000
##    .BFs               2.206    0.069   32.084    0.000
##     ZD               -0.292    0.143   -2.038    0.042
##    .BOEE              0.104    0.165    0.627    0.531 
## [...]</code></pre>
<p>Dem jeweiligen Unterpunkt <code>Regressions</code> in beiden Gruppen entnehmen wir, dass die Pfadkoeffizienten recht ähnlich groß zu sein scheinen. Die Standardfehler der Koeffizienten in beiden Gruppen überlappen sich stark, wenn wir jeweils <code>Estimate</code> <span class="math inline">\(\pm\)</span> <code>Std.Err</code> für einen Koeffizienten rechnen (zur Erinnerung: ein 95% Konfidenzintervall würden wir mit <span class="math inline">\(Est \pm 1.96SE\)</span> erhalten, was noch viel größer wäre und sich diese also “noch stärker” überlappen würde). Schauen wir uns jeweils die Interzepte in den Unterpunkten <code>Intercepts</code> in den beiden Gruppen an, erkennen wir an der Effektkodierung für <code>ZD</code> und <code>BOEE</code>, dass die latenten Interzepte (<span class="math inline">\(\kappa\)</span>) in der einen Gruppe auf 0 gesetzt und in der anderen Gruppe frei geschätzt wurden. Das Interzept in Gruppe 2 (den Männern) von Zeitdruck ist signifikant von 0 verschieden, das von emotionaler Erschöpfung nicht. Dies bedeutet, dass sich Männer und Frauen in ihrem latenten Mittelwert von Zeitdruck unterscheiden. Da der Mittelwert von Zeitdruck in der Gruppe der Frauen auf 0 gesetzt war und der Mittelwert von Zeitdruck der Männer signifikant von 0 abweicht (<code>Est</code> = -0.292, <span class="math inline">\(p &lt; .05\)</span>), verrät uns das negative Vorzeichen, dass Männer im Durchschnitt weniger Zeitdruck erleben. Auch wenn wir Konfidenzintervalle um die Interzeptschätzung von <code>BFs</code> legen, erhalten wir einen signifikanten Unterschied: die untere Grenze des Konfidenzintervalls in <em>Gruppe 1</em> liegt bei <span class="math inline">\(2.486-1.96*0.05 \approx 2.38\)</span> und und die obere Grenze in <em>Gruppe 2</em> liegt bei <span class="math inline">\(2.206+1.96*0.069 \approx 2.35\)</span>; hier haben wir konservativer “gerundet”, um den <span class="math inline">\(\beta\)</span>-Fehler zu minimieren; — die Konfidenzintervalle überlappen sich nicht! Diese signifikanten Unterschiede könnten der Grund gewesen sein, warum die vollständige Invarianz verworfen wurde. Um dies genauer zu prüfen, müssten wir sukzessive alle Parameter über die Gruppen gleichsetzen und schauen, für welchen Parameter diese Gleichsetzung zu einer signifikanten Verschlechterung des Modells führt.</p>
<p>Zusammenfassend können wir also nur von strikter Invarianz des Modells über das Geschlecht ausgehen. Wie sieht nun unser finales Modell aus?</p>
<pre class="r"><code>semPaths(object = fit_sem_sex_strikt, what = &quot;est&quot;, layout = &quot;tree2&quot;,
         rotation = 2, curve = T, col = list(man = &quot;skyblue&quot;, lat = &quot;yellow&quot;),
         curvePivot = T,  edge.label.cex=1, sizeMan = 5, sizeLat = 8)</code></pre>
<p><img src="/post/2021-04-13-MSA_files/figure-html/unnamed-chunk-33-1.png" width="672" style="display: block; margin: auto;" /><img src="/post/2021-04-13-MSA_files/figure-html/unnamed-chunk-33-2.png" width="672" style="display: block; margin: auto;" /></p>
<p>Wir erkennen deutlich, dass einige Koeffizienten gleich sind und bspw. der Mittelwert von <code>ZD</code> in einer Gruppe auf 0 ist (kein Pfeil) und in der zweiten Gruppe bei -0.29 liegt. Wenn wir hier <code>what = "model"</code> wählen, können wir das Modell mit allen Gleichsetzungen betrachten.</p>
<!-- ### Was bedeutet es, wenn ein Pfadkoeffizient nicht invariant über Gruppen ist? -->
</div>
<div id="multi-gruppen-modelle-und-moderierte-regression" class="section level2">
<h2>Multi Gruppen Modelle und moderierte Regression</h2>
<p>Auch wenn in unserem Beispiel die Regressionsgewichte über beide Gruppen hinweg gleich waren, ist das bei weitem nicht immer der Fall. In vielen Fällen zielen inhaltliche Fragestellungen genau darauf ab, in welchem Ausmaß es Unterschiede in den Beziehungen latenter Variablen über Gruppen hinweg gibt. Wir hatten bereits gesehen, dass Männer im Mittel weniger Zeitdruck erleben. Könnte es daher sein, dass Männer, die - entgegen der üblichen männlichen Erfahrung - erhöhten Zeitdruck empfinden, darauf stärker mit psychosomatischen Beschwerden reagieren als Frauen? Diese Frage impliziert einen <em>Interkationseffekt</em>. Gleichzeitig bedeutet diese Frage auch nichts anderes als: “Gibt es einen Unterschied in den Regressionsgewichten zwischen Männern und Frauen?”. In diesem Abschnitt gucken wir uns an, wie diese beiden Ansätze in Bezug zueinander stehen.</p>
<p>Vereinfachen wir unser Beispiel für einen Moment auf die manifeste Ebene, wie es schon bei den <a href="/post/sem#Pfadanalysen">Pfadanalysen im letzten Beitrag</a> der Fall war. Dazu nutzen wir neben den Skalenwerten der psychosomatischen Beschwerden (<code>BFs</code>) auch einen Skalenwert des Zeitdrucks (<code>ZDs</code>). Generell hält die folgende Beschreibung auch für den Fall mit latenten Variablen, aber für den Vergleich der beiden Ansätze ist ein übersichtliches Beispiel sinnvoller.</p>
<pre class="r"><code>StressAtWork$ZDs &lt;- rowMeans(StressAtWork[,paste0(&quot;zd&quot;,c(1, 2, 6))])</code></pre>
<p>Das einfache Multi Gruppen Modell sieht für diesen Fall in <code>lavaan</code> so aus:</p>
<pre class="r"><code>model_pfad_msa &lt;- &#39;BFs ~ ZDs&#39;
fit_pfad_msa &lt;- sem(model_pfad_msa, StressAtWork,
  group = &#39;sex&#39;)</code></pre>
<p>Als Ergebnis erhalten wir zwei gruppenspezifische Regressionen, die so notiert werden können:</p>
<p><span class="math display">\[\begin{align}
  BF &amp;= \beta_{01} + \beta_{11} ZD + \varepsilon \\
  BF &amp;= \beta_{02} + \beta_{12} ZD + \varepsilon 
\end{align}\]</span></p>
<p>Auf die Daten angepasst erhalten wir folgende Parameterschätzungen:</p>
<pre class="r"><code>summary(fit_pfad_msa)</code></pre>
<pre><code>## [...]
##  Regressions:
##                    Estimate  Std.Err  z-value  P(&gt;|z|)
##   BFs ~                                               
##     ZDs               0.220    0.045    4.885    0.000
## 
## Intercepts:
##                    Estimate  Std.Err  z-value  P(&gt;|z|)
##    .BFs               1.710    0.166   10.310    0.000 
## [...]</code></pre>
<pre><code>## [...]
##  Regressions:
##                    Estimate  Std.Err  z-value  P(&gt;|z|)
##   BFs ~                                               
##     ZDs               0.213    0.078    2.742    0.006
## 
## Intercepts:
##                    Estimate  Std.Err  z-value  P(&gt;|z|)
##    .BFs               1.487    0.262    5.677    0.000 
## [...]</code></pre>
<p>Die beiden Gruppen unterscheiden sich geringfügig im Regressionsgewicht und Intercept. Um uns die Mühe zu ersparen, einfache Subtraktion per Hand betreiben zu müssen, können wir diese Differenzen mit in das Modell aufnehmen. Dazu können wir wieder mit Labels arbeiten und neue Parameter definieren:</p>
<pre class="r"><code>model_pfad_msa &lt;- &#39;
  # Regressionen
  BFs ~ c(b11, b12)*ZDs

  # Interzepte
  BFs ~ c(b01, b02)*1

  # Differenzen
  b0d := b02 - b01
  b1d := b12 - b11&#39;

fit_pfad_msa &lt;- sem(model_pfad_msa, StressAtWork,
  group = &#39;sex&#39;)</code></pre>
<pre><code>## [...]
##  Defined Parameters:
##                    Estimate  Std.Err  z-value  P(&gt;|z|)
##     b0d              -0.223    0.310   -0.720    0.472
##     b1d              -0.007    0.090   -0.077    0.939 
## [...]</code></pre>
<p>Wir behalten diese Ergebnisse mal im Hinterkopf und gucken uns die moderierte Regression als Möglichkeit an, die gleiche Frage zu bearbeiten.</p>
<p>Für die moderierte Regression benötigen wir einen Interaktionsterm, der in das Modell aufgenommen werden muss. In unserem Datensatz ist das Geschlecht mit 1 und 2 kodiert, sodass wir hier etwas nachhelfen müssen, bevor wir einen sinnvollen Interaktionsterm bestimmen können:</p>
<pre class="r"><code>StressAtWork$sexDum &lt;- StressAtWork$sex - 1
StressAtWork$Int &lt;- StressAtWork$ZDs * StressAtWork$sexDum</code></pre>
<p>Durch die Subtraktion der 1 wird die Variable in eine <em>dummy-kodierte</em> Variable umgewandelt. Das hat folgende Auswirkungen auf die Variablen, die in die Regression eingehen:</p>
<pre class="r"><code>head(StressAtWork[, c(&#39;ZDs&#39;, &#39;sexDum&#39;, &#39;Int&#39;)])</code></pre>
<pre><code>##        ZDs sexDum      Int
## 1 2.666667      0 0.000000
## 2 3.666667      0 0.000000
## 3 2.333333      0 0.000000
## 4 2.333333      1 2.333333
## 5 3.333333      0 0.000000
## 6 3.666667      0 0.000000</code></pre>
<p>Personen mit einer <code>0</code> auf <code>sexDum</code> erhalten also eine <code>0</code> im Interaktionsterm, Personen mit <code>sexDum = 1</code> hingegen erhalten dort ihren ursprünglichen <code>ZDs</code>-Wert. Diese drei Variablen können wir dann im Rahmen einer moderierten Regression nutzen:</p>
<p><span class="math display">\[\begin{align}
  BF &amp;= \beta_{0} + \beta_{1} ZD + \beta_2 sex + \beta_3 (ZD \cdot sex) + \varepsilon
\end{align}\]</span></p>
<p>die in <code>lavaan</code> folgendermaßen aussieht:</p>
<pre class="r"><code>model_pfad_moderiert &lt;- &#39;BFs ~ ZDs + sexDum + Int&#39;
fit_pfad_moderiert &lt;- sem(model_pfad_moderiert, StressAtWork, meanstructure = T)</code></pre>
<p>Hier haben wir <code>meanstructure = T</code> gewählt, um auch das Interzept von <code>BFs</code> angezeigt zu bekommen. Als Ergebnis dieser moderierten Regression ergibt sich dann:</p>
<pre><code>## [...]
##  Regressions:
##                    Estimate  Std.Err  z-value  P(&gt;|z|)
##   BFs ~                                               
##     ZDs               0.220    0.044    4.986    0.000
##     sexDum           -0.223    0.323   -0.692    0.489
##     Int              -0.007    0.094   -0.074    0.941
## 
## Intercepts:
##                    Estimate  Std.Err  z-value  P(&gt;|z|)
##    .BFs               1.710    0.163   10.523    0.000 
## [...]</code></pre>
<p>Diese Ergebnisse sollten Ihnen außerordentlich bekannt vorkommen, weil wir alle drei Parameterschätzer vor wenigen Zeilen im Multi Gruppen Modell gesehen haben. Das liegt daran, dass beide Ansätze sich sehr leicht ineinander überführen lassen. Für die Gruppe der Frauen (<span class="math inline">\(sex = 0\)</span>):</p>
<p><span class="math display">\[\begin{align}
  BF &amp;= \beta_{0} + \beta_{1} ZD + \beta_2 0 + \beta_3 (ZD \cdot 0) + \varepsilon \\
  BF &amp;= \beta_{0} + \beta_{1} ZD
\end{align}\]</span></p>
<p>und für die Gruppe der Männer (<span class="math inline">\(sex = 1\)</span>):</p>
<p><span class="math display">\[\begin{align}
  BF &amp;= \beta_{0} + \beta_{1} ZD + \beta_2 1 + \beta_3 (ZD \cdot 1) + \varepsilon \\
  BF &amp;= \beta_{0} + \beta_2 + (\beta_{1} + \beta_3) ZD
\end{align}\]</span></p>
<p>Zusammengefasst ergibt sich also:</p>
<table>
<thead>
<tr class="header">
<th>Gruppe</th>
<th>Parameter</th>
<th>MSA</th>
<th>Mod. Reg</th>
<th>Ergebnis</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Frauen</td>
<td>Interzept</td>
<td><span class="math inline">\(\beta_{01}\)</span></td>
<td><span class="math inline">\(\beta_{0}\)</span></td>
<td>1.710</td>
</tr>
<tr class="even">
<td>Frauen</td>
<td>Gewicht</td>
<td><span class="math inline">\(\beta_{11}\)</span></td>
<td><span class="math inline">\(\beta_{1}\)</span></td>
<td>0.220</td>
</tr>
<tr class="odd">
<td>Männer</td>
<td>Interzept</td>
<td><span class="math inline">\(\beta_{02}\)</span></td>
<td><span class="math inline">\(\beta_{0} + \beta_2\)</span></td>
<td>1.487</td>
</tr>
<tr class="even">
<td>Männer</td>
<td>Gewicht</td>
<td><span class="math inline">\(\beta_{12}\)</span></td>
<td><span class="math inline">\(\beta_{1} + \beta_3\)</span></td>
<td>0.213</td>
</tr>
<tr class="odd">
<td>Differenz</td>
<td>Interzept</td>
<td><span class="math inline">\(\beta_{02} - \beta_{01}\)</span></td>
<td><span class="math inline">\(\beta_2\)</span></td>
<td>-0.223</td>
</tr>
<tr class="even">
<td>Differenz</td>
<td>Gewicht</td>
<td><span class="math inline">\(\beta_{12} - \beta_{11}\)</span></td>
<td><span class="math inline">\(\beta_3\)</span></td>
<td>-0.007</td>
</tr>
</tbody>
</table>
<p>Analog hätten wir auch eine Regression mit <code>factor(sex)</code> verwenden können, wie es <a href="/post/quadratische-und-moderierte-regression">in der Bachelor-Sitzung zur quadratischen und moderierten Regression</a> gemacht wurde; allerdings war die Umsetzung in <code>lavaan</code> überaus sinnvoll.</p>
<pre class="r"><code>reg &lt;- lm(BFs ~ factor(sex)*ZDs, data = StressAtWork)
summary(reg)</code></pre>
<pre><code>## 
## Call:
## lm(formula = BFs ~ factor(sex) * ZDs, data = StressAtWork)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -1.31507 -0.50409 -0.05418  0.49895  2.58601 
## 
## Coefficients:
##                   Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)       1.710453   0.163628  10.453  &lt; 2e-16 ***
## factor(sex)2     -0.223201   0.324913  -0.687    0.493    
## ZDs               0.220296   0.044477   4.953 1.22e-06 ***
## factor(sex)2:ZDs -0.006929   0.094498  -0.073    0.942    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.7103 on 301 degrees of freedom
## Multiple R-squared:  0.1233, Adjusted R-squared:  0.1145 
## F-statistic: 14.11 on 3 and 301 DF,  p-value: 1.256e-08</code></pre>
<p>Grafisch sehen wir, dass sich die Regressionsgerade über die Gruppen hinweg nur geringfügig unterscheiden (signifikant war der Unterschied nicht!). Allerdings ist dies eine gängige Form eine solche Interaktion darzustellen:</p>
<p><img src="/post/2021-04-13-MSA_files/figure-html/unnamed-chunk-46-1.png" width="672" /></p>
<p>Abgetragen sehen wir auch die Gruppenunterschiede. Wirklich erkennen tun wir nur ein leichten (nicht signifikanten) Unterschied im Interzept. Der Unterschied in der Slope (der ebenfalls nicht signifikant war), lässt sich höchstens erahnen. Diese Darstellungsform wird Simple Slopes genannt. Für mehr Informationen dazu und wie man das Ganze noch in 3D darstellen kann, können sich Interessierte in der Sitzung zur <a href="/post/quadratische-und-moderierte-regression">moderierten Regression</a> aus dem Bachelor ansehen/wiederholen. Wir bitten ebenfalls darauf zu achten, dass i.d.R. Prädiktoren zentriert werden sollten, wenn mit Interaktionseffekten oder quadratischen Effekten gearbeitet wird. Dies haben wir hier nicht berücksichtigt, um die Sitzung nicht in die Länge zu ziehen.</p>
<p>Dieses Prinzip gilt in der MSA für alle Parameter: wir implizieren eine Interaktion mit der Gruppierungsvariable, wenn wir keine Gleichheit über die Gruppen hinweg annehmen. Im Umkehrschluss gilt also auch: wenn wir eine Gruppenvariable als einen Prädiktor in ein SEM aufnehmen, ohne sie als Gruppierungsvariable in einer MSA einzuarbeiten, behaupten wir, dass es keinerlei Interaktionseffekt gibt. Dies gilt auf der Ebene des Messmodells genauso wie auf der Ebene des Strukturmodells.</p>
<p>Den gesamten R-Code, der in dieser Sitzung genutzt wird, können Sie <a href="https://raw.githubusercontent.com/jpirmer/MSc1_FEI/master/R-Scripts/MSA.R"><svg style="height:0.8em;top:.04em;position:relative;" viewBox="0 0 512 512"><path d="M216 0h80c13.3 0 24 10.7 24 24v168h87.7c17.8 0 26.7 21.5 14.1 34.1L269.7 378.3c-7.5 7.5-19.8 7.5-27.3 0L90.1 226.1c-12.6-12.6-3.7-34.1 14.1-34.1H192V24c0-13.3 10.7-24 24-24zm296 376v112c0 13.3-10.7 24-24 24H24c-13.3 0-24-10.7-24-24V376c0-13.3 10.7-24 24-24h146.7l49 49c20.1 20.1 52.5 20.1 72.6 0l49-49H488c13.3 0 24 10.7 24 24zm-124 88c0-11-9-20-20-20s-20 9-20 20 9 20 20 20 20-9 20-20zm64 0c0-11-9-20-20-20s-20 9-20 20 9 20 20 20 20-9 20-20z"/></svg> hier herunterladen</a>.</p>
<hr />
</div>
<div id="AppendixA" class="section level2">
<h2>Appendix A</h2>
<details>
<p><summary> <strong>MSA zu Fuß</strong> </summary></p>
<p>Wir wollen uns die Invarianztestung auch noch einmal zu Fuß ansehen. Um das ganze abzukürzen, schauen wir uns immer mit <code>fitMeasures</code> nur den <span class="math inline">\(\chi^2\)</span>-Wert, die <span class="math inline">\(df\)</span> sowie den <span class="math inline">\(p\)</span>-Wert an und vergleichen diese mit dem bereits geschätzten Modell aus dem Abschnitt zur <a href="#MSA">MSA</a>.</p>
<div id="konfigurale-invarianz-1" class="section level4">
<h4>Konfigurale Invarianz</h4>
<p>Wir beginnen mit der Spezifikation des konfigural invarianten Modells. Hier muss nichts gleichgesetzt werden. Wir kopieren also einfach das Modell <code>model_sem</code>:</p>
<pre class="r"><code>model_sem &lt;- &#39;
# Messmodelle
ZD =~ zd1 + zd2 + zd6
BOEE =~ bo1 + bo6 + bo12 + bo19

# Strukturmodell
BOEE ~ ZD
BFs ~  BOEE + ZD
&#39;</code></pre>
<p>und schätzen dies anschließend. Wir verwenden das Anhängsel <code>2</code>, um zu zeigen, welches die händisch gleichgesetzte Variante ist:</p>
<pre class="r"><code>fit_sem_sex_konfigural &lt;- sem(model_sem, data = StressAtWork, group = &quot;sex&quot;,
                                     group.equal = c(&quot;&quot;), group.partial = c(&quot;BFs ~ 1&quot;, &quot;BFs ~~*BFs&quot;))
fit_sem_sex_konfigural2 &lt;- sem(model_sem, data = StressAtWork,  group = &quot;sex&quot;)

# chi^2, df, p-Wert
fitmeasures(fit_sem_sex_konfigural, c(&quot;chisq&quot;, &#39;df&#39;, &quot;pvalue&quot;))
fitmeasures(fit_sem_sex_konfigural2, c(&quot;chisq&quot;, &#39;df&#39;, &quot;pvalue&quot;))</code></pre>
<pre><code>## group.equal:</code></pre>
<pre><code>##  chisq     df pvalue 
## 35.803 36.000  0.478</code></pre>
<pre><code>## zu Fuß/händisch:</code></pre>
<pre><code>##  chisq     df pvalue 
## 35.803 36.000  0.478</code></pre>
<p>Wir erkennen keine Unterschiede, was nicht verwunderlich ist. Hier wurde noch nichts gleichgesetzt.</p>
</div>
<div id="metrische-invarianz-1" class="section level4">
<h4>Metrische Invarianz</h4>
<p>Wir müssen nun ein neues Modell spezifizieren, in welchem wir allen Faktorladungen (<span class="math inline">\(\lambda\)</span>s) jeweils über die Gruppen hinweg das gleiche Label geben. Hierbei verwenden wir <code>l</code> als Label für die Faktorladungen und nummerieren alle Faktorladungen nacheinander durch (wie genau hier vorgegangen wird, ist immer den Anwendenden überlassen. Es muss lediglich darauf geachtet werden, nicht mehrfach das gleiche Label für unterschiedliche Parameter zu verwenden, wenn dies nicht explizit gewünscht ist).</p>
<pre class="r"><code>model_sem_metrisch &lt;- &#39;
# Messmodelle
ZD =~ zd1 + c(l1, l1)*zd2 + c(l2, l2)*zd6
BOEE =~ bo1 + c(l3,l3)*bo6 + c(l4, l4)*bo12 + c(l5, l5)*bo19

# Strukturmodell
BOEE ~ ZD
BFs ~  BOEE + ZD&#39;</code></pre>
<pre class="r"><code>fit_sem_sex_metrisch &lt;- sem(model_sem, data = StressAtWork, 
                            group = &quot;sex&quot;,
                            group.equal = c(&quot;loadings&quot;), 
                            group.partial = c(&quot;BFs~1&quot;, &quot;BFs ~~BFs&quot;))
fit_sem_sex_metrisch2 &lt;- sem(model_sem_metrisch, data = StressAtWork,  
                             group = &quot;sex&quot;)

# chi^2, df, p-Wert
fitmeasures(fit_sem_sex_metrisch, c(&quot;chisq&quot;, &#39;df&#39;, &quot;pvalue&quot;))
fitmeasures(fit_sem_sex_metrisch2, c(&quot;chisq&quot;, &#39;df&#39;, &quot;pvalue&quot;))</code></pre>
<pre><code>## group.equal:</code></pre>
<pre><code>##  chisq     df pvalue 
## 37.543 41.000  0.625</code></pre>
<pre><code>## zu Fuß/händisch:</code></pre>
<pre><code>##  chisq     df pvalue 
## 37.543 41.000  0.625</code></pre>
<p>Erneut erkennen wir keine Unterschiede zwischen den Modellen. Beide Vorgehensweisen kommen zum selben Ergebnis!</p>
</div>
<div id="skalare-invarianz-1" class="section level4">
<h4>Skalare Invarianz</h4>
<p>Erneut müssen wir ein neues Modell spezifizieren, in welchem wir jeweils allen Faktorladungen und Interzepten (<span class="math inline">\(\lambda\)</span>s und <span class="math inline">\(\tau\)</span>s) über die Gruppen hinweg das gleiche Label geben. Hierbei verwenden wir <code>tau</code> als Label für die Interzepte und nummerieren alle Interzepte der manifesten Variablen nacheinander durch. Wir fügen außerdem die Effektkodierung ein via <code>ZD ~ c(0, NA)*1</code> und <code>BOEE ~c(0, NA)*1</code>, womit der latente Mittelwert in einer Gruppe auf 0 gesetzt und in der zweiten frei geschätzt wird und erweitern das Modell <code>model_sem_metrisch</code> zu:</p>
<pre class="r"><code>model_sem_skalar &lt;- &#39;
# Messmodelle
ZD =~ zd1 + c(l1, l1)*zd2 + c(l2, l2)*zd6
BOEE =~ bo1 + c(l3,l3)*bo6 + c(l4, l4)*bo12 + c(l5, l5)*bo19

zd1 ~ c(tau1, tau1)*1
zd2 ~ c(tau2, tau2)*1
zd6 ~ c(tau3, tau3)*1

bo1 ~ c(tau4, tau4)*1
bo6 ~ c(tau5, tau5)*1
bo12 ~ c(tau6, tau6)*1
bo19 ~ c(tau7, tau7)*1

# Strukturmodell
BOEE ~ ZD
BFs ~  BOEE + ZD

BOEE ~ c(0, NA)*1
ZD ~ c(0, NA)*1
&#39;</code></pre>
<pre class="r"><code>fit_sem_sex_skalar &lt;- sem(model_sem, data = StressAtWork, 
                          group = &quot;sex&quot;,
                          group.equal = c(&quot;loadings&quot;, &quot;intercepts&quot;), 
                          group.partial = c(&quot;BFs~1&quot;, &quot;BFs ~~BFs&quot;))
fit_sem_sex_skalar2 &lt;- sem(model_sem_skalar, data = StressAtWork,  group = &quot;sex&quot;)

# chi^2, df, p-Wert
fitmeasures(fit_sem_sex_skalar, c(&quot;chisq&quot;, &#39;df&#39;, &quot;pvalue&quot;))
fitmeasures(fit_sem_sex_skalar2, c(&quot;chisq&quot;, &#39;df&#39;, &quot;pvalue&quot;))</code></pre>
<pre><code>## group.equal:</code></pre>
<pre><code>##  chisq     df pvalue 
## 41.694 46.000  0.653</code></pre>
<pre><code>## zu Fuß/händisch:</code></pre>
<pre><code>##  chisq     df pvalue 
## 41.694 46.000  0.653</code></pre>
<p>Erneut erkennen wir keine Unterschiede zwischen den Modellen. Beide Vorgehensweisen kommen zum selben Ergebnis!</p>
</div>
<div id="strikte-invarianz-1" class="section level4">
<h4>Strikte Invarianz</h4>
<p>Wieder müssen wir ein neues Modell spezifizieren, in welchem wir jeweils allen Faktorladungen, Interzepten und Fehlervarianzen (<span class="math inline">\(\lambda\)</span>s, <span class="math inline">\(\tau\)</span>s und <span class="math inline">\(\theta\)</span>s) über die Gruppen hinweg das gleiche Label geben. Hierbei verwenden wir <code>t</code> als Label für die Fehlervarianzen und nummerieren alle Fehlervarianzen der manifesten Variablen nacheinander durch. Wir erweitern das Modell <code>model_sem_skalar</code>.</p>
<pre class="r"><code>model_sem_strikt &lt;- &#39;
# Messmodelle
ZD =~ zd1 + c(l1, l1)*zd2 + c(l2, l2)*zd6
BOEE =~ bo1 + c(l3,l3)*bo6 + c(l4, l4)*bo12 + c(l5, l5)*bo19

zd1 ~ c(tau1, tau1)*1
zd2 ~ c(tau2, tau2)*1
zd6 ~ c(tau3, tau3)*1

bo1 ~ c(tau4, tau4)*1
bo6 ~ c(tau5, tau5)*1
bo12 ~ c(tau6, tau6)*1
bo19 ~ c(tau7, tau7)*1

zd1 ~~ c(t1, t1)*zd1
zd2 ~~ c(t2, t2)*zd2
zd6 ~~ c(t3, t3)*zd6

bo1 ~~ c(t4, t4)*bo1
bo6 ~~ c(t5, t5)*bo6
bo12 ~~ c(t6, t6)*bo12
bo19 ~~ c(t7, t7)*bo19

# Strukturmodell
BOEE ~ ZD
BFs ~  BOEE + ZD

BOEE ~ c(0, NA)*1
ZD ~ c(0, NA)*1
&#39;</code></pre>
<pre class="r"><code>fit_sem_sex_strikt &lt;- sem(model_sem, data = StressAtWork, 
                          group = &quot;sex&quot;,
                          group.equal = c(&quot;loadings&quot;, &quot;intercepts&quot;, &quot;residuals&quot;), 
                          group.partial = c(&quot;BFs~1&quot;, &quot;BFs~~BFs&quot;))
fit_sem_sex_strikt2 &lt;- sem(model_sem_strikt, data = StressAtWork,  group = &quot;sex&quot;)

# chi^2, df, p-Wert
fitmeasures(fit_sem_sex_strikt, c(&quot;chisq&quot;, &#39;df&#39;, &quot;pvalue&quot;))
fitmeasures(fit_sem_sex_strikt2, c(&quot;chisq&quot;, &#39;df&#39;, &quot;pvalue&quot;))</code></pre>
<pre><code>## group.equal:</code></pre>
<pre><code>##  chisq     df pvalue 
## 47.850 53.000  0.674</code></pre>
<pre><code>## zu Fuß/händisch:</code></pre>
<pre><code>##  chisq     df pvalue 
## 47.850 53.000  0.674</code></pre>
<p>Erneut erkennen wir keine Unterschiede zwischen den Modellen. Beide Vorgehensweisen kommen zum selben Ergebnis!</p>
</div>
<div id="vollständige-invarianz-1" class="section level4">
<h4>Vollständige Invarianz</h4>
<p>Zum letzten Mal müssen wir ein neues Modell spezifizieren, in welchem wir allen Parametern des Modells (insgesamt also <span class="math inline">\(\lambda\)</span>s, <span class="math inline">\(\tau\)</span>s, <span class="math inline">\(\theta\)</span>s, <span class="math inline">\(\gamma\)</span>s, <span class="math inline">\(\beta\)</span>s, <span class="math inline">\(\kappa\)</span>s, <span class="math inline">\(\phi\)</span>s und <span class="math inline">\(\psi\)</span>s) über die Gruppen hinweg das gleiche Label geben. Wir müssen die Effektkodierung der latenten Mittelwert wieder herausnehmen und setzen die Mittelwerte in beiden Gruppen auf 0. Als Label verwenden wir wieder die Notation, die wir schon aus den Mediationanalysen kennen (<code>a</code>, <code>b</code> und <code>c</code>). Für die latenten Residualvarianzen führen wir <code>psi</code> als Label ein (hierbei zählen wir weiterhin <code>BFs</code> zu den latenten Variablen). Für die latente Varianz von <code>ZD</code> verwenden wir <code>phi</code> als Label. Für den Mittelwert von <code>BFs</code> verwenden wir ausnahmsweise <code>kappa</code>, da wir <code>BFs</code>, wie zuvor erwähnt, weiter als latente Variable zählen wollen.</p>
<pre class="r"><code>model_sem_voll &lt;- &#39;
# Messmodelle
ZD =~ zd1 + c(l1, l1)*zd2 + c(l2, l2)*zd6
BOEE =~ bo1 + c(l3,l3)*bo6 + c(l4, l4)*bo12 + c(l5, l5)*bo19

zd1 ~ c(tau1, tau1)*1
zd2 ~ c(tau2, tau2)*1
zd6 ~ c(tau3, tau3)*1

bo1 ~ c(tau4, tau4)*1
bo6 ~ c(tau5, tau5)*1
bo12 ~ c(tau6, tau6)*1
bo19 ~ c(tau7, tau7)*1

zd1 ~~ c(t1, t1)*zd1
zd2 ~~ c(t2, t2)*zd2
zd6 ~~ c(t3, t3)*zd6

bo1 ~~ c(t4, t4)*bo1
bo6 ~~ c(t5, t5)*bo6
bo12 ~~ c(t6, t6)*bo12
bo19 ~~ c(t7, t7)*bo19

# Strukturmodell
BOEE ~ c(a, a)*ZD
BFs ~  c(b, b)*BOEE + c(c, c)*ZD

BOEE ~ c(0, 0)*1
ZD ~ c(0, 0)*1
BFs ~ c(kappa, kappa)*1

ZD ~~ c(phi, phi)*ZD
BOEE ~~ c(psi1, psi1)*BOEE
BFs ~~ c(psi2, psi2)*BFs
&#39;</code></pre>
<pre class="r"><code>fit_sem_sex_voll &lt;- sem(model_sem, data = StressAtWork, 
                        group = &quot;sex&quot;,
                        group.equal = c(&quot;loadings&quot;, &quot;intercepts&quot;, &quot;residuals&quot;,
                                        &quot;means&quot;,          # latente Mittelwerte
                                        &quot;lv.variances&quot;,   # latente Varianzen
                                        &quot;lv.covariances&quot;, # latente Kovarianzen
                                        &quot;regressions&quot;))   # Strukturparameter (Regressionsgewichte)
fit_sem_sex_voll2 &lt;- sem(model_sem_voll, data = StressAtWork,  
                         group = &quot;sex&quot;)

# chi^2, df, p-Wert
fitmeasures(fit_sem_sex_voll, c(&quot;chisq&quot;, &#39;df&#39;, &quot;pvalue&quot;))
fitmeasures(fit_sem_sex_voll2, c(&quot;chisq&quot;, &#39;df&#39;, &quot;pvalue&quot;))</code></pre>
<pre><code>## group.equal:</code></pre>
<pre><code>##  chisq     df pvalue 
## 73.140 62.000  0.157</code></pre>
<pre><code>## zu Fuß/händisch:</code></pre>
<pre><code>##  chisq     df pvalue 
## 73.140 62.000  0.157</code></pre>
<p>Erneut erkennen wir keine Unterschiede zwischen den Modellen. Beide Vorgehensweisen kommen zum selben Ergebnis! Zuvor hatten wir gesehen, dass ein Modellvergleich zwischen der strikten und der vollständigen Invarianz zu Gunsten der strikten Invarianz ausfällt. Somit wird die vollständige Invarianz verworfen und wir entscheiden uns final für die strikte Invarianz über das Geschlecht.</p>
</details>
<hr />
</div>
</div>
<div id="literatur" class="section level2">
<h2>Literatur</h2>
<p><a href="https://hds.hebis.de/ubffm/Record/HEB366849158">Eid, M., Gollwitzer, M., &amp; Schmitt, M. (2017).</a> <em>Statistik und Forschungsmethoden</em> (5. Auflage, 1. Auflage: 2010). Weinheim: Beltz.</p>
<p>Gregorich, S. E. (2006). Do self-report instruments allow meaningful comparisons across diverse population groups? Testing measurement invariance using the confirmatory factor analysis framework. <em>Medical Care</em>, <em>44</em>(11), 78-94.</p>
<p>Schermelleh-Engel, K., Moosbrugger, H., &amp; Müller, H. (2003). Evaluation the fit of structural equation models: tests of significance and descriptive goodness-of-fit measures. <em>Methods of Psychological Research Online,</em> <em>8</em>(2), 23-74.</p>
<div id="inhaltliche-literatur" class="section level3">
<h3>Inhaltliche Literatur</h3>
<p>Büssing, A., &amp; Perrar, K.-M. (1992). Die Messung von Burnout. Untersuchung einer deutschen Fassung des Maslach Burnout Inventory (MBI-D) [The measurement of Burnout. The study of a German version of the Maslach Burnout Inventory (MBI-D)]. <em>Diagnostica</em>, <em>38</em>, 328 – 353.</p>
<p>Maslach, C., &amp; Jackson, S.E. (1986). <em>Maslach Burnout Inventory</em> (Vol. 2). Palo Alto, CA: Consulting Psychologists Press.</p>
<p>Mohr, G. (1986). <em>Die Erfassung psychischer Befindensbeeinträchtigungen bei Arbeitern</em> [Assessment of impaired psychological well-being in industrial workers]. Frankfurt am Main, Fermany: Lang.</p>
<p>Semmer, N. K., Zapf, D., &amp; Dunckel, H. (1999). Instrument zur Stressbezogenen Tätigkeitsanalyse (ISTA) [Instrument for stress-oriented task analysis (ISTA)]. In H. Dunkel (Ed.), <em>Handbuch psychologischer Arbeitsanalyseverfahren (pp. 179 – 204)</em>. Zürich, Switzerland: vdf Hochschulverlag an der ETH.</p>
<ul>
<li><small> <em>Blau hinterlegte Autorenangaben führen Sie direkt zur universitätsinternen Ressource.</em></li>
</ul>
</div>
</div>
