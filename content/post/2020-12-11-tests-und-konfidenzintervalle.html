---
title: Tests und Konfidenzintervalle
date: '2020-12-11'
slug: tests-und-konfidenzintervalle
categories:
  - BSc2
tags:
  - t-Test
subtitle: ''
summary: ''
authors: [scheppa-lahyani, nehler]
lastmod: '2022-12-02T19:04:08+01:00'
featured: no
header:
  image: "/header/BSc2_Tests.jpg"
  caption: "[Courtesy of pxhere](https://pxhere.com/de/photo/1240882)"
projects: []
---



<details>
<summary>
Kernfragen dieser Lehreinheit
</summary>
<ul>
<li>Wie berechne ich, ob es einen <strong>Unterschied zwischen einer Stichprobe und der dazugehörigen Population</strong> gibt?</li>
<li>Wann und wie rechne ich einen <strong>z-Test (Einstichproben-Gauss-Test)</strong>? Wie interpretiere ich die Ergebnisse?</li>
<li>Wie bestimme ich das <strong>Konfidenzintervall</strong> des wahren Werts <span class="math inline">\(\mu\)</span>?</li>
<li>Wann und wie rechne ich einen <strong>t-Test</strong>? Welche Voraussetzungen hat dieser? Wie interpretiere ich die Ergebnisse?</li>
<li>Wie gehe ich mit <strong>gerichteten vs. ungerichteten Hypothesen</strong> um?</li>
<li>Was ist Cohen’s <em>d</em> und wie berechne ich es? Wie interpretiere ich die Ergebnisse?</li>
</ul>
</details>
<hr />
<div id="was-erwartet-sie-heute" class="section level2">
<h2>Was erwartet Sie heute?</h2>
<p>Nachdem wir uns die letzten Wochen mit Deskriptivstatistik und Verteilungen beschäftigt haben, wird unser Thema nun Gruppenunterschiede sein. Wir interessieren uns heute vor allem für den Unterschied zwischen dem Mittelwert einer Stichprobe und dem Mittelwert der dazugehörigen Population, aus der die Stichprobe stammt.</p>
</div>
<div id="aufbau-der-sitzung" class="section level2">
<h2>Aufbau der Sitzung</h2>
<ul>
<li>z-Test</li>
<li>Konfidenzintervalle</li>
<li>t-Test</li>
<li>Beispiel am Datensatz</li>
<li>Effektgröße</li>
</ul>
<hr />
</div>
<div id="prep" class="section level2">
<h2>Vorbereitende Schritte</h2>
<p>Der Datensatz wird in diesem Tutorial nicht direkt verwendet, wird aber für das spätere Beispiel gebraucht. Wir beschäftigen uns aber wieder zu Beginn mit dem Einladen, um die Struktur der Tutorials gleich zu lassen. Den Datensatz haben wir bereits unter diesem <a href="/post/fb22.rda"><i class="fas fa-download"></i> Link heruntergeladen</a> und können ihn über den lokalen Speicherort einladen oder Sie können Ihn direkt mittels des folgenden Befehls aus dem Internet in das Environment bekommen. In den vorherigen Tutorials und den dazugehörigen Aufgaben haben wir bereits Änderungen am Datensatz durchgeführt, die hier nochmal aufgeführt sind, um den Datensatz auf dem aktuellen Stand zu haben:</p>
<pre class="r"><code>#### Was bisher geschah: ----

# Daten laden
load(url(&#39;https://pandar.netlify.app/post/fb22.rda&#39;))  

# Nominalskalierte Variablen in Faktoren verwandeln
fb22$geschl_faktor &lt;- factor(fb22$geschl,
                             levels = 1:3,
                             labels = c(&quot;weiblich&quot;, &quot;männlich&quot;, &quot;anderes&quot;))
fb22$fach &lt;- factor(fb22$fach,
                    levels = 1:5,
                    labels = c(&#39;Allgemeine&#39;, &#39;Biologische&#39;, &#39;Entwicklung&#39;, &#39;Klinische&#39;, &#39;Diag./Meth.&#39;))
fb22$ziel &lt;- factor(fb22$ziel,
                        levels = 1:4,
                        labels = c(&quot;Wirtschaft&quot;, &quot;Therapie&quot;, &quot;Forschung&quot;, &quot;Andere&quot;))
fb22$wohnen &lt;- factor(fb22$wohnen, 
                      levels = 1:4, 
                      labels = c(&quot;WG&quot;, &quot;bei Eltern&quot;, &quot;alleine&quot;, &quot;sonstiges&quot;))

# Skalenbildung

fb22$prok2_r &lt;- -1 * (fb22$prok2 - 5)
fb22$prok3_r &lt;- -1 * (fb22$prok3 - 5)
fb22$prok5_r &lt;- -1 * (fb22$prok5 - 5)
fb22$prok7_r &lt;- -1 * (fb22$prok7 - 5)
fb22$prok8_r &lt;- -1 * (fb22$prok8 - 5)

# Prokrastination
fb22$prok_ges &lt;- fb22[, c(&#39;prok1&#39;, &#39;prok2_r&#39;, &#39;prok3_r&#39;,
                          &#39;prok4&#39;, &#39;prok5_r&#39;, &#39;prok6&#39;,
                          &#39;prok7_r&#39;, &#39;prok8_r&#39;, &#39;prok9&#39;, 
                          &#39;prok10&#39;)] |&gt; rowMeans()
# Naturverbundenheit
fb22$nr_ges &lt;-  fb22[, c(&#39;nr1&#39;, &#39;nr2&#39;, &#39;nr3&#39;, &#39;nr4&#39;, &#39;nr5&#39;,  &#39;nr6&#39;)] |&gt; rowMeans()
fb22$nr_ges_z &lt;- scale(fb22$nr_ges) # Standardisiert

# Weitere Standardisierugen
fb22$nerd_std &lt;- scale(fb22$nerd)
fb22$neuro_std &lt;- scale(fb22$neuro)</code></pre>
<hr />
</div>
<div id="lets-start" class="section level1">
<h1>Let’s start</h1>
<p>Der durchschnittliche IQ der Population ist <span class="math inline">\(\mu_0\)</span> = 100 und die Standardabweichung ist 15. Eine Forschungsgruppe glaubt aber, dass dieser gestiegen sei und entscheidet, diese Vermutung an einer zufälligen Stichprobe von 75 Erwachsenen zu testen. Sie finden heraus, dass der durchschnittliche IQ der Stichprobe <span class="math inline">\(\mu_1\)</span> = 105 (<em>SD</em> = 17) ist.</p>
<p><strong>Was wären hier <span class="math inline">\(H_0\)</span> und <span class="math inline">\(H_1\)</span>?</strong></p>
<p><span class="math inline">\(\alpha\)</span> = .05</p>
<p><span class="math inline">\(H_0\)</span>: Der durchschnittliche IQ der Stichprobe ist gleich oder geringer als zuvor.</p>
<p><span class="math inline">\(H_0\)</span>: <span class="math inline">\(\mu_0\)</span> <span class="math inline">\(\geq\)</span> <span class="math inline">\(\mu_1\)</span></p>
<p><span class="math inline">\(H_1\)</span>: Der durchschnittliche IQ der Stichprobe ist höher als zuvor.</p>
<p><span class="math inline">\(H_1\)</span>: <span class="math inline">\(\mu_0\)</span> <span class="math inline">\(&lt;\)</span> <span class="math inline">\(\mu_1\)</span></p>
<p>Die Frage: Reicht dieses deskriptive Ergebnis (100 vs. 105) um daraus schlusszufolgern, dass der durchschnittliche IQ sich verändert hat?</p>
<p><strong>Nein</strong>. Erst mit Hilfe des z- oder t-Tests kann herausgefunden werden, wie (un)wahrscheinlich die beobachtete Diskrepanz (100 vs. 105) ist.</p>
<p>ABER: ob z- oder t-Test zum Einsatz kommt, hängt davon ab, ob neben dem Mittelwert auch die Standardabweichung (<em>SD</em>, <span class="math inline">\(\sigma\)</span>) der Grundgesamtheit bekannt ist.<br />
In diesem Fall ist die <em>SD</em> bekannt, demnach wäre ein z-Test an dieser Stelle anzuwenden.</p>
<div id="z-test" class="section level2">
<h2>z-Test</h2>
<p>Der <strong>z-Test</strong> oder <strong>Einstichproben-Gauss-Test</strong> setzt voraus, dass das Merkmal in der Population, auf die sich die Nullhypothese (<span class="math inline">\(H_0\)</span>) bezieht, normalverteilt ist und der Mittelwert sowie die Standardabweichung bekannt sind.<br />
Des Weiteren verwendet der Gauss-Test grundsätzlich die Standardnormalverteilung als Stichprobenkennwerteverteilung (SKV), deswegen ist er nicht für kleine Stichproben geeignet.<br />
Der Einstichproben-Gauss-Test prüft anhand des arithmetischen Mittels einer Stichprobe, ob der Erwartungswert der zugehörigen Grundgesamtheit ungleich (bzw. kleiner oder größer) als ein vorgegebener Wert ist.</p>
<p>Die Formel für den <strong>empirischen <em>z-</em>Wert</strong> <span class="math inline">\(z_{emp}\)</span> ist:</p>
<p><span class="math display">\[z_{emp} = |\frac{\bar{x} - {\mu}}{\sigma_{\bar{x}}}|\]</span>
wobei sich der Standardfehler (<em>SE</em>) des Mittelwerts wie folgt berechnet:</p>
<p><span class="math display">\[\sigma_{\bar{x}} = {\frac{{\sigma}}{\sqrt{n}}}\]</span></p>
<p>Zunächst legen wir alle für den <em>z-</em>Wert relevanten Informationen in unser Environment ab, wobei wir auch schon den Standardfehler des Mittelwerts (<span class="math inline">\(\sigma_{\bar{x}}\)</span>) berechnen.</p>
<pre class="r"><code>mean_IQ &lt;- 100 #Mean Grundgesamtheit
sd_IQ &lt;- 15 #SD der Grundgesamtheit
sample_size &lt;- 75 #Stichprobengröße
se_IQ &lt;- sd_IQ/sqrt(sample_size) #standard error (SE), also Standardfehler
new_mean_IQ &lt;- 105 #Stichprobenmittelwert
new_sd_IQ &lt;- 17 #SD der Stichprobe (Populationsschätzer)</code></pre>
<p>Demnach wird der empirische <em>z-</em>Wert <span class="math inline">\(z_{emp}\)</span> wie folgt berechnet:</p>
<pre class="r"><code>z_IQ &lt;- abs((new_mean_IQ-mean_IQ)/(sd_IQ/sqrt(sample_size))) #abs() berechnet den Betrag des Ergebnisses
z_IQ</code></pre>
<pre><code>## [1] 2.886751</code></pre>
<p>bzw.</p>
<pre class="r"><code>z_IQ &lt;- abs((new_mean_IQ-mean_IQ)/se_IQ)
z_IQ</code></pre>
<pre><code>## [1] 2.886751</code></pre>
<p>Beachten Sie: es geht immer um den Betrag des Ergebnisses, weshalb wir die Funktion <code>abs()</code> verwenden.</p>
<p>Der empirische <em>z-</em>Wert <span class="math inline">\(z_{emp}\)</span> ist eine Angabe, um wie viele Standardabweichungen der Mittelwerte der SKV (das heißt: um wie viele Standardfehler <em>SE</em>) der Mittelwert der Stichprobe vom Mittelwert der Grundgesamtheit abweicht.<br />
Der beobachtete Stichprobenmittelwert weicht demnach um <strong><span class="math inline">\(z_{IQ}\)</span> = 2.89</strong> <em>SE</em> (nach oben) vom Mittelwert der Grundgesamtheit ab.<br />
Um entscheiden zu können, ob es sich um eine signifikante Abweichung handelt, muss der <strong>kritische <em>z-</em>Wert</strong> <span class="math inline">\(z_{krit}\)</span> bestimmt werden.<br />
Für eine Irrtumswahrscheinlichkeit von 5% und eine einseitige Hypothesentestung wäre dies:</p>
<pre class="r"><code>z_krit &lt;- qnorm(1-.05) #bei einer zweiseitigen Testung würden wir qnorm(1-(.05/2)) verwenden
z_krit</code></pre>
<pre><code>## [1] 1.644854</code></pre>
<p>Der <strong>kritische <em>z-</em>Wert</strong> beträgt demnach <strong><span class="math inline">\(z_{krit}\)</span> = 1.64</strong>. Damit das Ergebnis als signifikant gewertet wird, muss der empirische <em>z-</em>Wert <span class="math inline">\(z_{emp}\)</span> größer sein als der kritsiche <em>z-</em>Wert (<strong><span class="math inline">\(z_{IQ}\)</span> &gt; <span class="math inline">\(z_{krit}\)</span></strong>). Hierfür können wir auch eine logische Abfrage nutzen:</p>
<pre class="r"><code>z_IQ &gt; z_krit</code></pre>
<pre><code>## [1] TRUE</code></pre>
<p>Das Ergebnis <code>TRUE</code> zeigt uns, dass es sich um einen signifikanten Unterschied handelt.
Mit einer Irrtumswahrscheinlichkeit von 5% kann die <span class="math inline">\(H_0\)</span> verworfen werden. Der durchschnittliche IQ der Stichprobe ist höher als der durchschnittliche IQ der Grundgesamtheit.</p>
<div id="weitere-möglichkeit-pnorm" class="section level3">
<h3>Weitere Möglichkeit: <code>pnorm</code></h3>
<p>Wie hoch ist die Wahrscheinlichkeit angesichts der bekannten Normalverteilung diesen oder einen GRÖßEREN (einseitig) empirischen <em>z-</em>Wert <span class="math inline">\(z_{emp}\)</span> zu erreichen?</p>
<pre class="r"><code>p_z_IQ_oneside &lt;- pnorm(z_IQ, lower.tail = FALSE)
p_z_IQ_oneside</code></pre>
<pre><code>## [1] 0.001946209</code></pre>
<p>Wie hoch ist die Wahrscheinlichkeit angesichts der bekannten Normalverteilung diesen oder einen EXTREMEREN (zweiseitig) <em>z-</em>Wert <span class="math inline">\(z_{emp}\)</span> zu erreichen?</p>
<pre class="r"><code>p_z_IQ_twoside &lt;- 2*pnorm(z_IQ, lower.tail = FALSE) #verdoppeln, da zweiseitig
p_z_IQ_twoside</code></pre>
<pre><code>## [1] 0.003892417</code></pre>
<p>Wir erkennen, dass in beiden Fällen der Wert kleiner als .05 (5%) ist. Demnach ist die Wahrscheinlichkeit, diesen Wert (oder einen noch extremeren Wert) per Zufall erhalten zu haben, sehr gering, wenn in die <span class="math inline">\(H_0\)</span> gilt.</p>
<hr />
</div>
</div>
<div id="konfidenzintervalle" class="section level2">
<h2>Konfidenzintervalle</h2>
<p>Wir können auch ein Konfidenzintervall um den wahren Populationsmittelwert <span class="math inline">\(\mu\)</span> bestimmen. Wenn wir z.B. ein 95%-Konfidenzintervall wählen und wir aus der selben Grundgesamtheit wiederholt die selbe Anzahl an Fällen ziehen (unsere Studie also sehr oft wiederholen), dann werden 95% aller Konfidenzintervalle den wahren Populationsmittelwert <span class="math inline">\(\mu\)</span> enthalten.</p>
<p>Dabei gilt:</p>
<p><span class="math display">\[\mu = \bar{x} \pm z_{\frac{\alpha}{2}} * \sigma_{\bar{x}} = \bar{x} \pm z_{\frac{\alpha}{2}}*\frac{\sigma}{\sqrt{n}}\]</span></p>
<p>Ein 95%-Konfidenzintervall ist somit ein Intervall, welches in 95% der Fälle beim Ziehen aus der selben Grundgesamtheit den wahren Wert <span class="math inline">\(\mu\)</span> enthält.</p>
<p>Wenn wir ein 95%-Konfidenzintervall bestimmen wollen, brauchen wir das zugehörige Quantil aus der Standardnormalverteilung - also den <em>z</em>-Wert für <span class="math inline">\(\frac{\alpha}{2}\)</span>. Wir müssen das <span class="math inline">\(\alpha\)</span>-Niveau halbieren, da wir uns momentan beim Bilden eines zweiseitigen Konfidenzintervalles befinden. Wir haben bereits gelernt, dass man Quantile aus der Normalverteilung mit der Funktion <code>qnorm</code> erhalten kann. Die Standardnormalverteilung mitt Mittelwert von 0 und Standardabweichung von 1 ist dabei der Default, aber wir geben die Argumente zur Übung trotzdem selbst an.</p>
<pre class="r"><code>z_quantil_zweiseitig &lt;- qnorm(p = 1-(.05/2), mean = 0, sd = 1)
z_quantil_zweiseitig</code></pre>
<pre><code>## [1] 1.959964</code></pre>
<p>Wir sehen, dass der Wert 1.96 2.5% der Verteilung Richtung unendlich abtrennt. Nun haben wir alle wichtigen Informationen, um ein zweiseitiges Konfidenzintervall um unseren Mittelwert zu legen.</p>
<pre class="r"><code>positive_mean_IQ &lt;- new_mean_IQ+((z_quantil_zweiseitig*sd_IQ)/sqrt(sample_size))
positive_mean_IQ</code></pre>
<pre><code>## [1] 108.3948</code></pre>
<pre class="r"><code>negative_mean_IQ &lt;- new_mean_IQ-((z_quantil_zweiseitig*sd_IQ)/sqrt(sample_size))
negative_mean_IQ</code></pre>
<pre><code>## [1] 101.6052</code></pre>
<pre class="r"><code>conf_interval_IQ &lt;- c(negative_mean_IQ, positive_mean_IQ )
conf_interval_IQ</code></pre>
<pre><code>## [1] 101.6052 108.3948</code></pre>
<p>In diesem Fall liegt der Schätzer für den wahren IQ Wert der Grundgesamtheit <span class="math inline">\(\mu\)</span>, aus der die Stichprobe gezogen wurde, zwischen 101.61 und 108.39. Das bedeutet, dass mit einer Wahrscheinlichkeit von 95% der wahre IQ Wert der Grundgesamtheit in unserem Konfidenzinterall 101.61 und 108.39 liegt.</p>
<p>Das Konfidenzintervall kann auch dafür genutzt werdne, um eine Aussage über die von uns angenommenen Hypothesen zu treffen. Dafür müsste untersucht werden, ob das Intervall den angenommenen Populationsmittelwert (100 enthählt). Wir erinnern uns jedoch, dass in den Hypothesen eine Richtung vorgegeben wurde, weshalb hierfür auch ein einseitiges Konfidenzintervall benötigt werden würde.</p>
<p>Wir wollten also testen, ob der Stichprobenmittelwert größer als der Wert 100 ist. Daher müssen in unserem Konfidenzintervall um den Stichprobenmittelwert eine untere Grenze bestimmmen, während wir es nach oben offen halten können (Richtung unendlich). Die zugehörige Gleichung ändert sich nur geringfügig. Wir müssen den z-Wert nun einseitig bestimmen und dann eben auch nur die untere Grenze unseres Intervalls.</p>
<p><span class="math display">\[\mu = \bar{x} - z_{\alpha} * \sigma_{\bar{x}} = \bar{x} \pm z_{\alpha}*\frac{\sigma}{\sqrt{n}}\]</span></p>
<p>Wir haben bereits gesehen, dass eine Bestimmung des z-Werts durch die Funktion <code>qnorm</code> möglich ist.</p>
<pre class="r"><code>z_quantil_einseitig &lt;- qnorm(p = 1-.05, mean = 0, sd = 1)
z_quantil_einseitig</code></pre>
<pre><code>## [1] 1.644854</code></pre>
<p>Anschließend kann die untere Grenze des Intervalls sehr simpel bestimmt werden.</p>
<pre class="r"><code>new_mean_IQ-((z_quantil_einseitig*sd_IQ)/sqrt(sample_size))</code></pre>
<pre><code>## [1] 102.151</code></pre>
<p>Da das Konfidenzintervall für den Stichprobenmittelwert die 100 <strong>nicht</strong> enthält, ist die Annahme unter der <span class="math inline">\(H_0\)</span> (<span class="math inline">\(\mu \leq 100\)</span>) nicht haltbar. Daher würden wir die <span class="math inline">\(H_0\)</span> in diesem Fall verwerfen. Beachten Sie: Ein einseitiger <em>z</em>-Test bei einer Irrtumswahrscheinlichkeit <span class="math inline">\(\alpha\)</span> und die Besimmung über ein (1-<span class="math inline">\(\alpha\)</span>)-Konfidenzintervall kommen immer zu denselben Schlussfolgerungen.</p>
<hr />
</div>
<div id="t-test" class="section level2">
<h2>t-Test</h2>
<p>Die Bekanntheit des Populationsmittelwertes und der Populationsvarianz ist jedoch ein seltener Fall in der Praxis. Zunächst machen wir eine Erweiterung auf den Fall, dass die Populationsvarianz nicht bekannt ist. Trotzdem soll weiterhin ein <strong>Stichprobenmittelwert</strong> mit einem <strong>bekannten Populationsmittelwert</strong> verglichen werden. Wir werden sehen, dass dies zwar ein paar Veränderungen im Vorgehen und den Gleichungen mit sich bringt, das Prinzip aber erhalten bleibt. Bezeichnet wird das Vorgehen nun als t-Test, den wir im Einstichproben-Fall hier durchführen möchten.</p>
<p>Unterschiedliche Quellen geben an, dass die durchschnittliche Größe der Männer in Deutschland 180 cm beträgt (z.B. <a href="https://www.laenderdaten.info/durchschnittliche-körpergrössen.php" class="uri">https://www.laenderdaten.info/durchschnittliche-körpergrössen.php</a>). Eine Forschungsgruppe vermutet jedoch, dass die Männer in Deutschland eigentlich größer sind und ermittelt von zehn zufällig gezogenen Männer die Körpergröße.</p>
<p>Die Größe der Männer beträgt: 183, 178, 175, 186, 185, 179, 181, 179, 182, 177 (gemessen in cm).</p>
<div id="voraussetzungsprüfung" class="section level3">
<h3>Voraussetzungsprüfung</h3>
<p>Der Test hat die folgenden Voraussetzungen:</p>
<ol style="list-style-type: decimal">
<li>Metrisch skalierte abhängige Variable</li>
<li>Bei <em>n</em> &lt; 30 : Normalverteilung der abhängigen Variable in der Population.</li>
</ol>
<p>Die erste Voraussetzung lässt sich nicht mathematisch sondern theoretisch prüfen. Im Beispiel können wir uns mit der Größe in cm aber zum Glück sehr sicher sein, dass eine metrische Variable vorliegt.</p>
<p>Fehlt also noch die Testung der Normalverteilung der abhängigen Variable. Dafür sollten wir zunächst unsere gemessenen Werte in einen Vektor ablegen.</p>
<pre class="r"><code>men.height &lt;- c(183, 178, 175, 186, 185, 179, 181, 179, 182, 177)</code></pre>
<p>In der letzten Woche haben wir bereits gelernt, dass man die Normalverteilung einer erhobenen Variable graphisch prüfen kann. In einem sog. QQ-Plot werden die unter der Normalverteilung erwarteten Quantile und die tatsächlich beobachteten Quantile in einem Streudiagramm dargestellt. Je deutlicher die Punkte auf der Geraden liegen, desto näher ist die beobachtete Verteilung an der Normalverteilung.</p>
<pre class="r"><code>qqnorm(men.height) 
qqline(men.height)</code></pre>
<p><img src="/post/2020-12-11-tests-und-konfidenzintervalle_files/figure-html/unnamed-chunk-14-1.png" width="672" /></p>
<p>Es sind keine weiten Abweichungen zu erkennen, weshalb wir zunächst davon ausgehen, dass die Vermutung nicht verworfen werden muss.</p>
</div>
<div id="signifikanz-bestimmen" class="section level3">
<h3>Signifikanz bestimmen</h3>
<p>Nun wollen wir inferenzstatistisch prüfen, ob die Vermutung der Forschungsgruppe bestätigt werden kann. Als ersten Schritt berechnen wir den Mittelwert in unserer Stichprobe. Da unsere Alternativhypothese davon handelt, dass der Wert in der Stichprobe größer sein soll, können wir zunächst betrachten, ob dies deskriptiv überhaupt der Fall ist.</p>
<pre class="r"><code>mean.men.height &lt;- mean(men.height)
mean.men.height</code></pre>
<pre><code>## [1] 180.5</code></pre>
<p>Wir sehen, dass der Wert deskriptiv größer ist als die angegebene Größe der Population von 180cm. Der t-Test basiert auf folgender Formel:</p>
<p><span class="math display">\[t_{emp} = |\frac{\bar{x} - {\mu}}{\hat\sigma_{\bar{x}}}|\]</span>
wobei sich der Standardfehler (<em>SE</em>) des Mittelwerts wie folgt zusammensetzt:</p>
<p><span class="math display">\[\hat\sigma_{\bar{x}} = {\frac{{\hat\sigma}}{\sqrt{n}}}\]</span></p>
<p>Da die Varianz in der Population nicht bekannt ist, muss diese mittels Nutzung Varianz der Stichprobe geschätzt werden. Dies funktioniert über die Funktion <code>sd</code>.</p>
<pre class="r"><code>sd.men.height &lt;- sd(men.height)
sd.men.height</code></pre>
<pre><code>## [1] 3.535534</code></pre>
<p>Der Standardfehler des Mittelwerts wird anschließend auf der Basis dieses geschätzten Wertes selber geschätzt und nicht wie im z-Test bestimmt. Dafür brauchen wir als zusätzliche Information noch die Stichprobengröße, die wir beispielsweise über die <code>length</code> unserer Werte bestimmen können.</p>
<pre class="r"><code>n.men.height &lt;- length(men.height)
se.men.height &lt;- sd.men.height/sqrt(n.men.height)</code></pre>
<p>Als letzten Bestandteil unserer Berechnungen kann man jetzt noch den gegebenen Populationsmittelwert in ein Objekt ablegen.</p>
<pre class="r"><code>average.men.height &lt;- 180</code></pre>
<p>Nun haben wir alle Informationen gegeben, um den empirischen <em>t-</em>Wert <span class="math inline">\(t_{emp}\)</span> zu bestimmen:</p>
<pre class="r"><code>t.men.height &lt;- abs((mean.men.height-average.men.height)/se.men.height)
t.men.height</code></pre>
<pre><code>## [1] 0.4472136</code></pre>
<p>Die empirische Prüfgröße (wie auch der Name des Tests) weißt bereits darauf hin, dass wir uns bei der Hypothesenprüfung nicht mehr im Rahmen der Standardnormalverteilung bewegen. Dies liegt daran, dass sich durch das Schätzen der Populationsvarianz keine exakte Standardnormalverteilung mehr ergibt. Stattdessen wird mit einer t-Verteilung gearbeitet, deren genaue Form von der Anzahl der Freiheitsgraden abhängt. Die Unterscheidung zwischen Standardnormalverteilung und der t-Verteilung liegt besonders in den Extrembereichen. Da genau diese jedoch für die inferenzstatistische Testung von Interesse sind, ist die Nutzung der richtigen Verteilung wichtig.</p>
<p>Im Rahmen des t-Testes im Einstichproben-Fall bestimmen sich die Freiheitsgrade mittels <span class="math inline">\(n - 1\)</span>. Der kritische <em>t-</em>Wert <span class="math inline">\(t_{krit}\)</span> für unser Beispiel kann also folgendermaßen bestimmt werden:</p>
<pre class="r"><code>krit.t.men.height &lt;- qt(0.95, df=n.men.height-1) 
krit.t.men.height</code></pre>
<pre><code>## [1] 1.833113</code></pre>
<p>Ist der empirische größer als der kritische <em>t-</em>Wert (<span class="math inline">\(t_{emp} &gt; t_{krit}\)</span>)?</p>
<pre class="r"><code>t.men.height &gt; krit.t.men.height</code></pre>
<pre><code>## [1] FALSE</code></pre>
<p>Der empirische <em>t-</em>Wert wird hier nicht überboten.</p>
<p>Alternativ: Bestimmen des <span class="math inline">\(p\)</span>-Wertes:</p>
<pre class="r"><code>p.t.men.height &lt;- pt(t.men.height, n.men.height-1, lower.tail = F) #einseitige Testung
p.t.men.height</code></pre>
<pre><code>## [1] 0.3326448</code></pre>
<p>Der <em>p</em>-Wert liegt über .05 (<span class="math inline">\(p &gt; \alpha\)</span>).</p>
<p>Die Differenz zwischen dem Mittelwert der Population <span class="math inline">\(\mu\)</span> und dem beobachteten Mittelwert <span class="math inline">\(\bar{x}\)</span> in der Stichprobe ist nicht signifikant. Demnach wird die <span class="math inline">\(H_0\)</span> mit einer Irrtumswahrscheinlichkeit von 5% beibehalten.</p>
</div>
<div id="t-test-mit-t.test-funktion" class="section level3">
<h3>t-test mit <code>t.test</code> Funktion</h3>
<p>Natürlich geht alles auch noch einfacher:</p>
<pre class="r"><code>t.test(men.height, mu=180, alternative=&quot;greater&quot;) #alternative bestimmt, ob die Hypothese gerichtet ist oder nicht. Siehe hierzu ?t.test.</code></pre>
<pre><code>## 
##  One Sample t-test
## 
## data:  men.height
## t = 0.44721, df = 9, p-value = 0.3326
## alternative hypothesis: true mean is greater than 180
## 95 percent confidence interval:
##  178.4505      Inf
## sample estimates:
## mean of x 
##     180.5</code></pre>
<p>Hier haben wir nun alle wichtigen Informationen gebündelt.</p>
<p><code>t</code> = <span class="math inline">\(t_{emp}\)</span> = 0.4472136</p>
<p><code>df</code> = Freiheitsgrade = 9</p>
<p><code>p-value</code> = <span class="math inline">\(p\)</span> = 0.3326448</p>
<p><code>mean of x</code> = <span class="math inline">\(\bar{x}\)</span> = 180.5</p>
<p>Wir erkennen auch hier, dass der empirische <em>p</em>-Wert über .05 liegt (<span class="math inline">\(p &gt; \alpha\)</span>). Demnach wird die <span class="math inline">\(H_0\)</span> mit einer Irrtumswahrscheinlichkeit von 5% beibehalten.</p>
<p>Das 95%ige Konfidenzintervall wird uns ebenfalls ausgegeben. Beachten Sie, dass es sich aufgrund unserer Hypothese um ein einseitiges Intervall handelt (nach oben offen). Basierend auf der Stichprobe liegt der wahre Wert <span class="math inline">\(\mu\)</span> zwischen 178.4505174 und <span class="math inline">\(\infty\)</span>. Man erkennt also, dass der Wert von 180 in diesem Konfidenzintervall liegt, was ebenso bestätigt, dass es keinen Unterschied gibt.</p>
</div>
</div>
<div id="beispiel-mit-unserem-datensatz" class="section level2">
<h2>Beispiel mit unserem Datensatz</h2>
<p><strong>Unterscheidet sich unsere studentische Stichprobe in ihrem Neurotizismuswert von Studierenden im Allgemeinen?</strong>
Wir nehmen an, dass der mittlere Neurotizismuswert in der Population der Studierenden bei <span class="math inline">\(\mu\)</span> = 3.3 liegt.</p>
<ol style="list-style-type: decimal">
<li>Ist die erste Voraussetzung erfüllt?</li>
<li>Normalverteilungsannahme darf verletzt sein (verzerrt das Ergebnis des t-Tests nicht), wenn die Stichprobe mindestens 30 Personen umfasst. Dann gilt der <em>zentrale Grenzwertsatz</em>: “Die Stichprobenkennwertverteilung nähert sich einer Normalverteilung an, selbst wenn diese nicht normalverteilt ist.”</li>
</ol>
<p>Bevor wir in die inferenzstatistische Analyse einsteigen, ist es immer gut, sich einen Überblick über die deskriptiven Werte zu verschaffen. Wir können nun natürlich einfach die bereits gelernten Funktionen zu Mittelwert, Varianz, Minimum, etc. nutzen. Doch gibt es einen schnelleren Weg? Die Basisinstallation von <code>R</code> bietet uns keine Alternative. Jedoch gibt es zusätzliche <em>Pakete</em>, die den Pool an möglichen Funktionen erweitern. Die Logik wird im Folgenden erläutert.</p>
<div id="wie-können-andere-funktionen-in-r-genutzt-werden---library-und-pakete" class="section level3">
<h3>Wie können andere Funktionen in R genutzt werden? - Library und Pakete</h3>
<p>R ist in einer Pakete-Logik aufgebaut. Das liegt daran, dass es immer mehr Funktionen in R gibt, die aber nie jemand alle gleichzeitig brauchen wird. Zur Schonung der Kapazität sind diese Funktionalitäten also in Pakete aufgeteilt. In <em>Basispaketen</em>, die standardmäßig geladen werden (also vorinstalliert sind beim Öffnen von R), sind grundlegende Befehle und Analysen implementiert (Beispiele für solche Basispakete sind <code>base</code>, <code>stats</code>, <code>graphics</code>). Für spezifischere Analysen (also Funktionen) müssen <em>Zusatzpakete</em> teilweise erst installiert, zumindest aber immer per Hand geladen werden (Beispiele sind <code>psych</code>, <code>car</code>, <code>ggplot2</code>). Nur die Funktionen von erst installierten und dann geladenen Paketen können in einem Skript benutzt werden.</p>
<p>Unter dem Reiter <em>Packages</em> wird die <em>Library</em> angezeigt. Hier sind alle Pakete enthalten, die einmal installiert wurden. Pakete müssen ab und zu (per Hand) aktualisiert werden.</p>
<p><img src="/post/library.JPG" /></p>
<p>Sobald Sie eigene Pakete installiert haben, gibt es in dem Reiter <em>Packages</em> die Einteilung in die <em>System Library</em> (also standardmäßig installierte Pakete) und die <em>User Library</em> (von Ihnen installierte Pakete).</p>
<p>Die folgenden Bilder verdeutlichen nochmal das Prinzip vom Installieren und Laden. Bei der Installation von R werden die Basispakete automatisch in die Library installiert. Zusatzpakete müssen mit der Funktion <code>install.packages()</code> mit dem Paketnamen als Argument installiert werden. Hierzu ist meist eine Internetverbindung nötig.</p>
<p><img src="/post/pakete_installieren.JPG" /></p>
<p>Beim Start von R werden die Basispakete automatisch geladen. Zusatzpakete müssen hingegen mit der Funktion <code>library()</code> mit dem Paketnamen als Argument geladen werden.</p>
<p><img src="/post/pakete_laden.JPG" /></p>
<p>Gehen wir das Prinzip an dem Beispielpaket <code>psych</code> durch, das verschiedene Operationen enthält, die in der psychologischen Forschung häufig benötigt werden. Die Installation muss dem Laden des Paketes logischerweise vorausgestellt sein. Wenn R einmal geschlossen wird, müssen alle Zusatzpakete neu geladen, jedoch nicht neu installiert werden.</p>
<pre class="r"><code>install.packages(&#39;psych&#39;)          # installieren</code></pre>
<pre class="r"><code>library(psych)                     # laden</code></pre>
<p>Wir erhalten hier als <em>Warning Message</em> den Hinweis, unter welcher Version das Paket erstellt wurde.
Eine kleine Suche nach Hilfe zu Pakete kann man mit <code>??</code> erhalten.</p>
<pre class="r"><code>??psych                          # Hilfe</code></pre>
<p>Da das Paket <code>psych</code> nun geladen ist, können wir Funktionen aus diesem nutzen. Für unsere Übersicht über deskriptive Maße der Variable <code>neuro</code> gibt es die Funktion <code>describe</code>.</p>
<pre class="r"><code>describe(fb22$neuro)</code></pre>
<pre><code>##    vars   n mean   sd median trimmed  mad  min max range  skew kurtosis   se
## X1    1 159 3.63 0.72   3.75    3.65 0.74 1.25   5  3.75 -0.43     0.09 0.06</code></pre>
<p>Wir bekommen auf einen Schlag sehr viele relevante Informationen über unsere Variable. Der Mittelwert unserer Stichprobe liegt beispielsweise bei 3.6257862. Beachten Sie, dass auch bei <code>describe</code> unter <code>sd</code> die geschätzte Populationsstandardabweichung angegeben wird (wie bei der Basis-Funktion <code>sd</code>). Man müsste sie also umrechnen, um eine Angabe über die Stichprobe machen zu können.</p>
</div>
<div id="hypothesengenerierung" class="section level3">
<h3>Hypothesengenerierung</h3>
<p><strong>Variante 1</strong>:</p>
<p><strong>Ungerichtete <span class="math inline">\(H_1\)</span></strong>: “Der mittlere Neurotizismuswert unserer Stichprobe unterscheidet sich vom mittleren Neurotizismuswert der Studierenden-Population”
–&gt; zweiseitiger t-Test</p>
<p><strong>Ungerichtete <span class="math inline">\(H_0\)</span></strong>: “Der mittlere Neurotizismuswert unserer Stichprobe unterscheidet sich nicht vom mittleren Neurotizismuswert der Studierenden-Population”</p>
<p><strong>Variante 2</strong>:</p>
<p><strong>Gerichtete <span class="math inline">\(H_1\)</span></strong>: “Der mittlere Neurotizismuswert unserer Stichprobe ist höher (niedriger) als der mittlere Neurotizismuswert der Studierenden-Population.”
–&gt; einseitiger t-Test</p>
<p><strong>Gerichtete <span class="math inline">\(H_0\)</span></strong>: “Der mittlere Neurotizismuswert unserer Stichprobe ist gleich oder niedriger (höher) als der mittlere Neurotizismuswert der Studierenden-Population.”</p>
<p>In der Praxis würde man sich für eine der beiden Hypothesen-Varianten (<em>ungerichtet</em> vs. <em>gerichtet</em>) entscheiden. Zu Übungszwecken werden aber beide Varianten durchgespielt.</p>
<pre class="r"><code>t.test(fb22$neuro, mu=3.3) #ungerichtet</code></pre>
<pre><code>## 
##  One Sample t-test
## 
## data:  fb22$neuro
## t = 5.716, df = 158, p-value = 5.295e-08
## alternative hypothesis: true mean is not equal to 3.3
## 95 percent confidence interval:
##  3.513214 3.738358
## sample estimates:
## mean of x 
##  3.625786</code></pre>
<pre class="r"><code>t.test(fb22$neuro, mu=3.3, alternative=&quot;less&quot;) #gerichtet, Stichprobenmittelwert geringer</code></pre>
<pre><code>## 
##  One Sample t-test
## 
## data:  fb22$neuro
## t = 5.716, df = 158, p-value = 1
## alternative hypothesis: true mean is less than 3.3
## 95 percent confidence interval:
##      -Inf 3.720089
## sample estimates:
## mean of x 
##  3.625786</code></pre>
<pre class="r"><code>t.test(fb22$neuro, mu=3.3, alternative=&quot;greater&quot;) #gerichtet, Stichprobenmittelwert höher</code></pre>
<pre><code>## 
##  One Sample t-test
## 
## data:  fb22$neuro
## t = 5.716, df = 158, p-value = 2.648e-08
## alternative hypothesis: true mean is greater than 3.3
## 95 percent confidence interval:
##  3.531484      Inf
## sample estimates:
## mean of x 
##  3.625786</code></pre>
<p><strong>Konfidenzintervall:</strong> Wir erkennen, dass das 95%-ige Konfidenzintervall per Standardeinstellung berechnet wird. Falls wir dieses vergrößern oder verkleinern wollen, müssen wir dies explizit formulieren im Argument <code>conf.level</code>:</p>
<pre class="r"><code>t.test(fb22$neuro, mu=3.3, conf.level=0.99) #99%-iges Konfidenzintervall für die ungerichtete Hypothese</code></pre>
<pre><code>## 
##  One Sample t-test
## 
## data:  fb22$neuro
## t = 5.716, df = 158, p-value = 5.295e-08
## alternative hypothesis: true mean is not equal to 3.3
## 99 percent confidence interval:
##  3.477181 3.774391
## sample estimates:
## mean of x 
##  3.625786</code></pre>
<pre class="r"><code>t.test(fb22$neuro, mu=3.3, alternative=&quot;less&quot;, conf.level=0.99) #99%-iges Konfidenzintervall für die gerichtete Hypothese (Stichprobenmittelwert geringer)</code></pre>
<pre><code>## 
##  One Sample t-test
## 
## data:  fb22$neuro
## t = 5.716, df = 158, p-value = 1
## alternative hypothesis: true mean is less than 3.3
## 99 percent confidence interval:
##      -Inf 3.759737
## sample estimates:
## mean of x 
##  3.625786</code></pre>
<pre class="r"><code>t.test(fb22$neuro, mu=3.3, alternative=&quot;greater&quot;, conf.level=0.99) #99%-iges Konfidenzintervall für die gerichtete Hypothese (Stichprobenmittelwert höher)</code></pre>
<pre><code>## 
##  One Sample t-test
## 
## data:  fb22$neuro
## t = 5.716, df = 158, p-value = 2.648e-08
## alternative hypothesis: true mean is greater than 3.3
## 99 percent confidence interval:
##  3.491836      Inf
## sample estimates:
## mean of x 
##  3.625786</code></pre>
<p>Es zeigt sich, dass der Neurotizismuswert der Studierenden sich von der Studierenden-Population signifikant auf dem 5%-Niveau unterscheidet.</p>
<p><strong>Ungerichtet</strong></p>
<p>Die <span class="math inline">\(H_0\)</span> wird mit einer Irrtumswahrscheinlichkeit von 5% verworfen. Der Neurotizismuswert der Studierenden unterscheidet sich von der Studierenden-Population.</p>
<p><strong>Gerichtet (niedriger)</strong></p>
<p>Die <span class="math inline">\(H_0\)</span> wird mit einer Irrtumswahrscheinlichkeit von 5% beibehalten. Der Neurotizismuswert der Studierenden ist nicht kleiner als der der Studierenden-Population.
<em>Bemerke</em>: Einen gerichteten t-Test, der <span class="math inline">\(\bar{x} &lt; \mu\)</span> untersucht, würde man an dieser Stelle nicht durchführen, da die deskriptiven Werte schon gegen die Hypothese sprechen (da <span class="math inline">\(\bar{x} &gt; \mu\)</span> und nicht <span class="math inline">\(\bar{x} &lt; \mu\)</span>).</p>
<p><strong>Gerichtet (höher)</strong></p>
<p>Die <span class="math inline">\(H_0\)</span> wird mit einer Irrtumswahrscheinlichkeit von 5% verworfen. Der Neurotizismuswert der Studierenden ist höher als der der Studierenden-Population.</p>
<hr />
</div>
</div>
<div id="effektgröße" class="section level2">
<h2>Effektgröße</h2>
<p>Als Effektgröße für Mittelwertsunterschiede kann <strong>Cohen’s d</strong> (Cohen, 1988) verwendet werden.</p>
<p>Cohen, J. (1988). <em>Statistical power analysis for the Behavioral Sciences</em>. Routledge.</p>
<p>Dieses statistische Effektmaß beschreibt die Relevanz von signifikanten Ergebnissen. Zudem kann es verwendet werden, um den Effekt über verschiedene Studien hinweg zu vergleichen.</p>
<p><span class="math display">\[d = |\frac{\bar{x} - {\mu}}{\sigma}|\]</span></p>
<pre class="r"><code>mean_Neuro &lt;- mean(fb22$neuro) #Neurotizismuswert der Stichprobe
sd_Neuro &lt;- sd(fb22$neuro, na.rm = T) #Stichproben SD (Populationsschätzer)
mean_Popu_Neuro &lt;- 3.3 #Neurotizismuswert der Grundgesamtheit
d &lt;- abs((mean_Neuro-mean_Popu_Neuro)/sd_Neuro) #abs(), da Betrag
d</code></pre>
<pre><code>## [1] 0.4533059</code></pre>
<p>Die Effektgröße ist in diesem Fall mit einem Wert von .4533 mittelstark ausgeprägt. Normalerweise sollte die Einordnung der Größe anhand vergleichbarer Studien aus dem selben Bereich durchgeführt werden. Bei völliger Ahnungslosigkeit über relevante Größen gibt es eine Übersicht zur Orientierung. Es gilt nach Cohen (1988):</p>
<p><em>d</em> = 0.2 -&gt; kleiner Effekt</p>
<p><em>d</em> = 0.5 -&gt; mittlerer Effekt</p>
<p><em>d</em> = 0.8 -&gt; großer Effekt</p>
<hr />
</div>
</div>
