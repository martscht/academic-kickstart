---
title: Tests für unabhängige Stichproben
date: '2020-12-16'
slug: gruppenvergleiche-unabhaengig
categories:
  - BSc2
tags:
  - t-Test
  - chi2-Test
  - Wilcoxon-Test
  - unabhängig
subtitle: ''
summary: ''
authors: [koehler, buchholz, irmer]
lastmod: '2021-12-22T17:00:20+01:00'
featured: no
image:
  caption: ''
  focal_point: ''
  preview_only: no
projects: []
---

<script src="/rmarkdown-libs/header-attrs/header-attrs.js"></script>


<details>
<summary>
Kernfragen der Lehreinheiten über Gruppenvergleiche
</summary>
<ul>
<li>Wie fertige ich Deskriptivstatistiken (Grafiken, Kennwerte) zur Veranschaulichung des Unterschieds zwischen zwei Gruppen an?</li>
</ul>
<p><strong>unabhängige Stichproben</strong> (<a href="/post/gruppenvergleiche-unabhaengig">diese Sitzung</a>)</p>
<ul>
<li>Was sind Voraussetzungen des <em>t</em>-Tests und wie prüfe ich sie?</li>
<li>Wie führe ich einen <em>t</em>-Test in R durch?<br />
</li>
<li>Wie berechne ich die Effektstärke Cohen’s <em>d</em>?<br />
</li>
<li>Wie führe ich den Wilcoxon-Tests (auch “Mann-Whitney-Test”, “U-Test”, “Mann-Whitney-U-Test”, “Wilcoxon-Rangsummentest”) in R durch?<br />
</li>
<li>Wie führe ich den Vierfelder-Chi-Quadrat-Tests in R durch?</li>
</ul>
<p><strong>abhängige Stichproben</strong> (<a href="/post/gruppenvergleiche-abhaengig">nächste Sitzung</a>)</p>
<ul>
<li><p>Was sind Voraussetzungen des abhängigen <em>t</em>-Tests und wie prüfe ich sie?</p></li>
<li><p>Wie führe ich einen abhängigen <em>t</em>-Test in R durch?<br />
</p></li>
<li><p>Wie berechne ich den standardisierten Populationseffekt für abhängige Stichproben?<br />
</p></li>
<li><p>Wie führe ich einen abhängigen Wilcoxon-Test in R durch?</p></li>
<li><p>Wie berichte ich statistische Ergebnisse formal?</p></li>
</ul>
</details>
<hr />
<div id="was-erwartet-sie" class="section level2">
<h2>Was erwartet Sie?</h2>
<p>Nachdem wir uns die Woche vor der Weihnachtspause mit dem Unterschied zwischen dem Mittelwert einer Stichprobe und dem Mittelwert der dazugehörigen Population, aus der die Stichprobe stammt, auseinandergesetzt haben, fokussieren wir uns nun auf Unterschiede zwischen zwei Gruppen (also zwei Stichproben). Hierbei muss zwischen unabhängigen und abhängigen Stichproben unterschieden werden.</p>
</div>
<div id="aufbau-der-sitzungen-zu-gruppenvergleichen" class="section level2">
<h2>Aufbau der Sitzungen zu Gruppenvergleichen</h2>
<ol style="list-style-type: decimal">
<li>Fragestellung A: Unterscheidet sich die Anzahl erreichter Punkte in der Statistik-Klausur zwischen Personen, die das Tutorium regelmäßig besucht haben und denen, die nur unregelmäßig da waren? (<em>t-Test und Cohen’s d für unabhängige Stichproben</em>)</li>
<li>Fragestellung B: Sind Studentinnen verträglicher als Studenten? (<em>Wilcoxon-Test für unabhängige Stichproben</em>)</li>
<li>Fragestellung C: Haben Studierende mit Wohnort in Uninähe (Frankfurt) mit gleicher Wahrscheinlichkeit einen Nebenjob wie Studierende, deren Wohnort außerhalb von Frankfurt liegt? (<em>Vierfelder-<span class="math inline">\(\chi^2\)</span>-Test</em>)</li>
<li>Fragestellung D: Sind jüngere Geschwister kooperativer als ältere? (<em>t-Test und Cohen’s d für abhängige Stichproben</em>)</li>
<li>Fragestellung E: Sind jüngere Geschwister kooperativer als ältere? (<em>Wilcoxon-Test für abhängige Stichproben</em>)</li>
</ol>
<p>Fragen 1.-3. werden in dieser Sitzung behandelt. In der nächsten Sitzung schauen wir uns Fragestellung 4.-5. an.</p>
<hr />
</div>
<div id="fragestellung-a-unterscheidet-sich-die-anzahl-erreichter-punkte-in-der-statistik-klausur-zwischen-personen-die-das-tutorium-regelmäßig-besucht-haben-und-denen-die-nur-unregelmäßig-da-waren" class="section level2">
<h2>1. Fragestellung A: Unterscheidet sich die Anzahl erreichter Punkte in der Statistik-Klausur zwischen Personen, die das Tutorium regelmäßig besucht haben und denen, die nur unregelmäßig da waren?</h2>
<div id="vorbereitung-datenerzeugung" class="section level3">
<h3>Vorbereitung: Datenerzeugung</h3>
<p>Mithilfe unseres fb21-Datensatzes lässt sich diese Frage leider nicht beantworten. Wir nutzen daher die Funktion <code>rnorm()</code> und simulieren unsere Daten selbst, d.h. wir erstellen einen neuen Datensatz mit fiktiven Werten.</p>
<p>Dabei nehmen wir für unsere beiden Gruppen (regelmäßige Teilnahme: ja bzw. nein) Folgendes an:</p>
<ul>
<li>Stichprobengröße: 65 bzw. 53</li>
<li>Mittelwert der Punktzahl in der Population: 37.2 bzw. 33.8</li>
<li>Standardabweichung der Punktzahl in der Population: 5.4 bzw. 6.2</li>
</ul>
<pre class="r"><code>set.seed(123) # Vergleichbarkeit

# Datensatz für die Gruppe der regelmäßigen Teilnehmer
gruppe.regel &lt;- data.frame(Gruppe = &quot;ja&quot;,
                           Punktzahl = round(rnorm(n = 65, mean = 37.2, sd = 5.4))) 

# Datensatz für die Gruppe der unregelmäßigen Teilnehmer
gruppe.unreg &lt;- data.frame(Gruppe = &quot;nein&quot;,
                           Punktzahl = round(rnorm(n = 53, mean = 33.8, sd = 6.2)) )

# Datensätze &quot;untereinander&quot; zusammenfügen mit rbind.data.frame()
dataA &lt;- rbind.data.frame(gruppe.regel, gruppe.unreg)  

# Prüfen, ob es geklappt hat
dim(dataA)</code></pre>
<pre><code>## [1] 118   2</code></pre>
<pre class="r"><code>head(dataA)</code></pre>
<pre><code>##   Gruppe Punktzahl
## 1     ja        34
## 2     ja        36
## 3     ja        46
## 4     ja        38
## 5     ja        38
## 6     ja        46</code></pre>
<pre class="r"><code>tail(dataA)</code></pre>
<pre><code>##     Gruppe Punktzahl
## 113   nein        24
## 114   nein        33
## 115   nein        37
## 116   nein        36
## 117   nein        34
## 118   nein        30</code></pre>
<p>Die Daten werden erzeugt mittels <code>rnorm</code> und direkt in einen <code>data.frame</code> geschrieben. Wenn wir dann der Gruppe jeweils eine Ausprägung zuordnen (hier “ja” vs. “nein”), dann entstehen jeweils zwei kleine Datensätze, die aus normalverteilten Punktzahlen bestehen und einem Vektor, der jeweils “ja” und “nein” anzeigt (für die beiden Datensätze <code>gruppe.regel</code> und <code>gruppe.unreg</code>). Fügen wir diese beiden Gruppen zusammen, erhalten wir unseren gewünschten Datensatz. <code>head</code> zeigt die ersten 6 Zeilen und <code>tail</code> die letzten 6 Zeilen. Da wir hier eine zufällige Stichprobe (zum Seed 123) gezogen haben, sollten wir uns die Daten zunächst deskriptiv ansehen, um uns einen Überblick zu verschaffen (auch wenn wir bereits wissen, dass sich die beiden Gruppen in der Population unterscheiden).</p>
</div>
<div id="deskriptivstatistik" class="section level3">
<h3>1.1. Deskriptivstatistik</h3>
<p>Im ersten Schritt wollen wir uns die Daten deskriptiv anschauen. Das geht entweder grafisch oder deskriptiv-statistisch.</p>
<div id="grafisch" class="section level4">
<h4>1.1.1. grafisch</h4>
<p>Mit Hilfe eines Boxplots, bzw. mit Hilfe von Histogrammen lassen sich Unterschiede zwischen Gruppen gut untersuchen. Wir verwenden hier einige Zusatzeinstellungen, um die Grafiken übersichtlicher und auch ein wenig ansprechender zu gestalten.</p>
<pre class="r"><code># Gruppierter Boxplot :
boxplot(dataA$Punktzahl ~ dataA$Gruppe, 
        xlab=&quot;Regelmäßige Tutoriumsteilnahme&quot;, ylab=&quot;Punktzahl Statistikklausur&quot;, 
        las=1, cex.lab=1.5, 
        main=&quot;Tutoriumsteilnahme und Abschneiden in der Statistikklausur&quot;)</code></pre>
<p><img src="/post/2021-09-20-tests-fuer-unabhaengige-stichproben_files/figure-html/unnamed-chunk-2-1.png" width="672" /></p>
<pre class="r"><code># Je ein Histogramm pro Gruppe, untereinander dargestellt, vertikale Linie für den jeweiligen Mittelwert
par(mfrow=c(2,1), mar=c(3,2,2,0))
hist(dataA[(dataA$Gruppe==&quot;ja&quot;), &quot;Punktzahl&quot;], main=&quot;Punktzahl (regelmäßige Teilnahme)&quot;, 
     xlim=c(0,50), xlab=&quot;&quot;, ylab=&quot;&quot;, las=1)
abline(v=mean(dataA[(dataA$Gruppe==&quot;ja&quot;), &quot;Punktzahl&quot;], na.rm=T), col=&quot;aquamarine3&quot;, lwd=3)
hist(dataA[(dataA$Gruppe==&quot;nein&quot;), &quot;Punktzahl&quot;], main=&quot;Punktzahl (unregelmäßige Teilnahme)&quot;, 
     xlim=c(0,50), xlab=&quot;&quot;, ylab=&quot;&quot;, las=1)
abline(v=mean(dataA[(dataA$Gruppe==&quot;nein&quot;), &quot;Punktzahl&quot;], na.rm=T), col=&quot;darksalmon&quot;, lwd=3)</code></pre>
<p><img src="/post/2021-09-20-tests-fuer-unabhaengige-stichproben_files/figure-html/unnamed-chunk-2-2.png" width="672" /></p>
<p><code>dataA$Punktzahl ~ dataA$Gruppe</code> ist die Formelnotation in <code>R</code>, welche Sie im Rahmen der Regression noch genauer kennenlernen werden. Links von der <code>~</code> (Tilde) steht die abhängige Variable (hier die Punktzahl), deren Mittelwertsunterschiede durch die unabhängige Variable (hier Gruppe) rechts der <code>~</code> erklärt werden soll. Der Befehl
<code>par(mfrow=c(2,1), mar=c(3,2,2,0))</code> bewirkt, dass 2 Grafiken untereinander dargestellt werden - und zwar im selben Plot. Spielen Sie doch einmal selbst an den Einstellungen herum und schauen nach, was die Argumente jeweils bewirken!</p>
<p>Damit von nun an nicht immer zwei Grafiken in einem Plot dargestellt werden, können wir die Einstellungen folgendermaßen zurücksetzen:</p>
<pre class="r"><code>dev.off()</code></pre>
<pre><code>## null device 
##           1</code></pre>
</div>
<div id="statistisch" class="section level4">
<h4>1.1.2. statistisch</h4>
<p>Wir können uns auch Deskriptivstatistiken ansehen. Bspw. könnten wir den Mittelwerte oder die SDs etc uns ausgeben lassen. Dazu nehmen wir entweder die <code>summary</code> und wählen die entsprechenden Fälle aus oder wir machen uns das <code>psych</code>-Paket zur nutze. Dieses muss zuvor installiert sein (<code>install.packages</code>). Falls dem so ist, dann kann das Paket mit <code>library</code> eingeladen werden. Die Funktion, die uns interessiert heißt <code>describeBy</code>, welche die Gruppenaufteilung bereits für uns übernimmt.</p>
<pre class="r"><code># umständlich:
summary(dataA$Punktzahl[(dataA$Gruppe==&quot;ja&quot;)])   # Gruppe 1: regelmäßige Teilnahme</code></pre>
<pre><code>##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##   27.00   34.00   37.00   37.32   40.00   49.00</code></pre>
<pre class="r"><code>summary(dataA$Punktzahl[(dataA$Gruppe==&quot;nein&quot;)]) # Gruppe 2: unregelmäßige Teilnahme</code></pre>
<pre><code>##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##   19.00   30.00   34.00   34.04   37.00   47.00</code></pre>
<pre class="r"><code># komfortabler:
library(psych)
describeBy(x = dataA$Punktzahl, group = dataA$Gruppe)        # beide Gruppen im Vergleich </code></pre>
<pre><code>## 
##  Descriptive statistics by group 
## group: ja
##    vars  n  mean   sd median trimmed  mad min max range skew kurtosis   se
## X1    1 65 37.32 4.91     37   37.23 4.45  27  49    22 0.16    -0.52 0.61
## ------------------------------------------------------------ 
## group: nein
##    vars  n  mean  sd median trimmed  mad min max range  skew kurtosis   se
## X1    1 53 34.04 5.6     34   34.07 5.93  19  47    28 -0.02     0.18 0.77</code></pre>
<p>Achtung, bei den hier berichteten <code>sd</code> handelt es sich nicht um die Stichprobenkennwerte, sondern um die Populationsschätzer. Daher berechnen wir die Standardabweichung auch nochmals per Hand:</p>
<pre class="r"><code>punkte.regel &lt;- dataA$Punktzahl[(dataA$Gruppe==&quot;ja&quot;)]
sigma.regel &lt;- sd(punkte.regel)
n.regel &lt;- length(punkte.regel[!is.na(punkte.regel)])
sd.regel &lt;- sigma.regel * (n.regel-1) / n.regel
sd.regel</code></pre>
<pre><code>## [1] 4.830225</code></pre>
<pre class="r"><code>punkte.unreg &lt;- dataA$Punktzahl[(dataA$Gruppe==&quot;nein&quot;)]
sigma.unreg &lt;- sd(punkte.unreg)
n.unreg &lt;- length(punkte.unreg[!is.na(punkte.unreg)])
sd.unreg &lt;- sigma.unreg * (n.unreg-1) / n.unreg
sd.unreg</code></pre>
<pre><code>## [1] 5.492999</code></pre>
</div>
</div>
<div id="voraussetzungsprüfung" class="section level3">
<h3>1.2. Voraussetzungsprüfung</h3>
<p>Damit wir den Ergebnissen des <em>t</em>-Tests trauen können, müssen dessen Voraussetzungen erfüllt sein.</p>
<p><strong>Voraussetzungen für die Durchführung des <em>t</em>-Tests</strong></p>
<ol style="list-style-type: decimal">
<li>die abhängige Variable ist intervallskaliert <span class="math inline">\(\rightarrow\)</span> ok</li>
<li>die einzelnen Messwerte sind voneinander unabhängig (Messwert einer Vpn hat keinen Einfluss auf den Messwert einer anderen) <span class="math inline">\(\rightarrow\)</span> ok<br />
</li>
<li>das untersuchte Merkmal ist in den Grundgesamtheiten der beiden Gruppen normalverteilt <span class="math inline">\(\rightarrow\)</span> (ggf.) optische Prüfung<br />
</li>
<li>Homoskedastizität: Varianzen der Variablen innerhalb der Populationen sind gleich <span class="math inline">\(\rightarrow\)</span> Levene-Test</li>
</ol>
<p><strong>zu 3): Optische Prüfung auf Normalverteilung in den beiden Gruppen</strong></p>
<p>Falls das Merkmal in der Population normalverteilt ist und die Stichproben (so wie hier) groß genug sind, darf diese Voraussetzung generell als erfüllt betrachtet werden (<span class="math inline">\(\rightarrow\)</span> Zentraler Grenzwertsatz). Für kleinere Stichproben empfiehlt sich eine optische Prüfung auf Normalverteilung. Zur optischen Prüfung auf Normalverteilung gibt es mehrere Möglichkeiten, von denen zwei im Folgenden erläutert und dann jeweils durchgeführt werden.</p>
<ul>
<li>Möglichkeit 1: die bei Normalverteilung erwartete Dichtefunktion über das Histogramm legen und so die Übereinstimmung beurteilen<br />
</li>
<li>Möglichkeit 2: QQ-Plot (quantile-quantile): es wird die beobachtete Position eines Messwerts gegen diejenige Position, die unter Gültigkeit der Normalverteilung zu erwarten wäre, abgetragen. Bei Normalverteilung liegen die Punkte (in etwa) auf einer Geraden.</li>
</ul>
<pre class="r"><code># Gruppe 1 (regelmäßige Teilnahme) 
par(mfrow=c(1,2))
punkte.regel &lt;- dataA[(dataA$Gruppe==&quot;ja&quot;), &quot;Punktzahl&quot;]
hist(punkte.regel, xlim=c(0,60), main=&quot;Punktzahl (regelmäßige TN)&quot;, xlab=&quot;&quot;, ylab=&quot;&quot;, las=1, prob=T)
curve(dnorm(x, mean=mean(punkte.regel, na.rm=T), sd=sd(punkte.regel, na.rm=T)), col=&quot;blue&quot;, lwd=2, add=T)
qqnorm(punkte.regel)
qqline(punkte.regel, col=&quot;blue&quot;)</code></pre>
<p><img src="/post/2021-09-20-tests-fuer-unabhaengige-stichproben_files/figure-html/unnamed-chunk-6-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>Mit Hilfe von <code>curve</code> kann eine Linie in eine Grafik eingezeichnet werden. Hierbei bezeichnet <code>x</code> die x-Koordinate. <code>dnorm</code> hatten wir bereits kennen gelernt. Diese Funktion beschreibt die Dichte der Normalverteilung. Die Normalverteilung ist eindeutig durch ihren Mittelwert und durch ihre Standardabweichung definiert. Wir müssen <code>dnorm</code> also jeweils den empirischen Mittelwert sowie empirische Standardabweichung übergeben. Das Argument <code>add = T</code> ist nötig, da sonst ein neuer Plot für die Kurve erstellt wird. So wird sie dem Histogramm hinzugefügt. Damit die Dichte sichtbar ist, muss im Histogramm zuvor das Argument <code>prob = T</code> gewählt werden. Ansonsten werden absolute Häufigkeiten, anstatt von relativen Häufigkeiten abgetragen. Den <code>qqnorm</code> Befehl hatten wir bereits auch kennen gelernt. Mit <code>qqline</code> erhalten wir die nötige Linie, auf welcher die Punkte einigermaßen liegen müssen, damit sie als normalverteilt einzustufen sind.</p>
<p><span class="math inline">\(\rightarrow\)</span> Normalverteilung kann für Gruppe 1 (regelmäßige Teilnahme) angenommen werden</p>
<p>Wir wiederholen die Befehle von zuvor auch für die zweite Gruppe:</p>
<pre class="r"><code># Gruppe 2 (unregelmäßige Teilnahme)
par(mfrow=c(1,2))
punkte.unreg &lt;- dataA[(dataA$Gruppe==&quot;nein&quot;), &quot;Punktzahl&quot;]
hist(punkte.unreg, xlim=c(0,60), main=&quot;Punktzahl (unregmäßige TN)&quot;, xlab=&quot;&quot;, ylab=&quot;&quot;, las=1, prob=T)
curve(dnorm(x, mean=mean(punkte.unreg, na.rm=T), sd=sd(punkte.unreg, na.rm=T)), col=&quot;blue&quot;, lwd=2, add=T)
qqnorm(punkte.unreg)
qqline(punkte.unreg, col=&quot;blue&quot;)</code></pre>
<p><img src="/post/2021-09-20-tests-fuer-unabhaengige-stichproben_files/figure-html/unnamed-chunk-7-1.png" width="672" style="display: block; margin: auto;" /></p>
<p><span class="math inline">\(\rightarrow\)</span> Normalverteilung kann auch für Gruppe 2 (unregelmäßige Teilnahme) angenommen werden</p>
<p>Damit von nun an nicht immer zwei Grafiken in einem Plot dargestellt werden, können wir die Einstellungen folgendermaßen zurücksetzen:</p>
<pre class="r"><code>dev.off()</code></pre>
<pre><code>## null device 
##           1</code></pre>
<p><strong>zu 4) Test auf Homoskedastizität (Levene-Test)</strong></p>
<p>Das Hypothesenpaar im Levene-Test lautet:</p>
<ul>
<li><span class="math inline">\(H_0\)</span>: Homoskedastizität ist gegeben.<br />
</li>
<li><span class="math inline">\(H_1\)</span>: Homoskedastizität ist nicht gegeben.</li>
</ul>
<p>Ein nicht-signifikantes Ergebnis (<em>p</em> &gt; .05) zeigt also Homoskedastizität an. Den Levene-Test können wir mit Hilfe des <code>car</code>-Pakets durchführen (dieses muss natürlich vorher installiert sein). Die nötige Funktion heißt <code>leveneTest</code>. Sie nimmt eine Formel entgegen, die die Punktzahl auf die Gruppen aufteilt. Links von der <code>~</code> (Tilde) steht die abhängige Variable (hier die Punktzahl), deren Mittelwertsunterschiede durch die unabhängige Variable (hier Gruppe) rechts der <code>~</code> erklärt werden soll.</p>
<pre class="r"><code>library(car)
leveneTest(dataA$Punktzahl ~ dataA$Gruppe)</code></pre>
<pre><code>## Levene&#39;s Test for Homogeneity of Variance (center = median)
##        Df F value Pr(&gt;F)
## group   1  0.4986 0.4815
##       116</code></pre>
<p><em>F</em>(1,116) = 0.499, <em>p</em> = .482 <span class="math inline">\(\rightarrow\)</span> Das Ergebnis ist nicht signifikant, die <span class="math inline">\(H_0\)</span> wird beibehalten. Homoskedastizität wird angenommen.</p>
<p>Für Fragestellung A sind somit alle Voraussetzungen für die Durchführung des <em>t</em>-Test erfüllt. :-) Hätte der Levene-Test keine Homoskedastizität angezeigt (<em>p</em> &lt;. 05), so kann der <em>t</em>-Test trotzdem, nach Korrektur der Freiheitsgrade (“Welch-Korrektur”), durchgeführt werden (s.u.).</p>
</div>
<div id="inferenzstatistik-t-test" class="section level3">
<h3>1.3. Inferenzstatistik: <em>t</em>-Test</h3>
<p>Zur Erinnerung:</p>
<blockquote>
<p>Fragestellung A: “Unterscheidet sich die Anzahl erreichter Punkte in der Statistik-Klausur zwischen Personen, die das Tutorium regelmäßig besucht haben und denen, die nur unregelmäßig da waren?”</p>
</blockquote>
<p><span class="math inline">\(\rightarrow\)</span> Fragestellung ist ungerichtet, erfordert also auch ungerichtete Hypothesen.</p>
<p><strong>Hypothesen</strong></p>
<ul>
<li>Art des Effekts: Unterschiedshypothese</li>
<li>Richtung des Effekts: Ungerichtet</li>
<li>Größe des Effekts: Unspezifisch</li>
</ul>
<p>Hypothesenpaar (inhaltlich):</p>
<ul>
<li><span class="math inline">\(H_0\)</span>: Studierende, die regelmäßig am Tutorium teilgenommen haben, unterscheiden sich nicht in der Punktzahl ihrer Statistikklausur von jenen, die nur unregelmäßig da waren.<br />
</li>
<li><span class="math inline">\(H_1\)</span>: Studierende, die regelmäßig am Tutorium teilgenommen haben, unterscheiden sich in der Punktzahl ihrer Statistikklausur von jenen, die nur unregelmäßig da waren.</li>
</ul>
<p>Hypothesenpaar (statistisch):</p>
<ul>
<li><span class="math inline">\(H_0\)</span>: <span class="math inline">\(\mu_\text{regelmäßig} = \mu_\text{unregelmäßig}\)</span> bzw. <span class="math inline">\(\mu_\text{regelmäßig} - \mu_\text{unregelmäßig} = 0\)</span><br />
</li>
<li><span class="math inline">\(H_1\)</span>: <span class="math inline">\(\mu_\text{regelmäßig} \ne \mu_\text{unregelmäßig}\)</span> bzw. <span class="math inline">\(\mu_\text{regelmäßig} - \mu_\text{unregelmäßig} \ne 0\)</span></li>
</ul>
<p><strong>Signifikanzniveau</strong></p>
<p>Das Signifikanzniveau muss vor der Untersuchung festgelegt werden. Es soll hier 5% betragen. <span class="math inline">\(\rightarrow \alpha=.05\)</span></p>
<p><strong>Durchführung des <em>t</em>-Tests in R: Funktion <code>t.test()</code></strong></p>
<p>Wir hatten im Rahmen des Einstichproben-<em>t</em>-Tests bereits die Funktion <code>t.test</code> kennengelernt. Diese nutzen wir wieder. Wir übergeben dieser wieder die Formel, die wir bereits im Boxplot und im Levene-Test verwendet haben. Außerdem wählen wir einige Zusatzargumente, die dann zum Zweistichproben-<em>t</em>-Test für unabhängige Stichproben führt:</p>
<pre class="r"><code>t.test(dataA$Punktzahl ~ dataA$Gruppe,  # abhängige Variable ~ unabhängige Variable
      paired = FALSE,                   # Stichproben sind unabhängig 
      alternative = &quot;two.sided&quot;,        # zweiseitige Testung (Default)
      var.equal = TRUE,                 # Homoskedastizität liegt vor (-&gt; Levene-Test)
      conf.level = .95)                 # alpha = .05 (Default)</code></pre>
<pre><code>## 
##  Two Sample t-test
## 
## data:  dataA$Punktzahl by dataA$Gruppe
## t = 3.3957, df = 116, p-value = 0.0009381
## alternative hypothesis: true difference in means between group ja and group nein is not equal to 0
## 95 percent confidence interval:
##  1.369061 5.201622
## sample estimates:
##   mean in group ja mean in group nein 
##           37.32308           34.03774</code></pre>
<p><em>t</em>(<em>df</em> = 116, zweis.) = 3.396, <em>p</em> &lt; .001 <span class="math inline">\(\rightarrow\)</span> signifikant, <span class="math inline">\(H_0\)</span> wird verworfen, <span class="math inline">\(H_1\)</span> wird angenommen.</p>
</div>
<div id="berechnung-der-effektstärke-cohens-d" class="section level3">
<h3>1.4. Berechnung der Effektstärke Cohen’s <em>d</em></h3>
<p>Wir wissen nun, dass sich die Mittelwertsdifferenz auf die Population verallgemeinern lässt. Um das Ergebnis besser einordnen zu können, greifen wir auf Effektstärken zurück: Cohen’s <em>d</em> gibt den standardisierten Mittelwertsunterschied zwischen zwei Gruppen an. “Standardisiert” bedeutet, dass wir uns nicht mehr auf der Originalmetrik befinden (hier: Punkte in der Statistikklausur), sondern mit Standardabweichungen arbeiten. Ein Wert von 1 zeigt also an, dass sich die Gruppenmittelwerte um eine Standardabweichung voneinander unterscheiden. Es berechnet sich wie folgt:</p>
<p><span class="math display">\[ d = \frac{\bar{x}_1-\bar{x}_2} {\hat{\sigma}_{inn}} \]</span>
wobei</p>
<p><span class="math display">\[ {\hat{\sigma}_{inn}} = \sqrt{ \frac{{\hat{\sigma}_1^2}*(n_1-1) + {\hat{\sigma}^2_2}*(n_2-1)} {(n_1-1) + (n_2-1)} }\]</span>
Cohen (1988) hat folgende Konventionen zur Beurteilung der Effektstärke <em>d</em> vorgeschlagen, die man heranziehen kann, um den Effekt “bei kompletter Ahnungslosigkeit” einschätzen zu können (wissen wir mehr über den Sachverhalt, so sollten Effektstärken lieber im Bezug zu anderen Studienergebnissen interpretiert werden):</p>
<table>
<thead>
<tr class="header">
<th align="center"><em>d</em></th>
<th align="center">Interpretation</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">~ .2</td>
<td align="center">kleiner Effekt</td>
</tr>
<tr class="even">
<td align="center">~ .5</td>
<td align="center">mittlerer Effekt</td>
</tr>
<tr class="odd">
<td align="center">~ .8</td>
<td align="center">großer Effekt</td>
</tr>
</tbody>
</table>
<p><strong>Berechnung von Hand</strong></p>
<p>Wir führen die Berechnung von Cohen’s <em>d</em> zunächst mit Hand durch. Dafür speichern wir uns die nötigen Größen ab und wenden dann die präsentierte Formel an:</p>
<pre class="r"><code>punkte.regel &lt;- dataA[(dataA$Gruppe==&quot;ja&quot;), &quot;Punktzahl&quot;]
mw.regel &lt;- mean(punkte.regel, na.rm=T)
n.regel &lt;- length(punkte.regel[!is.na(punkte.regel)])
sigma.regel &lt;- var(punkte.regel) * (n.regel - 1)

punkte.unreg &lt;- dataA[(dataA$Gruppe==&quot;nein&quot;), &quot;Punktzahl&quot;]
mw.unreg &lt;- mean(punkte.unreg, na.rm=T)
n.unreg &lt;- length(punkte.unreg[!is.na(punkte.unreg)])
sigma.unreg &lt;- var(punkte.unreg) * (n.unreg - 1)

sigma.inn &lt;- sqrt((sigma.regel + sigma.unreg) / (n.regel-1 + n.unreg-1))

d1 &lt;- (mw.regel - mw.unreg) / sigma.inn
d1</code></pre>
<pre><code>## [1] 0.6284493</code></pre>
<p><strong>Berechnung mit Funktion <code>cohen.d()</code></strong></p>
<p>Natürlich gibt es in <code>R</code> auch eine angenehmere Alternative:</p>
<pre class="r"><code>#alternativ:
#install.packages(&quot;effsize&quot;)
library(&quot;effsize&quot;)</code></pre>
<pre class="r"><code>d2 &lt;- cohen.d(dataA$Punktzahl, dataA$Gruppe)
d2</code></pre>
<pre><code>## 
## Cohen&#39;s d
## 
## d estimate: 0.6284493 (medium)
## 95 percent confidence interval:
##     lower     upper 
## 0.2530381 1.0038605</code></pre>
<p>Die Effektstärke für diesen Mittelwertsunterschied beträgt <em>d</em> = 0.628.</p>
</div>
<div id="ergebnisinterpretation" class="section level3">
<h3>1.5. Ergebnisinterpretation</h3>
<p>Es wurde untersucht, ob sich Studierende, die regelmäßig am Tutorium teilgenommen haben und diejenigen, die nur unregelmäßig da waren, in der von ihnen in der Statistikklausur erreichten Punktzahl unterscheiden. Tatsächlich findet sich deskriptiv ein Unterschied: regelmäßig Teilnehmende weisen einen durchschnittlichen Wert von 37.323 (<em>SD</em> = 4.83) auf, während die unregelmäßig Teilnehmenden einen Wert von 34.038 (<em>SD</em> = 5.493) aufweisen. Dies entspricht einem nach Cohens Konvention (1988) mittleren bis großen Effekt (<em>d</em> = 0.628).</p>
<p>Zur Beantwortung der Fragestellung wurde ein <em>t</em>-Test unter Annahme von Homoskedastizität (<em>F</em>(1,116) = 0.499, <em>p</em> = .482) durchgeführt. Der Gruppenunterschied ist signifikant (<em>t</em>(<em>df</em> = 116, zweis.) = 3.396, <em>p</em> &lt; .001), somit wird die Nullhypothese verworfen und die Alternativhypothese angenommen. Studierende, die regelmäßig am Tutorium teilgenommen haben, unterscheiden sich im Ergebnis der Statistikklausur (erreichte Punktzahl) bedeutsam von jenen, die nur unregelmäßig da waren.</p>
<hr />
</div>
</div>
<div id="fragestellung-b-sind-studentinnen-verträglicher-als-studenten" class="section level2">
<h2>2. Fragestellung B: Sind Studentinnen verträglicher als Studenten?</h2>
<p>Wir widmen uns nun der 2. Fragestellung.</p>
<div id="vorbereitung-daten-einlesen-daten-aufbereiten" class="section level3">
<h3>2.1 Vorbereitung (Daten einlesen, Daten aufbereiten)</h3>
<p>Zunächst müssen wir die Daten entsprechend vorbereiten.</p>
<pre class="r"><code>setwd(&quot;...&quot;)
load(&quot;fb21.rda&quot;)</code></pre>
<p>Das Geschlecht <code>geschl</code> sollte als Faktor vorliegen. Falls Sie das Geschlecht bereits in einen Faktor mit benannten <code>levels</code> umgewandelt haben, dann können Sie dies in der Regel nicht noch einmal tun. Deswegen ist es sinnvoll, zunächst zu prüfen, ob das Geschlecht ein <code>factor</code> ist oder nicht. Das können wir mit <code>is.factor</code> machen. Diese Funktion gibt uns einen boolschen Wert (<code>TRUE</code> oder <code>FALSE</code>) wieder und beantwortet damit unsere Frage, ob das Geschlecht ein <code>factor</code> ist oder nicht.</p>
<pre class="r"><code>is.factor(fb21$geschl)</code></pre>
<pre><code>## [1] FALSE</code></pre>
<p>Da wir den Datensatz “ganz frisch” eingeladen haben, ist dies nicht der Fall. Demnach können wir ganz unbedacht den <code>factor</code> nach unseren Wünschen generieren:</p>
<pre class="r"><code>fb21$geschl &lt;- factor(fb21$geschl,          
                        levels = c(1, 2, 3),
                        labels = c(&#39;weiblich&#39;, &#39;maennlich&#39;, &#39;anderes&#39;))</code></pre>
<p>Variable <code>geschl</code> liegt (nun) als Faktor vor.</p>
<pre class="r"><code>is.factor(fb21$geschl)</code></pre>
<pre><code>## [1] TRUE</code></pre>
<p>Seine <code>levels</code> lauten</p>
<pre class="r"><code>levels(fb21$geschl)</code></pre>
<pre><code>## [1] &quot;weiblich&quot;  &quot;maennlich&quot; &quot;anderes&quot;</code></pre>
</div>
<div id="deskriptivstatistik-1" class="section level3">
<h3>2.2. Deskriptivstatistik</h3>
<p>Nun folgt wieder die deskriptive Untersuchung, ob Unterschiede über das Geschlecht vorliegen.</p>
<div id="grafisch-1" class="section level4">
<h4>2.2.1. grafisch</h4>
<p>Wir beginnen mit einer grafischen Auseinandersetzung mit der Fragestellung.</p>
<pre class="r"><code>table(fb21$geschl)</code></pre>
<pre><code>## 
##  weiblich maennlich   anderes 
##        80        31         1</code></pre>
<p>Insgesamt gibt es nur eine Person, welche die Option “anderes” ausgewählt hat. Leider lässt sich über einen Datenpunkt allein keine Varianz bestimmen und auch keine Inferenzstatistik betreiben. Aus diesem Grund müssen wir uns hier auf “maennlich” und “weiblich” beschränken und verwenden im Folgenden den gekürzten Datensatz <code>dataB</code>:</p>
<pre class="r"><code># nur Männer und Frauen auswählen:
dataB &lt;- fb21[ (fb21$geschl==&quot;maennlich&quot;|fb21$geschl==&quot;weiblich&quot;), ]  
dataB$geschl &lt;- droplevels(dataB$geschl) # levels aus den Datensatz entfernen, 
# die keine Erhebungen haben

# Gruppierter Boxplot:
boxplot(dataB$vertr ~ dataB$geschl, 
        xlab=&quot;Geschlecht&quot;, ylab=&quot;Verträglichkeit&quot;, 
        las=1, cex.lab=1.5, 
        main=&quot;Verträglichkeit je nach Geschlecht&quot;)</code></pre>
<p><img src="/post/2021-09-20-tests-fuer-unabhaengige-stichproben_files/figure-html/unnamed-chunk-21-1.png" width="672" /></p>
<p>Graphisch ist kein Unterschied zu erkennen.</p>
</div>
<div id="statistisch-1" class="section level4">
<h4>2.2.2. statistisch</h4>
<p>Nun schauen wir uns das Ganze wieder deskriptivstatistisch an.</p>
<pre class="r"><code>describeBy(dataB$vertr, dataB$geschl) # beide Gruppen im Vergleich</code></pre>
<pre><code>## 
##  Descriptive statistics by group 
## group: weiblich
##    vars  n mean   sd median trimmed  mad  min max range  skew kurtosis   se
## X1    1 80 4.15 0.52   4.25    4.18 0.37 2.75   5  2.25 -0.48    -0.24 0.06
## ------------------------------------------------------------ 
## group: maennlich
##    vars  n mean   sd median trimmed  mad min max range skew kurtosis   se
## X1    1 31 4.18 0.52   4.25    4.21 0.37   3   5     2 -0.5    -0.03 0.09</code></pre>
<pre class="r"><code># Interquartilsbereich (IBQ) über summary()
summary( dataB[(dataB$geschl==&quot;weiblich&quot;), &quot;vertr&quot;])</code></pre>
<pre><code>##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA&#39;s 
##   2.750   3.750   4.250   4.153   4.500   5.000       2</code></pre>
<pre class="r"><code>summary( dataB[(dataB$geschl==&quot;maennlich&quot;), &quot;vertr&quot;]) </code></pre>
<pre><code>##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA&#39;s 
##   3.000   4.000   4.250   4.177   4.500   5.000       2</code></pre>
<p>Deskriptiv weist die Gruppe der männlichen Studierenden den gleichen Median auf wie die Gruppe der weiblichen Studierenden. Nur die Interquartilbereiche unterscheiden sich leicht.</p>
</div>
</div>
<div id="voraussetzungsprüfung-1" class="section level3">
<h3>2.3. Voraussetzungsprüfung</h3>
<p>Um diese Beobachtung inferenzstatistisch zu untermauern, müssen wir den richtigen Test durchführen. Wir beginnen damit die Voraussetzungen des <em>t</em>-Tests zu untersuchen:</p>
<p><strong>Voraussetzungen für die Durchführung des <em>t</em>-Tests:</strong></p>
<ol style="list-style-type: decimal">
<li>die abhängige Variable ist intervallskaliert <span class="math inline">\(\rightarrow\)</span> ok<br />
</li>
<li>die einzelnen Messwerte sind voneinander unabhängig (Messwert einer Vpn hat keinen Einfluss auf den Messwert einer anderen) <span class="math inline">\(\rightarrow\)</span> ok<br />
</li>
<li>das untersuchte Merkmal ist in den Grundgesamtheiten der beiden Gruppen normalverteilt <span class="math inline">\(\rightarrow\)</span> (ggf.) optische Prüfung<br />
</li>
<li>Homoskedastizität: Varianzen der Variablen innerhalb der Populationen sind gleich <span class="math inline">\(\rightarrow\)</span> Levene-Test</li>
</ol>
<p><strong>zu 3): Optische Prüfung auf Normalverteilung in den beiden Gruppen</strong></p>
<p>(Hinweis: In diesem Datenbeispiel betragen die Stichprobengrößen 80 (Gruppe “weiblich”) bzw. 31 (Gruppe “männlich”). Unter der Annahme von Normalverteilung des Merkmals “Verträglichkeit” in der Population könnte man bei diesen Stichprobengrößen von Normalverteilung ausgehen, ohne dies explizit zu prüfen, und einen <em>t</em>-Test durchführen (s.o.). Aus didaktischen Gründen betrachten wir hier die Normalverteilungsannahme als verletzt und führen daher den Wilcoxon-Test durch.)</p>
<pre class="r"><code>#Gruppe 1 (weiblich) 
par(mfrow=c(1,2))
vertr.w &lt;- dataB[(dataB$geschl==&quot;weiblich&quot;), &quot;vertr&quot;]
hist(vertr.w, xlim=c(1,7), ylim=c(0,1), main=&quot;Verträglichkeit (weiblich)&quot;, xlab=&quot;&quot;, ylab=&quot;&quot;, las=1, prob=T)
curve(dnorm(x, mean=mean(vertr.w, na.rm=T), sd=sd(vertr.w, na.rm=T)), col=&quot;red&quot;, lwd=2, add=T)
qqnorm(vertr.w)
qqline(vertr.w, col=&quot;red&quot;)</code></pre>
<p><img src="/post/2021-09-20-tests-fuer-unabhaengige-stichproben_files/figure-html/unnamed-chunk-23-1.png" width="672" style="display: block; margin: auto;" /></p>
<p><span class="math inline">\(\rightarrow\)</span> Entscheidung: Normalverteilung in Gruppe 1 (weiblich) ist einigermaßen gegeben <span class="math inline">\(\rightarrow\)</span> spricht für t-Test</p>
<pre class="r"><code>#Gruppe 2 (männlich)
par(mfrow=c(1,2))
vertr.m &lt;- dataB[(dataB$geschl==&quot;maennlich&quot;), &quot;vertr&quot;]
hist(vertr.m, xlim=c(1,7), ylim=c(0,.8), main=&quot;Verträglichkeit (männlich)&quot;, xlab=&quot;&quot;, ylab=&quot;&quot;, las=1, prob=T)
curve(dnorm(x, mean=mean(vertr.m, na.rm=T), sd=sd(vertr.m, na.rm=T)), col=&quot;red&quot;, lwd=2, add=T)
qqnorm(vertr.m)
qqline(vertr.m, col=&quot;red&quot;)</code></pre>
<p><img src="/post/2021-09-20-tests-fuer-unabhaengige-stichproben_files/figure-html/unnamed-chunk-24-1.png" width="672" style="display: block; margin: auto;" /></p>
<p><span class="math inline">\(\rightarrow\)</span> Entscheidung: Normalverteilung in Gruppe 2 (männlich) ist nicht gegeben <span class="math inline">\(\rightarrow\)</span> spricht für Wilcoxon-Test</p>
<p><strong>zu 4) Test auf Homoskedastizität (Levene-Test)</strong></p>
<p>Das Hypothesenpaar im Levene-Test lautet:</p>
<ul>
<li><span class="math inline">\(H_0\)</span>: Homoskedastizität ist gegeben.<br />
</li>
<li><span class="math inline">\(H_1\)</span>: Homoskedastizität ist nicht gegeben.</li>
</ul>
<p>Ein nicht-signifikantes Ergebnis (<em>p</em> &gt; .05) zeigt also Homoskedastizität an.</p>
<pre class="r"><code>library(car)
leveneTest(dataB$vertr ~ dataB$geschl)</code></pre>
<pre><code>## Levene&#39;s Test for Homogeneity of Variance (center = median)
##        Df F value Pr(&gt;F)
## group   1  0.1105 0.7402
##       109</code></pre>
<p><span class="math inline">\(F(1,109) = 0.11, p = .740 \rightarrow H_0\)</span> wird beibehalten: Homoskedastizität wird angenommen</p>
</div>
<div id="inferenzstatistik-wilcoxon-test" class="section level3">
<h3>2.4. Inferenzstatistik: Wilcoxon-Test</h3>
<p>Da wir die Normalverteilung hier als verletzt betrachtet haben, führen wir nun den Wilcoxon-Test (für unabhängige Stichproben) durch.</p>
<p>Zur Erinnerung:</p>
<blockquote>
<p>Fragestellung B: “Sind Studentinnen <em>verträglicher</em> als Studenten?”</p>
</blockquote>
<p><span class="math inline">\(\rightarrow\)</span> Fragestellung ist gerichtet, erfordert also auch gerichtete Hypothesen.</p>
<p><strong>Hypothesen</strong></p>
<ul>
<li>Art des Effekts: Unterschiedshypothese</li>
<li>Richtung des Effekts: Gerichtet</li>
<li>Größe des Effekts: Unspezifisch</li>
</ul>
<p>Hypothesenpaar (inhaltlich):</p>
<ul>
<li><span class="math inline">\(H_0\)</span>: Studentinnen sind weniger oder genauso verträglich wie Studenten.<br />
</li>
<li><span class="math inline">\(H_1\)</span>: Studentinnen sind verträglicher als Studenten.</li>
</ul>
<p>Hypothesenpaar (statistisch):</p>
<ul>
<li><span class="math inline">\(H_0\)</span>: <span class="math inline">\(\eta_\text{weiblich} \leq \eta_\text{männlich}\)</span> bzw. <span class="math inline">\(\eta_\text{weiblich} - \eta_\text{männlich} \leq 0\)</span><br />
</li>
<li><span class="math inline">\(H_1\)</span>: <span class="math inline">\(\eta_\text{weiblich} \gt \eta_\text{männlich}\)</span> bzw. <span class="math inline">\(\eta_\text{weiblich} - \eta_\text{männlich} \gt 0\)</span></li>
</ul>
<p><strong>Signifikanzniveau</strong></p>
<p>Das Signifikanzniveau muss vor der Untersuchung festgelegt werden. Es soll hier 5% betragen. <span class="math inline">\(\rightarrow \alpha = .05\)</span></p>
<p><strong>Durchführung des Wilcoxon-Tests in R: Funktion <code>wilcox.test()</code></strong></p>
<p>Die Funktion <code>wilcox.test</code> nimmt im Grunde die gleichen Argumente entgegen, wie die Funktion <code>t.test</code>. Damit wir die gerichtete Hypothese in die richtige Richtung aufstellen können, müssen wir wissen, welche das erste Level des Faktors Geschlecht ist:</p>
<pre class="r"><code>levels(dataB$geschl) # wichtig zu wissen: die erste der beiden Faktorstufen ist &quot;weiblich&quot; </code></pre>
<pre><code>## [1] &quot;weiblich&quot;  &quot;maennlich&quot;</code></pre>
<p>Da die erste Faktorstufe “weiblich” ist, wissen wir, dass die gerichtete Hypothese “&gt;” lauten muss, also “greater”:</p>
<pre class="r"><code>wilcox.test(dataB$vertr ~ dataB$geschl,   # abhängige Variable ~ unabhängige Variable
            paired = FALSE,               # Stichproben sind unabhängig
            alternative = &quot;greater&quot;,      # einseitige Testung, und zwar so, dass Gruppe1(w)-Gruppe2(m) &gt; 0
            conf.level = .95)             # alpha = .05</code></pre>
<pre><code>## 
##  Wilcoxon rank sum test with continuity correction
## 
## data:  dataB$vertr by dataB$geschl
## W = 1213, p-value = 0.5726
## alternative hypothesis: true location shift is greater than 0</code></pre>
<p><span class="math inline">\(W = 1213, p = .573 \rightarrow\)</span> Ergebnis ist nicht signfikant, <span class="math inline">\(H_0\)</span> wird beibehalten.</p>
</div>
<div id="ergebnisinterpretation-1" class="section level3">
<h3>2.5. Ergebnisinterpretation</h3>
<p>Es wurde untersucht, ob Studentinnen verträglicher sind als Studenten. Deskriptiv besteht kein Unterschied in der Verträglichkeit: Beide Gruppen weisen einen Median von 4.25 auf (<span class="math inline">\(IQB_w\)</span> = [3.75; 4.5]; <span class="math inline">\(IQB_m\)</span> = [4.0; 4.5]). Zur Beantwortung der Fragestellung wurde ein Wilcoxon-Test durchgeführt. Der Gruppenunterschied über das Geschlecht ist nicht statistisch bedeutsam (<em>W</em> = 1213, <em>p</em> = .573). Somit wird die Nullhypothese beibehalten: Studentinnen sind nicht verträglicher als Studenten.</p>
<hr />
</div>
</div>
<div id="fragestellung-c-haben-studierende-mit-wohnort-in-uninähe-frankfurt-mit-gleicher-wahrscheinlichkeit-einen-nebenjob-wie-studierende-deren-wohnort-außerhalb-von-frankfurt-liegt" class="section level2">
<h2>3. Fragestellung C: Haben Studierende mit Wohnort in Uninähe (Frankfurt) mit gleicher Wahrscheinlichkeit einen Nebenjob wie Studierende, deren Wohnort außerhalb von Frankfurt liegt?</h2>
<p>Gehen wir nun zur 3. Fragestellung über. Wir verwenden wieder den vollen Datensatz <code>fb21</code>.</p>
<p>Zusätzlich zur Gruppenvariable ist in diesem Beispiel auch die abhängige Variable nominalskaliert. Um Fragen wie diese zu beantworten, werden daher die Populationswahrscheinlichkeiten (<code>job</code>: ja vs. nein) zwischen den beiden Gruppen (<code>ort</code>: Frankfurt [<code>FFM</code>] vs. außerhalb [<code>andere</code>]) miteinander verglichen. Diese Prüfung erfolgt mithilfe der <span class="math inline">\(\chi^2\)</span>-Verteilung <span class="math inline">\(\rightarrow \chi^2\)</span>-Test.</p>
<div id="datenaufbereitung" class="section level3">
<h3>3.1. Datenaufbereitung</h3>
<p>Zunächst müssen wir den <code>ort</code> und den <code>job</code> als Faktor abspeichern und entsprechende Labels vergeben. Damit wir hier keine Probleme bekommen, müssen wir zunächst prüfen, ob die Variablen ein <code>factor</code> sind:</p>
<pre class="r"><code>is.factor(fb21$ort)</code></pre>
<pre><code>## [1] FALSE</code></pre>
<pre class="r"><code>is.factor(fb21$job)</code></pre>
<pre><code>## [1] FALSE</code></pre>
<p>Dies ist bei beiden nicht der Fall, weswegen wir hier die Variable als Faktor ablegen können. Wir verwenden die Labels, die wir oben bereits in Klammern geschrieben haben!</p>
<pre class="r"><code># Achtung nur einmal durchführen (ansonsten Datensatz neu einladen und Code erneut durchlaufen lassen!)
fb21$ort &lt;- factor(fb21$ort, levels=c(1,2), labels=c(&quot;FFM&quot;, &quot;anderer&quot;))

fb21$job &lt;- factor(fb21$job, levels=c(1,2), labels=c(&quot;nein&quot;, &quot;ja&quot;))</code></pre>
</div>
<div id="deskriptivstatistikvoraussetzungsprüfung" class="section level3">
<h3>3.2. Deskriptivstatistik/Voraussetzungsprüfung</h3>
<p>Wir wollen wieder Deskriptivstatistiken betrachten und die Voraussetzungen des <span class="math inline">\(\chi^2\)</span>-Tests prüfen.</p>
<p><strong>Voraussetzungen:</strong></p>
<ol style="list-style-type: decimal">
<li>Die einzelnen Beobachtungen sind voneinander unabhängig <span class="math inline">\(\rightarrow\)</span> ok (durch das Studiendesign anzunehmen)</li>
<li>Jede Person lässt sich eindeutig einer Kategorie bzw. Merkmalskombination zuordnen <span class="math inline">\(\rightarrow\)</span> ok (durch das Studiendesign anzunehmen)</li>
<li>Zellbesetzung für alle <span class="math inline">\(n_{ij}\)</span> &gt; 5 <span class="math inline">\(\rightarrow\)</span> Prüfung anhand von Häufigkeitstabelle</li>
</ol>
<p><strong>zu Punkt 3) Zellbesetzung <em>n</em> &gt; 5</strong></p>
<p>Jede Zelle muss mindestens 5 Fälle aufzeigen, da die Ergebnisse sonst verzerrt werden.</p>
<pre class="r"><code>tab &lt;- table(fb21$ort, fb21$job)
tab</code></pre>
<pre><code>##          
##           nein ja
##   FFM       29 27
##   anderer   33 22</code></pre>
<p><span class="math inline">\(\rightarrow n_{ij}\)</span> &gt; 5 in allen Zellen gegeben.</p>
</div>
<div id="inferenzstatistische-beantwortung-der-fragestellung" class="section level3">
<h3>3.3. Inferenzstatistische Beantwortung der Fragestellung</h3>
<p>Kommen wir nun zur inferenzstatistischen Prüfung unserer Hypothese.</p>
<p><strong>Hypothesen</strong></p>
<ul>
<li>Art des Effekts: Zusammenhangshypothese<br />
</li>
<li>Richtung des Effekts: Ungerichtet<br />
</li>
<li>Größe des Effekts: Unspezifisch</li>
</ul>
<p>Hyothesenpaar (inhaltlich):</p>
<ul>
<li><span class="math inline">\(H_0\)</span>: Studierende mit Wohnort in Uninähe haben mit gleicher Wahrscheinlichkeit einen Nebenjob wie Studierende, deren Wohnort außerhalb von Frankfurt liegt.<br />
</li>
<li><span class="math inline">\(H_1\)</span>: Studierende mit Wohnort in Uninähe haben mit einer höheren oder niedrigeren Wahrscheinlichkeit einen Nebenjob wie Studierende, deren Wohnort außerhalb von Frankfurt liegt.</li>
</ul>
<p>Hypothesenpaar (statistisch):</p>
<ul>
<li><span class="math inline">\(H_0\)</span>: <span class="math inline">\(\pi_{ij} = \pi_{i\bullet} \cdot \pi_{\bullet j}\)</span><br />
</li>
<li><span class="math inline">\(H_1\)</span>: <span class="math inline">\(\pi_{ij} \neq \pi_{i\bullet} \cdot \pi_{\bullet j}\)</span></li>
</ul>
<p>wobei <span class="math inline">\(\pi_{ij}\)</span> die Wahrscheinlichkeit in Zelle <span class="math inline">\(ij\)</span> zu landen ist. Betrachten wir die Häufigkeitstabelle, dann entspricht dies der Wahrscheinlichkeit der Ausprägung der <span class="math inline">\(i\)</span>-ten Zeile (Varible: Wohnortnähe) und der <span class="math inline">\(j\)</span>-ten Spalte (Varible: Nebenjob). <span class="math inline">\(\pi_{i\bullet}\)</span> beschreibt die Wahrscheinlichkeit die Ausprägung der der <span class="math inline">\(i\)</span>-ten Zeile (Varible: Wohnortnähe) zu haben. <span class="math inline">\(\pi_{\bullet j}\)</span> beschreibt die Wahrscheinlichkeit die Ausprägung der der <span class="math inline">\(j\)</span>-ten Spalte (Varible: Nebenjob) zu haben. Sind die beiden betrachtet Variablen von einander unabhängig, so sollte sich die Wahrscheinlichkeit einer bestimmten Kombination aus den beiden Variablen durch das Produkt der beiden Wahrscheinlichkeiten der jeweiligen Ausprägung der beiden Variablen ausdrücken. Bspw. sollte sich die Wahrscheinlichkeit in Frankfurt zu wohnen und keinen Nebenjob zu haben ausdrücken lassen (gleich sein) mit der Wahrscheinlichkeit in Frankfurt zu wohnen multipliziert mit der Wahrscheinlichkeit keinen Nebenjob zu haben: <span class="math inline">\(\pi_\text{FFM,nein}=\pi_{\text{FFM},\bullet}\cdot\pi_{\bullet,\text{nein}}\)</span> (unter <span class="math inline">\(H_0\)</span>).</p>
<p>Da Wahrscheinlichkeiten im Grunde relative Häufigkeiten sind, betrachten wir im Folgenden die absoluten Häufigkeiten, um der Fragestellung nachzugehen. Aus den relativen Häufigkeiten (Wahrscheinlichkeiten) lassen sich erwartete absolute Häufigkeiten für die jeweiligen Kombinationen der Ausprägungen der Variablen ableiten.</p>
<p><strong>Signifikanzniveau <span class="math inline">\(\alpha\)</span></strong></p>
<p>Die Irrtumswahrscheinlichkeit soll 5% betragen. <span class="math inline">\(\rightarrow \alpha=.05\)</span></p>
<div id="vierfelder-chi2-test-in-r-manuelle-berechnung-über-formel" class="section level4">
<h4>3.3.1. Vierfelder-<span class="math inline">\(\chi^2\)</span>-Test in R: “manuelle” Berechnung über Formel</h4>
<p><strong>erwartete Häufigkeiten berechnen</strong></p>
<p>Für jede Zelle lassen sich die unter Gültigkeit der Nullhypothese erwarteten Häufigkeiten <span class="math inline">\(e_{ij}\)</span> bestimmen (hier sind <span class="math inline">\(n_{i\bullet}\)</span> und <span class="math inline">\(n_{\bullet j}\)</span> die absoluten Häufigkeiten, die zu den Wahrscheinlichkeiten oben gehören (diese lassen sich im Übrigen leicht bestimmen: <span class="math inline">\(n_{i\bullet}=n\hat{\pi}_{i\bullet}\)</span>, mit <span class="math inline">\(n\)</span> als Stichprobengröße):</p>
<p><span class="math display">\[e_{ij} = \frac{n_{i\bullet} \cdot n_{\bullet j}}{n}\]</span></p>
<p><span class="math inline">\(n_{i\bullet}\)</span> und <span class="math inline">\(n_{\bullet j}\)</span> lassen sich über die Randsummen bestimmen. Diese hängen wir unseren Daten an. Anschließend erstellen wir einen neuen Datensatz und fügen alle erwarteten Häufigkeiten dort ein.</p>
<pre class="r"><code>tab_mar &lt;- addmargins(tab) # Randsummen zu Tabelle hinzufügen
tab_mar</code></pre>
<pre><code>##          
##           nein  ja Sum
##   FFM       29  27  56
##   anderer   33  22  55
##   Sum       62  49 111</code></pre>
<pre class="r"><code>expected &lt;- data.frame(nein=c((tab_mar[1,3]*tab_mar[3,1])/tab_mar[3,3],
                              (tab_mar[2,3]*tab_mar[3,1])/tab_mar[3,3]),
                       ja=c((tab_mar[1,3]*tab_mar[3,2])/tab_mar[3,3],
                            (tab_mar[2,3]*tab_mar[3,2])/tab_mar[3,3]))
expected</code></pre>
<pre><code>##       nein       ja
## 1 31.27928 24.72072
## 2 30.72072 24.27928</code></pre>
<p>Bspw. für die Kombination (FFM, nein) ergibt sich eine erwartete Häufigkeit von 31.28, welcher eine beobachtete Häufigkeit von 29 gegenüber steht. Mit dem <span class="math inline">\(\chi^2\)</span>-Test können wir nun bestimmen, ob diese Unterschiede statistisch bedeutsam groß sind.</p>
<p><strong>Prüfgröße <span class="math inline">\(\chi^2\)</span> berechnen</strong></p>
<p>Formel:
<span class="math display">\[\chi^2 = \sum_{i=1}^{2}{ \sum_{j=1}^{2}{ \frac{(n_{ij}-e_{ij})^2} {e_{ij}}}}\]</span></p>
<pre class="r"><code>chi_quadrat_Wert &lt;- (tab[1,1]-expected[1,1])^2/expected[1,1]+
                    (tab[1,2]-expected[1,2])^2/expected[1,2]+
                    (tab[2,1]-expected[2,1])^2/expected[2,1]+
                    (tab[2,2]-expected[2,2])^2/expected[2,2]
chi_quadrat_Wert</code></pre>
<pre><code>## [1] 0.7593212</code></pre>
<p><strong>Signfikanztestung: per Vergleich von empirischem und kritischem <span class="math inline">\(\chi^2\)</span></strong></p>
<p>Die Freiheitsgrade berechnen sich aus der Anzahl der untersuchten Kategorien: <span class="math inline">\(df = (p - 1) \cdot (k - 1)\)</span>. Hier, im Fall des Vierfelder-<span class="math inline">\(\chi^2\)</span>-Tests also mit <span class="math inline">\(df = 1\)</span>, wobei</p>
<ul>
<li><em>p</em>: Anzahl Kategorien Variable “ort” = 2<br />
</li>
<li><em>k</em>: Anzahl Kategorien Variable “job” = 2</li>
</ul>
<p>Zur Bestimmung des kritischen Wertes und des <span class="math inline">\(p\)</span>-Wertes ziehen wir die jeweiligen Funktionen der <span class="math inline">\(\chi^2\)</span> Verteilung heran:</p>
<pre class="r"><code>qchisq(.95, 1) # kritischer Wert</code></pre>
<pre><code>## [1] 3.841459</code></pre>
<pre class="r"><code>pchisq(chi_quadrat_Wert, 1, lower.tail = FALSE) # p-Wert</code></pre>
<pre><code>## [1] 0.383541</code></pre>
<p>Insgesamt ergibt sich damit.</p>
<ul>
<li><em>df</em> = 1</li>
<li><span class="math inline">\(\chi^2_{krit}\)</span> = 3.84</li>
<li><span class="math inline">\(\chi^2_{emp}\)</span> = 0.759</li>
<li><span class="math inline">\(\chi^2_{emp} &lt; \chi^2_{krit}\)</span> <span class="math inline">\(\rightarrow H_0\)</span> wird beibehalten</li>
<li><span class="math inline">\(p\)</span> = 0.384</li>
<li><span class="math inline">\(p\)</span>-Wert &gt; <span class="math inline">\(\alpha\)</span>-Fehlerniveau <span class="math inline">\(\rightarrow H_0\)</span> wird beibehalten</li>
</ul>
<p>In einem Artikel würden wir schreiben: Die Nähe zur Uni hängt nicht damit zusammen, ob ein Nebenjob ausgeübt wird <span class="math inline">\(\chi^2\)</span>(df=1)=0.759, <span class="math inline">\(p\)</span> = 0.384 (bzw. p&gt;0.05).</p>
</div>
<div id="vierfelder-chi2-test-in-r-funktion-chisq.test" class="section level4">
<h4>3.3.2. Vierfelder-<span class="math inline">\(\chi^2\)</span>-Test in R: Funktion <code>chisq.test()</code></h4>
<p>Die Funktion <code>chisq.test</code> übernimmt die Arbeit für uns, wenn wir Ihr einfach eine 4-Feldertabelle üebrgeben.</p>
<pre class="r"><code>chisq.test(tab,        # Kreuztabelle
           correct=F)  # keine Kontinuinitaetskorrektur nach Yates</code></pre>
<pre><code>## 
##  Pearson&#39;s Chi-squared test
## 
## data:  tab
## X-squared = 0.75932, df = 1, p-value = 0.3835</code></pre>
</div>
</div>
<div id="effektstärken" class="section level3">
<h3>3.4. Effektstärken</h3>
<p>Auch für den <span class="math inline">\(\chi^2\)</span>-Test gibt es ein Effektstärkenmaß.</p>
<p><strong>Yules Q</strong></p>
<p>Dieses berechnet sich als</p>
<p><span class="math display">\[Q=\frac{n_{11}n_{22}-n_{12}n_{21}}{n_{11}n_{22}+n_{12}n_{21}},\]</span></p>
<p>welches einen Wertebereich von [-1,1] aufweist und analog zur Korrelation interpretiert werden kann. 1 steht in diesem Fall für einen perfekten positiven Zusammenhang (dazu in der entsprechenden Sitzung mehr).</p>
<p>In <code>R</code> sieht das so aus:</p>
<pre class="r"><code>effekt_YulesQ &lt;- (tab[1,1]*tab[2,2]-tab[1,2]*tab[2,1])/
                 (tab[1,1]*tab[2,2]+tab[1,2]*tab[2,1])
effekt_YulesQ</code></pre>
<pre><code>## [1] -0.1654676</code></pre>
<p><strong>Phi (<span class="math inline">\(\phi\)</span>)</strong></p>
<p>Auch kann man <span class="math inline">\(\phi\)</span> bestimmen:</p>
<p><span class="math display">\[\phi = \frac{n_{11}n_{22}-n_{12}n_{21}}{\sqrt{(n_{11}+n_{12})(n_{11}+n_{21})(n_{12}+n_{22})(n_{21}+n_{22})}}\]</span>
welches einen Wertebereich von [-1,1] aufweist und analog zur Korrelation interpretiert werden kann. 1 steht in diesem Fall für einen perfekten positiven Zusammenhang (dazu in der entsprechenden Sitzung mehr).</p>
<p>In <code>R</code> sieht das so aus:</p>
<pre class="r"><code>effekt_phi &lt;- (tab[1,1]*tab[2,2]-tab[1,2]*tab[2,1])/
  sqrt((tab[1,1]+tab[1,2])*(tab[1,1]+tab[2,1])*(tab[1,2]+tab[2,2])*(tab[2,1]+tab[2,2]))
effekt_phi</code></pre>
<pre><code>## [1] -0.08270872</code></pre>
<p>Das ganze lässt sich auch mit dem <code>psych</code> und der darin enthaltenen Funktion <code>phi</code> umsetzen:</p>
<pre class="r"><code># alternativ mit psych Paket
library(psych)
phi(tab, digits = 8)</code></pre>
<pre><code>## [1] -0.08270872</code></pre>
<pre class="r"><code># Äquivalentes Ergebnis mittels Pearson-Korrelation (kommt in den nächsten Sitzungen)
# (dichotome Variablen)
ort_num &lt;- as.numeric(fb21$ort)
job_num &lt;- as.numeric(fb21$job)
cor(ort_num, job_num, use=&quot;pairwise&quot;)</code></pre>
<pre><code>## [1] -0.08270872</code></pre>
</div>
<div id="ergebnisinterpretation-2" class="section level3">
<h3>3.5. Ergebnisinterpretation</h3>
<p>Es wurde untersucht, ob Studierende mit Wohnort in Uninähe (also in Frankfurt) mit gleicher Wahrscheinlichkeit einen Nebenjob haben wie Studierende, deren Wohnort außerhalb von Frankfurt liegt. Zur Beantwortung der Fragestellung wurde ein Vierfelder-Chi-Quadrat-Test für unabhängige Stichproben berechnet. Der Zusammenhang zwischen Wohnort und Nebenjob ist nicht signifikant (<span class="math inline">\(\chi^2\)</span>(1) = 0.759, <em>p</em> = 0.384), somit wird die Nullhypothese beibehalten. Der Effekt ist von vernachlässigbarer Stärke (<span class="math inline">\(\phi\)</span> = -0.083). Studierende mit Wohnort in Uninähe haben mit gleicher Wahrscheinlichkeit einen Nebenjob wie Studierende, deren Wohnort außerhalb von Frankfurt liegt.</p>
<hr />
</div>
</div>
