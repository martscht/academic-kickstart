---
title: Diskriminanzanalyse
date: '2020-11-03'
slug: diskriminanzanalyse
categories:
  - MSc1
tags:
  - Diskriminanzanlyse
  - LDA
  - lineares Modell
  - deskriptiv
  - Trennung
  - Kovarianzanalyse
  - MANOVA
subtitle: 'Deskriptive lineare Diskriminanzanalyse'
summary: ''
authors: [irmer]
lastmod: '2020-11-10T10:22:58+02:00'
featured: no
header:
  image: "/header/FEI_Sitzung_Zusatz_post.jpg"
  caption: "[Courtesy of pxhere](https://pxhere.com/en/photo/92126)"
projects: []
---

<script src="/rmarkdown-libs/header-attrs/header-attrs.js"></script>


<div id="einleitung" class="section level2">
<h2>Einleitung</h2>
<p>Die (deskriptive) Diskriminanzanalyse geht der entgegengesetzten Fragestellung der MANOVA auf den Grund. Mit ihr können wir (deskriptiv) untersuchen, ob Gruppenzugehörigkeiten durch die AVs der MANOVA vorhergesagt werden können (siehe bspw. <a href="https://ubffm.hds.hebis.de/Record/HEB371183324">Pituch und Stevens, 2016,</a> Kapitel 10 sowie <a href="https://ubffm.hds.hebis.de/Record/HEB366849158">Eid, Gollwitzer &amp; Schmitt, 2017</a>, Kapitel 15.4). Wir wollen uns wieder das fiktive Datenbeispiel (Datensatz <code>Therapy</code> aus dem gleichnamigen .rda File <code>Therapy.rda</code>) ansehen, den wir bereits in der <a href="/post/manova">MANOVA-Sitzung</a> untersucht haben. Sie können den <a href="https://pandar.netlify.app/post/Therapy.rda"><svg aria-hidden="true" role="img" viewBox="0 0 512 512" style="height:1em;width:1em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:currentColor;overflow:visible;position:relative;"><path d="M216 0h80c13.3 0 24 10.7 24 24v168h87.7c17.8 0 26.7 21.5 14.1 34.1L269.7 378.3c-7.5 7.5-19.8 7.5-27.3 0L90.1 226.1c-12.6-12.6-3.7-34.1 14.1-34.1H192V24c0-13.3 10.7-24 24-24zm296 376v112c0 13.3-10.7 24-24 24H24c-13.3 0-24-10.7-24-24V376c0-13.3 10.7-24 24-24h146.7l49 49c20.1 20.1 52.5 20.1 72.6 0l49-49H488c13.3 0 24 10.7 24 24zm-124 88c0-11-9-20-20-20s-20 9-20 20 9 20 20 20 20-9 20-20zm64 0c0-11-9-20-20-20s-20 9-20 20 9 20 20 20 20-9 20-20z"/></svg> Datensatz “Therapy.rda” hier herunterladen</a>.</p>
<div id="daten-laden" class="section level3">
<h3>Daten laden</h3>
<p>Wir laden zunächst die Daten: entweder lokal von Ihrem Rechner:</p>
<pre class="r"><code>load(&quot;C:/Users/Musterfrau/Desktop/Therapy.rda&quot;)</code></pre>
<p>oder wir laden sie direkt über die Website:</p>
<pre class="r"><code>load(url(&quot;https://pandar.netlify.app/post/Therapy.rda&quot;))</code></pre>
<p>Nun sollte in <code>R</code>-Studio oben rechts in dem Fenster unter der Rubrik “Data” unser Datensatz mit dem Namen “<em>Therapy</em>” erscheinen.</p>
</div>
<div id="übersicht-über-die-daten" class="section level3">
<h3>Übersicht über die Daten</h3>
<p>Wir wollen uns einen Überblick über die Daten verschaffen:</p>
<pre class="r"><code>head(Therapy)</code></pre>
<pre><code>##   Lebenszufriedenheit Arbeitsbeanspruchung Depressivitaet Arbeitszufriedenheit
## 1                   7                    4              7                    5
## 2                   5                    5              8                    3
## 3                   8                    7              6                    6
## 4                   6                    4              5                    5
## 5                   6                    9              8                    5
## 6                   8                    7              8                    6
##     Intervention Geschlecht
## 1 Kontrollgruppe          0
## 2 Kontrollgruppe          1
## 3 Kontrollgruppe          0
## 4 Kontrollgruppe          1
## 5 Kontrollgruppe          1
## 6 Kontrollgruppe          1</code></pre>
<pre class="r"><code>levels(Therapy$Intervention)</code></pre>
<pre><code>## [1] &quot;Kontrollgruppe&quot;              &quot;VT Coaching&quot;                
## [3] &quot;VT Coaching + Gruppenuebung&quot;</code></pre>
<pre class="r"><code>levels(Therapy$Geschlecht)</code></pre>
<pre><code>## [1] &quot;0&quot; &quot;1&quot;</code></pre>
<p>Die abhängigen Variablen sind <code>Lebenszufriedenheit</code>, <code>Arbeitsbeanspruchung</code> <code>Depressivitaet</code> und <code>Arbeitszufriedenheit</code>. Die Variable <code>Intervention</code> hat drei Stufen: eine Kontrollgruppe, ein verhaltenstherapiebasiertes Coaching, sowie das verhaltenstherapiebasierte Coaching inklusive einer Gruppenübung. Das Geschlecht ist 0-1 kodiert, wobei <code>0</code> für männlich und <code>1</code> für weiblich steht. Insgesamt sind die Variablennamen der AVs recht lang. Wir wollen diese kürzen:</p>
<pre class="r"><code>colnames(Therapy) # Spaltennamen ansehen</code></pre>
<pre><code>## [1] &quot;Lebenszufriedenheit&quot;  &quot;Arbeitsbeanspruchung&quot; &quot;Depressivitaet&quot;      
## [4] &quot;Arbeitszufriedenheit&quot; &quot;Intervention&quot;         &quot;Geschlecht&quot;</code></pre>
<pre class="r"><code>colnames(Therapy) &lt;- c(&quot;LZ&quot;, &quot;AB&quot;, &quot;Dep&quot;, &quot;AZ&quot;, &quot;Intervention&quot;, &quot;Geschlecht&quot;) # Spaltennamen neu zuordnen
head(Therapy)</code></pre>
<pre><code>##   LZ AB Dep AZ   Intervention Geschlecht
## 1  7  4   7  5 Kontrollgruppe          0
## 2  5  5   8  3 Kontrollgruppe          1
## 3  8  7   6  6 Kontrollgruppe          0
## 4  6  4   5  5 Kontrollgruppe          1
## 5  6  9   8  5 Kontrollgruppe          1
## 6  8  7   8  6 Kontrollgruppe          1</code></pre>
<p>So - schon viel übersichtlicher!</p>
</div>
<div id="pakete-laden" class="section level3">
<h3>Pakete laden</h3>
<p>Nachdem wir neue Pakete installiert haben (<code>install.packages</code>), laden wir diese:</p>
<pre class="r"><code>library(MASS) # für lineare Diskrimianzanalys (lda)
library(ggplot2) # Grafiken</code></pre>
</div>
</div>
<div id="ziel-der-linearen-diskriminanzanalyse" class="section level2">
<h2>Ziel der linearen Diskriminanzanalyse</h2>
<p>Wir wollen mit der Lebenszufriedenheit, der Depression, der Arbeitsbeanspruchung und der Arbeitszufriedenheit die Zugehörigkeit zu den Therapiegruppen vorhersagen (ob dies inhaltlich sinnvoll ist, sei jetzt mal dahingestellt!). Die lineare Diskriminanzanalyse (LDA) funktioniert ähnlich wie die <a href="/post/pca">PCA</a>. Die PCA maximiert die Varianz auf jeder Hauptkomponente. Die LDA maximiert die Diskrimination entlang der Achsen, also quasi die Varianz zwischen den Gruppen auf den Achsen. Somit sind beide Verfahren de facto Varianzmaximierungsverfahren.</p>
<p>Die LDA hat im Grunde die gleichen Annahmen wie die <a href="/post/manova">MANOVA</a>. Die Kovarianzmatrizen über die Gruppen müssen homogen sein. Die Daten sollten multivariat normalverteilt sein (diese Annahme lässt sich bspw. in Fisher’s linearer Diskriminanzanalye lockern, sodass sie nicht so wichtig ist). Die Beobachtungen stammen aus einer <em>independent and identically distributed</em> (<span class="math inline">\(i.i.d.\)</span>, deutsch: unabhängig und identisch verteilt) Population (dies bedeutet, dass alle Beobachtungen unabhängig sind und den gleichen Verteilungs- und Modellannahmen unterliegen). Die letzte Annahme können wir nicht prüfen. Sie kann nur über die sinnvolle Wahl des Designs (Randomisierung etc.) angenommen werden. Wie dies zu prüfen ist, hatten wir in der Sitzung zur <a href="/post/manova">MANOVA</a> kennengelernt.</p>
</div>
<div id="analysen" class="section level2">
<h2>Analysen</h2>
<p>Der Befehl in <code>R</code> heißt <code>lda</code> für <strong>l</strong>ineare <strong>D</strong>iskriminanz<strong>a</strong>nalyse. Ihr übergeben wir wieder eine Gleichung, ähnlich der MANOVA-Gleichung der vergangenen Sitzung. Allerdings ist diesmal die <code>Intervention</code> die AV und die AVs der MANOVA (<code>LZ</code>, <code>Dep</code>, <code>AB</code> und <code>AZ</code>) sind die UVs, die zur Prädiktion herangezogen werden. Mit Hilfe von <code>$scaling</code> können wir die Gewichtungskoeffizienten der Variablen auf den Diskriminanzachsen einsehen. Insgesamt sind bei einer linearen Diskriminanzanalyse immer maximal <span class="math inline">\(\min(p, k-1)\)</span> Diskriminanzfunktionen/achsen möglich, wobei <span class="math inline">\(p\)</span> die Anzahl an UVs ist und <span class="math inline">\(k\)</span> die Anzahl an Gruppen beschreibt. Hier sind es <span class="math inline">\(p=4\)</span> UVs und <span class="math inline">\(k=3\)</span> Gruppen. Folglich können maximal <span class="math inline">\(2\)</span> Diskriminanzfunktionen bestimmt werden:</p>
<pre class="r"><code>model_DA &lt;- lda(Intervention ~ LZ + Dep + AB + AZ, Therapy)
model_DA</code></pre>
<pre><code>## Call:
## lda(Intervention ~ LZ + Dep + AB + AZ, data = Therapy)
## 
## Prior probabilities of groups:
##              Kontrollgruppe                 VT Coaching 
##                   0.3333333                   0.3333333 
## VT Coaching + Gruppenuebung 
##                   0.3333333 
## 
## Group means:
##                                   LZ      Dep       AB       AZ
## Kontrollgruppe              5.933333 7.133333 6.033333 5.133333
## VT Coaching                 5.933333 5.066667 5.833333 6.833333
## VT Coaching + Gruppenuebung 7.333333 4.766667 6.300000 7.500000
## 
## Coefficients of linear discriminants:
##            LD1         LD2
## LZ   0.1618370 -0.88229519
## Dep  0.7453510  0.09824489
## AB  -0.4155893 -0.35778884
## AZ  -0.1519953  0.48104478
## 
## Proportion of trace:
##    LD1    LD2 
## 0.7892 0.2108</code></pre>
<pre class="r"><code>model_DA$scaling # Koeffizienten</code></pre>
<pre><code>##            LD1         LD2
## LZ   0.1618370 -0.88229519
## Dep  0.7453510  0.09824489
## AB  -0.4155893 -0.35778884
## AZ  -0.1519953  0.48104478</code></pre>
<p>Für die erste Achse sind besonders <code>Dep</code> und <code>AB</code> relevant, während auf der zweiten Achse <code>AZ</code> und <code>LZ</code> stärker ins Gewicht fallen. Wir können <code>predict</code> nutzen, um eine Vorhersage mittels dieses Modells (<code>model_DA</code>) zu erhalten. <code>predict</code> gibt hierbei 3 Listen aus: <code>$posterior</code> gibt die Wahrscheinlichkeit an, in die jeweilige Gruppe zu gelangen, <code>$class</code> gibt die Vorhersage für die Gruppenzugehörigkeit an und <code>$x</code> gibt die vorhergesagte Ausprägung auf der jeweiligen Diskriminanzachse an.</p>
<pre class="r"><code>head(predict(model_DA)$posterior) # Wahrscheinlichkeit in der jeweiligen Gruppe zu landen</code></pre>
<pre><code>##   Kontrollgruppe VT Coaching VT Coaching + Gruppenuebung
## 1      0.9518348  0.02825584                 0.019909382
## 2      0.9669084  0.02447494                 0.008616686
## 3      0.2868306  0.08677168                 0.626397717
## 4      0.4461846  0.36122866                 0.192586789
## 5      0.5512585  0.12202873                 0.326712765
## 6      0.8868980  0.02379371                 0.089308278</code></pre>
<pre class="r"><code>head(predict(model_DA)$class)     # Vorhergesagte Klasse</code></pre>
<pre><code>## [1] Kontrollgruppe              Kontrollgruppe             
## [3] VT Coaching + Gruppenuebung Kontrollgruppe             
## [5] Kontrollgruppe              Kontrollgruppe             
## Levels: Kontrollgruppe VT Coaching VT Coaching + Gruppenuebung</code></pre>
<pre class="r"><code>head(predict(model_DA)$x)         # vorhergesagte Ausprägung auf der jeweiligen Diskriminanzachse</code></pre>
<pre><code>##         LD1        LD2
## 1 2.1797562 -0.3780597
## 2 2.4898346  0.1648972
## 3 0.1974790 -1.9509215
## 4 0.5272172  0.3077457
## 5 0.6853238 -1.1864638
## 6 1.6881810 -1.7544317</code></pre>
<p>Wir wollen uns die Ausprägungen auf den beiden Diskriminanzachsen grafisch ansehen. Dazu speichern wir diese unter <code>DA1</code> und <code>DA2</code> jeweils für 1. und 2. Diskriminanzachse ab.</p>
<pre class="r"><code>Therapy$DA1 &lt;- predict(model_DA)$x[, 1] # erste DA
Therapy$DA2 &lt;- predict(model_DA)$x[, 2] # zweite DA</code></pre>
<p>Anschließend können wir wieder <code>ggplot</code> verwenden, um die beiden Diskriminanzachsen gegeneinander abzutragen. Außerdem fügen wir noch die Nullpunkte auf den Diskriminanzachsen als gepunktete Linie ein:</p>
<pre class="r"><code>ggplot(data = Therapy, aes(x = DA1, y = DA2, color = Intervention)) +
  geom_point()+
  geom_hline(yintercept = 0, lty = 3)+
  geom_vline(xintercept = 0, lty = 3)+
  ggtitle(label = &quot;Diskriminanzachsen&quot;, subtitle = &quot;mit Trennlinien&quot;)</code></pre>
<p><img src="/post/2020-11-03-MSc1_SitzungZusatz_Diskriminanzanalyse_files/figure-html/unnamed-chunk-9-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>Was wir nun sehen, ist, dass entlang der x-Achse besonders zwischen blau/grün vs rot unterschieden wird. D.h. die erste Diskriminanzachse hilft uns, zwischen den Interventionsgruppen und der Kontrollgruppe zu unterscheiden. Die zweite Achse trennt eher zwischen den beiden Interventionsgruppen, wobei diese Trennung nicht sehr eindeutig ist.</p>
<p>Wir hätten auch einfach die <code>plot</code>-Funktion auf das <code>model_DA</code>-Objekt anwenden können:</p>
<pre class="r"><code>plot(model_DA)</code></pre>
<p><img src="/post/2020-11-03-MSc1_SitzungZusatz_Diskriminanzanalyse_files/figure-html/unnamed-chunk-10-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>Wenn wir diesem noch Farben zuordnen (hier jeweils 30 mal die selbe Farbe, da die Gruppen so häufig hintereinander im Datensatz standen…), dann sieht diese Grafik der mit <code>ggplot</code> erzeugten Grafik recht ähnlich. Natürlich können wir auch hier die Nullpunkte einfügen:</p>
<pre class="r"><code>plot(model_DA, col = c(rep(&quot;red&quot;, 30), rep(&quot;gold3&quot;, 30), rep(&quot;blue&quot;, 30)))
abline(v = 0, lty = 3)
abline(h = 0, lty = 3)</code></pre>
<p><img src="/post/2020-11-03-MSc1_SitzungZusatz_Diskriminanzanalyse_files/figure-html/unnamed-chunk-11-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>Zu guter Letzt fügen wir noch die Trennlinien, die zwischen den Gruppen unterscheiden, in die erste Grafik ein. Diese liegen immer auf halbem Weg (durchgezogenen schwarzen Linien, hier für <em>Kontrollgruppe</em> vs. <em>VT-Coaching + Gruppenübung</em>) zwischen zwei Mittelwerten pro Gruppe (gestrichelten Linien) auf den jeweiligen Achsen:</p>
<pre class="r"><code># Mittelwerte auf den DAs
Means &lt;- aggregate(cbind(DA1, DA2) ~ Intervention, data = Therapy, FUN = mean)

# Mittelwerte auf DA1
mDA1_K &lt;- Means[1,2] # Kontrollgruppenmittelwert auf DA1
mDA1_V &lt;- Means[2,2] # Mittelwert VT auf DA1
mDA1_VG &lt;- Means[3,2] # Mittelwert VT + Gruppenuebung auf DA1

# Mittelwerte auf DA2
mDA2_K &lt;- Means[1,3] # Kontrollgruppenmittelwert auf DA2
mDA2_V &lt;- Means[2,3] # Mittelwert VT auf DA2
mDA2_VG &lt;- Means[3,3] # Mittelwert VT + Gruppenuebung auf DA2

ggplot(data = Therapy, aes(x = DA1, y = DA2, color = Intervention)) + geom_point()+
        geom_hline(yintercept = mDA2_K, lty = 2, col = &quot;red&quot;)+
        geom_hline(yintercept = mDA2_V, lty = 2, col = &quot;gold3&quot;)+
        geom_hline(yintercept = mDA2_VG, lty = 2, col = &quot;blue&quot;)+
        geom_hline(yintercept = (mDA2_VG+mDA2_K)/2, lty = 1, col = &quot;black&quot;, lwd = 0.2)+
        geom_vline(xintercept = mDA1_K, lty = 2, col = &quot;red&quot;)+
        geom_vline(xintercept = mDA1_V, lty = 2, col = &quot;gold3&quot;)+
        geom_vline(xintercept = mDA1_VG, lty = 2, col = &quot;blue&quot;)+
        geom_vline(xintercept = (mDA1_VG+mDA1_K)/2, lty = 1, col = &quot;black&quot;, lwd = 0.2)+
        ggtitle(label = &quot;Diskriminanzachsen&quot;, subtitle = &quot;mit Mittelwerten pro Gruppe&quot;)</code></pre>
<p><img src="/post/2020-11-03-MSc1_SitzungZusatz_Diskriminanzanalyse_files/figure-html/unnamed-chunk-12-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>Wir sehen auch an den mit <code>plot</code> erstellten Grafiken, dass sich die Kontrollgruppe von den Interventionsgruppen unterscheiden lässt, während sich die Interventionsgruppen nicht stark voneinander unterscheiden. Dies hatten wir insbesondere auch in der <a href="/post/manova">Sitzung zur MANOVA</a> so herausgefunden.</p>
<div id="wie-gut-ist-unsere-gruppenzuordnung" class="section level3">
<h3>Wie gut ist unsere Gruppenzuordnung?</h3>
<p>Um zu prüfen, wie gut wir die Gruppen zugeordnet haben, müssen wir untersuchen, wie häufig richtig zugeordnet wurde. Das können wir bspw. mit <code>table</code> machen und hier die Vorhersagen (<code>predict(model_DA)$class</code>) mit den Beobachtungen (<code>Therapy$Intervention</code>) vergleichen. Wir speichern <code>predict(model_DA)$class</code> zunächst als Variable ab und hängen es an den Datensatz dran:</p>
<pre class="r"><code>Therapy$predict_class &lt;- predict(model_DA)$class
table(Therapy$predict_class, Therapy$Intervention)</code></pre>
<table>
<thead>
<tr class="header">
<th align="left"></th>
<th align="right">Kontrollgruppe</th>
<th align="right">VT Coaching</th>
<th align="right">VT Coaching + Gruppenuebung</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Kontrollgruppe</td>
<td align="right">25</td>
<td align="right">5</td>
<td align="right">4</td>
</tr>
<tr class="even">
<td align="left">VT Coaching</td>
<td align="right">3</td>
<td align="right">15</td>
<td align="right">6</td>
</tr>
<tr class="odd">
<td align="left">VT Coaching + Gruppenuebung</td>
<td align="right">2</td>
<td align="right">10</td>
<td align="right">20</td>
</tr>
</tbody>
</table>
<p>Die Diagonalelemente dieser Tabelle zeigen die richtig zugeordneten Werte. Wir können diese Werte auch nochmals durch 30 teilen, was die relativen Anteile erzeugt (dies funktioniert hier so einfach, da in jeder Gruppe 30 Probanden waren, normalerweise müssten wir hier die relativen Anteile pro Gruppe betrachten).</p>
<pre class="r"><code>table(Therapy$predict_class, Therapy$Intervention)/30</code></pre>
<table>
<thead>
<tr class="header">
<th align="left"></th>
<th align="right">Kontrollgruppe</th>
<th align="right">VT Coaching</th>
<th align="right">VT Coaching + Gruppenuebung</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Kontrollgruppe</td>
<td align="right">0.8333333</td>
<td align="right">0.1666667</td>
<td align="right">0.1333333</td>
</tr>
<tr class="even">
<td align="left">VT Coaching</td>
<td align="right">0.1000000</td>
<td align="right">0.5000000</td>
<td align="right">0.2000000</td>
</tr>
<tr class="odd">
<td align="left">VT Coaching + Gruppenuebung</td>
<td align="right">0.0666667</td>
<td align="right">0.3333333</td>
<td align="right">0.6666667</td>
</tr>
</tbody>
</table>
<p>83.33% der <em>Kontrollgruppenprobanden</em> wurden dieser wieder <em>richtig</em> zugeordnet, 50% der <em>VT-Coaching</em>- Gruppe wurden dieser wieder <em>richtig</em> zugeordnet und 66.67% der <em>VT-Coaching + Gruppenübung</em>- Gruppe wurden dieser wieder <em>richtig</em> zugeordnet. Insgesamt wurden</p>
<pre class="r"><code>mean(Therapy$predict_class == Therapy$Intervention)*100</code></pre>
<pre><code>## [1] 66.66667</code></pre>
<p>% der Probanden der richtigen Gruppe zugeordnet. Dies zeigt, dass die Prädiktion nicht perfekt war, was höchstwahrscheinlich daran liegt, dass Proband*innen aus den Interventionsgruppen sich kaum in der Lebenszufriedenheit, Arbeitszufriedenheit, Depression und Arbeitsbeanspruchung unterschieden. Ähnliches hatten wir bereits mit der <a href="/post/manova">MANOVA</a> herausgefunden.</p>
</div>
</div>
<div id="trennlinien-im-ursprünglichen-variablenkoordinatensystem" class="section level2">
<h2>Trennlinien im ursprünglichen Variablenkoordinatensystem</h2>
<p>Nun wollen wir die Trennlinien auch einmal in das ursprüngliche Koordinatensystem einzeichnen. Dazu führen wir eine Diskriminanzanalyse nur mit den beiden Zufriedenheitsmaßen durch.</p>
<pre class="r"><code>model_DA2 &lt;- lda(Intervention ~ LZ + AZ, data = Therapy)
model_DA2</code></pre>
<pre><code>## Call:
## lda(Intervention ~ LZ + AZ, data = Therapy)
## 
## Prior probabilities of groups:
##              Kontrollgruppe                 VT Coaching 
##                   0.3333333                   0.3333333 
## VT Coaching + Gruppenuebung 
##                   0.3333333 
## 
## Group means:
##                                   LZ       AZ
## Kontrollgruppe              5.933333 5.133333
## VT Coaching                 5.933333 6.833333
## VT Coaching + Gruppenuebung 7.333333 7.500000
## 
## Coefficients of linear discriminants:
##           LD1       LD2
## LZ -0.3160376  0.883895
## AZ  0.8736389 -0.337895
## 
## Proportion of trace:
##    LD1    LD2 
## 0.7589 0.2411</code></pre>
<pre class="r"><code>model_DA2$scaling # Koeffizienten</code></pre>
<pre><code>##           LD1       LD2
## LZ -0.3160376  0.883895
## AZ  0.8736389 -0.337895</code></pre>
<p>Wir sehen, dass jeweils eine Variable besonders stark auf einer Diskriminanzfunktion diskriminiert (großer Koeffizient). Um jetzt die Trennlinien einzeichnen zu können, brauchen wir ein Koordinatensystem, in dem für alle Kombinationen von <code>LZ</code> und <code>AZ</code> entschieden wird, in welcher Gruppe ein/e Proband*in mit dieser Ausprägung landen würde. Dies übernimmt die <code>expand.grid</code> Funktion für uns.</p>
<pre class="r"><code># Ein Koordinatensystem erstellen von 0 bis 12 auf den beiden Variablen
contour_data &lt;- expand.grid(LZ = seq(0,12, 0.01), AZ = seq(0,12,0.01))
contour_data</code></pre>
<table>
<thead>
<tr class="header">
<th align="right">LZ</th>
<th align="right">AZ</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">0.00</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="right">0.01</td>
<td align="right">0</td>
</tr>
<tr class="odd">
<td align="right">0.02</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="right">0.03</td>
<td align="right">0</td>
</tr>
<tr class="odd">
<td align="right">0.04</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="right">0.05</td>
<td align="right">0</td>
</tr>
</tbody>
</table>
<p><span class="math inline">\(\vdots\)</span></p>
<table>
<thead>
<tr class="header">
<th align="left"></th>
<th align="right">LZ</th>
<th align="right">AZ</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">1442395</td>
<td align="right">11.94</td>
<td align="right">12</td>
</tr>
<tr class="even">
<td align="left">1442396</td>
<td align="right">11.95</td>
<td align="right">12</td>
</tr>
<tr class="odd">
<td align="left">1442397</td>
<td align="right">11.96</td>
<td align="right">12</td>
</tr>
<tr class="even">
<td align="left">1442398</td>
<td align="right">11.97</td>
<td align="right">12</td>
</tr>
<tr class="odd">
<td align="left">1442399</td>
<td align="right">11.98</td>
<td align="right">12</td>
</tr>
<tr class="even">
<td align="left">1442400</td>
<td align="right">11.99</td>
<td align="right">12</td>
</tr>
<tr class="odd">
<td align="left">1442401</td>
<td align="right">12.00</td>
<td align="right">12</td>
</tr>
</tbody>
</table>
<p>Die <code>predict</code>-Funktion sagt die modellimplizierten Werte vorher. Wir können dieser Funktion auch einen Wert übergeben, der so in den Daten noch nicht vorkam, nämlich dem Argument <code>newdata</code>. Somit bekommen wir die Vorhersage unter unserem Modell für die neuen Datenpunkte. Als letztes kann mit <code>stat_contour</code> die Gruppenzugehörigkeit eingezeichnet werden. Diese übergeben wir der 3. Dimension <code>z</code> in der <code>stat_contour</code>-Funktion. Bei diesem Plot ist es von Vorteil, wenn die Gruppierungsvariable im Originaldatensatz gleich heißt wie die Prädiktion im neuen Datensatz.</p>
<pre class="r"><code># Für das Koordinatensystem für jeden Punkt die Gruppenzugehörigkeit bestimmen
contour_data$Intervention &lt;- as.numeric(predict(object = model_DA2, newdata = contour_data)$class)

head(contour_data$Intervention)</code></pre>
<pre><code>## [1] 1 1 1 1 1 1</code></pre>
<pre class="r"><code># Gruppenzugehörigkeiten in Originalkoordinatensystem einzeichnen
ggplot(data = Therapy, mapping = aes(x = LZ, y = AZ, color = Intervention))+
        geom_point()+
        stat_contour(aes(x = LZ, y = AZ, z = Intervention), data = contour_data)+
        ggtitle(&quot;Lebenszufriedenheit vs Arbeitszufriedenheit&quot;, subtitle = &quot;inklusive retransformierter Entscheidungslinien\nabgeleitet von den Diskriminanzachsen&quot;)</code></pre>
<p><img src="/post/2020-11-03-MSc1_SitzungZusatz_Diskriminanzanalyse_files/figure-html/unnamed-chunk-22-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>Wir sehen, dass die Trennlinien nicht rechtwinklig zueinander verlaufen. Dies liegt daran, dass die Achsen hier in die Originalskala retransformiert wurden. Die Gruppen werden wie folgt zugeordnet: <em>oben links</em> = <code>VT Coaching</code>, <em>oben rechts</em> = <code>VT Coaching + Gruppenuebung</code> und <em>unten rechts/unten</em> = <code>Kontrollgruppe</code>. Allerdings ist diese Zuordnung nicht sehr genau…</p>
<hr />
</div>
<div id="r-skript" class="section level2">
<h2>R-Skript</h2>
<p>Den gesamten <code>R</code>-Code, der in dieser Sitzung genutzt wird, können Sie <a href="/post/MSc1_R_Files/4_Log_Reg_RCode.R"><svg aria-hidden="true" role="img" viewBox="0 0 512 512" style="height:1em;width:1em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:currentColor;overflow:visible;position:relative;"><path d="M216 0h80c13.3 0 24 10.7 24 24v168h87.7c17.8 0 26.7 21.5 14.1 34.1L269.7 378.3c-7.5 7.5-19.8 7.5-27.3 0L90.1 226.1c-12.6-12.6-3.7-34.1 14.1-34.1H192V24c0-13.3 10.7-24 24-24zm296 376v112c0 13.3-10.7 24-24 24H24c-13.3 0-24-10.7-24-24V376c0-13.3 10.7-24 24-24h146.7l49 49c20.1 20.1 52.5 20.1 72.6 0l49-49H488c13.3 0 24 10.7 24 24zm-124 88c0-11-9-20-20-20s-20 9-20 20 9 20 20 20 20-9 20-20zm64 0c0-11-9-20-20-20s-20 9-20 20 9 20 20 20 20-9 20-20z"/></svg> hier herunterladen</a>.</p>
<hr />
</div>
<div id="literatur" class="section level2">
<h2>Literatur</h2>
<p><a href="https://ubffm.hds.hebis.de/Record/HEB366849158">Eid, M., Gollwitzer, M., &amp; Schmitt, M. (2017).</a> <em>Statistik und Forschungsmethoden</em> (5. Auflage, 1. Auflage: 2010). Weinheim: Beltz.</p>
<p><a href="https://ubffm.hds.hebis.de/Record/HEB371183324">Pituch, K. A. &amp; Stevens, J. P. (2016).</a> <em>Applied Multivariate Statistics for the Social Sciences</em> (6th ed.). New York: Taylor &amp; Francis.</p>
<ul>
<li><small> <em>Blau hinterlegte Autor:innenangaben führen Sie direkt zur universitätsinternen Ressource.</em> </small></li>
</ul>
</div>
