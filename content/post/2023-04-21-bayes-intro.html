---
title: Einführung in Bayes
date: '2023-04-21'
slug: bayes-intro
categories:
  - extras
tags:
  - Bayes
  - Verteilungen
subtitle: 'Eine imperfekte Einführung für absolute Beginner'
summary: ''
authors: [schultze]
lastmod: '2023-04-21T20:46:31+02:00'
featured: no
header: 
  image: "/header/bayes_intro.jpg"
  caption: "[Courtesy of pxhere](https://pxhere.com/en/photo/769748)"
projects: []
---



<p>In vielen Bereichen der Psychologie haben wir ein Problem. Also, eigentlich mehrere, aber eins beschäftigt uns außerordentlich häufig, auch während des Studiums: unsere Studien arbeiten oft mit sehr kleinen Stichproben. Insbesondere in klinischen Untersuchungen liegt das oft einfach daran, dass es sehr aufwendig ist Probanden zu erheben. Wenn wir psychotherapeutische Interventionen untersuchen bedeutet oft jedes einzelne zusätzliche <span class="math inline">\(n\)</span>, dass wir dutzende Stunden Arbeit aufwenden müssen. Auf der anderen Seite steht das Problem, dass wir bei jeder Verringerung des <span class="math inline">\(n\)</span> unsere Fähigkeit einschränken, aus unserer Stichprobe auch zulässige Rückschlüsse auf die Population ziehen zu können. In diesem Abschnitt wird es - wie der Titel hoffentlich klar gemacht hat - um eine Einführung in Bayes gehen. Wie die beiden Dinge zusammenhängen, sollte idealerweise nach ungefähr der Hälfte dieses Beitrags klar geworden sein. Danach gibt es ein paar technische Spielereien.</p>
<div id="ein-einfaches-beispiel" class="section level2">
<h2>Ein einfaches Beispiel</h2>
<p>Nehmen wir an, dass Sie in einer Suchtklinik arbeiten - oder vielleicht ein Praktikum machen. Das bisherige System, nach welchem Patient:innen Ausgang außerhalb des Klinikgeländes gewährt wird bezieht sich vor allem auf die Zeit, die die Person schon in der Klinik ist. Als Sie anfangen, finden Sie das System irgendwie suboptimal und Sie denken sich: “Das sollte doch eigentlich vom Therapiefortschritt abhängen…”. Obwohl Sie vielleicht Recht haben, ist auch für die Patient:innen Planbarkeit wichtig: ein Termin beim Bürgeramt, zum Beispiel, muss etliche Wochen vorab vereinbart werden. Also denken Sie sich etwas Neues aus, das alle super glücklich machen sollte. Sie können dieses System aber nicht an 42 Leuten testen (wie Ihre Poweranalyse Ihnen rät), sondern probieren es zunächst mit den zehn Patient:innen, die im Rahmen des Praktikums in Ihre Obhut übergeben wurden.</p>
<p>Ihr neues System führt dazu, dass 7 von 10 Patient:innen aus dem Ausgang zurück kommen ohne Drogen genommen zu haben. Angesichts der Tatsache, dass es bei den Kolleg:innen, die sich an das alte System halten immer knapp die Hälfte ist, verbuchen Sie das als Erfolg. Übertragen wir das Ganze mal in <code>R</code>:</p>
<pre class="r"><code># Beobachtungen
obs &lt;- c(0, 1, 1, 0, 1, 1, 1, 0, 1, 1)

# N
length(obs)</code></pre>
<pre><code>## [1] 10</code></pre>
<pre class="r"><code># Erfolgsquote
mean(obs)</code></pre>
<pre><code>## [1] 0.7</code></pre>
<p>Jede <code>1</code> stellt eine Person dar, die erfolgreich aus dem Ausgang zurückkam, ohne Drogen genommen zu haben. Jede <code>0</code> ein Scheitern, dass Sie an Ihrer Berufswahl zweifeln lässt.</p>
<p>Etwas formaler ausgedrückt: wir wollen jetzt prüfen, ob die Erfolgsquote Ihres Systems sich von der Quote Ihrer Kolleg:innen unterscheidet. Die Nullhypothese ist also, dass wir vermuten, dass auch Ihr System eine Erfolgsquote von 50% produziert: <span class="math inline">\(H_0: \pi = .5\)</span>. <span class="math inline">\(\pi\)</span> stellt hierbei die Wahrscheinlichkeit des “erfolgreichen” Ausgangs in der Population aller Personen dar, die jemals an diesem System teilnehmen könnten.</p>
</div>
<div id="frequentistische-ansätze" class="section level2">
<h2>Frequentistische Ansätze</h2>
<p>Gucken wir uns zunächst die Möglichkeiten an, zu prüfen, ob Ihr System besser ist als das Ihrer Kolleg:innen. Ein klassischer Ansatz (den Sie <a href="/post/gruppenvergleiche-unabhaengig/#fragestellung-c">hier in Fragestellung C</a> nachlesen können) ist der <span class="math inline">\(\chi^2\)</span>-Test. In unserem Fall haben wir zwar nicht vier sondern nur zwei Felder, aber das macht das Ganze einfach nur einfacher:</p>
<pre class="r"><code># Häufigkeitstabelle der Erfolge
tab &lt;- table(obs)

# Tabelle in den Chi2-Test
chisq.test(tab)</code></pre>
<pre><code>## 
##  Chi-squared test for given probabilities
## 
## data:  tab
## X-squared = 1.6, df = 1, p-value = 0.2059</code></pre>
<p>Was hier geprüft wird ist die gleichmäßige Besetzung der Zellen. Unter der Nullhypothese <span class="math inline">\(H_0 : \pi = .5\)</span> müssten wir also fünf Erfolge und fünf Misserfolge beobachten:</p>
<pre class="r"><code>chisq.test(tab)$expected</code></pre>
<pre><code>## 0 1 
## 5 5</code></pre>
<p>In diesem Fall erhalten wir ein nicht bedeutsames Ergebnis - wir behalten die Nullhypothese also bei.</p>
<p>Den Aufmerksamen unter Ihnen ist vielleicht aufgefallen, dass der <span class="math inline">\(\chi^2\)</span>-Test, den wir hier nutzen, mit ein paar Annahmen einhergeht. Das liegt daran, dass wir <a href="/post/gruppenvergleiche-unabhaengig/#Chi-Sq">die Diskrepanz zwischen Erwartung und Beobachtung zu einer Zahl verrechnen</a> und die erzeugte Zahl dann mit einer bekannten Verteilung (der <span class="math inline">\(\chi^2\)</span>-Verteilung) abgleichen, um festzustellen wie wahrscheinlich unser Ergebnis wäre, wenn die Nullhypothese wahr wäre. Die Übertragung funktioniert nur unter bestimmten Annahmen, vor allem aber funktioniert Sie <em>immer</em> besser, je größer <span class="math inline">\(n\)</span> ist. Das gilt nicht nur für den <span class="math inline">\(\chi^2\)</span>-Test, sondern für alle parametrischen Tests - also Tests, die sich darauf verlassen, eine Prüfgröße zu erstellen und diese mit einer bekannten Verteilung abzugleichen.</p>
<p>Diese Tatsache führt dazu, dass insbesondere in klinischen Studien häufig gefordert wird, stattdessen mit Tests zu arbeiten, die sich nicht auf asymptotische Eigenschaften verlassen - sogenannte non-parametrische Tests. Für unser Beispiel gibt es da zum Glück eine recht einfache Möglichkeit!</p>
<p>Wenn Ihre Statistik I Vorlesung noch nicht allzu lange her ist, erinnern Sie sich vielleicht, dass die Anzahl von Erfolgen <span class="math inline">\(x\)</span> aus <span class="math inline">\(n\)</span> unabhängigen Versuchen <a href="/post/verteilungen/#Binomial">binomialverteilt</a> ist. Das ist, im Gegensatz zu dem was ich gerade über die <span class="math inline">\(\chi^2\)</span>-Tests gesagt habe, keine Annahme, sondern einfach eine Realität der Welt in der wir leben. Wir können also mit einer Gleichung direkt bestimmen, wie wahrscheinlich es ist, dass sieben Ihrer zehn Patient:innen aus dem Ausgang zurückkommen ohne rückfällig geworden zu sein, wenn ihr Ausgangsprinzip genauso gut funktioniert, wie das Ihrer Kolleg:innen (<span class="math inline">\(H_0: \pi = .5\)</span>).</p>
<p><span class="math display">\[
  P(X = x | n, \pi) = {n \choose x} \cdot \pi^x \cdot (1 - \pi)^{n-x}
\]</span></p>
<p>Für diesen Fall also:</p>
<p><span class="math display">\[
  P(X = 7 | 10, .5) = {10 \choose 7} \cdot .5^7 \cdot (1 - .5)^{10-7} = .117
\]</span></p>
<pre class="r"><code># Wahrscheinlichkeit händisch bestimmen
choose(10, 7) * .5^7 * (1 - .5)^(10 - 7)</code></pre>
<pre><code>## [1] 0.1171875</code></pre>
<p>Uns interessiert aber nicht, wie wahrscheinlich es ist, dass Sie <em>genau</em> sieben Erfolge haben. In der Inferenzstatistik interessiert uns typischerweise, wie wahrscheinlich es ist dieses oder ein extremeres (im Fall der ungerichteten Nullhypothese) Ergebnis zu finden. Dafür können wir einfach die Funktion zur Binomialverteilung nutzen:</p>
<pre class="r"><code># Gerichtet
pbinom(6, 10, .5, lower.tail = FALSE)</code></pre>
<pre><code>## [1] 0.171875</code></pre>
<pre class="r"><code># Ungerichtet
pbinom(6, 10, .5, lower.tail = FALSE) + pbinom(3, 10, .5)</code></pre>
<pre><code>## [1] 0.34375</code></pre>
<p>Wir setzen hier 6 und nicht 7 in die Funktion ein, weil uns <code>pbinom</code> die <em>Überschreitungswahrscheinlichkeit</em> ausgibt. Wir brauchen also die Wahrscheinlichkeit dafür einen Wert von 6 zu überschreiten (weil wir die 7 ja einschließen wollen). Der Test, den wir gerade durchgeführt haben, nennt man <em>Binomialtest</em> und auch für diesen gibt es eine eigene Funktion in <code>R</code>, die dem gleichen Schema folgt, wie z.B. die <code>t.test</code>-Funktion:</p>
<pre class="r"><code>binom.test(7, 10, .5)</code></pre>
<pre><code>## 
##  Exact binomial test
## 
## data:  7 and 10
## number of successes = 7, number of trials = 10, p-value = 0.3438
## alternative hypothesis: true probability of success is not equal to 0.5
## 95 percent confidence interval:
##  0.3475471 0.9332605
## sample estimates:
## probability of success 
##                    0.7</code></pre>
<p>Auch hier also keine statistische Bedeutsamkeit.</p>
<div id="power-in-unseren-frequentistischen-möglichkeiten" class="section level3">
<h3>Power in unseren frequentistischen Möglichkeiten</h3>
<p>Wir haben jetzt also zwei Ansätze gesehen die einfache Frage zu prüfen, ob Ihr Ausgangssystem zu anderen Erfolgsquoten führt, als das Ihrer Kolleg:innen. Dabei hatten wir zunächst den klassischen, parametrischen Weg gewählt und einen <span class="math inline">\(\chi^2\)</span>-Test durchgeführt. Allerdings fällt es uns bei kleinen Stichproben häufig schwer uns auf die asymptotischen Eigenschaften von Tests zu verlassen. Bei anderen parametrischen Tests - wie z.B. <span class="math inline">\(t\)</span>-Tests oder ANOVAs - kann es bei kleinen Stichproben auch quasi unmöglich werden überhaupt zu prüfen, ob die Annahmen haltbar sind, die diese Verfahren voraussetzen.</p>
<p>Also sind wir auf einen non-parametrischen Test ausgewichen (den Binomialtest). Das Problem dabei ist, dass wir die Power unsere Inferenzstatistik sogar noch verringern. In parametrischen Tests “gewinnen” wir ein wenig Power dadurch, dass wir Annahmen machen. Wenn wir weniger Annahmen machen, brauchen wir mehr Daten, um zur gleichen Sicherheit zu kommen.</p>
</div>
</div>
