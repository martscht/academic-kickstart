---
title: MSA - Invarianzstufen
author: ''
date: '2021-04-13'
slug: exkurs-invarianzstufen
categories: 
  - MSc1
  - Zusatz
tags: 
  - Invarianztestung
  - Invarianzstufen
  - Strukturgleichungsmodelle
  - latente Modellierung
  - MSA
subtitle: 'Ein Exkurs'
summary: ''
authors: [irmer, schultze]
lastmod: '2021-04-21T10:30:02+02:00'
featured: no
header:
  image: "/header/FEII_Invarianz.jpg"
  caption: "[Courtesy of pxhere](https://pxhere.com/en/photo/1587291)"
---



<p>In einer Multi-Sample Analysis werden in der Regel verschiedene Invarianz (also Gleichheiten über die Gruppen) getesten. Diese werden hier noch einmal wiederholt.</p>
<div id="invarianzstufen" class="section level2">
<h2>Invarianzstufen</h2>
<p>Die Invarianzstufen sind nach Einschränkungen der Modellparameter sortiert und werden auch (fast) immer in dieser Reihenfolge sukzessive getestet: konfigurale, metrische (schwache), skalare (starke), strikte und vollständige Invarianz. Wir gehen so vor, wie dies per Default im <code>R</code>-Paket <code>lavaan</code> durchgeführt wird. Wir gehen hierzu davon aus, dass die Skalierung für die Varianzen auf den ersten Faktorladungen (<span class="math inline">\(\lambda=1\)</span>) liegt und dass die Skalierung für die Mittelwerte (Interzepte) auf dem latenten Mittelwert liegt (<span class="math inline">\(\kappa=0\)</span>).</p>
<p>Die erste und am wenigsten restriktive Invarianzstufe ist die <strong>konfigurale Invarianz</strong>. Unter konfiguraler Invarianz verstehen wir die Gleichheit der Modelle in den Gruppen - oder salopp gesprochen: gilt konfigurale Invarianz, dann gilt in beiden Gruppen die selbe Faktorstruktur (bzw. die gleiche Konstruktdefinition). Die folgende Grafik soll dies für ein einfaches CFA Modell veranschaulichen, welches auch die oben erwähnten Skalierer enthält. In Schwarz dargestellt sind Invarianzen über die Gruppen hinweg (natürlich ist das Modell, das wir hier behandeln, wesentlich komplexer, aber das angegeben Modell stellt die wichtigsten Aspekte der Gleichsetzung dar!):</p>
<center>
<img src="https://raw.githubusercontent.com/martscht/PsyMSc1/master/inst/tutorials/SEM/images/1_Invarianz_Grafiken.png" width="100%"/>
</center>
<p>Ob diese Invarianzstufe hält, können wir durch die Modellpassung des Multigruppenmodells aus dem letzten Abschnitt prüfen. Weil wir das Modell aufgrund der sehr guten Passung nicht verwerfen müssen, gibt uns das den Hinweis, dass zumindest die Faktorstruktur in beiden Gruppen gleich ist (als konfigurale Invarianz hält). Wenn wir z.B. durch Fehlpassung feststellen würden, dass in einer der beiden Gruppen eine zusätzliche Residualkorrelation oder eine Querladung aufgenommen werden muss, müssten wir die Annahme der konfiguralen Messinvarianz verwerfen.</p>
<p>Um die weiteren Invarianzstufen und deren Implikationen besser zu verstehen, schauen wir uns noch einmal die modellimplizierte Varianz und die modellimplizierte Erwartung (den modellimplizierten Mittelwert) einer manifesten Variable <span class="math inline">\(X\)</span> an. Wir verwenden <span class="math inline">\(^{(g)}\)</span> um Unterschiede zwischen Gruppen darzustellen, wobei dies als Platzhalter für bspw. die Gruppennummer fungiert. Lassen wir dies weg, so gehen wir davon aus, dass der Parameter gleich ist über die Gruppen hinweg. Alle anderen Indizes lassen wir weg, um das ganze übersichtlicher zu gestalten.</p>
<p>Eine einfache modellimplizierte Gleichung einer Messung <span class="math inline">\(X\)</span> ist:</p>
<p><span class="math display">\[X^{(g)}=\tau^{(g)}+\lambda^{(g)}\xi^{(g)}+\delta^{(g)}.\]</span></p>
<p><span class="math inline">\(\tau\)</span> ist das Interzept und <span class="math inline">\(\lambda\)</span> ist die Faktorladung. Die Varianz von <span class="math inline">\(X\)</span> ist folglich:</p>
<p><span class="math display">\[\mathbb{V}ar\left[X^{(g)}\right]=\left(\lambda^{(g)}\right)^2\phi^{(g)}+\theta^{(g)}.\]</span></p>
<p><span class="math inline">\(\phi\)</span> ist die Varianz der latenten Variable, <span class="math inline">\(\xi\)</span>, und <span class="math inline">\(\theta\)</span> ist die Residualvarianz, also die Varianz von <span class="math inline">\(\delta\)</span>. Wenn Sie sich nun fragen, wieso wir <span class="math inline">\(\lambda\)</span> hier quadrieren müssen, dann überlegen Sie sich folgendes Beispiel anhand der empirischen Stichprobenvarianz von einer Variable <span class="math inline">\(Y\)</span>. Diese berechnen wir so:</p>
<p><span class="math display">\[\hat{\mathbb{V}ar}[Y] = \frac{1}{n}\sum_{i=1}^n(Y_i-\bar{Y})^2,\]</span></p>
<p>wobei <span class="math inline">\(\bar{Y}\)</span> der Mittelwert von <span class="math inline">\(Y\)</span> ist. Wenn wir nun alle Einträge von <span class="math inline">\(Y\)</span> mit einer Konstanten multiplizieren, also für jede Person <span class="math inline">\(i\)</span> das Produkt <span class="math inline">\(aY_i\)</span> berechnen (z.B. <span class="math inline">\(a=10\)</span>) und die Varianz bestimmen (der Mittelwert von <span class="math inline">\(aY\)</span> ist einfach <span class="math inline">\(a\bar{Y}\)</span>), dann ergibt sich:</p>
<p><span class="math display">\[\begin{align}
\hat{\mathbb{V}ar}[aY] &amp;= \frac{1}{n}\sum_{i=1}^n(aY_i-a\bar{Y})^2\\
&amp;=\frac{1}{n}\sum_{i=1}^n\big(a(Y_i-a\bar{Y})\big)^2\\
&amp;=\frac{1}{n}\sum_{i=1}^na^2(Y_i-\bar{Y})^2\\
&amp;=a^2\frac{1}{n}\sum_{i=1}^n(Y_i-\bar{Y})^2=a^2\hat{\mathbb{V}ar}[Y],
\end{align}\]</span></p>
<p>Da <span class="math inline">\(a\)</span> in der Klammer steht, die quadriert wird, muss natürlich <span class="math inline">\(a\)</span> quadriert werden. Da auch <span class="math inline">\(a^2\)</span> eine Konstante ist, kann sie vor die Summe gezogen werden. Daraus wird dann ersichtlich, dass die Varianz des Produktes einer Variablen mit einer Konstanten gleich der Konstanten zum Quadrat multipliziert mit der Varianz der Variablen ist. Der Mittelwert von <span class="math inline">\(X\)</span> ergibt sich als:
<span class="math display">\[\mathbb{E}\left[X^{(g)}\right]=\tau^{(g)}+\lambda^{(g)}\kappa^{(g)},\]</span>
wobei <span class="math inline">\(\kappa\)</span> das Interzept (den Mittelwert) von <span class="math inline">\(\xi\)</span> darstellt. Da <span class="math inline">\(X\)</span> von so vielen Parametern abhängt, ist ohne weitere Annahmen (von Invarianzen der Parameter über die Gruppen hinweg) nicht zu sagen, ob Unterschiede zwischen Gruppen bspw. im Mittelwert von <span class="math inline">\(X\)</span> auf Unterschiede in der latenten Variable oder auf Unterschiede in der Messung zurückzuführen sind. Ähnlich sieht es für die Varianz aus.</p>
<p>Die nächste Invarianzstufe ist die <strong>metrische</strong> oder <strong>schwache Invarianz</strong>. Nehmen wir metrische Invarianz an, so gehen wir davon aus, dass die Faktorladungen (<span class="math inline">\(\lambda\)</span>) über die Gruppen hinweg gleich sind. Dies impliziert, dass die latenten Variablen über die Gruppen hinweg die gleiche Bedeutung haben. Die latenten Variablen lassen sich also inhaltlich gleich interpretieren und die Beziehungen zwischen ihnen sind vergleichbar. Dies ist sehr wichtig, wenn wir bspw. Fragebögen oder Tests über Gruppen (z.B. Länder oder das Geschlecht) hinweg vergleichen wollen. In der Grafik sind nun alle <span class="math inline">\(\lambda\)</span>s schwarz (anstatt blau oder rot):</p>
<center>
<img src="https://raw.githubusercontent.com/martscht/PsyMSc1/master/inst/tutorials/SEM/images/2_Invarianz_Grafiken.png" width="100%"/>
</center>
<p>Die Varianz von <span class="math inline">\(X\)</span> vereinfacht sich zu (Weglassen von <span class="math inline">\(^{(g)}\)</span> symbolisiert Gleichheit über die Gruppen hinweg):
<span class="math display">\[\mathbb{V}ar\left[X^{(g)}\right]=\lambda^2\phi^{(g)}+\theta^{(g)}.\]</span></p>
<p>Hierbei ist es so, dass <span class="math inline">\(\lambda^2\phi^{(g)}\)</span> gerade die Systematik oder den wahren Anteil in der Varianz von <span class="math inline">\(X\)</span> beschreibt. Falls metrische Invarianz gilt, so lassen sich also Unterschiede in den wahren Anteilen der Varianzen der Beobachtungen auf Unterschiede in den latenten Varianzen zurückführen (Achtung: dies ist nicht das Gleiche wie Gleichheit der Reliabilitäten, was anteilig die Systematik in <span class="math inline">\(X\)</span> an der gesamten Varianz von <span class="math inline">\(X\)</span> beschreibt - hierfür müssten ebenfalls <span class="math inline">\(\theta\)</span> gleich sein). Dies bedeutet, wenn wir metrische Invarianz nicht verwerfen (also weiter davon ausgehen, dass metrische Invarianz gilt), dass wir durch weitere Modellrestriktionen die latenten Varianzen auf Gleichheit prüfen können. Dies ist nicht zulässig, wenn metrische Invarianz <em>nicht</em> gilt, also die Faktorladungen sich über die Gruppen hinweg unterscheiden. Spezifizieren wir <code>group.equal = c("loadings")</code>, so wird das metrisch-invariante Modell geschätzt.</p>
Unter <strong>skalarer</strong> oder <strong>starker Invarianz</strong> verstehen wir die nächste Invarianzstufe, welche zusätzlich zu den Faktorladungen auch noch die Interzepte (<span class="math inline">\(\tau\)</span>) als invariant über die Gruppen hinweg annimmt. Der Mittelwert von <span class="math inline">\(X\)</span> vereinfacht sich zu:
<span class="math display">\[\mathbb{E}\left[X^{(g)}\right]=\tau+\lambda\kappa^{(g)},\]</span>
wobei nun ersichtlich ist, dass nur noch <span class="math inline">\(\kappa\)</span> über die Gruppen hinweg variiert (wegen <span class="math inline">\(^{(g)}\)</span>). Dies bedeutet also, dass unter Annahme der skalaren Invarianz Unterschiede in den Mittelwerten der Beobachtungen auf Unterschiede in den Mittelwerten der latenten Variablen zurückzuführen sind. Um dies zu prüfen, würden überlicherweise über die skalare Invarianz hinaus auch noch <span class="math inline">\(\kappa\)</span> über die Gruppen hinweg gleichgesetzt werden. Der Likelihood-Ratio-Test (<span class="math inline">\(\chi^2\)</span>-Differenzentest) zwischen dem skalar-invarianten Modell und dem zusätzlich <span class="math inline">\(\kappa\)</span>-invarianten Modell entscheidet dann darüber, ob die latenten Mittelwerte sich über die Gruppen hinweg unterscheiden. Wir schätzen das skalar-invariante Modell durch <code>group.equal = c("loadings", "intercepts")</code>. Da auch für die Mittelwertsstruktur Skalierer gesetzt werden müssen und diese üblicherweise auf den latenten Mittelwerten liegen (<span class="math inline">\(\kappa=0\)</span>), muss dies bei der Invarianztestung berücksichtigt werden. Wenn wir die Skalierer auf den latenten Mittelwerten lassen und die Interzept der manifesten Variablen gleichsetzen, so nehmen wir damit auch implizit an, dass die latenten Mittelwerte über die Gruppen hinweg gleich sind. Um diesem Problem aus dem Weg zu gehen, stellt die <code>sem</code>-Funktion klugerweise ein, dass nur in der ersten Gruppe die latenten Mittelwerte/Interzepte (<span class="math inline">\(\kappa\)</span>) auf 0 gesetzt werden, alle übrigen werden frei geschätzt. Dies haben wir uns an entsprechender Stelle im Output unserer Modellschäzung angesehen! In der Grafik sind nun alle <span class="math inline">\(\lambda\)</span>s und <span class="math inline">\(\tau\)</span>s schwarz (anstatt blau oder rot). Außerdem ist die Effektkodierung der <span class="math inline">\(\kappa\)</span>s zu sehen: diese bedeutet, dass der erste latente Mittelwert auf 0 restringiert wird, während der zweite frei geschätzt wird und somit die Abweichungen (den Effekt) quantifiziert (beide sind in der Gruppenfarbe dargestellt):
<center>
<img src="https://raw.githubusercontent.com/martscht/PsyMSc1/master/inst/tutorials/SEM/images/3_Invarianz_Grafiken.png" width="100%"/>
</center>
Setzen wir zusätzlich zu Faktorladungen und Interzepten auch noch die Residualvarianzen (<span class="math inline">\(\theta\)</span>) gleich über die Gruppen, so sprechen wir von <strong>strikter Invarianz</strong>. Gilt diese Invarianzbedingung, so lassen sich Unterschiede in den beobachteten Varianzen ausschließlich auf Unterschiede in den latenten Varianzen (also die Varianzen der latenten Variablen) zurückführen. Dies lässt sich der Varianzformel entnehmen:
<span class="math display">\[\mathbb{V}ar\left[X^{(g)}\right]=\lambda^2\phi^{(g)}+\theta.\]</span>
Nur noch <span class="math inline">\(\phi\)</span> trägt auf der rechten Seite ein <span class="math inline">\(^{(g)}\)</span>. Somit sind nur noch Unterschiede in <span class="math inline">\(\phi\)</span> verantwortlich für Unterschiede in <span class="math inline">\(\mathbb{V}ar\left[X\right]\)</span>. In der Grafik sind nun alle <span class="math inline">\(\lambda\)</span>s, <span class="math inline">\(\tau\)</span>s und <span class="math inline">\(\theta\)</span>s schwarz (anstatt blau oder rot):
<center>
<img src="https://raw.githubusercontent.com/martscht/PsyMSc1/master/inst/tutorials/SEM/images/4_Invarianz_Grafiken.png" width="100%"/>
</center>
<p>Wir schätzen das strikt-invariante Modell durch <code>group.equal = c("loadings", "intercepts", "residuals")</code>.</p>
Gehen wir von <strong>vollständiger Invarianz</strong> aus, so sind alle Parameter über die Gruppen hinweg gleich. Es gibt also keinerlei Unterschiede mehr zwischen den Gruppen. Die <span class="math inline">\(\phi\)</span>s und auch die <span class="math inline">\(\kappa\)</span>s müssen wieder auf den gleichen Wert über die Gruppen hinweg gesetzt werden. Die Variablen selbst (<span class="math inline">\(X\)</span>, <span class="math inline">\(\xi\)</span> und <span class="math inline">\(\delta\)</span>) bleiben farbig, da wir nur Parameter über die Gruppen hinweg gleichsetzen. Die Grafik der vollständigen Invarianz sieht folgendermaßen aus:
<center>
<img src="https://raw.githubusercontent.com/martscht/PsyMSc1/master/inst/tutorials/SEM/images/5_Invarianz_Grafiken.png" width="100%"/>
</center>
<p>Das vollständig-invariante Modell erhalten wir mit <code>group.equal = c("loadings", "intercepts", "residuals",</code> <code>"means", "lv.variances", "lv.covariances", "regressions")</code>. Hierbei restringiert <code>"means"</code> die latenten Mittelwerte (<span class="math inline">\(\kappa\)</span>), <code>"lv.variances"</code> die latenten (Residual-)Varianzen (<span class="math inline">\(\phi\)</span>s und <span class="math inline">\(\psi\)</span>s exogen und endogen) und <code>"regressions"</code> die Strukturpfadkoeffizienten (<span class="math inline">\(\gamma\)</span>s und <span class="math inline">\(\beta\)</span>s). Hätten wir Residualkovarianzen bei den manifesten oder latenten Variablen gehabt, so müssten wir diese auch mit <code>"residual.covariances"</code> sowie mit <code>"lv.covariances"</code> restringieren.</p>
<p>Die Invarianzstufen lassen sich nach der Anzahl der zu schätzenden Parameter oder den <span class="math inline">\(df\)</span> sortieren. Im <em>konfigural-invarianten Modell müssen am meisten Parameter</em> geschätzt werden, es besitzt also die wenigsten <span class="math inline">\(df\)</span>, während im <em>vollständig-invarianten Modell die wenigsten Parameter</em> geschätzt werden müssen, weswegen dieses auch die meisten <span class="math inline">\(df\)</span> hat. Die anderen Modelle liegen wie folgt dazwischen (je weiter links, desto weniger restriktiv ist das Modell, desto mehr Parameter sind zu schätzen und desto weniger <span class="math inline">\(df\)</span> gibt es):
<span class="math display">\[\textbf{konfigural}\quad&lt;\quad\textbf{metrisch/schwach}\quad&lt;\quad\textbf{skalar/stark}\quad&lt;\quad\textbf{strikt}\quad&lt;\quad\textbf{vollständig}.\]</span></p>
<p>Likelihood-Ratio-Tests (<span class="math inline">\(\chi^2\)</span>-Differenzentests) werden herangezogen, um zu prüfen, ob die Invarianzeinschränkungen das Modell signifikant hinsichtlich der Passung zu den Daten verschlechtern.</p>
<hr />
</div>
<div id="literatur" class="section level2">
<h2>Literatur</h2>
<p>Gregorich, S. E. (2006). Do self-report instruments allow meaningful comparisons across diverse population groups? Testing measurement invariance using the confirmatory factor analysis framework. <em>Medical Care</em>, <em>44</em>(11), 78-94.</p>
<p>Schermelleh-Engel, K., Moosbrugger, H., &amp; Müller, H. (2003). Evaluation the fit of structural equation models: tests of significance and descriptive goodness-of-fit measures. <em>Methods of Psychological Research Online,</em> <em>8</em>(2), 23-74.</p>
</div>
