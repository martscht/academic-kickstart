---
title: Logistische Regression
date: '2021-10-18'
slug: logistische-regression-klipps
categories:
  - MSc5a
tags:
  - dichotom
  - generalisiertes lineares Modell
  - Regression
  - Linkfunktion
  - Maximum Likelihood
  - Likelihood Ratio Test
subtitle: 'Generalisiertes lineares Modell: dichotome abhängige Variablen'
summary: ''
authors: [nehler, irmer]
lastmod: '2021-10-06T08:32:21+02:00'
featured: no
header:
  image: "/header/KliPsy_Sitzung5.jpg"
  caption: "[Courtesy of pxhere](https://pxhere.com/en/photo/565804)"
projects: []
---

<script src="/rmarkdown-libs/header-attrs/header-attrs.js"></script>


<div id="einleitung" class="section level2">
<h2>Einleitung</h2>
<p>In dieser Sitzung wollen wir dichotome abhängige Variablen mit der logistischen Regression (vgl. bspw. <a href="https://hds.hebis.de/ubffm/Record/HEB366849158">Eid, Gollwitzer &amp; Schmitt, 2017</a>, Kapitel 22 und <a href="https://hds.hebis.de/ubffm/Record/HEB371183324">Pituch und Stevens, 2016,</a> Kapitel 11) analysieren. Diese Daten sind dahingehend speziell, dass die abhängige Variable nur zwei Ausprägungen hat, welche in der Regel mit <span class="math inline">\(0\)</span> und <span class="math inline">\(1\)</span> kodiert werden. Dies führt zu verschiedenen Problemen in der linearen Regression, die wir gleich betrachten wollen. Wir wollen uns ein reales Datenbeispiel ansehen, in welchem die Wahrscheinlichkeit der Drogenabhängigkeit durch einen Depressionsscore und das Geschlecht vorhergesagt werden soll. Der Datensatz ist öffentlich zugänglich auf dem <a href="https://osf.io/prc92/">Open-Science-Framework</a> zu finden.</p>
<div id="daten-laden" class="section level3">
<h3>Daten laden</h3>
<p>Wir laden zunächst die Daten. Dies können Sie lokal von Ihrem Rechner machen. Falls Sie den Datensatz lokal einladen wollen, müssen Sie ihn natürlich zunächst von der bereits angegebenen Seite herunterladen. Beachten Sie, dass es sich bei dem Datensatz um einen im Format von SPSS handelt. Um diesen in <code>R</code> einzulesen, kann das Paket <code>haven</code> installiert und die Funktion <code>read_sav</code> genutzt werden. Der Rest des verwendeten Codes entspricht dem Code, den wir auch bei <code>load</code> verwendet haben. Wir weisen den Datensatz aber direkt einem Objekt zu, da er sonst nur in der Konsole angezeigt werden würde.</p>
<pre class="r"><code>install.packages(&quot;haven&quot;)
library(haven)
osf &lt;- read_sav(&quot;C:/Users/Musterfrau/Desktop/Raw SubdataSet.sav&quot;)</code></pre>
<p>Sie können den Datensatz aber auch direkt über die Website in das Environment einladen. Dafür verwenden Sie den folgendenen Befehl:</p>
<pre class="r"><code>library(haven)
osf &lt;- read_sav(file = url(&quot;https://osf.io/prc92/download&quot;))</code></pre>
<p>Nun sollte in <code>R</code>-Studio oben rechts in dem Fenster unter der Rubrik “Data” unser Datensatz mit dem Namen “<em>osf</em>” erscheinen.
.</p>
</div>
<div id="übersicht-über-die-daten" class="section level3">
<h3>Übersicht über die Daten</h3>
<p>Wir wollen uns einen Überblick über die Daten verschaffen:</p>
<pre class="r"><code>names(osf)  # Variablennamen im Datensatz</code></pre>
<pre><code>##  [1] &quot;CASEID&quot;           &quot;QUESTID&quot;          &quot;GENDER_R&quot;         &quot;WHITENH&quot;         
##  [5] &quot;BLACKNH&quot;          &quot;NATAMNH&quot;          &quot;PACISL&quot;           &quot;ASIAN&quot;           
##  [9] &quot;MIXED&quot;            &quot;HISPANIC&quot;         &quot;TOTFAMINCOME&quot;     &quot;MJANDCOKE&quot;       
## [13] &quot;MDELASTYR&quot;        &quot;MARJLTYR&quot;         &quot;COCCRKLY&quot;         &quot;FEMALE&quot;          
## [17] &quot;COCINDEX&quot;         &quot;MRJINDEX&quot;         &quot;ANYINDEX&quot;         &quot;COCDUMMY&quot;        
## [21] &quot;MRJDUMMY&quot;         &quot;ANYDUMMY&quot;         &quot;DEPRESSIONINDEX&quot;  &quot;DEPRESSIONINDEX2&quot;
## [25] &quot;Sex&quot;              &quot;EverUse_MarCoc&quot;   &quot;LY_MDE&quot;           &quot;LY_Marijuana&quot;    
## [29] &quot;LY_CocaineCrack&quot;  &quot;Deplvl_Cocaine&quot;   &quot;Deplvl_Marijuana&quot; &quot;Deplvl_Anydrug&quot;  
## [33] &quot;CocaineDep&quot;       &quot;MarijuanaDep&quot;     &quot;AnydrugDeg&quot;       &quot;Depression_lvl1&quot; 
## [37] &quot;Depression_lvl&quot;   &quot;AnydrugDep&quot;</code></pre>
<pre class="r"><code>dim(osf)    # Dimensionen des Datensatzes</code></pre>
<pre><code>## [1] 55602    38</code></pre>
<p>Es gibt insgesamt 38 Variablen. Viele Variablen sind hier auch doppelt in verschiedener Kodierung enthalten. Wir wollen uns auf 3 Variablen fokussieren. Die Variable <code>ANYDUMMY</code> gibt dabei an, ob eine Person irgendeine Drogeanbhängigkeit hat. Diese Fälle sind mit 1 kodiert. Die Variable <code>Gender_R</code> enthält eine Dummykodierung für das Geschlecht (in diesem Fall dichotom aufgeführt), wobei <code>0</code> für weiblich und <code>1</code> für männlich steht. Die Variablen <code>Depression_lvl</code> enthält eine Likert-Skala, auf der zwischen 0 und 9 die Depressionswerte der Personen abgetragen sind.</p>
<p>Auch in diesem Datensatz gibt es natürlich fehlende Werte. Zur Illustration werden wir Personen entfernen, wenn sie auf einer der relevanten Variable einen fehlenden Wert haben. Beachten Sie, dass dieses Vorgehen in einer normalen Analyse weitreichende Probleme mit sich bringen würde und nur zur Vereinfachung für Lehrzwecke eingesetzt wird.</p>
<pre class="r"><code>missings_id &lt;- which(is.na(osf$ANYDUMMY) |
                        is.na(osf$GENDER_R) |
                        is.na(osf$Depression_lvl))
length(missings_id)</code></pre>
<pre><code>## [1] 18659</code></pre>
<p>Durch die Kombination aus <code>which</code> und <code>is.na</code> werden alle Zeilennummern identifiziert, in denen eine der drei Variablen fehlend ist. Der vertikale Strich steht dabei für eine Verknüpfung mit “oder”. Es reicht also ein fehlender Wert auf einer der Variablen, um in dem Objekt <code>missings_id</code> getracked zu werden. Insgesamt sind von unserem Ausschluss 18659 Personen betroffen. Nun müssen wir die Fälle noch ausschließen:</p>
<pre class="r"><code>osf &lt;- osf[-missings_id, ]
dim(osf) # nach Fallauschluss</code></pre>
<pre><code>## [1] 36943    38</code></pre>
<p>Die Menge an Personen hat sich drastische reduziert. Dennoch können wir mit der vorhanden Stichprobe, die Funktionsweise der logistischen Regression gut erläutern. Für diese wollen wir auch noch das Geschlecht als Variable des Typs <code>factor</code> hinterlegen. Dabei steht <code>0</code> für weiblich und <code>1</code> für männlich.</p>
<pre class="r"><code>osf$GENDER_R &lt;- as.factor(osf$GENDER_R)
levels(osf$GENDER_R) &lt;- c(&quot;weiblich&quot;, &quot;maennlich&quot;)</code></pre>
</div>
<div id="fragestellungen" class="section level3">
<h3>Fragestellungen</h3>
<p>Für unser Beispiel wollen wir die Drogenabhängigkeit als abhängige Variable benutzen. Dabei wollen wir untersuchen, ob der Depressionswert oder das Geschlecht eine Vorhersage leisten können.</p>
</div>
<div id="warum-keine-lineare-regression" class="section level3">
<h3>Warum keine lineare Regression?</h3>
<p>Um die Drogenabhängigkeit zu modellieren, könnten wir eine <a href="/post/regression-aussreisser-klipps/">Regressionsanalyse</a> heranziehen und die Drogenabhängigkeit (<code>ANYDUMMY</code>) durch bspw. den Depressionswert (<code>Depression_lvl</code>) vorhersagen. Wir nennen unser Modell zur Modellierung der Drogenabhängigkeit <code>reg_model</code>.</p>
<pre class="r"><code>reg_model &lt;- lm(ANYDUMMY ~ 1 + Depression_lvl, data = osf)
summary(reg_model)</code></pre>
<pre><code>## 
## Call:
## lm(formula = ANYDUMMY ~ 1 + Depression_lvl, data = osf)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -0.09351 -0.02512 -0.02512 -0.02512  0.97488 
## 
## Coefficients:
##                 Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)    0.0251208  0.0010294   24.40   &lt;2e-16 ***
## Depression_lvl 0.0075993  0.0003446   22.05   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.1809 on 36941 degrees of freedom
## Multiple R-squared:  0.01299,    Adjusted R-squared:  0.01297 
## F-statistic: 486.3 on 1 and 36941 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>Laut der einfachen Regressionsanalyse scheint es, dass der Depressionsscore sehr gering mit dem Drogenkonsum zusammenhängt. Lassen Sie sich dabei von der Signifikanz nicht täuschen. Der Zusammenhang würde zwar für die Population angenommen werden, aber das heißt nicht, dass es ein starker Zusammenhang ist. Die erklärte Varianz wäre aber bei einem Prozent.</p>
<p>Betrachten wir nun exemplarisch zwei Voraussetzungen der Regression. Der Code für die Grafiken ist in <a href="#AppendixB">Appendix B</a> zu finden.</p>
<p><img src="/post/2021-10-18-Logistic_Regression_Klipps_files/figure-html/unnamed-chunk-8-1.png" width="672" style="display: block; margin: auto;" /><img src="/post/2021-10-18-Logistic_Regression_Klipps_files/figure-html/unnamed-chunk-8-2.png" width="672" style="display: block; margin: auto;" /></p>
<p>In dieser Analyse sind einige Annahmen der Regressionsanalyse verletzt: Normalverteilung der Residuen, Homoskedastizität und auch Unabhängigkeit der Residuen. Den Verteilungen der Residuen können wir deutlich entnehmen, dass diese systematisch ausfallen (mit steigender Depression steigen die Residuen linear an) und auch die Normalverteilungsannahme ist deutlich verletzt. Eine Regression erscheint nicht sinnvoll. Den Ergebnisse der Signifikanzentscheidungen kann nicht getraut werden. Zusätzlich würde eine Vorhersage der abhängigen Variable viele Werte außerhalb der beiden sinnvollen Ausprägungen <code>0</code> und <code>1</code> ergeben. Wir müssen uns also irgendwie anders mit den Daten auseinandersetzen! Aus diesem Grund wollen wir die logistische Regression heranziehen.</p>
<p>Im Grunde wird bei der logistischen Regression die Wahrscheinlichkeit des “Erfolgs” (was auch immer der Erfolg ist: erkrankt ja/nein, genesen ja/nein etc.) modelliert. Der Trick dabei ist, dass sich diese Wahrscheinlichkeit auf unterschiedlichen Ausprägungen der Prädiktoren unterschiedlich verhalten kann. Sie wird also durch die Prädiktoren <em>bedingt</em>. Die Funktion in <code>R</code> hierzu heißt <code>glm</code>, was für <strong>G</strong>eneralized <strong>L</strong>inear <strong>M</strong>odel steht. Um den Wertebereich der AV einzuhalten, wird die Erfolgswahrscheinlichkeit so transformiert, dass sie linear durch die UVs vorhergesagt werden kann, aber die Wahrscheinlichkeit trotzdem zwischen 0 und 1 liegt. Gehen wir bspw. von zwei Prädiktoren <span class="math inline">\(X_1\)</span> und <span class="math inline">\(X_2\)</span> aus:</p>
<p><span class="math display">\[\begin{align*}
p &amp;= \mathbb{P}(Y = 1 | X_1 = x_1, X_2 = x_2) = \frac{e^{\beta_0 + \beta_1x_1 + \beta_2x_2}}{1 + e^{\beta_0 + \beta_1x_1 + \beta_2x_2}}\\[2ex]
odds(p) &amp; = \frac{\mathbb{P}(Y = 1 | X_1 = x_1, X_2 = x_2)}{1-\mathbb{P}(Y = 1 | X_1 = x_1, X_2 = x_2)} = e^{\beta_0 + \beta_1x_1 + \beta_2x_2}\\[2ex]
logit(p) &amp;  = \ln\left(\frac{\mathbb{P}(Y = 1 | X_1 = x_1, X_2 = x_2)}{1-\mathbb{P}(Y = 1 | X_1 = x_1, X_2 = x_2)}\right) = \beta_0 + \beta_1x_1 + \beta_2x_2
\end{align*}\]</span></p>
<p>Hier ist <span class="math inline">\(\ln\)</span> der natürliche Logarithmus zur Basis <span class="math inline">\(e\)</span> (<span class="math inline">\(e\)</span> ist die Eulersche Zahl <span class="math inline">\(\approx 2.718282\)</span>). Der <span class="math inline">\(logit\)</span> stellt hierbei die Link-Funktion dar, die eine transformierte Version der interessanten Wahrscheinlichkeit, linear durch die Prädiktoren darstellen lässt. Die <span class="math inline">\(odds\)</span> und <span class="math inline">\(p\)</span> sind dann nur Retransformationen, die aus der Link-Funktion resultieren. Einige Wiederholungen zu Exponenten- oder Logarithmusregeln können Sie am Anfang der <a href="/post/nichtlineare-regression">Sitzung zu exponentiellem Wachstum aus dem Bachelor</a> nachlesen.</p>
</div>
<div id="generalisiertes-lineares-modell-logistische-regressionsanalyse" class="section level3">
<h3>Generalisiertes Lineares Modell: Logistische Regressionsanalyse</h3>
<div id="fragestellung-1-depression-als-prädiktor" class="section level4">
<h4>Fragestellung 1: Depression als Prädiktor</h4>
<p>Für die erste Hypothese müssen wir den Einfluss des Depressionsscores auf die Wahrscheinlichkeit der Drogenabhängigkeit bestimmen. Dafür wollen wir eine logistische Regressionsanlyse durchführen. In dieser werden die Residuen nicht länger als normalverteilt angenommen, sondern die AV wird als (bedingt) binomialverteilt modelliert. Wir nennen das Modell <code>glm_model</code>, da wir uns im Generalisierten Linearen Model bewegen. Die Funktion <code>glm</code> übernimmt für uns die richtige Transformation, nämlich den Logit als Link-Funktion, indem wir noch das Zusatzargument <code>family = "binomial"</code> festlegen. Die Binomialverteilung ist gerade jene Verteilung, die beschreibt, wie häufig bei <span class="math inline">\(n\)</span> Versuchen Erfolg eintritt (also genau die richtige Verteilung für unser Modell!).</p>
<pre class="r"><code>glm_model &lt;- glm(ANYDUMMY ~ 1 + Depression_lvl, family = &quot;binomial&quot;, data = osf)
summary(glm_model)</code></pre>
<pre><code>## 
## Call:
## glm(formula = ANYDUMMY ~ 1 + Depression_lvl, family = &quot;binomial&quot;, 
##     data = osf)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -0.4615  -0.2268  -0.2268  -0.2268   2.7106  
## 
## Coefficients:
##                 Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)    -3.648086   0.035940 -101.50   &lt;2e-16 ***
## Depression_lvl  0.162463   0.007836   20.73   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 11043  on 36942  degrees of freedom
## Residual deviance: 10671  on 36941  degrees of freedom
## AIC: 10675
## 
## Number of Fisher Scoring iterations: 6</code></pre>
<p>Der Output der Summary unterscheidet sich geringfügig von der der normalen Regressionsanalyse:</p>
<pre><code>## 
## Call:
## glm(formula = ANYDUMMY ~ 1 + Depression_lvl, family = &quot;binomial&quot;, 
##     data = osf)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -0.4615  -0.2268  -0.2268  -0.2268   2.7106</code></pre>
<p>zeigt uns, dass wir kein <code>lm</code>-Objekt sondern ein <code>glm</code>-Objekt vor uns haben. Außerdem werden uns dieses Mal <code>Deviance Residuals</code> angezeigt anstatt normale Residuen. Mit der Bedeutung dieser Residuen werden wir uns im Rahmen des Seminars nicht auseinandersetzen. Das Schätzverfahren ist ein anderes. Es wird nicht das Kleinste-Quadrate-Verfahren angewandt, sondern die Maximum-Likelihood-Schätzmethode (ML).</p>
<pre><code>## 
## Coefficients:
##                 Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)    -3.648086   0.035940 -101.50   &lt;2e-16 ***
## Depression_lvl  0.162463   0.007836   20.73   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)</code></pre>
<p>Der Überblick über die (ML-)Parameterschätzung unterscheidet sich kaum von der normalen Regression. Lediglich die <span class="math inline">\(t\)</span>-Werte werden durch <span class="math inline">\(z\)</span>-Werte ersetzt. Die Idee hinter der Signifikanzentscheidung ist aber komplett identisch (außerdem geht die <span class="math inline">\(t\)</span>-Verteilung für große <span class="math inline">\(n\)</span> in die <span class="math inline">\(z\)</span>-(Standardnormal-)Verteilung über). Hier scheint sich ein signifikanter Effekt des Depressionsscores zu zeigen.</p>
<pre><code>##     Null deviance: 11043  on 36942  degrees of freedom
## Residual deviance: 10671  on 36941  degrees of freedom
## AIC: 10675
## 
## Number of Fisher Scoring iterations: 6</code></pre>
<p>In diesem Abschnitt werden die Devianzen angezeigt. Diese beschreiben gerade die Log-Likelihooddifferenz zum saturierten Modell (einem Modell, das genau perfekt zu den Daten passt - also de facto die Abweichung des Modells zu den Daten). Die <code>Null deviance</code> beschreibt hier den Unterschied eines Modells ohne Prädiktoren zu den Daten. Dieses hat hier 36942 Freiheitsgrade. Unter <code>Residual deviance</code> wird nun die Devianz unseres angenommenen Modells verstanden. Da wir einen Prädiktor mit in das Modell aufgenommen haben (Depressionsscore), geht ein Freiheitsgrad für diesen Parameter verloren, weswegen die Residualdevianz hier 36941 Freiheitsgrade hat (siehe bspw. <a href="https://hds.hebis.de/ubffm/Record/HEB366849158">Eid, et al., 2017,</a> Kapitel 22.8 und insbesondere Seiten 823-824). Der AIC (Akaike’s Information Criterion) unseres Modells liegt bei 10675. Mit Hilfe dieses AICs können auch nicht geschachtelte Modelle sowie Modelle mit unterschiedlichen Annahmen verglichen werden. Eine Signifikanzentscheidung ist allerdings nicht möglich (siehe bspw. <a href="https://hds.hebis.de/ubffm/Record/HEB366849158">Eid, et al., 2017,</a> Seite 750). Die letzte Zeile gibt an, wie lange der Fisher-Scoring-Algorithmus gebraucht hat, um die Standardfehler zu bestimmen. Dies kann Auskunft über mögliche Konvergenzschwierigkeiten liefern , also Schwierigkeiten des Algorithmus damit, bei einer guten Lösung
anzukommen. Hier ist ein Wert von 6 aber sehr niedrig!</p>
<p>Wir haben bereits anhand des Tests des Steigungsparameters gesehen, dass ein signifikanter Einfluss des Depressionsscores auf die Wahrscheinlichkeit der Drogenabhängigkeit für die Population angenommen werden kann. Trotzdem wollen wir uns nochmal damit auseinandersetzen, wie ein gesamtes Modell (mit allen Prädiktoren) gegen das Nullmodell (also ohne jeglichen Prädiktor) getestet werden kann. Natürlich könnte man sich diese Funktion schnell selbst schreiben und den kritischen Wert raus suchen, aber es gibt ein Paket, welches diese Arbeit für uns übernhemen kann. Dafür müssen wir <code>lmtest</code> installieren. Bei der Installation sollte auch die Abhängigkeit <code>zoo</code> mit installiert werden.</p>
<pre class="r"><code>install.packages(&quot;lmtest&quot;)
library(lmtest)</code></pre>
<p>Im theoretischen Teil haben wir gelernt, dass für den Modellvergleich der Likelihood-Ratio-Test verwendet wird, in dem die Likelihood des Modells mit Prädiktoren in Verhältnis zu der Likelihood des Modells ohne Prädiktoren gesetzt wird. Ist der Gewinn in der Likelihood durch die Prädiktoren groß genug, resultiert ein signifikantes Ergebnis. Die zugehörige Funktion in <code>R</code> heißt <code>lr.test</code>. Diese braucht als einziges Argument jenes mit Prädiktoren und kann dieses mit dem Modell ohne Prädiktoren vergleichen.</p>
<pre class="r"><code>lrtest(glm_model)</code></pre>
<pre><code>## Likelihood ratio test
## 
## Model 1: ANYDUMMY ~ 1 + Depression_lvl
## Model 2: ANYDUMMY ~ 1
##   #Df  LogLik Df  Chisq Pr(&gt;Chisq)    
## 1   2 -5335.4                         
## 2   1 -5521.6 -1 372.43  &lt; 2.2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>Der Output zeigt uns zunächst nochmal an, welche Modelle verglichen werden. In <code>Model 1</code> ist die Variable <code>Depression_lvl</code> als Prädiktor enthalten, während bei <code>Model 2</code> kein Prädiktor vorhanden ist. In der kleinen Tabelle sehen wir dann die Likelihoods der beiden Modelle, ihren Unterschied in Freiheitsgraden und den empirischen <span class="math inline">\(\chi^2\)</span>-Wert. Dabei wird auch angezeigt, dass der Test signifikant ausfällt - das Modell leistet einen signifikanten Beitrag zur Vorhersage über das Null-Modell hinaus.</p>
</div>
<div id="fazit-der-analyse" class="section level4">
<h4>Fazit der Analyse</h4>
<p>Der Effekt des Despressionsscores ist statistisch signifikant. Wir haben dieses Mal ein sinnvolleres Modell eingesetzt, was bedeutet, dass wir den Ergebnissen eher trauen können. Insgesamt stützen die Daten unsere erste Hypothese. Allerdings ist dieser Effekt sehr klein (dazu später mehr, wenn wir zur Ergebnisinterpretation und zur Einordnung der Koeffizienten kommen). Wenn wir den Wertebereich entlang der x-Achse sehr/unrealistisch groß wählen und das Alter von -20 bis 60 laufen lassen, so können wir uns die linearen und nichtlinearen Beziehungen zwischen Depressionsscore - Logit, Depressionsscore - Odds und Depressionsscore - Wahrscheinlichkeit ansehen, andernfalls ist der Effekt so klein, dass wir kaum etwas erkennen. <code>glm_model$coefficients[1] + glm_model$coefficients[2]*Depressionswerte</code> ist hierbei die Formel für den Logit, da die Parameterschätzungen einfach die <span class="math inline">\(\beta\)</span>-Koeffizienten sind, welche linear verknüpft den Logit ergeben.</p>
<pre class="r"><code>Depressionswerte &lt;- seq(-20, 60, 0.1)
logit &lt;- glm_model$coefficients[1] + glm_model$coefficients[2]*Depressionswerte 
plot(x = Depressionswerte, y = logit, type = &quot;l&quot;, col = &quot;blue&quot;, lwd = 3)</code></pre>
<p><img src="/post/2021-10-18-Logistic_Regression_Klipps_files/figure-html/unnamed-chunk-16-1.png" width="672" style="display: block; margin: auto;" /></p>
<p><code>type = "l"</code> fordert eine Linie anstatt von Punkten an, <code>lwd = 3</code> sagt, dass diese Linie dreimal so dick wie der Default sein soll und <code>col = "blue"</code> sagt, dass die Linie blau sein soll.</p>
<p>Glücklicherweise sind Logit, Odds und Wahrscheinlichkeit sehr leicht ineinander überführbar. Für die Berechnung der Odds muss nur die Funktion <code>exp</code> auf die Logit-Werte angewendet werden, während die Wahrscheinlichkeit die Odds geteilt durch eins plus Odds ist.</p>
<pre class="r"><code>odds &lt;- exp(logit)
plot(x = Depressionswerte, y = odds, type = &quot;l&quot;, col = &quot;blue&quot;, lwd = 3)</code></pre>
<p><img src="/post/2021-10-18-Logistic_Regression_Klipps_files/figure-html/unnamed-chunk-17-1.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>p &lt;- odds/(1 + odds)
plot(x = Depressionswerte, y = p, type = &quot;l&quot;, col = &quot;blue&quot;, lwd = 3)</code></pre>
<p><img src="/post/2021-10-18-Logistic_Regression_Klipps_files/figure-html/unnamed-chunk-17-2.png" width="672" style="display: block; margin: auto;" /></p>
<p>Wir erkennen in allen drei Plots die positive Beziehung zwischen Drogenabhängigkeit und Depressionsscore. Der Logit ist eine lineare Funktion (Wertebereich [<span class="math inline">\(-\infty\)</span>,<span class="math inline">\(\infty\)</span>]). Somit steigt (bzw. sinkt) der Logit um <span class="math inline">\(\beta_1\)</span>, wenn der Prädiktor (hier Depressionsscore) um eine Einheit erhöht wird. Die Odds sind eine Exponentialfunktion (Wertebereich [0,<span class="math inline">\(\infty\)</span>]) und bei der Wahrscheinlichkeit handelt es sich um eine sogenannte Ogive (Wertebereich [0,1]). Die Odds steigen (bzw. sinken) um den Faktor <span class="math inline">\(e^{\beta_1}\)</span> (auch Odds-Ratio genannt), wenn der Prädiktor (hier Depressionsscore) um eine Einheit erhöht wird - die Beziehung zwischen Odds und Prädiktor ist somit multiplikativ! Wir schauen uns die Parameterinterpretation der Odds im nächsten Abschnitt genauer an. Wie sich die Wahrscheinlichkeit verändert, ist nicht pauschal zu sagen. Diese Veränderung hängt von der Ausprägung des Prädiktors ab und lässt sich nicht durch eine einzige Zahl quantifizieren. Wir erkennen aber, dass die Ogive erst nach einem Depressionsscore von Null nach links laufend flacher gegen 0 geht. Im Intervall von 0 bis 9 (also möglichen Depressionsscores) ist die Wahrscheinlichkeit der Drogenabhängigkeit kleiner als 20% und steigend mit dem Depressionsscore. In <a href="#AppendixA">Appendix A</a> haben Sie die Möglichkeit, spielerisch die Einflüsse der Parameter in der logistischen Regression kennen zu lernen.</p>
</div>
</div>
<div id="fragestellung-2-geschlecht-als-prädiktor" class="section level3">
<h3>Fragestellung 2: Geschlecht als Prädiktor</h3>
<p>Nun wollen wir das Geschlecht mit in unser Modell aufnehmen und somit Hypothese 2 untersuchen. Da das Geschlecht hier auch nur 2 Ausprägungen hat, kann dieser Effekt als Vergleich zwischen Gruppen verstanden werden. Diese Dummy-Variable haben wir zu Beginn schon als Faktor festgelegt. Mit der Funktion <code>table</code> erhalten wir einen Überblick über die Kombination an Drogenabhängigkeit und dem Geschlecht.</p>
<pre class="r"><code>table(osf$GENDER_R, osf$ANYDUMMY)</code></pre>
<pre><code>##            
##                 0     1
##   weiblich  18381   600
##   maennlich 17294   668</code></pre>
<p>In der Tabelle wird entlang der Spalten die Drogenabhängigkeit vs. das Geschlecht in den Zeilen abgetragen. Dieser Tabelle ist zu entnehmen, dass der relative Anteil an Männerr, die unter einer Abhängigkeit leiden, höher ist als der der Frauen: 668 vs. 17294 für die Männer und 600 vs. 18381 für die Frauen. Auch absolut gesehen leiden mehr Männer unter einer Abhängigkeit. Da die Unterschiede aber recht klein sind, ist ein Geschlechtereffekt erstmal fraglich. Diese 4-Feldertafel könnten wir auch heranziehen, um einen <span class="math inline">\(\chi^2\)</span>-Unabhängigkeitstest durchzuführen. Wir wollen aber den Effekt des Geschlechts über den Depressionsscore hinaus auf die Wahrscheinlichkeit der Drogenabhängigkeit modellieren:</p>
<pre class="r"><code>glm_model2 &lt;-  glm(ANYDUMMY ~ 1 + Depression_lvl + GENDER_R, family = &quot;binomial&quot;, data = osf)
summary(glm_model2)</code></pre>
<pre><code>## 
## Call:
## glm(formula = ANYDUMMY ~ 1 + Depression_lvl + GENDER_R, family = &quot;binomial&quot;, 
##     data = osf)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -0.5225  -0.2460  -0.2460  -0.2040   2.7867  
## 
## Coefficients:
##                    Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)       -3.862029   0.050888 -75.893  &lt; 2e-16 ***
## Depression_lvl     0.173445   0.008049  21.549  &lt; 2e-16 ***
## GENDER_Rmaennlich  0.378801   0.059125   6.407 1.49e-10 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 11043  on 36942  degrees of freedom
## Residual deviance: 10630  on 36940  degrees of freedom
## AIC: 10636
## 
## Number of Fisher Scoring iterations: 6</code></pre>
<p>Das Besondere an diesem Output ist, dass bei der Variable Geschlecht noch <code>maennlich</code> dahinter steht:</p>
<pre><code>## 
## Coefficients:
##                    Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)       -3.862029   0.050888 -75.893  &lt; 2e-16 ***
## Depression_lvl     0.173445   0.008049  21.549  &lt; 2e-16 ***
## GENDER_Rmaennlich  0.378801   0.059125   6.407 1.49e-10 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)</code></pre>
<p>Dies gibt an, dass hier dummy-kodiert wurde und der Effekt von 1 (maennlich) im Vergleich zur Referenzgruppe (also 0, weiblich) dargestellt ist. Bei der Betrachtung der Signifikanztestung der einzelnen Prädiktoren erhalten wir für beide signifikante Ergebnisse.</p>
<div id="ergebnisinterpretation" class="section level4">
<h4>Ergebnisinterpretation</h4>
<p>Die <span class="math inline">\(\beta\)</span>-Gewichte zu interpretieren, hat wenig inhaltliche Aussagekraft. Wir könnten bspw. für das Geschlecht lediglich die Aussage treffen, dass (unter Konstanthaltung aller weiteren Prädiktoren im Modell), wenn Männer im Vergleich zu Frauen betrachtet werden, der Logit (der Wahrscheinlichkeit der Drogenabhängigkeit) um 0.379 steigt. Wenn wir allerdings anstatt des Logits die Odds heranziehen, so können wir mit Hilfe des Odds-Ratio doch eine Aussage über die Wahrscheinlichkeit der Drogenabhängigkeit treffen. Dazu müssen wir die <span class="math inline">\(\beta\)</span>-Gewichte transformieren via <span class="math inline">\(e^\beta\)</span>:</p>
<pre class="r"><code>exp(glm_model2$coefficients) # Odds-Ratios</code></pre>
<pre><code>##       (Intercept)    Depression_lvl GENDER_Rmaennlich 
##        0.02102529        1.18939523        1.46053194</code></pre>
<p>Nun können wir die Ergebnisse (einigermaßen) sinnvoll interpretieren. Das Interzept wird an der Stelle interpretiert, wo alle Prädiktoren den Wert 0 annehmen. Für den Depressionsscore würde das natürlich eine Person ohne Punkte im Fragebogen darstellen. Außerdem ist noch die Variable <code>GENDER_R</code> im Modell. Dies ist eine Dummy-Variable, die den Wert 1 annimmt, wenn das Geschlecht den Wert 1 (im Vergleich zu 0; der Referenzkategorie) annimmt; also wenn wir einen Mann im Vergleich zu einer Frau betrachten. Folglich hat diese Dummy-Variable gerade den Wert 0, wenn eine Frau betrachtet wird. Wir interpretieren das Interzept bzgl. der Odds wie folgt: Eine weibliche Person mit einem Depressionsscore von 0 Person hat Drogenabahängigkeits-Odds von 0.021. Dies bedeutet, dass es für sie 0.021-mal so wahrscheinlich eine Drogenabhängigkeit zu haben als sie nicht zu haben.</p>
<p>Der Effekt der Depression lässt sich wie folgt interpretieren: Steigt der Depressionsscore um 1 an (unter Konstanthaltung aller weiteren Prädiktoren im Modell), so verändern sich die Odds zur Drogenabhängigkeit um den Faktor (multiplikativ) 1.189. Insgesamt steigen die Odds und damit die Wahrscheinlichkeit einer Drogenabhängigkeit mit dem Depressionsscore, denn das Odds-Ratio ist genau dann größer 1, wenn der <span class="math inline">\(\beta\)</span>-Koeffizient des Logit größer als 0 ist und es sich somit um eine positive/steigende Beziehung handelt!</p>
<p>Beschäftigen wir uns nun mit der Geschlechtervariable: Wird ein Mann im Vergleich zu einem Frau betrachtet, so steigen die Odds für eine Drogenabhängigkeit um den Faktor 1.461. Somit haben (unter Konstanthaltung aller weiteren Prädiktoren im Modell) Männer eine 1.461 mal so hohe Wahrscheinlichkeit für eine Drogenabhängigkeit wie die Frauen. Hier ist extrem wichtig, zu beachten, dass die Odds sich multiplikativ ändern und nicht additiv, wie wir es von der linearen Regression (und im Übrigen auch vom Logit) gewohnt sind.</p>
</div>
<div id="grafische-veranschaulichung" class="section level4">
<h4>Grafische Veranschaulichung</h4>
<p>Wir können uns dieses Modell auch grafisch ansehen und damit die oben aufgezeigten Effekte verdeutlichen. Den Code können Sie im <a href="#AppendixB">Appendix B</a> finden.</p>
<p><img src="/post/2021-10-18-Logistic_Regression_Klipps_files/figure-html/unnamed-chunk-23-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>In dem Plot sind die vorhergesagten Logits für alle Personen im Datensatz zu sehen. Dabei ist der Logit natürlich vom Depressionsscore abhängig und das Geschlecht wird als Gruppierungsvariable für zwei verschiedene Geraden verwendet. Die Logik lässt sich auch auf die Odds und die Wahrscheinlichkeit der Drogenabhängigkeit übertragen.</p>
<p><img src="/post/2021-10-18-Logistic_Regression_Klipps_files/figure-html/unnamed-chunk-24-1.png" width="672" style="display: block; margin: auto;" /></p>
<p><img src="/post/2021-10-18-Logistic_Regression_Klipps_files/figure-html/unnamed-chunk-25-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>Der Verlauf der Odds und der Wahrscheinlichkeit sieht in diesem Beispiel recht ähnlich aus. Das liegt daran, dass wir nun den realistischen Bereich der Daten betrachten. Wenn wir den Bereich der x-Achse erweitern würden, würden die Odds gegen <span class="math inline">\(\infty\)</span> gehen, während die Wahrscheinlichkeit die ogive Form zeigen und sich damit der 1 annähern würde.</p>
<p>Wie bereits in der ersten Analyse festgestellt, scheint ein höherer Depressionscore mit einer erhöhten Wahrscheinlichkeit des Drogenkonsums einherzugehen. Auch das Geschlecht scheint einen Einfluss auf diese Wahrscheinlichkeit zu haben.</p>
</div>
</div>
<div id="modellvergleich" class="section level3">
<h3>Modellvergleich</h3>
<p>Zum Abschluss wollen wir uns jetzt mittels Modellvergleichen nochmal der Frage widmen, ob das Geschlecht über den Depressionsscore hinaus einen signifikanten Beitrag zur Vorhersage leistet.</p>
<p>Zunächst testen wir das neu erstellte Gesamtmodell gegen das Null-Modell, wie wir es bereits mit dem <code>glm_model</code> getan haben.</p>
<pre class="r"><code>lrtest(glm_model2)</code></pre>
<pre><code>## Likelihood ratio test
## 
## Model 1: ANYDUMMY ~ 1 + Depression_lvl + GENDER_R
## Model 2: ANYDUMMY ~ 1
##   #Df  LogLik Df  Chisq Pr(&gt;Chisq)    
## 1   3 -5314.8                         
## 2   1 -5521.6 -2 413.66  &lt; 2.2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>Wenig überraschend erzeugt auch dieser Test ein signifikantes Ergebnis. Spannender ist jetzt, ob die Hinzunahme des Geschlechts auch einen signifikanten Mehrwert bringt. Wie immer in <code>R</code> gibt es für den Vergleich zwischen zwei Modellen mehrere Wege, wir bleiben aber bei der verwendeten <code>lrtest</code> Funktion. Diese kann nämlich auch zwei Modelle als Argumente annehmen und vegleichen.</p>
<pre class="r"><code>lrtest(glm_model, glm_model2)</code></pre>
<pre><code>## Likelihood ratio test
## 
## Model 1: ANYDUMMY ~ 1 + Depression_lvl
## Model 2: ANYDUMMY ~ 1 + Depression_lvl + GENDER_R
##   #Df  LogLik Df  Chisq Pr(&gt;Chisq)    
## 1   2 -5335.4                         
## 2   3 -5314.8  1 41.232  1.352e-10 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>Der Output ist für uns nicht mehr neu. Statt dem Nullmodell sind jetzt zwei Modelle mit Prädiktoren aufgeführt. <code>Model 1</code> enthält allerdings nur einen Prädiktor und wird deshalb auch als <em>eingeschränkt</em> bezeichnet. <code>Model 2</code> hingegen ist das <em>uneingeschränkte</em> Modell. Da wir ein signifikantes Ergebnis erhalten, würden wir uns für das uneingeschränkte Modell entscheiden.</p>
</div>
<div id="fazit" class="section level3">
<h3>Fazit</h3>
<p>Final können wir festhalten, dass sowohl der Depressionsscore als auch das Geschlecht als Prädiktoren für die Wahrscheinlichkeit der Drogenabhängigkeit fungieren können.</p>
<hr />
</div>
</div>
<div id="r-skript" class="section level2">
<h2>R-Skript</h2>
<p>Den gesamten <code>R</code>-Code, der in dieser Sitzung genutzt wird, können Sie <a href="/post/under-construction"><svg aria-hidden="true" role="img" viewBox="0 0 512 512" style="height:1em;width:1em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:currentColor;overflow:visible;position:relative;"><path d="M216 0h80c13.3 0 24 10.7 24 24v168h87.7c17.8 0 26.7 21.5 14.1 34.1L269.7 378.3c-7.5 7.5-19.8 7.5-27.3 0L90.1 226.1c-12.6-12.6-3.7-34.1 14.1-34.1H192V24c0-13.3 10.7-24 24-24zm296 376v112c0 13.3-10.7 24-24 24H24c-13.3 0-24-10.7-24-24V376c0-13.3 10.7-24 24-24h146.7l49 49c20.1 20.1 52.5 20.1 72.6 0l49-49H488c13.3 0 24 10.7 24 24zm-124 88c0-11-9-20-20-20s-20 9-20 20 9 20 20 20 20-9 20-20zm64 0c0-11-9-20-20-20s-20 9-20 20 9 20 20 20 20-9 20-20z"/></svg> hier herunterladen</a>.</p>
<hr />
</div>
<div id="appendix" class="section level2">
<h2>Appendix</h2>
<div id="AppendixA" class="section level3">
<h3>Appendix A</h3>
<details>
<summary>
<strong>Parametereinflüsse</strong>
</summary>
<p>Die folgende Funktion stellt vier Grafiken dar: den Logit, die Odds, die Wahrscheinlichkeit und die Wahrscheinlichkeit vs. eine Zufallserhebung. Sie können <span class="math inline">\(\beta_0\)</span> und <span class="math inline">\(\beta_1\)</span> dieses Modells so einstellen, wie Sie wünschen und können sich den Effekt auf die verschiedenen Darstellungsformen der logistischen Regression ansehen. In hellblau wird jeweils die Funktion mit <span class="math inline">\(\beta_0 = 0\)</span> und <span class="math inline">\(\beta_1 = 1\)</span> als Referenz dargestellt. Die gestrichelten Linien stellen jeweils die x- und die y-Achse dar. In roten Punkten werden Realisierungen von <span class="math inline">\(Y=0,1\)</span> dargestellt, die mit der angezeigten Wahrscheinlichkeit gezogen wurden. Um die Ergebnisse vergleichbar zu machen, wird <code>set.seed(1234)</code> verwendet (vgl. <a href="/post/einleitung-und-wiederholung">Einführungssitzung</a>).</p>
<pre class="r"><code>Logistic_functions &lt;- function(beta0 = 0, beta1 = 1)
{
        par(mfrow=c(2,2)) # 4 Grafiken in einer

        xWerte &lt;- seq(-5, 5, 0.1)
        logit &lt;- beta0 + beta1*xWerte
        plot(x = xWerte, y = logit, type = &quot;l&quot;, col = &quot;blue&quot;, lwd = 3, main = &quot;Logit vs X&quot;, xlab = &quot;X&quot;)
        lines(xWerte, xWerte, col = &quot;skyblue&quot;)
        abline(h = 0, lty = 3); abline(v = 0, lty = 3)

        odds &lt;- exp(logit)
        plot(x = xWerte, y = odds, type = &quot;l&quot;, col = &quot;blue&quot;, lwd = 3, main = &quot;Odds vs X&quot;, xlab = &quot;X&quot;)
        abline(h = 0, lty = 3); abline(v = 0, lty = 3)
        lines(xWerte, exp(xWerte), col = &quot;skyblue&quot;)

        p &lt;- odds/(1 + odds)
        plot(x = xWerte, y = p, type = &quot;l&quot;, col = &quot;blue&quot;, lwd = 3, main = &quot;P vs X&quot;, ylim = c(0,1), xlab = &quot;X&quot;)
        lines(xWerte, exp(xWerte)/(1 + exp(xWerte)), col = &quot;skyblue&quot;)
        abline(h = 0, lty = 3); abline(v = 0, lty = 3)

        set.seed(1234) # Vergleichbarkeit
        Y &lt;- rbinom(n = length(xWerte), size = 1, prob = p)
        plot(x = xWerte, y = p, type = &quot;l&quot;, col = &quot;blue&quot;, lwd = 3, main = &quot;P vs X und zufällige Realisierungen&quot;,
             ylim = c(0,1), xlab = &quot;X&quot;, ylab = &quot;P und Y&quot;)
        abline(h = 0, lty = 3); abline(v = 0, lty = 3)
        points(x = xWerte, y = Y, pch = 16, cex = .5, col = &quot;red&quot;)
}</code></pre>
<p>Sie führen diese Funktion aus, indem Sie alles von <code>Logistic_functions &lt;- function(beta0 = 0, beta1 = 1){</code> bis <code>}</code> kopieren und in Ihrem <code>R</code>-Studio Fenster ausführen, sodass in der Rubrik oben rechts (dort wo auch immer <code>Data</code> erscheint) unter <code>Functions</code> <code>Logistic_functions</code> als Funktion aufgeführt wird. Sie können sich bspw. die Konstellation für <span class="math inline">\(\beta_0 = 1\)</span> und <span class="math inline">\(\beta_1 = -0.5\)</span> im Vergleich zu <span class="math inline">\(\beta_0 = 0\)</span> und <span class="math inline">\(\beta_1 = 1\)</span> ansehen:</p>
<pre class="r"><code>Logistic_functions(beta0 = 1, beta1 = -.5)</code></pre>
<p><img src="/post/2021-10-18-Logistic_Regression_Klipps_files/figure-html/unnamed-chunk-29-1.png" width="672" style="display: block; margin: auto;" /></p>
</details>
</div>
<div id="AppendixB" class="section level3">
<h3>Appendix B</h3>
<details>
<summary>
<strong>Fortgeschrittene Grafiken</strong>
</summary>
<p>Zunächst beschäftigen wir uns mit den beiden Grafiken, die die Residuen der linearen Regression zwischen Depressionsscore und Drogenabhängigkeit betrachten. Für den ersten Plot benötigen wir das Paket <code>car</code>.</p>
<pre class="r"><code>library(car) # nötiges Paket laden
avPlots(model = reg_model, pch = 16)</code></pre>
<p><img src="/post/2021-10-18-Logistic_Regression_Klipps_files/figure-html/unnamed-chunk-30-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>Für die Erstellung des zweiten Plots muss das Paket <code>MASS</code> aktiviert sein. Zunächst werden die studentisierten Residuen als Objekt abgelegt. Dafür kann die Funktion <code>studres</code> verwendet werden. Diese werden in einem Histogramm abgebildet.</p>
<pre class="r"><code>library(MASS)# nötiges Paket laden
res &lt;- studres(reg_model) # Studentisierte Residuen als Objekt speichern
hist(res, freq = F)
xWerte &lt;- seq(from = min(res), to = max(res), by = 0.01)
lines(x = xWerte, y = dnorm(x = xWerte, mean = mean(res), sd = sd(res)), lwd = 3)</code></pre>
<p><img src="/post/2021-10-18-Logistic_Regression_Klipps_files/figure-html/unnamed-chunk-31-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>Um die Normalverteilunskurve auch noch einzuzeichnen erstellen wir einen Vektor mit x Variablen vom Minimum bis zum Maximum der Residuen-Werte. Anschließend legen wir über <code>lines</code> und <code>dnorm</code> die Kurve auf unser Histogramm. <code>dnorm</code> bestimmt dabei die Werte, die die Normalverteilung an der Stelle x mit dem Mittelwert und der Standardabweichung der Residuen hätte.</p>
<p>Die beschriebenen Plots sind mit einem Paket und einer Basis-Funktion von <code>R</code> erstellt. Für die Erstellung von individuellen Plots ist <code>ggplot2</code> das richtige Paket. Dieses wurde bereits häufiger im Appendix als Möglichkeit zum Erzeugen von Plots beschrieben. Weitere Informationen zu <code>ggplot2</code> erhalten Sie bspw. auf <a href="https://ggplot2.tidyverse.org"><svg aria-hidden="true" role="img" viewBox="0 0 640 512" style="height:1em;width:1.25em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:currentColor;overflow:visible;position:relative;"><path d="M622.34 153.2L343.4 67.5c-15.2-4.67-31.6-4.67-46.79 0L17.66 153.2c-23.54 7.23-23.54 38.36 0 45.59l48.63 14.94c-10.67 13.19-17.23 29.28-17.88 46.9C38.78 266.15 32 276.11 32 288c0 10.78 5.68 19.85 13.86 25.65L20.33 428.53C18.11 438.52 25.71 448 35.94 448h56.11c10.24 0 17.84-9.48 15.62-19.47L82.14 313.65C90.32 307.85 96 298.78 96 288c0-11.57-6.47-21.25-15.66-26.87.76-15.02 8.44-28.3 20.69-36.72L296.6 284.5c9.06 2.78 26.44 6.25 46.79 0l278.95-85.7c23.55-7.24 23.55-38.36 0-45.6zM352.79 315.09c-28.53 8.76-52.84 3.92-65.59 0l-145.02-44.55L128 384c0 35.35 85.96 64 192 64s192-28.65 192-64l-14.18-113.47-145.03 44.56z"/></svg> Tidyverse</a>. Außerdem können Sie sich auch eine <a href="/post/grafiken-mit-ggplot2"><svg aria-hidden="true" role="img" viewBox="0 0 640 512" style="height:1em;width:1.25em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:currentColor;overflow:visible;position:relative;"><path d="M622.34 153.2L343.4 67.5c-15.2-4.67-31.6-4.67-46.79 0L17.66 153.2c-23.54 7.23-23.54 38.36 0 45.59l48.63 14.94c-10.67 13.19-17.23 29.28-17.88 46.9C38.78 266.15 32 276.11 32 288c0 10.78 5.68 19.85 13.86 25.65L20.33 428.53C18.11 438.52 25.71 448 35.94 448h56.11c10.24 0 17.84-9.48 15.62-19.47L82.14 313.65C90.32 307.85 96 298.78 96 288c0-11.57-6.47-21.25-15.66-26.87.76-15.02 8.44-28.3 20.69-36.72L296.6 284.5c9.06 2.78 26.44 6.25 46.79 0l278.95-85.7c23.55-7.24 23.55-38.36 0-45.6zM352.79 315.09c-28.53 8.76-52.84 3.92-65.59 0l-145.02-44.55L128 384c0 35.35 85.96 64 192 64s192-28.65 192-64l-14.18-113.47-145.03 44.56z"/></svg> Einführung in <code>ggplot2</code></a> auf dieser Website ansehen.</p>
<pre class="r"><code>library(ggplot2)</code></pre>
<p>Wir können hier sehr leicht Gruppierungen in Grafiken darstellen. Zunächst müssen wir allerdings die Prädiktionen unseres Modells bestimmen, denn wir wollen uns die Vorhersage/Erwartung unseres Modells ansehen. Die Funktion, mit der wir dies machen können, heißt genauso wie die Funktion die sie ausführt: <code>predict</code>. Wir sagen damit den Logit für alle Konstellationen von Alter und Geschlecht in unseren Daten vorher, indem wir der Funktion das Modell übergeben. Wir bestimmen also für jede Personen die erwartete Wahrscheinlichkeit der Drogenabhängigkeit unter diesem Modell (der Prädiktion durch Geschlecht und Alter). Anschließend können wir den Logit so transformieren, dass wir die Odds oder die Wahrscheinlichkeit erhalten. Um dies leichter nachvollziehbar zu machen, führen wir die Transformationen mit neu erstellten Variablen durch, ehe wir diese dem Datensatz anhängen (denn <code>ggplot</code> hat es am liebsten, wenn wir mit <code>data.frames</code>, also ganzen Datensätzen arbeiten).</p>
<pre class="r"><code>logit_glm2 &lt;- predict(glm_model2)           # Logit unter Modell glm2 bestimmen
odds_glm2 &lt;- exp(logit_glm2)          # Logit unter Modell glm2 in Odds transformieren
p_glm2 &lt;- odds_glm2/(1 + odds_glm2)     # Odds in Wahrscheinlichkeiten transformieren
  
# dem Datensatz anhängen:
osf$logit_glm2 &lt;- logit_glm2
osf$odds_glm2 &lt;- odds_glm2
osf$p_glm2 &lt;- p_glm2</code></pre>
<p>Eine Grafik erhalten wir nun mit <code>ggplot</code> sehr einfach:</p>
<pre class="r"><code>ggplot(data = osf, mapping = aes(x =
                                   as.numeric(Depression_lvl),
                                 y = logit_glm2, col =
                                   GENDER_R)) +
  geom_line(lwd = 2) +
  ggtitle(&quot;Logit vs Depression and Sex&quot;) +
  xlab(&quot;Depressionsscore&quot;) + 
  ylab(&quot;Logit&quot;)</code></pre>
<p><img src="/post/2021-10-18-Logistic_Regression_Klipps_files/figure-html/unnamed-chunk-34-1.png" width="672" style="display: block; margin: auto;" /></p>
<p><code>ggplot</code> arbeitet etwas anders als die Basisfunktion <code>plot</code>. Zunächst übergeben wir ihr die Daten <code>data = osf</code>. Dem <code>mapping</code> übergeben wir sozusagen das Achsenkreuz und Gruppenzugehörigkeiten und Farbkodierungen innerhalb von <code>aes(x = Depression_lvl, y = logit_glm2, col = GENDER_R)</code>. Hier wird gesagt, dass der Depressionsscore auf die x-Achse soll und wir den Logit entlang der y-Achse plotten wollen. Außerdem soll für das Geschlecht eine separate Linie eingezeichnet werden und diese soll farblich kodiert sein. Damit dies funktioniert, müssen natürlich die Variablen im richtigen Format vorliegen. Bspw. müssen Gruppierungen, wie etwa das Geschlecht, als Faktor vorliegen. Anschließend fügen wir mit <code>+</code> hinzu, was genau geplottet werden soll. In diesem Beispiel wollen wir Linien haben. Deshalb verwenden wir die Funktion <code>geom_line</code> mit dem Argument <code>lwd = 2</code> für zweifache Liniendicke. Würden wir hier bspw. <code>geom_point</code> verwenden, so würden Punkte gezeichnet werden. Wieder mit dem <code>+</code> fügen wir außerdem einen Titel hinzu mit der Funktion <code>ggtitle</code>. <code>xlab</code> und <code>ylab</code> lassen uns die Achsentitel modifizieren. Gleiches können wir auch für die Odds oder die Wahrscheinlichkeit durchführen:</p>
<pre class="r"><code>ggplot(data = osf, mapping = aes(x = Depression_lvl,
                                 y = odds_glm2, 
                                 col = GENDER_R)) +
  geom_line(lwd = 2) +
  ggtitle(&quot;Odds vs Depression and Sex&quot;)+
  xlab(&quot;Depressionsscore&quot;) + 
  ylab(&quot;Odds&quot;)</code></pre>
<p><img src="/post/2021-10-18-Logistic_Regression_Klipps_files/figure-html/unnamed-chunk-35-1.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>ggplot(data = osf, mapping = aes(x = Depression_lvl, 
                                 y = p_glm2, 
                                 col = GENDER_R)) +
  geom_line(lwd = 2) +
  ggtitle(&quot;P vs Depression and Sex&quot;) +  
  xlab(&quot;Depressionsscore&quot;) + 
  ylab(&quot;Logit&quot;)</code></pre>
<p><img src="/post/2021-10-18-Logistic_Regression_Klipps_files/figure-html/unnamed-chunk-36-1.png" width="672" style="display: block; margin: auto;" /></p>
</details>
<hr />
</div>
</div>
<div id="literatur" class="section level2">
<h2>Literatur</h2>
<p><a href="https://hds.hebis.de/ubffm/Record/HEB366849158">Eid, M., Gollwitzer, M., &amp; Schmitt, M. (2017).</a> <em>Statistik und Forschungsmethoden</em> (5. Auflage, 1. Auflage: 2010). Weinheim: Beltz.</p>
<p><a href="https://hds.hebis.de/ubffm/Record/HEB371183324">Pituch, K. A. &amp; Stevens, J. P. (2016).</a> <em>Applied Multivariate Statistics for the Social Sciences</em> (6th ed.). New York: Taylor &amp; Francis.</p>
<ul>
<li><small> <em>Blau hinterlegte Autorenangaben führen Sie direkt zur universitätsinternen Ressource.</em></li>
</ul>
</div>
