---
title: Korrelation
author: 
date: '2021-01-04'
slug: korrelation
categories:
  - BSc2
tags:
  - Korrelation
subtitle: ''
summary: ''
authors: [winkler, schroeder]
lastmod: '2021-12-13T13:13:57+01:00'
featured: no
image:
  caption: ''
  focal_point: ''
  preview_only: no
projects: []
---

<script src="/rmarkdown-libs/header-attrs/header-attrs.js"></script>


<details>
<summary>
Kernfragen dieser Lehreinheit
</summary>
<ul>
<li>Wie können Kreuztabellen in R erstellt werden? Welche Varianten gibt es, relative Häufigkeitstabellen zu erstellen?</li>
<li>Wie kann ein gemeinsames Balkendiagramm für zwei Variablen erstellt werden?</li>
<li>Welche zwei Varianten gibt es, Varianzen und Kovarianzen zu bestimmen?</li>
<li>Wie kann die Produkt-Moment-Korrelation, die Rang-Korrelation nach Spearman und Kendalls <span class="math inline">\(\tau\)</span> bestimmt werden?</li>
<li>Wie wird bei der Berechnung von Korrelationen mit fehlenden Werten umgegangen?</li>
</ul>
</details>
<hr />
<div id="datensatz-laden" class="section level2">
<h2>Datensatz laden</h2>
<p>Zu Beginn laden wir wie gewohnt den Datensatz und verteilen die relevanten Labels.</p>
<pre class="r"><code>fb21 &lt;- read.table(&#39;https://pandar.netlify.app/post/fb21.csv&#39;, header = TRUE, sep = &quot;,&quot;)

#Labels
fb21$fach &lt;- factor(fb21$fach, levels = 1:5, labels = c (&#39;Allgemeine&#39;, &#39;Biologische&#39;, &#39;Entwicklung&#39;, &#39;Klinische&#39;, &#39;Diag./Meth.&#39;))
fb21$ziel &lt;- factor(fb21$ziel, levels = 1:4, labels = c (&#39;Wirtschaft&#39;, &#39;Therapie&#39;, &#39;Forschung&#39;, &#39;Andere&#39;))</code></pre>
<hr />
</div>
<div id="häufigkeitstabellen" class="section level2">
<h2>Häufigkeitstabellen</h2>
<p>Die Erstellung von <em>Häufigkeitstabellen</em> zur Darstellung univariater Häufigkeiten haben Sie schon kennengelernt. Dies funktioniert mit einfachen Befehlen für die Häufigkeiten und die zugehörigen relativen Prozentzahlen.</p>
<pre class="r"><code>tab &lt;- table(fb21$fach)                 #Absolut
tab</code></pre>
<pre><code>## 
##  Allgemeine Biologische Entwicklung   Klinische Diag./Meth. 
##          21          19          16          44           9</code></pre>
<pre class="r"><code>prop.table(tab)                       #Relativ</code></pre>
<pre><code>## 
##  Allgemeine Biologische Entwicklung   Klinische Diag./Meth. 
##  0.19266055  0.17431193  0.14678899  0.40366972  0.08256881</code></pre>
<p>Die Erweiterung für den bivariaten Fall ist dabei nicht schwierig und wird als <em>Kreuztabelle</em> bezeichnet. Sie liefert die Häufigkeit von Kombinationen von Ausprägungen in mehreren Variablen. In den Zeilen wird die erste Variable abgetragen und in den Spalten die zweite. Im Unterschied zum univariaten Fall muss im <code>table()</code> Befehl nur die zweite interessierende Variable zusätzlich genannt werden. Tabellen können beliebig viele Dimensionen haben, werden dann aber sehr unübersichtlich.</p>
<pre class="r"><code>tab&lt;-table(fb21$fach,fb21$ziel)       #Kreuztabelle
tab</code></pre>
<pre><code>##              
##               Wirtschaft Therapie Forschung Andere
##   Allgemeine           5        5         7      4
##   Biologische          0        7        11      1
##   Entwicklung          2        4         5      5
##   Klinische            2       34         5      2
##   Diag./Meth.          2        3         2      2</code></pre>
<p>In eine Kreuztabelle können Randsummen mit dem <code>addmargins()</code> Befehl hinzugefügt werden. Randsummen erzeugen in der letzten Spalte bzw. Zeile die univariaten Häufigkeitstabellen der Variablen.</p>
<pre class="r"><code>addmargins(tab)                       #Randsummen hinzufügen</code></pre>
<pre><code>##              
##               Wirtschaft Therapie Forschung Andere Sum
##   Allgemeine           5        5         7      4  21
##   Biologische          0        7        11      1  19
##   Entwicklung          2        4         5      5  16
##   Klinische            2       34         5      2  43
##   Diag./Meth.          2        3         2      2   9
##   Sum                 11       53        30     14 108</code></pre>
<p>Auch für die Kreuztabelle ist die Möglichkeit der Darstellung der Häufigkeiten in Relation zur Gesamtzahl der Beobachtungen gegeben.</p>
<pre class="r"><code>prop.table(tab)                       #Relative Häufigkeiten</code></pre>
<pre><code>##              
##                Wirtschaft    Therapie   Forschung      Andere
##   Allgemeine  0.046296296 0.046296296 0.064814815 0.037037037
##   Biologische 0.000000000 0.064814815 0.101851852 0.009259259
##   Entwicklung 0.018518519 0.037037037 0.046296296 0.046296296
##   Klinische   0.018518519 0.314814815 0.046296296 0.018518519
##   Diag./Meth. 0.018518519 0.027777778 0.018518519 0.018518519</code></pre>
<p>34 von insgesamt 108 (31.48%) wollen therapeutisch arbeiten <em>und</em> interessieren sich bisher am meisten für die klinische Psychologie.</p>
<p><code>prob.table()</code> kann allerdings nicht nur an der Gesamtzahl relativiert werden, sondern auch an der jeweiligen Zeilen- oder Spaltensumme. Dafür gibt man im Argument <code>margin</code> für Zeilen <code>1</code> oder für Spalten <code>2</code> an.</p>
<pre class="r"><code>prop.table(tab, margin = 1)           #relativiert an Zeilen</code></pre>
<pre><code>##              
##               Wirtschaft   Therapie  Forschung     Andere
##   Allgemeine  0.23809524 0.23809524 0.33333333 0.19047619
##   Biologische 0.00000000 0.36842105 0.57894737 0.05263158
##   Entwicklung 0.12500000 0.25000000 0.31250000 0.31250000
##   Klinische   0.04651163 0.79069767 0.11627907 0.04651163
##   Diag./Meth. 0.22222222 0.33333333 0.22222222 0.22222222</code></pre>
<p>Von 43 Personen, die sich am meisten für klinische Psychologie interessieren, wollen 79.07% (nämlich 34 Personen) später therapeutisch arbeiten.</p>
<pre class="r"><code>prop.table(tab, margin = 2)           #relativiert an Spalten</code></pre>
<pre><code>##              
##               Wirtschaft   Therapie  Forschung     Andere
##   Allgemeine  0.45454545 0.09433962 0.23333333 0.28571429
##   Biologische 0.00000000 0.13207547 0.36666667 0.07142857
##   Entwicklung 0.18181818 0.07547170 0.16666667 0.35714286
##   Klinische   0.18181818 0.64150943 0.16666667 0.14285714
##   Diag./Meth. 0.18181818 0.05660377 0.06666667 0.14285714</code></pre>
<p>Von 53 Personen, die später therapeutisch arbeiten wollen, interessieren sich 64.15% (nämlich 34 Personen) für die klinische Psychologie.</p>
<p><code>addmargins()</code>und <code>prop.table()</code> können beliebig kombiniert werden.
<code>prop.table(addmargins(tab))</code> behandelt die Randsummen als eigene Kategorie (inhaltlich meist unsinnig!).
<code>addmargins(prop.table(tab))</code> liefert die Randsummen der relativen Häufigkeiten.</p>
<pre class="r"><code>addmargins(prop.table(tab))      # als geschachtelte Funktion</code></pre>
<pre><code>##              
##                Wirtschaft    Therapie   Forschung      Andere         Sum
##   Allgemeine  0.046296296 0.046296296 0.064814815 0.037037037 0.194444444
##   Biologische 0.000000000 0.064814815 0.101851852 0.009259259 0.175925926
##   Entwicklung 0.018518519 0.037037037 0.046296296 0.046296296 0.148148148
##   Klinische   0.018518519 0.314814815 0.046296296 0.018518519 0.398148148
##   Diag./Meth. 0.018518519 0.027777778 0.018518519 0.018518519 0.083333333
##   Sum         0.101851852 0.490740741 0.277777778 0.129629630 1.000000000</code></pre>
<pre class="r"><code>prop.table(tab) |&gt; addmargins()  # als Pipe</code></pre>
<pre><code>##              
##                Wirtschaft    Therapie   Forschung      Andere         Sum
##   Allgemeine  0.046296296 0.046296296 0.064814815 0.037037037 0.194444444
##   Biologische 0.000000000 0.064814815 0.101851852 0.009259259 0.175925926
##   Entwicklung 0.018518519 0.037037037 0.046296296 0.046296296 0.148148148
##   Klinische   0.018518519 0.314814815 0.046296296 0.018518519 0.398148148
##   Diag./Meth. 0.018518519 0.027777778 0.018518519 0.018518519 0.083333333
##   Sum         0.101851852 0.490740741 0.277777778 0.129629630 1.000000000</code></pre>
<hr />
</div>
<div id="balkendiagramme" class="section level2">
<h2>Balkendiagramme</h2>
<p>Grafisch kann eine solche Kreuztabelle durch gruppierte Balkendiagramme dargestellt werden. Das Argument <code>beside</code> sorgt für die Anordnung der Balken (bei <code>TRUE</code> nebeneinander, bei <code>FALSE</code> übereinander). Das Argument <code>legend</code> nimmt einen Vektor für die Beschriftung entgegen. Die Zeilen des Datensatzes bilden dabei stets eigene Balken, während die Spalten die Gruppierungsvariable bilden. Deshalb müssen als Legende die Namen der Reihen <code>rownames()</code> unserer Tabelle <code>tab</code> ausgewählt werden.</p>
<pre class="r"><code>barplot (tab,
         beside = TRUE,
         col = c(&#39;mintcream&#39;,&#39;olivedrab&#39;,&#39;peachpuff&#39;,&#39;steelblue&#39;,&#39;maroon&#39;),
         legend = rownames(tab))</code></pre>
<p><img src="/post/2021-09-20-korrelation_files/figure-html/unnamed-chunk-9-1.png" width="672" /></p>
<hr />
</div>
<div id="varianz-kovarianz-und-korrelation" class="section level2">
<h2>Varianz, Kovarianz und Korrelation</h2>
<p>In der Vorlesungen haben Sie gelernt, dass es für <em>Kovarianzen</em> und <em>Varianzen</em> empirische und geschätzte Werte gibt. R berechnet standardmäßig für die Varianz und Kovarianz die <em>Populationsschätzer</em>, verwendet also folgende Formeln für Varianz</p>
<p><span class="math display">\[\hat{\sigma}^2_{X} = \frac{\sum_{m=1}^n (y_m - \bar{y})^2}{n-1}\]</span></p>
<p>und Kovarianz.</p>
<p><span class="math display">\[\hat{\sigma}_{XY} = \frac{\sum_{m=1}^n (x_m - \bar{x}) \cdot (y_m - \bar{y})}{n-1}\]</span></p>
<p>Die Funktionen für die Varianz ist dabei <code>var()</code>. Im Folgenden wird diese für die Variablen <code>vertr</code> (Verträglichkeit) und <code>gewis</code> (Gewissenhaftigkeit) aus dem Datensatz bestimmt. Als Argumente müssen jeweils die Variablennamen verwendet werden.
Wie bereits in vergangenen Sitzungen gesehen führen fehlende Werte zu der Ausgabe <code>NA</code>. Um dies vorzubeugen, wird im univariaten Fall <code>na.rm = TRUE</code> zum Ausschluss verwendet.</p>
<pre class="r"><code>var(fb21$vertr, na.rm = TRUE)               #Varianz Verträglichkeit</code></pre>
<pre><code>## [1] 0.2669422</code></pre>
<pre class="r"><code>var(fb21$gewis, na.rm = TRUE)            #Varianz Gewissenhaftigkeit</code></pre>
<pre><code>## [1] 0.4420121</code></pre>
<p>Die Funktion <code>cov()</code> wird für die Kovarianz verwendet und benötigt als Argumente die Variablen.</p>
<pre class="r"><code>cov(fb21$vertr, fb21$gewis)                #Kovarianz Verträglichkeit und Gewissenhaftigkeit</code></pre>
<pre><code>## [1] 0.06875873</code></pre>
<p>Da Kovarianzen unstandardisierte Kennzahlen sind, können wir Kovarianzen nicht pauschal nach ihrer Höhe beurteilen. Die Höhe hängt beispielsweise von der Antwortskala ab.</p>
<p>Natürlich können auch bei der Kovarianzberechnung fehlende Werte einen zu einem Problem werden. Zur Bewältigung des Problems gibt es das Argument <code>use</code>. Bei Zusammenhangsmaßen gibt es in R mehrere Möglichkeiten für den Umgang mit fehlenden Werten, die sich nur unterscheiden, wenn mehr als zwei Variablen korreliert werden:</p>
<ul>
<li><em>Paarweiser Fallausschluss</em>: Personen, die auf (mindestens) einer von <strong>zwei</strong> Variablen <code>NA</code> haben, werden von der Berechnung ausgeschlossen.</li>
<li><em>Listenweiser Fallausschluss</em>: Personen, die auf (mindestens) einer von <strong>allen</strong> Variablen <code>NA</code> haben, werden von der Berechnung ausgeschlossen.</li>
<li><em>na.or.complete</em>: Zeilen, die einen fehlenden Wert (<code>NA</code>) enthalten, werden bei den Berechnungen ignoriert. Das entspricht der Angabe von <code>na.rm = TRUE</code> bei der Betrachtung von lediglich zwei Variablen.</li>
</ul>
<p>Am besten lässt sich der Unterschied in einer <em>Kovarianzmatrix</em> veranschaulichen. Hier werden alle Varianzen und Kovarianzen von einer Menge an Variablen berechnet und in einer Tabelle darstellt. Dafür muss ein Datensatz erstellt werden, der nur die interessierenden Variablen enthält. Zu unseren beiden Variablen nehmen wir als drittes noch die Lebenszufriedenheit (<code>lz</code>) auf.</p>
<pre class="r"><code>drei &lt;- fb21[, c(&#39;vertr&#39;,&#39;gewis&#39;,&#39;lz&#39;)]         #Datensatzreduktion
cov(drei)                                       #Kovarianzmatrix   </code></pre>
<pre><code>##            vertr      gewis lz
## vertr 0.26694224 0.06875873 NA
## gewis 0.06875873 0.44201211 NA
## lz            NA         NA NA</code></pre>
<p>Da die fehlenden Werte nicht entfernt wurden, gibt R <code>NA</code> aus.
Nun folgt die Gegenüberstellung der beiden betrachteten Möglichkeiten zum Ausschluss.</p>
<pre class="r"><code>cov(drei, use = &#39;pairwise&#39;)             #Paarweiser Fallausschluss</code></pre>
<pre><code>##            vertr      gewis         lz
## vertr 0.26694224 0.06875873 0.05928652
## gewis 0.06875873 0.44201211 0.27308156
## lz    0.05928652 0.27308156 1.28460425</code></pre>
<pre class="r"><code>cov(drei, use = &#39;complete&#39;)             #Listenweiser Fallausschluss</code></pre>
<pre><code>##            vertr      gewis         lz
## vertr 0.25924529 0.06773347 0.05928652
## gewis 0.06773347 0.44956061 0.27308156
## lz    0.05928652 0.27308156 1.28460425</code></pre>
<p>Wie wir sehen unterscheiden sich die Werte voneinander, da beim listenweisen Fallausschluss noch mehr Personen von Beginn an von der Berechnung ausgeschlossen werden.
Anmerkung: Die Kovarianz einer Variablen mit sich selbst (zu finden in der Hauptdiagonalen) entspricht ihrer Varianz.</p>
<p>Der Zusammenhang zwischen zwei Variablen kann in einem <em>Scatterplot</em> bzw. <em>Streupunktdiagramm</em> dargestellt werden. Dafür kann man die <code>plot()</code> Funktion nutzen. Als Argumente können dabei <code>x</code> für die Variable auf der x-Achse, <code>y</code> für die Variable auf der y-Achse, <code>xlim</code>, <code>ylim</code> für eventuelle Begrenzungen der Achsen und <code>pch</code> für die Punktart angegeben werden.</p>
<pre class="r"><code>plot(x = fb21$vertr, y = fb21$gewis, xlim = c(1,5) , ylim = c(1,5))</code></pre>
<p><img src="/post/2021-09-20-korrelation_files/figure-html/unnamed-chunk-14-1.png" width="672" /></p>
<p>Wie in der Vorlesung besprochen, sind für verschiedene Skalenniveaus verschiedene Zusammenhangsmaße verfügbar, die im Gegensatz zur Kovarianz auch eine Vergleichbarkeit zwischen zwei Zusammenhangswerten sicherstellen. Für zwei metrisch skalierte Variablen gibt es dabei die <em>Produkt-Moment-Korrelation</em>. In der Funktion <code>cor()</code> werden dabei die Argumente <code>x</code> und <code>y</code> für die beiden betrachteten Variablen benötigt. <code>use</code> beschreibt weiterhin den Umgang mit fehlenden Werten.</p>
<pre class="r"><code>cor(x = fb21$vertr, y = fb21$gewis, use = &#39;pairwise&#39;)</code></pre>
<pre><code>## [1] 0.2001714</code></pre>
<p>Bei einer positiven Korrelation gilt „je mehr Variable x… desto mehr Variable y" bzw. umgekehrt, bei einer negativen Korrelation „je mehr Variable x… desto weniger Variable y" bzw. umgekehrt. Korrelationen sind immer ungerichtet, das heißt, sie enthalten keine Information darüber, welche Variable eine andere vorhersagt - beide Variablen sind gleichberechtigt. Korrelationen (und Regressionen, s. nächste Woche) liefern <em>keine</em> Hinweise auf Kausalitäten. Sie sagen beide etwas über den (linearen) Zusammenhang zweier Variablen aus.</p>
<p>In R können wir uns auch eine <em>Korrelationsmatrix</em> ausgeben lassen. Dies geschieht äquivalent zu der Kovarianzmatrix mit dem Datensatz als Argument in der <code>cor()</code> Funktion. In der Diagonale stehen die Korrelationen der Variable mit sich selbst - also 1 - und in den restlichen Feldern die Korrelationen der Variablen untereinander.</p>
<pre class="r"><code>cor(drei, use = &#39;pairwise&#39;)</code></pre>
<pre><code>##           vertr     gewis        lz
## vertr 1.0000000 0.2001714 0.1027344
## gewis 0.2001714 1.0000000 0.3593466
## lz    0.1027344 0.3593466 1.0000000</code></pre>
<p>Die Stärke des korrelativer Zusammenhangs wird mit dem Korrelationskoeffizienten ausgedrückt, der zwischen -1 und +1 liegt.
Die default Einstellung bei <code>cor()</code>ist die <em>Produkt-Moment-Korrelation</em>, also die Pearson-Korrelation.</p>
<pre class="r"><code>cor(fb21$vertr, fb21$gewis, use = &quot;pairwise&quot;, method = &quot;pearson&quot;)</code></pre>
<pre><code>## [1] 0.2001714</code></pre>
<p>Achtung! Die inferenzstatistische Testung der Pearson-Korrelation hat gewisse Voraussetzungen, die vor der Durchführung überprüft werden sollten!</p>
<p><strong>Voraussetzungen Pearson-Korrelation:</strong></p>
<ol style="list-style-type: decimal">
<li>Skalenniveau: intervallskalierte Daten <span class="math inline">\(\rightarrow\)</span> ok (Ratingskalen werden meist als intervallskaliert aufgefasst, auch wenn das nicht 100% korrekt ist)<br />
</li>
<li>Linearität: Zusammenhang muss linear sein <span class="math inline">\(\rightarrow\)</span> grafische Überprüfung (siehe Scatterplot)<br />
</li>
<li>Normalverteilung <span class="math inline">\(\rightarrow\)</span> QQ-Plot, Histogramm oder Shapiro-Wilk-Test</li>
</ol>
<p><strong>zu 3. Normalverteilung</strong></p>
<p><span class="math inline">\(\rightarrow\)</span> QQ-Plot, Histogramm &amp; Shapiro-Wilk-Test</p>
<pre class="r"><code>#QQ
qqnorm(fb21$vertr)
qqline(fb21$vertr)</code></pre>
<p><img src="/post/2021-09-20-korrelation_files/figure-html/unnamed-chunk-18-1.png" width="672" /></p>
<pre class="r"><code>qqnorm(fb21$gewis)
qqline(fb21$gewis)</code></pre>
<p><img src="/post/2021-09-20-korrelation_files/figure-html/unnamed-chunk-18-2.png" width="672" /></p>
<pre class="r"><code>#Histogramm

hist(fb21$vertr, prob = T, ylim = c(0, 1))
curve(dnorm(x, mean = mean(fb21$vertr, na.rm = T), sd = sd(fb21$vertr, na.rm = T)), col = &quot;blue&quot;, add = T)  </code></pre>
<p><img src="/post/2021-09-20-korrelation_files/figure-html/unnamed-chunk-18-3.png" width="672" /></p>
<pre class="r"><code>hist(fb21$gewis, prob = T, ylim = c(0,1))
curve(dnorm(x, mean = mean(fb21$gewis, na.rm = T), sd = sd(fb21$gewis, na.rm = T)), col = &quot;blue&quot;, add = T)</code></pre>
<p><img src="/post/2021-09-20-korrelation_files/figure-html/unnamed-chunk-18-4.png" width="672" /></p>
<pre class="r"><code>#Shapiro
shapiro.test(fb21$vertr)</code></pre>
<pre><code>## 
##  Shapiro-Wilk normality test
## 
## data:  fb21$vertr
## W = 0.95157, p-value = 0.0004162</code></pre>
<pre class="r"><code>shapiro.test(fb21$gewis)</code></pre>
<pre><code>## 
##  Shapiro-Wilk normality test
## 
## data:  fb21$gewis
## W = 0.96023, p-value = 0.001855</code></pre>
<p><span class="math inline">\(p &lt; \alpha\)</span> <span class="math inline">\(\rightarrow\)</span> H1: Normalverteilung kann nicht angenommen werden. Somit ist diese Voraussetzung verletzt. Eine Möglichkeit damit umzugehen, ist die Rangkorrelation nach Spearman. Diese ist nicht an die Voraussetzung der Normalverteilung gebunden. Das Verfahren kann über <code>method = "spearman"</code> angewendet werden.</p>
<p><strong>Rangkorrelation in R</strong></p>
<pre class="r"><code>r1 &lt;- cor(fb21$vertr,fb21$gewis,
          method = &quot;spearman&quot;,     #Pearson ist default
          use = &quot;complete&quot;) 

r1</code></pre>
<pre><code>## [1] 0.1438822</code></pre>
<pre class="r"><code>r1^2                               #R^2, Anteil an erklärter Varianz</code></pre>
<pre><code>## [1] 0.02070208</code></pre>
<p><strong>Interpretation des deskriptiven Zusammenhangs:</strong><br />
Es handelt sich um eine positive Korrelation von <em>r</em> = .14. Der Effekt ist nach Cohens (1988) Konvention als schwach zu bewerten. Je höher die Ausprägung in Verträglichkeit, desto höher ist die Ausprägung in der Gewissenhaftigkeit und anders herum.</p>
<p><strong>Exkurs: Cohens (1988) Konvention zur Interpretation von <span class="math inline">\(|r|\)</span>:</strong></p>
<ul>
<li>~ .10: schwacher Effekt<br />
</li>
<li>~ .30: mittlerer Effekt<br />
</li>
<li>~ .50: starker Effekt</li>
</ul>
<p>Als weitere Variante der Rangkorrelation gibt es noch Kendalls <span class="math inline">\(\tau\)</span>. Diese kann man mit <code>method = "kendall"</code> angesprochen werden.</p>
<pre class="r"><code>cor(fb21$vertr, fb21$gewis, use = &#39;complete&#39;, method = &#39;kendall&#39;)</code></pre>
<pre><code>## [1] 0.108256</code></pre>
<p>Die Interpretation erfolgt wie bei Spearman’s Rangkorrelation.</p>
<p><strong>Signifikanztestung des Korrelationskoeffizienten:</strong>
Nachdem der Korrelationskoeffizient berechnet wurde, muss dieser noch auf Signifikanz geprüft werden. Dazu verwenden wir die <code>cor.test()</code> Funktion.</p>
<ul>
<li>H0: <span class="math inline">\(\rho = 0\)</span> <span class="math inline">\(\rightarrow\)</span> es gibt keinen Zusammenhang zwischen Verträglichkeit und Gewissenhaftigkeit</li>
<li>H1: <span class="math inline">\(\rho \neq 0\)</span> <span class="math inline">\(\rightarrow\)</span> es gibt einen Zusammenhang zwischen Verträglichkeit und Gewissenhaftigkeit</li>
</ul>
<pre class="r"><code>cor.test(fb21$vertr, fb21$gewis, 
         alternative = &quot;two.sided&quot;, 
         method = &quot;spearman&quot;,       #Da Voraussetzungen für Pearson verletzt
         use = &quot;complete&quot;)</code></pre>
<pre><code>## Warning in cor.test.default(fb21$vertr, fb21$gewis, alternative = &quot;two.sided&quot;, :
## Cannot compute exact p-value with ties</code></pre>
<pre><code>## 
##  Spearman&#39;s rank correlation rho
## 
## data:  fb21$vertr and fb21$gewis
## S = 211380, p-value = 0.1267
## alternative hypothesis: true rho is not equal to 0
## sample estimates:
##       rho 
## 0.1438822</code></pre>
<p><span class="math inline">\(p &gt; \alpha\)</span> <span class="math inline">\(\rightarrow\)</span> H0. Die Korrelation ist <strong>nicht</strong> mit einer Irrtumswahrscheinlichkeit von 5% signifikant von 0 verschieden.
Anmerkung: Bei der Rangkorrelation kann der exakte p-Wert nicht berechnet werden. Wenn die Voraussetzungen für die Pearson-Korrelation erfüllt wären, würde das Ganze so aussehen:</p>
<pre class="r"><code>cor.test(fb21$vertr, fb21$gewis, 
         alternative = &quot;two.sided&quot;, 
         method = &quot;pearson&quot;,       
         use = &quot;complete&quot;)</code></pre>
<pre><code>## 
##  Pearson&#39;s product-moment correlation
## 
## data:  fb21$vertr and fb21$gewis
## t = 2.1622, df = 112, p-value = 0.03273
## alternative hypothesis: true correlation is not equal to 0
## 95 percent confidence interval:
##  0.0168780 0.3704484
## sample estimates:
##       cor 
## 0.2001714</code></pre>
<p><strong>Ergebnisinterpretation:</strong>
Es wurde untersucht, ob Verträglichkeit und Gewissenhaftigkeit miteinander zusammenhängen. Der Pearson-Korrelationskoeffizient beträgt .20 und ist statistisch signifikant (<em>t</em>(112) = 2.16, <em>p</em> = .033). Folglich wird die Nullhypothese hier verworfen: Verträglichkeit und Lebenszufriedenheit weisen einen signifikanten Zusammenhang auf.</p>
</div>
<div id="wie-können-zusammenhangsmaße-für-ordinalskalierte-daten-berechnet-werden" class="section level2">
<h2>Wie können Zusammenhangsmaße für ordinalskalierte Daten berechnet werden?</h2>
<p>Ordinalskalierte Daten können aufgrund der Verletzung der Äquidistanz zwischen bspw. Antwortstufen eines Items eines Messinstrumentes nicht schlicht mittels Pearson-Korrelation in Zusammenhang gesetzt werden. Zudem sind oft Verteilungsannahmen bei ordinalskalierten Variablen verletzt. Der Koeffizient <span class="math inline">\(\hat{\gamma}\)</span> ist zur Betrachtung solcher Zusammenhänge am besten geeignet (sogar besser als Spearman’s und Kendalls’s Rangkorrelation). Er nimmt - ähnlich wie Spearman’s und Kendall’s Koeffizenten - weder eine gewisse Verteilung der Daten an, noch deren Äquidistanz.</p>
<p>Zur Berechnung dieses Koeffizienten müssen wir das Paket <code>rococo</code> installieren, welches verschiedene Konkordanz-basierte Zusammenhangsmaße enthält. Die Installation muss dem Laden des Paketes logischerweise vorausgestellt sein. Wenn R einmal geschlossen wird, müssen alle Zusatzpakete neu geladen, jedoch nicht neu installiert werden.</p>
<pre class="r"><code>install.packages(&#39;rococo&#39;)          #installieren</code></pre>
<pre class="r"><code>library(rococo)                     #laden</code></pre>
<p>Wir erhalten hier als Message den Hinweis, unter welcher Version das Paket erstellt wurde.
Übersichte über Pakete kann man mit <code>??</code>erhalten.</p>
<pre class="r"><code>??rococo</code></pre>
<p>Die Funktion heißt hier zufälligerweise genau gleich wie das Paket. Wenn man nur Informationen über die Funktion statt das Paket sucht, geht das anhand von <code>?</code>.</p>
<pre class="r"><code>?rococo</code></pre>
<p>Dank dem neuen Paket können wir nun den Koeffizienten <span class="math inline">\(\hat{\gamma}\)</span> berechnen und uns damit den Zusammenhang zwischen Items betrachten. Schauen wir uns nun mal den Zusammenhang der beiden Prokrastinationsitems <code>prok1</code> und <code>prok9</code> an, um zu überprüfen, ob die beiden Items auch (wie beabsichtigt) etwas Ähnliches messen (nähmlich Prokrastionationstendenz). Die beiden Variablen wurden ursprünglich auf einer Skala von 1 (<em>stimmt nicht</em>) bis 4 (<em>stimmt genau</em>) (also auf Ordinalskalenniveau) erfasst.</p>
<pre class="r"><code>rococo(fb21$prok1, fb21$prok9)</code></pre>
<pre><code>## [1] 0.464443</code></pre>
<p>Um zu überprüfen, ob zwei ordinalskalierte Variablen signifikant miteinaner zusammenhängen, können wir die <code>rococo.test()</code> Funktion anwenden.</p>
<pre class="r"><code>rococo.test(fb21$prok1, fb21$prok5)</code></pre>
<pre><code>## 
##  Robust Gamma Rank Correlation:
## 
## data: fb21$prok1 and fb21$prok5 (length = 114)
## similarity: linear 
## rx = 0.1 / ry = 0.1 
## t-norm: min 
## alternative hypothesis: true gamma is not equal to 0 
## sample gamma = -0.657041 
## estimated p-value = 0.008 (8 of 1000 values)</code></pre>
<p>hier haben wir <code>prok9</code> mit <code>prok5</code> ausgetauscht. Der Koeffizient von -0.66 zeigt uns, dass die Items zwar hoch miteinander korrelieren, allerdings negativ. Ist hier etwas schief gelaufen? Nein, <code>prok5</code> ist lediglich ein invertiertes Item. Wir können uns das <code>-</code> für diese Zwecke einfach wegdenken und sehen, dass <code>prok1</code> mit <code>prok5</code> stark und signitfikant zusammenhängt. Die beiden Items messen demnach ein ähnliches zugrundeliegendes Konstrukt.</p>
<hr />
</div>
