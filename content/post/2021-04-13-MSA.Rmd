---
title: Multi Sample Analysis - Multigruppenvergleich
author: ''
date: '2021-04-13'
slug: msa
categories: 
  - MSc1
tags: 
  - lavaan
  - SEM
  - MSA
  - Invarianztestung
  - Strukturgleichungsmodelle
  - Regression
subtitle: 'MSA'
summary: ''
authors: [irmer, schultze]
lastmod: '2021-04-13T10:30:02+02:00'
featured: no
header:
  image: "/header/FEII_MSA.jpg"
  caption: "[Courtesy of pxhere](https://pxhere.com/en/photo/644378)"
---

```{r setup, echo=F}
abbrev <- function(X, begin = 'Latent Variables', end = NULL, ellipses = 'both', shift = 2, ...) {
  
  tmp <- capture.output(lavaan::summary(X,...))
  
  if (is.null(begin)) begin <- 1
  else begin <- grep(begin, tmp, fixed = TRUE)[1]
  if (is.null(end)) end <- length(tmp)-shift
  else end <- grep(end, tmp, fixed = TRUE)[grep(end, tmp, fixed = TRUE) > begin][1]-shift
  
  if (ellipses == 'both') {
    cat('[...]\n', paste(tmp[begin:end], collapse = '\n'), '\n[...]\n')
  }
  if (ellipses == 'top') {
    cat('[...]\n', paste(tmp[begin:end], collapse = '\n'))
  }
  if (ellipses == 'bottom') {
    cat(paste(tmp[begin:end], collapse = '\n'), '\n[...]\n')
  }
  if (ellipses == 'none') {
    cat(paste(tmp[begin:end], collapse = '\n'))
  }
}

```


## Multi Sample Analysis {#MSA}

In einer Multi-Sample-Analysis wird in mehreren Gruppen gleichzeitig ein Strukturgleichungsmodell geschätzt. Wir könnten uns bspw. fragen, ob die gleichen Beziehungen zwischen Zeitdruck, Emotionaler Erschöpfung und psychosomatischen Beschwerden, wie wir sie in der letzten Sitzung zu [SEM](/post/sem) beobachtet haben, gleichermaßen für Männer und Frauen gelten. Im Datensatz `StressAtWork` der [SEM](/post/sem) Sitzung ist die Variable `sex` enthalten. Hier sind Frauen mit `1` und Männer mit `2` kodiert. Wir können diesen wie gewohnt laden:
Sie können den im Folgenden verwendeten  [`r fontawesome::fa("download")` Datensatz "StressAtWork.rda" hier herunterladen](https://pandar.netlify.app/post/StressAtWork.rda).

Wir laden zunächst die Daten: entweder lokal von Ihrem Rechner:

```{r, eval = F}
load("C:/Users/Musterfrau/Desktop/StressAtWork.rda")
```

oder wir laden sie direkt über die Website:

```{r, eval = T}
load(url("https://pandar.netlify.app/post/StressAtWork.rda"))
```

Als Paket brauchen wir erneut `lavaan` und `semPlot`:
```{r, message=F,warning=F}
library(lavaan)
library(semPlot)
```

Wir verwenden das gleiche Modell wie in der vorherigen Sitzung zu [SEM](/post/sem) für die Variablen Zeitdruck, emotionale Erschöpfung und psychosomatische Beschwerden (als manifesten Skalenmittelwert, siehe dazu die [Diskussion zu reflexiven vs. formativen Messmodellen](/post/sem/#formvsreflMessmodell) in der Sitzung zu SEM), welches so aussah (für Details, wie etwa das erstellen der Skalenmittelwerte für `BFs` schaue gerne nochmal in der vorherigen Sitzung zu [SEM](/post/sem) vorbei):

```{r exercise_graph_sem1, fig.align="center", fig.height=6}
StressAtWork$BFs <- rowMeans(StressAtWork[,paste0("bf",1:20)])

model_sem <- '
# Messmodelle
ZD =~ zd1 + zd2 + zd6
BOEE =~ bo1 + bo6 + bo12 + bo19

# Strukturmodell
BOEE ~ ZD
BFs ~  BOEE + ZD
'

fit_sem <- sem(model_sem, StressAtWork)

semPaths(object = fit_sem,  what = "model", layout = "tree2",
         rotation = 2, curve = T, col = list(man = "skyblue", lat = "yellow"),
         curvePivot = T,  edge.label.cex=1.2, sizeMan = 5, sizeLat = 8)
```


Wenn wir die Variable Geschlecht als Gruppierung verwenden, können wir die Invarianz der Parameter über das Geschlecht untersuchen. Um die Gruppierung in das Modell mit aufzunehmen, können wir in `sem` einfach dem Argument `group` den Namen der Gruppierungsvariable übergeben (hierbei sind die "Gänsefüßchen" wichtig!).

```{r, results = "hide"}
fit_sem_MSA <- sem(model_sem, data = StressAtWork, group = "sex")
summary(fit_sem_MSA)
```

Wir sehen, dass im Output nun für jede Gruppe das Modell einzeln geschätzt wurde. Alle Parameter werden sowohl für Frauen als auch für Männer geschätzt. Wir entnehmen,

```{r, echo = F}
abbrev(X = fit_sem_MSA, begin = "Number of observations per group", end = "Model Test User Model")
```

dass insgesamt `r sum(StressAtWork$sex == 1)` der Probanden Frauen und `r sum(StressAtWork$sex == 2)` Männer waren. Auch erhalten wir einen globalen sowie einen substichprobenspezifischen Modellfitwert:


```{r, echo = F}
abbrev(X = fit_sem_MSA, begin = "Model Test User Model", end = "Parameter Estimates")
```

Der $\chi^2$-Wert für das gesamte Modell liegt bei `r round(fitmeasures(fit_sem_MSA)[3], 3)` bei $df=$ `r round(fitmeasures(fit_sem_MSA)[4], 3)` mit zugehörigem $p$-Wert von `r round(fitmeasures(fit_sem_MSA)[5], 3)`. Demnach verwerfen unsere Daten das Modell nicht. Die Freiheitsgrade sind doppelt so hoch, wie im Ein-Stichprobenfall, da wir alle Parameter für beide Stichproben schätzen müssen. Die $\chi^2$-Werte der beiden Stichproben waren 21.400 für die Frauen und 14.403 für die Männer. Der $\chi^2$-Wert für das gesamte Modell ist also einfach die Summe der subpopulationsspezifischen $\chi^2$-Werte ($\chi^2_{g=1}$ und $\chi^2_{g=2}$, wobei $g=1$ und $g=2$ für die erste und zweite Gruppe steht):
$$\chi^2=\chi^2_{g=1}+\chi^2_{g=2}.$$
Wir haben hier keine Koeffizienten mehr benannt, da in einem Update von `lavaan` verändert wurde, dass eine einzelne Bezeichnung direkt zwei Koeffizienten aus zwei Gruppen gleichsetzt (als invariant annimmt). Wie man dies dennoch machen kann, schauen wir uns auch gleich an!

```{r, echo = F}
abbrev(X = fit_sem_MSA, begin = "Group 1", end = "Variances")

abbrev(X = fit_sem_MSA, begin = "Group 2", end = "Variances")
```
Uns fällt auf, dass sowohl die Faktorladungen als auch die Pfadkoeffizienten sich kaum über die Gruppen hinweg unterscheiden. Da sich die Subpopulationen auch hinsichtlich der Mittelwerte unterscheiden können, werden diese nun per Default im Output mit ausgegeben. Natürlich können sich die Subpopulationen auch in allen weiteren Koeffizienten unterscheiden (Faktorladungen, Pfadkoeffizienten, Interzept, (Residual-)Varianzen).

Eben hatten wir angesprochen, dass das einfache Setzen eines Labels für einen Koeffizienten automatisch zu dessen Invarianz über die Gruppen führt. Um nun doch die Parameter über die Gruppen hinweg zu benennen, ohne diese gleichzusetzen, müssen wir die Labels als Vektor schreiben, also bspw. `BOEE ~ c(a1, a2)*ZD`, um den Effekt der unabhängigen Variable auf den Mediator in den Gruppen jeweils `a1` und `a2` zu nennen.

Wir nutzen diese Schreibweise, um den indirekten Effekt sowohl für Frauen als auch für  Männer zu berechnen und erweitern unser Modell entsprechend:

```{r, results="hide"}
model_sem_IE_TE_MSA <- '
# Messmodelle
ZD =~ zd1 + zd2 + zd6
BOEE =~ bo1 + bo6 + bo12 + bo19

# Strukturmodell
BOEE ~ c(a1, a2)*ZD
BFs ~  c(b1, b2)*BOEE + c(c1,c2)*ZD

# Neue Parameter
IE1 := a1*b1
TE1 := IE1 + c1

IE2 := a2*b2
TE2 := IE2 + c2
'
fit_sem_IE_TE_MSA <- sem(model_sem_IE_TE_MSA, StressAtWork, group = "sex")
summary(fit_sem_IE_TE_MSA)
```

Nun sind alle Pfadkoeffizienten benannt:

```{r, echo = F}
abbrev(X = fit_sem_IE_TE_MSA, begin = "Group 1", end = "Intercepts")

abbrev(X = fit_sem_IE_TE_MSA, begin = "Group 2", end = "Intercepts")
```
Bis auf die hinzukommenden indirekten und totalen Effekte:

```{r, echo = F}
abbrev(X = fit_sem_IE_TE_MSA, begin = "Defined Parameters", end = NULL, shift = 1)
```
hat sich nichts am Output geändert. Wir haben ja auch nur Labels vergeben und neu definierte Parameter hinzugefügt, die allerdings, wie zuvor schon erwähnt, die Modellstruktur (und somit auch die $df$) nicht tangieren. Auch können wir die Modelle in den beiden Gruppen darstellen via (die Dreiecke haben eine 1 in der Mitte stehen und stellen die Mittelwertsstruktur dar, die Kante/das Gewicht eines Dreiecks auf bspw die manifesten Variablen stellt dann den Mittelwert dieser manifesten Variable dar):

```{r, fig.align="center"}
semPaths(object = fit_sem_IE_TE_MSA, what = "est", layout = "tree2",
         rotation = 2, curve = T, col = list(man = "skyblue", lat = "yellow"),
         curvePivot = T,  edge.label.cex=1, sizeMan = 5, sizeLat = 8)
```

Die totalen und die indirekten Effekte müssten in einer wissenschaftlichen Untersuchung erneut mithilfe von Bootstrapping inferenzstatistisch geprüft werden. Diesen Schritt überlassen wir an dieser Stelle dem/der aufmerksamen Leser/in. Auch können die indirekten Effekten, bspw., gegeneinander untersucht werden via Bootstrapping, indem geschaut wird, ob die Konfidenzintervalle sich überschneiden. Allerdings können wir auch mittels des $\chi^2$-Tests einen "richtigen" Invarianztest durchführen. Das schauen wir uns im Folgenden genauer an:

### Invarianzstufen

Mit Invarianz meinen wir die Gleichheit von Parametern über Gruppen hinweg, also bspw., dass es keine Unterschiede über das Geschlecht hinweg gibt. Welche Stufen der Invarianz es gibt, was diese bedeuten und wie wir diese spezifizieren, gucken wir uns im Folgenden nochmal kurz an.

So wie wir die indirekten Effekte bestimmt und die Koeffizienten für beide Gruppen benannt haben, lassen sich auch Invarianzen händisch prüfen. Wenn zwei Koeffizienten das selbe Label tragen, werden diese Parameter in den Gruppen auf den gleichen Wert gesetzt. Wir könnten nun für die jeweiligen Invarianzstufen die Parameter händisch gleichsetzen. Dieses ganze Prozedere erscheint recht aufwendig. Allerdings kann so in jedem Schritt überprüft werden, dass die Parameter richtig restringiert wurden. Auch lassen sich so auch leicht partielle Invarianz einbauen, in welchen bspw. nicht alle Faktorladungen über die Gruppen hinweg gleich sind. Außerdem könnten Invarianzen nur für bestimmte Variablen angenommen werden. Diesen kompletten, händischen Prozess sehen Sie in [Appendix A](#AppendixA). Glücklicherweise enthält das `lavaan`-Paket aber Möglichkeiten, Invarianzen global zu definieren. Dazu müssen wir lediglich in der Schätzung unserer Modelle in `sem` das Zusatzargument `group.equal` spezifizieren. Für partielle Invarianzen gibt es zusätzlich `group.partial`. Bevor wir mit den Analysen beginnen, sehen Sie in der folgenden Tabelle noch einmal eine Übersicht über die Invarianzstufen. Eine detaillierte Wiederholung dessen, was auch in den inhaltlichen Sitzungen zu den Invarianzstufen behandelt wurde, finden Sie im [Exkurs zu Invarianztestungen](/post/Exkurs-Invarianztestungen). Die beiden Spalten "Annahme" und "Implikation" sind kumulativ: Invarianzstufen, die weiter unten stehen, enthalten immer auch alle vorherigen Annahmen und erlauben auch immer alle vorherigen Aussagen. Die jeweiligen Einträge einer Zeile sind lediglich für diese Stufe **_zusätzlich_**.

Invarianzstufe | Annahme | Implikation
---- | ------- | --------
konfigural | gleiche Modellstruktur | gleiche Konstruktdefinition
metrisch (schwach) | gleiche Faktorladungen | latente Variablen haben gleiche Bedeutung; Beziehungen zwischen latenten Variablen vergleichbar
skalar (stark) | gleiche Interzepte | mittlere Gruppenunterschiede in manifesten Variablen auf Unterschiede in latenten Mittelwerten zurückführbar; latente Mittelwerte vergleichbar
strikt | gleiche Residualvarianzen | Varianzunterschiede in manifesten Variablen auf Varianzunterschiede in latenten Varianzen zurückführbar


Probieren wir dies doch gleich einmal aus (das Modell sollte hierzu keine Parameterbenennungen haben, da diese die gloablen Invarianzeinstellungen in `sem` überschreiben könnten):

```{r}
model_sem <- '
# Messmodelle
ZD =~ zd1 + zd2 + zd6
BOEE =~ bo1 + bo6 + bo12 + bo19

# Strukturmodell
BOEE ~ ZD
BFs ~  BOEE + ZD
'
```

Um `BFs` hier wie eine latente Variable zu behandeln, müssen wir bestimmen, dass das Interzept und die Residualvarianz nicht mit den manifesten Variablen zusammen gleichgesetzt werden, sondern erst mit den latenten Variablen über die Gruppen restringiert werden (bei der Testung der vollständigen Invarianz). Dazu müssen wir zusätzlich die partielle Invarianzeinstellung verwenden: `group.partial = c("BFs~1", "BFs~~BFs")`. Hiermit wird bestimmt, welche Koeffizienten **nicht** von den Invarianzeinstellungen betroffen sein sollen. Auch wenn diese Einstellungen erst bei der skalaren/starken Invarianz (`"BFs~1"`) und bei der strikten Invarianz (`"BFs~~BFs"`) zum tragen kommen, stellen wir diese auch beim konfigural-invarianten und beim metrisch-invarianten (schwach-invarianten) Modell mit ein, um aufzuzeigen, dass wir in jedem Punkt genau wissen, was wir tun. Fangen wir mit dem Fitten des konfigural-invarianten Modells an.

### Konfigurale Invarianz

Bei der konfiguralen Invarianz geht es darum, dass in beiden Gruppen die gleichen Modelle aufgestellt werden. Gilt diese Annahme bereits nicht, so macht es keinen Sinn, das Modell weiter einzuschränken und Parameter über die Gruppen zu restringieren. Glücklicherweise passt das Modell zu den Daten, in welchem das Modell für das Geschlecht jeweils geschätzt wurde. Hier schauen wir uns dies noch einmal zur Wiederholung und zum Umbenennen des geschätzten Modells an und spezifizieren mit `group.equal = c("")`, dass keine Parameter über die Gruppen als identisch angenommen werden sollen:

```{r, results = "hide"}
fit_sem_sex_konfigural <- sem(model_sem, data = StressAtWork, 
                              group = "sex",
                              group.equal = c(""), 
                              group.partial = c("BFs~1", "BFs~~BFs"))
summary(fit_sem_sex_konfigural, fit.measures = T)
```

Dem Modell-Fit Teil der Summary entnehmen wir, dass das Modell gut zu den Daten passt:
```{r, echo = F}
abbrev(X = fit_sem_sex_konfigural, begin = "Model Test User Model", end = "Parameter Estimates", fit.measures = T)
```
Der $\chi^2$-Wert ist nicht signifikant und auch die Fit-Indizes CFI, TLI, RMSEA und SRMR sind unauffällig und deuten auf guten Modell-Fit hin. Dies bedeutet, dass wir frohen Mutes das Modell einschränken können, um zu prüfen, welche Invarianz über das Geschlecht hinweg gilt.


### Metrische Invarianz

Unter metrischer oder schwacher Invarianz verstehen wir, dass die Faktorladungen ($\lambda$, bzw. $\Lambda$) über die Gruppen hinweg gleich sind. Somit ist der Anteil jedes Items, der auf die latenten Variablen zurückzuführen ist, über die Gruppen hinweg gleichen. Dies ist wichtig, um zu prüfen, ob die Konstrukte über die beiden Gruppen hinweg die gleiche Bedeutung haben. Wir erreichen dies, indem wir `group.equal = c("loadings")` spezifizieren.

```{r, results="hide"}
fit_sem_sex_metrisch <- sem(model_sem, data = StressAtWork, 
                            group = "sex",
                            group.equal = c("loadings"), 
                            group.partial = c("BFs~1", "BFs~~BFs"))
summary(fit_sem_sex_metrisch, fit.measures = T)
```

Wir entnehmen,
```{r, echo = F}
abbrev(X = fit_sem_sex_metrisch, begin = "Model Test User Model", end = "Parameter Estimates", fit.measures = T)
```
dass das Modell immer noch gut zu den Daten passt. Die Frage ist nur, ob das metrisch-invariante Modell nicht doch vielleicht signifikant schlechter zu den Daten passt als das konfigural-invariante Modell. Bevor wir dieser Frage nachgehen, schauen wir uns noch schnell an, wie Parameter hier per Default benannt werden:


```{r, echo = F}
abbrev(X = fit_sem_sex_metrisch, begin = "Group 1", end = "Intercepts")

abbrev(X = fit_sem_sex_metrisch, begin = "Group 2", end = "Intercepts")
```

Wir erkennen, dass "einfach" nur die Parameter durchnummeriert werden, wobei Parameter, die auf 1 restringiert sind, mitgezählt werden, aber nicht ihr eigenes Label erhalten. So heißt $\lambda_{21}^x$, der Ladungskoeffizient von `zd2` hier `.p2.`, wobei das `p` für Parameter steht und die Punkte andeuten, dass es sich hierbei um ein intern vergebenes (also ein durch die Funktion selbst vergebenes) Label handelt. Wollen wir nun wissen, ob sich die Modelle statistisch signifikant von einander unterscheiden, können wir wieder den Likelihood-Ratio-Test ($\chi^2$-Differenzentest) heranziehen.

```{r, eval = F}
lavTestLRT(fit_sem_sex_metrisch, fit_sem_sex_konfigural)
```

```{r, echo = F}
res_metrisch <- lavTestLRT(fit_sem_sex_metrisch, fit_sem_sex_konfigural)
print(res_metrisch)
```

Die $\chi^2$-Differenz liegt bei `r round(res_metrisch[[5]][2], 4)` bei $\Delta df=$ `r res_metrisch[[6]][2]` mit dem zugehörigen $p$-Wert von `r round(res_metrisch[[7]][2], 4)` (die Null-Hypothese war: $H_0: \Sigma_{konfigural}=\Sigma_{metrisch}$). Das metrische Modell ist hier das restriktivere, da Koeffizienten gleichgesetzt wurden. Weil es keine signifikanten Unterschiede zwischen den Modellen gibt, entschieden wir uns --- Ockhams Rasiermesser folgend (siehe [Eid et al., 2017, p. 787](https://hds.hebis.de/ubffm/Record/HEB366849158)) --- für das sparsamere Modell, also jenes, welches weniger Parameter enthält und somit restriktiver ist, hier: das *metrisch-invariante* Modell. Somit können wir weiter von metrischer Invarianz ausgehen. Dies bedeutet, dass sich Unterschiede zwischen Frauen auf der latenten Variable in gleicher Weise in den beobachtbaren Variablen niederschlagen, wie sie es bei Männern tun.

### Skalare Invarianz

Als nächsten wollen wir prüfen, ob zusätzlich zu den Faktorladungen auch die Interzepte ($\tau$) über die Gruppen hinweg gleich sind (insgesamt also $\lambda$s und $\tau$s gleich über die Gruppen hinweg). Dazu passen wir erneut unser Modell an. Hierbei ist zu beachten, dass wir nicht das Interzept von `BFs` über die Gruppen hinweg gleichsetzten, da sich die Interzepte auf die manifesten Variablen beziehen, wir `BFs` hier allerdings wie eine latente Variable behandeln wollen, bzw. diese zu einer der Variablen der Strukturgleichung zählen wollen. Dazu haben wir die `group.partial = c("BFs~1", "BFs~~BFs")` Einstellungen verwendet. Eine Besonderheit der skalaren Invarianz ist, dass wir sobald wir die Interzepte über die Gruppen hinweg gleichsetzten, die Freiheitsgrade haben, mit welchen wir die latenten Interzepte von `ZD` und `BOEE` schätzen können. Dies ist  dann eine Art Effektkodierung, wobei der Mittelwert der einen Gruppe auf 0 gesetzt und in der anderen Gruppe dann die Abweichung zu dieser Gruppe mitgeführt wird. Andernfalls würden wir fälschlicherweise Invarianz der latenten Mittelwerte annehmen, was wir hier noch gar nicht prüfen wollen! Wir schauen uns dies im Output an.

```{r, results = "hide"}
fit_sem_sex_skalar <- sem(model_sem, data = StressAtWork, 
                          group = "sex",
                          group.equal = c("loadings", "intercepts"), 
                          group.partial = c("BFs~1", "BFs~~BFs"))
summary(fit_sem_sex_skalar, fit.measures = T)
```

```{r, echo = F}
abbrev(X = fit_sem_sex_skalar, begin = "Group 1", end = "Variances")

abbrev(X = fit_sem_sex_skalar, begin = "Group 2", end = "Variances")
```

Wir erkennen, dass nun `lavaan` sogar nur Zahlen zwischen zwei Punkten als Labels vergibt. Diese Nummer enspricht weiterhin der Parameternummer. Hier greift nun tatsächlich die Einstellung `"BFs~1"` in `group.partial`. `BFs` hat zwei unterschiedlichte Interzepte. Bei `ZD` und `BOEE` fällt auf, dass diese in Gruppe 1 auf 0 gesetzt sind (ohne Unsicherheit) und in Gruppe 2 hier eine Effektkodierung durchgeführt wurde: hier wurden die Interzepte geschätzt. Unterscheidet sich dieser Interzept nun von 0, so unterscheiden sich die Gruppe in ihren Interzepten ([möglicherweise bedingten] Mittelwerten). Dazu später mehr!

Nun wollen wir untersuchen, ob das metrisch- und das skalar-invariante Modell sich signifikant in der Modellbeschreibung unterscheiden.

```{r, eval = F}
lavTestLRT(fit_sem_sex_skalar, fit_sem_sex_metrisch)
```

```{r, echo = F}
res_skalar <- lavTestLRT(fit_sem_sex_skalar, fit_sem_sex_metrisch)
print(res_skalar)
```

Die $\chi^2$-Differenz ist erneut klein (`r round(res_skalar[[5]][2], 3)`) und der p-Wert zeigt auch hier an, dass es sich um keine signifikante Verschlechterung des Modells handelt p = `r round(res_skalar[[7]][2], 3)`. Die Null-Hypothese, dass die Interzepte über die Faktorladungen hinaus über das Geschlecht hinweg gleich sind, wird somit nicht verworfen (die Null-Hypothese war: $H_0: \Sigma_{metrisch}=\Sigma_{skalar}$). Dies bedeutet nun, dass Unterschiede im Mittelwert der Items zwischen den beiden Gruppen tatsächlich auch auf Unterschiede der Mittelwerte der latenten Variablen zurückzuführen sind. Das heißt, dass es erst ab dieser Invarianzstufe zulässig ist, Mittelwerte zwischen den Gruppen zu vergleichen.


### Strikte Invarianz

Unter strikter Invarianz verstehen wir, dass zusätzlich zu den Faktorladungen und den Interzepten auch die Residualvarianzen ($\theta$) gleich sind (insgesamt also $\lambda$s, $\tau$s und $\theta$s gleich über die Gruppen hinweg). Wir passen entsprechend das Modell an:
```{r}
fit_sem_sex_strikt <- sem(model_sem, data = StressAtWork, 
                          group = "sex",
                          group.equal = c("loadings", "intercepts", "residuals"), 
                          group.partial = c("BFs~1", "BFs~~BFs"))
```
Hier greift nun tatsächlich die Einstellung `"BFs~~BFs"` in `group.partial`. Wir vergleichen das skalar- und das strikt-invariante Modell hinsichtlich der Modellbeschreibung.
```{r, eval = F}
lavTestLRT(fit_sem_sex_strikt, fit_sem_sex_skalar)
```

```{r, echo = F}
res_strikt <- lavTestLRT(fit_sem_sex_strikt, fit_sem_sex_skalar)
print(res_strikt)
```

Die $\chi^2$-Differenz ist erneut klein (`r round(res_strikt[[5]][2], 3)`) und der p-Wert zeigt auch hier an, dass es sich um keine signifikante Verschlechterung des Modells handelt p = `r round(res_strikt[[7]][2], 3)`. Die Null-Hypothese, dass die Fehlervarianzen über die Faktorladungen und Interzepte hinaus über das Geschlecht hinweg gleich sind, wird somit nicht verworfen (die Null-Hypothese war: $H_0: \Sigma_{skalar}=\Sigma_{strikt}$).
Dies bedeutet nun, dass Unterschiede in der Varianz der manifesten Variablen tatsächlich auf Unterschiede in den Varianzen der latenten Variablen zurückzuführen sind. In anderen Worten, wenn wir z.B. beobachten, dass Männer in den beobachtbaren Verhaltensweisen homogener sind als Frauen, können wir bei dieser Varianzstufe davon ausgehen, dass dies daher kommt, dass Männer im Konstrukt ähnlicher sind und nicht nur daher, dass sie z.B. aufgrund der Formulierung der Fragen genauer gemessen werden konnten.


### Vollständige Invarianz

Unter vollständiger Invarianz verstehen wir das Gleichsetzten aller Strukturparameter. Hier werden nun alle Varianzen, Residualvarianzen, ungerichtete und gerichtete Effekte des Strukturmodells über die Gruppen hinweg gleichgesetzt (insgesamt also $\lambda$s, $\tau$s, $\theta$s, $\gamma$s, $\beta$s, $\kappa$s, $\phi$s und $\psi$s gleich über die Gruppen hinweg). Wir passen entsprechend das Modell an.  Außerdem müssen wir nun das Interzept und die Residualvarianz von `BFs` invariant zwischen den Gruppen setzen, was wir erreichen, indem wir die `group.partial` Option rausnehmen.
```{r}
fit_sem_sex_voll <- sem(model_sem, data = StressAtWork, 
                        group = "sex",
                        group.equal = c("loadings", "intercepts", "residuals",
                                        "means",          # latente Mittelwerte
                                        "lv.variances",   # latente Varianzen
                                        "lv.covariances", # latente Kovarianzen
                                        "regressions"))   # Strukturparameter (Regressionsgewichte)
```

Wenn wir nun den Modellvergleich zwischen dem strikt invarianten und dem vollständig invarianten Modell durchführen,
```{r, eval = F}
lavTestLRT(fit_sem_sex_voll, fit_sem_sex_strikt)
```

```{r, echo = F}
res_voll <- lavTestLRT(fit_sem_sex_voll, fit_sem_sex_strikt)
print(res_voll)
```

erhalten wir diesmal eine große $\chi^2$-Differenz  (`r round(res_voll[[5]][2], 3)`) und der p-Wert zeigt an, dass es sich um eine signifikante Verschlechterung des Modells handelt p = `r round(res_voll[[7]][2], 3)` $< 0.05$, wenn wir  die Restriktion der vollständigen Invarianz in das Modell aufnehmen. Die Null-Hypothese, dass alle Parameter im Modell über das Geschlecht hinweg gleich sind, wird somit verworfen (die Null-Hypothese war: $H_0: \Sigma_{strikt}=\Sigma_{vollständig}$). Dies bedeutet also, dass es Geschlechtsunterschiede in den Beziehungen zwischen den latenten Variablen gibt. 

Natürlich ist es nun interessant, wo diese Unterschiede leigen. Deshalb schauen wir uns dies an, indem wir uns den Output der Summary des strikt-invarianten Modells ansehen, da sich hier Pfadkoeffizienten, sowie die Mittelwerte und Varianzen der latenten Variablen (bzw. von `BFs`, was wir als latente Variable mitführen) noch unterscheiden:

```{r, eval = F}
summary(fit_sem_sex_strikt)
```

```{r, echo = F}
abbrev(X = fit_sem_sex_strikt, begin = "Group 1", end = "Variances")

abbrev(X = fit_sem_sex_strikt, begin = "Group 2", end = "Variances")
```

Dem jeweiligen Unterpunkt `Regressions` in beiden Gruppen entnehmen wir, dass die Pfadkoeffizienten  recht ähnlich groß zu sein scheinen. Die Standardfehler der Koeffizienten in beiden Gruppen überlappen sich stark, wenn wir jeweils `Estimate` $\pm$ `Std.Err` für einen Koeffizienten rechnen (zur Erinnerung: ein 95% Konfidenzintervall würden wir mit $Est \pm 1.96SE$ erhalten, was noch viel größer wäre und sich diese also "noch stärker" überlappen würde). Schauen wir uns jeweils die Interzepte in den Unterpunkten `Intercepts` in den beiden Gruppen an, erkennen wir an der Effektkodierung für `ZD` und `BOEE`, dass die latenten Interzepte ($\kappa$) in der einen Gruppe auf 0 gesetzt und in der anderen Gruppe frei geschätzt wurden. Das Interzept in Gruppe 2 (den Männern) von Zeitdruck ist signifikant von 0 verschieden, das von emotionaler Erschöpfung nicht. Dies bedeutet, dass sich Männer und Frauen in ihrem latenten Mittelwert von Zeitdruck unterscheiden. Da der Mittelwert von Zeitdruck in der Gruppe der Frauen auf 0 gesetzt war und der Mittelwert von Zeitdruck der Männer signifikant von 0 abweicht (`Est` = `r round(parameterEstimates(fit_sem_sex_strikt)[59,7], 3)`, $p < .05$), verrät uns das negative Vorzeichen, dass Männer im Durchschnitt weniger Zeitdruck erleben. Auch wenn wir Konfidenzintervalle um die Interzeptschätzung von `BFs` legen, erhalten wir einen signifikanten Unterschied: die untere Grenze des Konfidenzintervalls in *Gruppe 1* liegt bei $2.486-1.96*0.05 \approx 2.38$ und und die obere Grenze in *Gruppe 2* liegt bei $2.206+1.96*0.069 \approx 2.35$; hier haben wir konservativer "gerundet", um den $\beta$-Fehler zu minimieren; --- die Konfidenzintervalle überlappen sich nicht! Diese signifikanten Unterschiede könnte der Grund gewesen sein, dass die vollständige Invarianz verworfen wurde. Um dies genauer zu prüfen, müssten wir sukzessive alle Parameter über die Gruppen gleichsetzen und schauen, für welchen Parameter diese Gleichsetzung zu einer signifikanten Verschlechterung des Modells führt.

Zusammenfassend können wir also nur von strikter Invarianz des Modells über das Geschlecht ausgehen. Wie sieht nun unser finales Modell aus?


```{r, fig.align="center"}
semPaths(object = fit_sem_sex_strikt, what = "est", layout = "tree2",
         rotation = 2, curve = T, col = list(man = "skyblue", lat = "yellow"),
         curvePivot = T,  edge.label.cex=1, sizeMan = 5, sizeLat = 8)
```

Wir erkennen deutlich, dass einige Koeffizienten gleich sind und bspw. der Mittelwert von `ZD` in einer Gruppe auf 0 ist (kein Pfeil) und in der zweiten Gruppe bei -0.29 liegt. Wenn wir hier `what = "model"` wählen, können wir das Modell mit allen Gleichsetzungen betrachten.

### Was bedeutet es, wenn ein Pfadkoeffizient nicht invariant über Gruppen ist?
Wir wollen uns trotzdem noch kurz die Frage stellen, was es eigentlich bedeutet, falls ein Pfadkoeffizient über Gruppen hinweg nicht gleich ist. Das haben wir zwar in unseren Daten nicht beobachtet, es stellt aber eine interessante Fragestellung dar. _Wir gehen dazu davon aus, dass der (Regressions-)Koeffizient des Zeitdruck auf Burnout (Emotionale Erschöpfung) nicht invariant über das Geschlecht wäre._ Dann bedeutet dies, dass es für das Geschlecht unterschiedlich starke Beziehung zwischen Zeitdruck und Burnout gibt. Damit sprechen wir eigentlich von einer "Interaktion" zwischen Geschlecht und Zeitdruck im Effekt auf Burnout. Dies ist somit gleichbedeutend wie eine in eine Regression involvierte Interaktion à la `lm(BF~1 + factor(sex) + ZD + factor(sex):ZD)`. Hierbei steht `:` für Interaktion, also Produkt, zwischen der Dummy-Variable `sex` (deshalb auch `factor` außen herum) und dem Zeitdruck. In einer solchen Regression lassen wir also im Grunde 2 Steigungskoeffizienten für den Zeitdruck zu. In *Regressionsschreibweise* (Achtung, diese weicht von der Strukturmodellsschreibweise ab!): 

\begin{align}
BF_i&=\beta_0 + \beta_1ZD_i + \beta_2sex_i + \beta_3ZD_isex_i + \varepsilon_i\\
BF_i&=\underbrace{(\beta_0 + \beta_2sex_i)}_{\text{Interzept}(sex_i)} + \underbrace{(\beta_1 +  + \beta_3sex_i)}_{\text{Slope}(sex_i)}ZD_i + \varepsilon_i\\
\end{align}
In der zweiten Schreibweise/Zeile erkennen wir, dass es eigentlich eine geschlechtsspezifische Slope gibt, welche sich mit 2 Parametern (also $df=2$) ergibt: $\beta_1 + \beta_3sex_i$, also in der einen Gruppe ist die Beziehung $\beta_1$ ($sex=0$, da dummykodiert wird, entspricht dies den Frauen) und in der anderen $\beta_1 + \beta_3$ ($sex=1$, da dummykodiert wird, entspricht dies den Männern)! Genauso kann man auch zwei Gleichungen für das Interzept formulieren. (Wer sich weiter für Interaktionen interessiert, kann sich ansehen wie Interaktionen in Regressionen mit kontinuierlichen Variablen aussehen: [quadaratische und moderierte Regression](/post/quadratische-und-moderierte-regression/#modReg) --- dies ist eine Sitzung aus dem Bachelor!). 
Analog zur Regressionsschreibweise werden nun bei der Invarianztestung auch die beiden Koeffizienten in den beiden Gruppen auf den selben Wert gesetzt und es wird geschaut, ob diese Annahme die Passung des Modells zu den Daten stark verschlechtert. Die oben gewählte Regressionsschreibweise erleichtert nur das Ablesen eines signifikanten Unterschiedes über die Gruppe via Signifikanzentscheidung von $\beta_3$, für SEM geschiet dies durch eine Invarianztestung! Da wir nun angenommen hatten, dass dies der Fall ist, wird also für die beiden Gruppen, also für Männer und für Frauen, eine eigene Beziehung zwischen Zeitdruck und Burnout angenommen (und ggf. auch ein eigenes Interzept). Dies sieht doch der Schreibweise in der Regression sehr ähnlich --- damit erkennen wir, dass dies eigentlich eine **Interkation zwischen Geschlecht und Zeitdruck** darstellt! Um das nochmals zu veranschaulichen, stellen wir die empirischen Beziehungen grafisch dar, indem wir zwei Gerade zeichnen, welche so in den beiden Subpopulationen beobachtet wurden (diese sind allerdings nicht signifikant verschieden von einander). Wir plotten dazu das strikt invariante Modell: Die Beziehung zwischen Zeitdruck und emotionaler Erschöpfung beläuft sich empirisch auf: $\hat{\gamma}_{11}^{Frauen}=$.490 und  $\hat{\gamma}_{11}^{Männer}=$ .583. Die latente Interzepte liegen bei: $\hat{\kappa}_{11}^{Frauen}=$ 0 und $\hat{\kappa}_{11}^{Männer}=$ 0.104. Somit haben wir alle Informationen, die nötig sind, um für Frauen und Männer jeweils eine Regressionsgerade einzuzeichnen.

```{r}
plot(NA,                                                                     # leeren Plot erstellen
     xlim = c(-1, 1), ylim = c(-1, 1),                                       # festlegen, von wo bis wo der Plot dargestellt werden soll                             
     main = "Beziehung zwischen Zeitdruck\n und emotionaler Erschöpfung",    # Titel vergeben
     xlab = "ZD", ylab = "EE")                                               # Achsenbeschriftung vergeben 
abline(a = 0, b = .490, col = "red", lwd = 2)                                # eigene Gerade für Frauen einzeichnen
abline(a = 0.104, b = .583, col = "blue", lwd = 2)                            # eigene Gerade für Männer einzeichnen
                                                                             # a = Interzept, b = Steigung, col = Farbe, lwd = Liniendicke
legend(x="topleft", col = c("red", "blue"), lwd = c(2, 2), lty = c(1, 1),    # Legende einzeichnen oben links mit Farben
       legend = c("Frauen", "Männer"))                                       # und Liniendicken von abline
abline(v = 0, lty = 3)                                                       # vertikale Linie bei 0 einzeichnen (y-Achse)
```

Der Grafik entnehmen wir die deskriptiven Unterschiede zwischen den Interzepten ($\hat{\kappa}_{11}^{Männer} > \hat{\kappa}_{11}^{Frauen}$) und zwischen den Slopes ($\hat{\gamma}_{11}^{Männer}>\hat{\gamma}_{11}^{Frauen}$), allerdings sind diese Unterschiede nicht statistisch signifikant und werden hier nur für illustrationszwecke so dargestellt!

Eine detaillierte Wiederholung dessen, was auch in den inhaltlichen Sitzungen zu den Invarianzstufen behandelt wurde, finden Sie im [Exkurs zu Invarianztestungen](/post/Exkurs-Invarianzstufen). Für weiterführende Literatur, die zum Teil für diesen Abschnitt aufgearbeitet wurde, siehe bspw. Gregorich (2006) - _dies ist keine Prüfungsliteratur_.

Den gesamten R-Code, der in dieser Sitzung genutzt wird, können Sie [`r fontawesome::fa("download")` hier herunterladen](https://raw.githubusercontent.com/jpirmer/MSc1_FEI/master/R-Scripts/MSA.R).

***

## Appendix A {#AppendixA}

<details><summary> **MSA zu Fuß** </summary>

Wir wollen uns die Invarianztestung auch noch einmal zu Fuß ansehen. Um das ganze abzukürzen, schauen wir uns immer mit `fitMeasures` nur den $\chi^2$-Wert, die $df$ sowie den $p$-Wert an und vergleichen diese mit den bereits geschätzten Modell aus dem Abschnitt zur [MSA](#MSA).

#### Konfigurale Invarianz
Wir beginnen mit der Spezifikation des konfigural invarianten Modells. Hier muss nichts gleichgesetzt werden. Wir kopieren also einfach das Modell `model_sem`:

```{r}
model_sem <- '
# Messmodelle
ZD =~ zd1 + zd2 + zd6
BOEE =~ bo1 + bo6 + bo12 + bo19

# Strukturmodell
BOEE ~ ZD
BFs ~  BOEE + ZD
'
```

und schätzen dies anschließend. Wir verwenden das Anhängsel `2`, um zu zeigen, welches die händisch gleichgesetzte Variante ist:

```{r, results = "hide"}
fit_sem_sex_konfigural <- sem(model_sem, data = StressAtWork, group = "sex",
                                     group.equal = c(""), group.partial = c("BFs ~ 1", "BFs ~~*BFs"))
fit_sem_sex_konfigural2 <- sem(model_sem, data = StressAtWork,  group = "sex")

# chi^2, df, p-Wert
fitmeasures(fit_sem_sex_konfigural, c("chisq", 'df', "pvalue"))
fitmeasures(fit_sem_sex_konfigural2, c("chisq", 'df', "pvalue"))
```

```{r, echo = F}
cat("group.equal:")
print(round(fitmeasures(fit_sem_sex_konfigural, c("chisq", 'df', "pvalue")), 3))
cat("zu Fuß/händisch:")
print(round(fitmeasures(fit_sem_sex_konfigural2, c("chisq", 'df', "pvalue")), 3))
```

Wir erkennen keine Unterschiede, was nicht verwunderlich ist. Hier wurde noch nichts gleichgesetzt.


#### Metrische Invarianz
Wir müssen nun ein neues Modell spezifizieren, in welchem wir allen Faktorladungen ($\lambda$s) jeweils über die Gruppen hinweg das gleiche Label geben. Hierbei verwenden wir `l` als Label für die Faktorladungen und nummerieren alle Faktorladungen nacheinander durch (wie genau hier vorgegangen wird, ist immer den Anwendenden überlassen. Es muss lediglich darauf geachtet werden, nicht mehrfach das gleiche Label für unterschiedliche Parameter zu verwenden, wenn dies nicht explizit gewünscht ist).

```{r}
model_sem_metrisch <- '
# Messmodelle
ZD =~ zd1 + c(l1, l1)*zd2 + c(l2, l2)*zd6
BOEE =~ bo1 + c(l3,l3)*bo6 + c(l4, l4)*bo12 + c(l5, l5)*bo19

# Strukturmodell
BOEE ~ ZD
BFs ~  BOEE + ZD'
```

```{r, results="hide"}
fit_sem_sex_metrisch <- sem(model_sem, data = StressAtWork, 
                            group = "sex",
                            group.equal = c("loadings"), 
                            group.partial = c("BFs~1", "BFs ~~BFs"))
fit_sem_sex_metrisch2 <- sem(model_sem_metrisch, data = StressAtWork,  
                             group = "sex")

# chi^2, df, p-Wert
fitmeasures(fit_sem_sex_metrisch, c("chisq", 'df', "pvalue"))
fitmeasures(fit_sem_sex_metrisch2, c("chisq", 'df', "pvalue"))
```

```{r, echo = F}
cat("group.equal:")
print(round(fitmeasures(fit_sem_sex_metrisch, c("chisq", 'df', "pvalue")), 3))
cat("zu Fuß/händisch:")
print(round(fitmeasures(fit_sem_sex_metrisch2, c("chisq", 'df', "pvalue")), 3))
```

Erneut erkennen wir keine Unterschiede zwischen den Modellen. Beide Vorgehensweisen kommen zum selben Ergebnis!



#### Skalare Invarianz
Erneut müssen wir ein neues Modell spezifizieren, in welchem wir jeweils allen Faktorladungen und Interzepten ($\lambda$s und $\tau$s) über die Gruppen hinweg das gleiche Label geben. Hierbei verwenden wir `tau` als Label für die Interzepte und nummerieren alle Interzepte der manifesten Variablen nacheinander durch. Wir fügen außerdem die Effektkodierung ein via `ZD ~ c(0, NA)*1` und `BOEE ~c(0, NA)*1`, womit der latente Mittelwert in einer Gruppe auf 0 gesetzt und in der zweiten frei geschätzt wird und erweitern das Modell `model_sem_metrisch` zu:

```{r}
model_sem_skalar <- '
# Messmodelle
ZD =~ zd1 + c(l1, l1)*zd2 + c(l2, l2)*zd6
BOEE =~ bo1 + c(l3,l3)*bo6 + c(l4, l4)*bo12 + c(l5, l5)*bo19

zd1 ~ c(tau1, tau1)*1
zd2 ~ c(tau2, tau2)*1
zd6 ~ c(tau3, tau3)*1

bo1 ~ c(tau4, tau4)*1
bo6 ~ c(tau5, tau5)*1
bo12 ~ c(tau6, tau6)*1
bo19 ~ c(tau7, tau7)*1

# Strukturmodell
BOEE ~ ZD
BFs ~  BOEE + ZD

BOEE ~ c(0, NA)*1
ZD ~ c(0, NA)*1
'
```

```{r, results="hide"}
fit_sem_sex_skalar <- sem(model_sem, data = StressAtWork, 
                          group = "sex",
                          group.equal = c("loadings", "intercepts"), 
                          group.partial = c("BFs~1", "BFs ~~BFs"))
fit_sem_sex_skalar2 <- sem(model_sem_skalar, data = StressAtWork,  group = "sex")

# chi^2, df, p-Wert
fitmeasures(fit_sem_sex_skalar, c("chisq", 'df', "pvalue"))
fitmeasures(fit_sem_sex_skalar2, c("chisq", 'df', "pvalue"))
```

```{r, echo = F}
cat("group.equal:")
print(round(fitmeasures(fit_sem_sex_skalar, c("chisq", 'df', "pvalue")), 3))
cat("zu Fuß/händisch:")
print(round(fitmeasures(fit_sem_sex_skalar2, c("chisq", 'df', "pvalue")), 3))
```

Erneut erkennen wir keine Unterschiede zwischen den Modellen. Beide Vorgehensweisen kommen zum selben Ergebnis!


#### Strikte Invarianz
Wieder müssen wir ein neues Modell spezifizieren, in welchem wir jeweils allen Faktorladungen, Interzepten und Fehlervarianzen ($\lambda$s, $\tau$s und $\theta$s) über die Gruppen hinweg das gleiche Label geben. Hierbei verwenden wir `t` als Label für die Fehlervarianzen und nummerieren alle Fehlervarianzen der manifesten Variablen nacheinander durch. Wir erweitern das Modell `model_sem_skalar`.

```{r}
model_sem_strikt <- '
# Messmodelle
ZD =~ zd1 + c(l1, l1)*zd2 + c(l2, l2)*zd6
BOEE =~ bo1 + c(l3,l3)*bo6 + c(l4, l4)*bo12 + c(l5, l5)*bo19

zd1 ~ c(tau1, tau1)*1
zd2 ~ c(tau2, tau2)*1
zd6 ~ c(tau3, tau3)*1

bo1 ~ c(tau4, tau4)*1
bo6 ~ c(tau5, tau5)*1
bo12 ~ c(tau6, tau6)*1
bo19 ~ c(tau7, tau7)*1

zd1 ~~ c(t1, t1)*zd1
zd2 ~~ c(t2, t2)*zd2
zd6 ~~ c(t3, t3)*zd6

bo1 ~~ c(t4, t4)*bo1
bo6 ~~ c(t5, t5)*bo6
bo12 ~~ c(t6, t6)*bo12
bo19 ~~ c(t7, t7)*bo19

# Strukturmodell
BOEE ~ ZD
BFs ~  BOEE + ZD

BOEE ~ c(0, NA)*1
ZD ~ c(0, NA)*1
'
```

```{r, results="hide"}
fit_sem_sex_strikt <- sem(model_sem, data = StressAtWork, 
                          group = "sex",
                          group.equal = c("loadings", "intercepts", "residuals"), 
                          group.partial = c("BFs~1", "BFs~~BFs"))
fit_sem_sex_strikt2 <- sem(model_sem_strikt, data = StressAtWork,  group = "sex")

# chi^2, df, p-Wert
fitmeasures(fit_sem_sex_strikt, c("chisq", 'df', "pvalue"))
fitmeasures(fit_sem_sex_strikt2, c("chisq", 'df', "pvalue"))
```

```{r, echo = F}
cat("group.equal:")
print(round(fitmeasures(fit_sem_sex_strikt, c("chisq", 'df', "pvalue")), 3))
cat("zu Fuß/händisch:")
print(round(fitmeasures(fit_sem_sex_strikt2, c("chisq", 'df', "pvalue")), 3))
```

Erneut erkennen wir keine Unterschiede zwischen den Modellen. Beide Vorgehensweisen kommen zum selben Ergebnis!


#### Vollständige Invarianz
Zum letzten Mal müssen wir ein neues Modell spezifizieren, in welchem wir allen Parametern des Modells (insgesamt also $\lambda$s, $\tau$s, $\theta$s, $\gamma$s, $\beta$s, $\kappa$s, $\phi$s und $\psi$s) über die Gruppen hinweg das gleiche Label geben. Wir müssen die Effektkodierung der latenten Mittelwert wieder herausnehmen und setzten die Mittelwerte in beiden Gruppen auf 0. Als Label verwenden wir wieder die Notation, die wir schon aus den Mediationanalysen kennen (`a`, `b` und `c`). Für die latenten Residualvarianzen führen wir `psi` als Label ein (hierbei zählen wir weiterhin `BFs` zu den latenten Variablen). Für die latente Varianz von `ZD` verwenden wir `phi` als Label. Für den Mittelwert von `BFs` verwenden wir ausnahmsweise `kappa`, da wir `BFs`, wie zuvor erwähnt, weiter als latente Variable zählen wollen.


```{r}
model_sem_voll <- '
# Messmodelle
ZD =~ zd1 + c(l1, l1)*zd2 + c(l2, l2)*zd6
BOEE =~ bo1 + c(l3,l3)*bo6 + c(l4, l4)*bo12 + c(l5, l5)*bo19

zd1 ~ c(tau1, tau1)*1
zd2 ~ c(tau2, tau2)*1
zd6 ~ c(tau3, tau3)*1

bo1 ~ c(tau4, tau4)*1
bo6 ~ c(tau5, tau5)*1
bo12 ~ c(tau6, tau6)*1
bo19 ~ c(tau7, tau7)*1

zd1 ~~ c(t1, t1)*zd1
zd2 ~~ c(t2, t2)*zd2
zd6 ~~ c(t3, t3)*zd6

bo1 ~~ c(t4, t4)*bo1
bo6 ~~ c(t5, t5)*bo6
bo12 ~~ c(t6, t6)*bo12
bo19 ~~ c(t7, t7)*bo19

# Strukturmodell
BOEE ~ c(a, a)*ZD
BFs ~  c(b, b)*BOEE + c(c, c)*ZD

BOEE ~ c(0, 0)*1
ZD ~ c(0, 0)*1
BFs ~ c(kappa, kappa)*1

ZD ~~ c(phi, phi)*ZD
BOEE ~~ c(psi1, psi1)*BOEE
BFs ~~ c(psi2, psi2)*BFs
'
```

```{r, results="hide"}
fit_sem_sex_voll <- sem(model_sem, data = StressAtWork, 
                        group = "sex",
                        group.equal = c("loadings", "intercepts", "residuals",
                                        "means",          # latente Mittelwerte
                                        "lv.variances",   # latente Varianzen
                                        "lv.covariances", # latente Kovarianzen
                                        "regressions"))   # Strukturparameter (Regressionsgewichte)
fit_sem_sex_voll2 <- sem(model_sem_voll, data = StressAtWork,  
                         group = "sex")

# chi^2, df, p-Wert
fitmeasures(fit_sem_sex_voll, c("chisq", 'df', "pvalue"))
fitmeasures(fit_sem_sex_voll2, c("chisq", 'df', "pvalue"))
```

```{r, echo = F}
cat("group.equal:")
print(round(fitmeasures(fit_sem_sex_voll, c("chisq", 'df', "pvalue")), 3))
cat("zu Fuß/händisch:")
print(round(fitmeasures(fit_sem_sex_voll2, c("chisq", 'df', "pvalue")), 3))
```

Erneut erkennen wir keine Unterschiede zwischen den Modellen. Beide Vorgehensweisen kommen zum selben Ergenis! Zuvor hatten wir gesehen, dass ein Modellvergleich zwischen der strikten und der vollständigen Invarianz zu Gunsten der strikten Invarianz ausfällt. Somit wird die vollständige Invarianz verworfen und wir entscheiden uns final für die strikte Invarianz über das Geschlecht.

</details>



## Literatur
[Eid, M., Gollwitzer, M., & Schmitt, M. (2017).](https://hds.hebis.de/ubffm/Record/HEB366849158) *Statistik und Forschungsmethoden* (5. Auflage, 1. Auflage: 2010). Weinheim: Beltz.

Gregorich, S. E. (2006). Do self-report instruments allow meaningful comparisons across diverse population groups? Testing measurement invariance using the confirmatory factor analysis framework. _Medical Care_, _44_(11), 78-94.

Schermelleh-Engel, K., Moosbrugger, H., & Müller, H. (2003). Evaluation the fit of structural equation models: tests of significance and descriptive goodness-of-fit measures. _Methods of Psychological Research Online,_ *8*(2), 23-74.


### Inhaltliche Literatur
Büssing, A., & Perrar, K.-M. (1992). Die Messung von Burnout. Untersuchung einer deutschen Fassung des Maslach Burnout Inventory (MBI-D) [The measurement of Burnout. The study of a German version of the Maslach Burnout Inventory (MBI-D)]. _Diagnostica_, _38_, 328 – 353.

Cloetta, B. (2014). Machiavellismus-Konservatismus. _Zusammenstellung sozialwissenschaftlicher Items und Skalen (ZIS)._ [https://doi.org/10.6102/zis82](https://doi.org/10.6102/zis82)

Maslach, C., & Jackson, S.E. (1986). _Maslach Burnout Inventory_ (Vol. 2). Palo Alto, CA: Consulting Psychologists Press.

Mohr, G. (1986). _Die Erfassung psychischer Befindensbeeinträchtigungen bei Arbeitern_ [Assessment of impaired psychological well-being in industrial workers]. Frankfurt am Main, Fermany: Lang.

Semmer, N. K., Zapf, D., & Dunckel, H. (1999). Instrument zur Stressbezogenen Tätigkeitsanalyse (ISTA) [Instrument for stress-oriented task analysis (ISTA)]. In H. Dunkel (Ed.), _Handbuch psychologischer Arbeitsanalyseverfahren (pp. 179 – 204)_. Zürich, Switzerland: vdf Hochschulverlag an der ETH.



* <small> *Blau hinterlegte Autorenangaben führen Sie direkt zur universitätsinternen Ressource.*

