---
title: Hierarchische Regression
date: '2020-10-06'
slug: multi-level-modeling
categories:
  - MSc1
tags:
  - hierarchische Regression
  - Multi-Level
  - ggplot
  - linear
  - Interaktion
subtitle: 'Multi-Level Modeling'
summary: ''
authors: [irmer]
lastmod: '2020-10-13T17:32:21+02:00'
featured: no
image:
  caption: ''
  focal_point: ''
  preview_only: no
projects: []
---



<div id="einleitung" class="section level2">
<h2>Einleitung</h2>
<p>In dieser Sitzung wollen wir hierarchische Daten mit der Multi-Level-Regression (auch hierarchische Regression, Multi-Level-Modeling, Linear Mixed-Effects Modeling, vgl. bspw. <a href="https://hds.hebis.de/ubffm/Record/HEB366849158">Eid, Gollwitzer &amp; Schmitt, 2017</a>, Kapitel 20 und <a href="https://hds.hebis.de/ubffm/Record/HEB371183324">Pituch und Stevens (2016)</a> Kapitel 13) analysieren. Diese Daten sind dahingehend speziell, dass es in ihnen Clusterungen von Datenpunkten gibt, die zueinander ähnlicher sind als zu den übrigen. Dies verletzt die Annahme der Unabhängigkeit in der typischen Regressionsanalyse, was zu erheblichen Fehlschlüssen führen kann. Wir wollen uns ein fiktives Datenbeispiel (Datensatz <code>StudentsInClasses</code> aus dem gleichnamigen .rda File <code>StudentsInClasses.rda</code>) mit Schüler/innen (Ebene 1) in Schulklassen (Eben 2) anschauen. Sie können den <a href="/post/StudentsInClasses.rda"><svg style="height:0.8em;top:.04em;position:relative;" viewBox="0 0 512 512"><path d="M216 0h80c13.3 0 24 10.7 24 24v168h87.7c17.8 0 26.7 21.5 14.1 34.1L269.7 378.3c-7.5 7.5-19.8 7.5-27.3 0L90.1 226.1c-12.6-12.6-3.7-34.1 14.1-34.1H192V24c0-13.3 10.7-24 24-24zm296 376v112c0 13.3-10.7 24-24 24H24c-13.3 0-24-10.7-24-24V376c0-13.3 10.7-24 24-24h146.7l49 49c20.1 20.1 52.5 20.1 72.6 0l49-49H488c13.3 0 24 10.7 24 24zm-124 88c0-11-9-20-20-20s-20 9-20 20 9 20 20 20 20-9 20-20zm64 0c0-11-9-20-20-20s-20 9-20 20 9 20 20 20 20-9 20-20z"/></svg> Datensatz “StudentsInClasses.rda” hier herunterladen</a>.</p>
<div id="daten-laden" class="section level3">
<h3>Daten laden</h3>
<p>Dazu laden wir mit <code>load</code> die Daten (bspw. auf dem Desktop von Frau “Musterfrau”) <em>Tipp: Verwenden Sie unbedingt die automatische Vervollständigung von <code>R</code>-Studio, wie in den letzten Sitzung beschrieben</em>.</p>
<pre class="r"><code>load(&quot;C:/Users/Musterfrau/Desktop/StudentsInClasses.rda&quot;)</code></pre>
<p>Genauso können Sie die Daten direkt von der Website laden:</p>
<pre class="r"><code>load(url(&quot;https://pandar.netlify.app/post/StudentsInClasses.rda&quot;))</code></pre>
<p>Nun sollte in <code>R</code>-Studio oben rechts in dem Fenster unter der Rubrik “Data” unser Datensatz mit dem Namen “<em>StudentsInClasses</em>” erscheinen.</p>
</div>
<div id="übersicht-über-die-daten" class="section level3">
<h3>Übersicht über die Daten</h3>
<p>In Multilevel-Daten gibt es, wie der Name schon andeutet, mehrere Level. In unserem Datensatz gibt es zwei: Level 1 enthält die Individualdaten (within) und Level 2 enthält die clusterspezifischen Daten (between). Wir verwenden wieder <code>head</code>, um zu schauen, welche Variablen wohl auf welchem Level liegen:</p>
<pre class="r"><code>head(StudentsInClasses)</code></pre>
<pre><code>##   MatheL Motivation KFT KlassenG schulklasse
## 1  48.76          4  98       26           1
## 2  46.01          3  96       26           1
## 3  65.96          5 112       26           1
## 4  42.08          4  94       26           1
## 5   0.00          2  78       26           1
## 6  56.52          5 104       26           1</code></pre>
<p>Aus dieser Übersicht ergibt sich folgende Aufteilung:</p>
<p><strong>Ebene 1 (within-level)</strong></p>
<ul>
<li>Mathematikleistung als AV: <code>MatheL</code></li>
<li>Motivation der Schüler/innen als Pädiktor: <code>Motivation</code></li>
<li>Intelligenz der Schüler/innen als Pädiktor: <code>KFT</code> (Kognitiver Fähigkeitstest)</li>
</ul>
<p><strong>Ebene 2 (between-level)</strong></p>
<ul>
<li>Klassengröße als Prädiktor: <code>KlassenG</code></li>
<li>Klassenzugehörigkeit als Gruppierungsvariable: <code>schulklasse</code></li>
</ul>
<p>Die Daten liegen hier im “Long”-Format vor, was bedeutet, dass Schüler aus einer Klasse untereinander stehen und es eine Clustervariable gibt, die die Schüler jeweils einer Klasse zuordnet. In diesem Fall ist dies die Level 2 Variable <code>schulklasse</code> (hierbei ist es wichtig, dass jedes Schulkind nur einer Schulklasse zugeordnet werden kann und dass unterschiedliche Schulklassen auch unterschiedliche Bezeichnungen haben müssen - die Level 2 Variable <code>KlassenG</code> kann für unterschiedliche Schulklassen die selbe Ausprägung aufweisen, sie ist nämlich nur eine Variable, die das Cluster näher beschreibt). Wir schauen uns noch schnell die Mittelwerte der Variablen an:</p>
<pre class="r"><code>colMeans(StudentsInClasses)</code></pre>
<pre><code>##      MatheL  Motivation         KFT    KlassenG schulklasse 
##   53.616047    4.285882  100.001176   27.090588   20.280000</code></pre>
<p>Bei Multi-Level-Analysen ist darauf zu achten, dass für bessere Interpretierbarkeit unabhängige Variablen zentriert werden sollten. Wir können zwischen <em>Grand-Mean-Centering</em> und <em>Group-Mean-Centering</em> unterscheiden. Beim <em>Grand-Mean-Centering</em> wird am Stichprobenmittelwert der jeweiligen Variable zentriert. Somit spricht ein Wert von Null auf der zentrierten Variable für den Mittelwert über alle Erhebungen (hier: Schulkinder). Beim Group-Mean-Centering wird am Mittelwert des jeweiligen Clusters zentriert. Somit entspricht ein Mittelwert von 0 auf der zentrierten Variable für einen durchschnittlichen Wert innerhalb dieses Clusters (hier: für einen durchschnittlichen Wert innerhalb dieser Schulklasse). Beim Group-Mean-Centering können die Ergebnisse gut in Hinsicht auf die Schulklasse interpretiert werden, allerdings geht die Unterschiedlichkeit zwischen Klassen verloren, weswegen häufig zusätzlich zur zentrierten Variable auch der Mittelwert pro Cluster als L2 Variable mit in das Modell aufgenommen wird.</p>
</div>
<div id="hypothesen" class="section level3">
<h3>Hypothesen</h3>
<p>Wir wollen folgende Hypothesen untersuchen:</p>
<ol style="list-style-type: decimal">
<li>Mathematikleistung hängt von der Lernmotivation ab</li>
<li>Der Effekt der Motivation unterscheidet sich zwischen Klassen</li>
<li>Mathematikleistung hängt von der Klassengröße ab</li>
<li>Es gibt eine Wechselwirkung (Cross-Level-Interaktion) zwischen Motivation und Klassengröße</li>
</ol>
</div>
<div id="pakete-laden" class="section level3">
<h3>Pakete laden</h3>
<p>Wir werden im Folgenden wieder neue <code>R</code>-Pakete benötigen. Diese müssen zunächst installiert werden (<code>install.packages</code>) und anschließend geladen werden: Das wichtigste Paket ist <code>lme4</code> (<strong>l</strong>inear <strong>m</strong>ixed <strong>e</strong>ffects 4, wobei wir annehmen können, dass die 4 hier für <em>four</em> steht, was sich wie “<em>for <strong>r</strong></em>” spricht), welches für die Multi-Level Analysen von Nöten ist. <code>robutmeta</code> verwenden wir, um Daten gruppenspezifisch zu zentriern.</p>
<pre class="r"><code>library(lme4)       # für das Durchführen von Multi-Level Regressionen
library(robumeta)   # Datensatzmanipulation
library(lmerTest) # lmerTest markiert in der Ausgabe signifikante Koeffizienten
library(ggplot2) # ggplot2 und dplyr werden nur für Grafiken benötigt
library(dplyr)   # für Datensatzmanipulationen</code></pre>
</div>
</div>
<div id="modellspezifikation" class="section level2">
<h2>Modellspezifikation</h2>
<p>Wir verwenden die Funktion <code>lmer</code> des Pakets <code>lme4</code>, um Multi-Level-Modelle zu schätzen. Die allgemeine Syntax ähnelt sehr der Syntax der <code>lm</code>-Funktion für lineare Modelle. Diese Syntax sah so aus:</p>
<ul>
<li><code>lm(Y ~ 1 + X, data = StudentsInClasses)</code></li>
</ul>
<p>Die Syntax für <code>lmer</code> wird nun erweitert, um die Clusterung zu enthalten: wir nehmen für einen Augenblick an, dass <code>X</code> eine L1-Variable ist, <code>Z</code> eine L2 Variable und <code>gruppe</code> die Clusterungsvariable. In der Modellgleichung werden wie im linearen Modell die Prädiktoren aufgeführt, deren Effekte als <em>feste Effekte</em> geschätzt werden. Zusätzlich werden mit dem senkrechten Strich <code>|</code> <em>Zufallseffekte</em> spezifiziert, welche Variationen beschreiben, die auf das Cluster (hier die Zugehörigkeit zu einer Schulklasse) zurückzuführen sind. Vor dem <code>|</code> stehen die Effekte, die als zufällig behandelt werden sollen, danach die Gruppierungsvariable, durch die die Ebene definiert ist:</p>
<ul>
<li><code>Y ~ 1 + (1 | gruppe)</code>: <em>Random Intercept</em> für Y auf Ebene der Gruppen</li>
<li><code>Y ~ 1 + X + (1 | gruppe)</code>: <em>Random Intercept</em> und fester Effekt für X</li>
<li><code>Y ~ 1 + X + (1 + X | gruppe)</code>: <em>Random Intercept</em> und <em>Random Slope</em> für X</li>
<li><code>Y ~ 1 + X + Z + (1 + X | gruppe)</code>: <em>Random Intercept</em> und <em>Random Slope</em> für X und Prädiktor Z auf L2 (Aufklärung der Interzeptvariation durch <code>Z</code>)</li>
<li><code>Y ~ 1 + X + Z + Z:X + (1 + X | gruppe)</code>: <em>Random Intercept</em> und <em>Random Slope</em> für X und Prädiktor Z auf L2, sowie Cross-Level-Interaktion (Aufklärung der Interzept- und Slopevariation durch <code>Z</code>)</li>
</ul>
<p>Wir erkennen, wie oben schon angedeutet, L2-Variablen nur daran, dass sie über eine Clustereinheit nicht variieren. In unserem Beispiel sehen wir dies daran, dass die Klassengröße für jedes Schulkind aus der selben Schulklasse identisch ist. Dies ist auch in der Modellgleichung so: hier wird <code>Z</code> analog zu <code>X</code> in die Modellgleich aufgenommen, an welcher wir nicht erkennen, ob es sich hierbei um einen L2-Effekt handelt - dies können wir nur wissen, wenn wir wissen in welchem Format die Daten vorliegen. <code>:</code> steht für das Produkt zwischen Variablen in Regressionsmodellen. Oft wird auch <code>*</code> verwendet, welches dann sowohl die einzelnen Haupteffekte, als auch die Interaktion repräsentiert: also <code>Z*X = Z + X + Z:X</code>.</p>
<p>Die zugehörigen Gleichungen zu den Modellen sehen so aus (siehe auch
<a href="https://hds.hebis.de/ubffm/Record/HEB366849158">Eid, et al., 2017,</a> Kapitel 20.2).</p>
<ul>
<li><code>Y ~ 1 + (1 | gruppe)</code>
<ul>
<li><span class="math inline">\(Y_{ij} = \beta_{0j} + \varepsilon_{ij}\)</span></li>
<li><span class="math inline">\(\beta_{0j}=\gamma_{00} + u_{0j}\)</span></li>
<li><span class="math inline">\(\Longrightarrow Y_{ij} = \gamma_{00} + u_{0j} + \varepsilon_{ij}\)</span></li>
</ul></li>
<li><code>Y ~ 1 + X + (1 | gruppe)</code>
<ul>
<li><span class="math inline">\(Y_{ij} = \beta_{0j} + \beta_{1j}X_{ij} + \varepsilon_{ij}\)</span></li>
<li><span class="math inline">\(\beta_{0j}=\gamma_{00} + u_{0j}\)</span></li>
<li><span class="math inline">\(\beta_{1j}=\gamma_{10}\)</span> [<span class="math inline">\(\beta_{1j}\)</span> ist konstant/ gleich für alle <span class="math inline">\(j\)</span>]</li>
<li><span class="math inline">\(\Longrightarrow Y_{ij} = \gamma_{00} + u_{0j} + \gamma_{10}X_{ij} + \varepsilon_{ij}\)</span></li>
</ul></li>
<li><code>Y ~ 1 + X + (1 + X | gruppe)</code>
<ul>
<li><span class="math inline">\(Y_{ij} = \beta_{0j} + \beta_{1j}X_{ij} + \varepsilon_{ij}\)</span></li>
<li><span class="math inline">\(\beta_{0j}=\gamma_{00} + u_{0j}\)</span></li>
<li><span class="math inline">\(\beta_{1j}=\gamma_{10} + u_{1j}\)</span></li>
<li><span class="math inline">\(\Longrightarrow Y_{ij} = \gamma_{00} + u_{0j} + \gamma_{10}X_{ij} + u_{1j}X_{ij} + \varepsilon_{ij}\)</span></li>
</ul></li>
<li><code>Y ~ 1 + X + Z + (1 + X | gruppe)</code>
<ul>
<li><span class="math inline">\(Y_{ij} = \beta_{0j} + \beta_{1j}X_{ij} + \varepsilon_{ij}\)</span></li>
<li><span class="math inline">\(\beta_{0j}=\gamma_{00} + \gamma_{01}Z_j + u_{0j}\)</span></li>
<li><span class="math inline">\(\beta_{1j}=\gamma_{10} + u_{1j}\)</span></li>
<li><span class="math inline">\(\Longrightarrow Y_{ij} = \gamma_{00} + \gamma_{01}Z_j + u_{0j} + \gamma_{10}X_{ij} + u_{1j}X_{ij} + \varepsilon_{ij}\)</span></li>
</ul></li>
<li><code>Y ~ 1 + X + Z + Z:X + (1 + X | gruppe)</code>
<ul>
<li><span class="math inline">\(Y_{ij} = \beta_{0j} + \beta_{1j}X_{ij} + \varepsilon_{ij}\)</span></li>
<li><span class="math inline">\(\beta_{0j}=\gamma_{00} + \gamma_{01}Z_j + u_{0j}\)</span></li>
<li><span class="math inline">\(\beta_{1j}=\gamma_{10} + \gamma_{11}Z_j+ u_{1j}\)</span></li>
<li><span class="math inline">\(\Longrightarrow Y_{ij} = \gamma_{00} + \gamma_{01}Z_j + u_{0j} + \gamma_{10}X_{ij} + \gamma_{11}Z_jX_{ij} + u_{1j}X_{ij} + \varepsilon_{ij}\)</span></li>
</ul></li>
</ul>
<p>Hierbei ist zu beachten, dass natürlich auch <em>nur</em> eine L2 Variable in das Modell aufgenommen werden könnte oder die Interzeptvariation durch die L2-Variable erklärt werden könnte, ohne, dass eine <em>Random Slope</em> spezifiziert wird, etc. Dies hängt von den Hypothesen ab.</p>
</div>
<div id="analysen-mit-dem-beispieldatensatz" class="section level2">
<h2>Analysen mit dem Beispieldatensatz</h2>
<p>Bevor wir mit den Analysen beginnen, müssen wir prüfen, ob eine Multi-Level-Analyse überhaupt nötig ist. Dazu wollen wir uns die Intraklassenkorrelation ansehen. Diese erhalten wir durch Schätzen des sogenannten Nullmodells ohne weiteren Prädiktoren.</p>
<div id="preliminary-analyses-nullmodell-und-intraklassenkorrelation-icc" class="section level3">
<h3>Preliminary Analyses: Nullmodell und Intraklassenkorrelation (ICC)</h3>
<p>Wir nennen das Nullmodell-Objekt einfach mal <code>m0</code> (für Modell 0).</p>
<pre class="r"><code>m0 &lt;- lmer(MatheL ~ 1 +  (1 | schulklasse), data = StudentsInClasses)
summary(m0)</code></pre>
<pre><code>## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [
## lmerModLmerTest]
## Formula: MatheL ~ 1 + (1 | schulklasse)
##    Data: StudentsInClasses
## 
## REML criterion at convergence: 6565.3
## 
## Scaled residuals: 
##     Min      1Q  Median      3Q     Max 
## -4.5448 -0.5642 -0.0015  0.5695  3.5476 
## 
## Random effects:
##  Groups      Name        Variance Std.Dev.
##  schulklasse (Intercept)  23.87    4.885  
##  Residual                123.12   11.096  
## Number of obs: 850, groups:  schulklasse, 40
## 
## Fixed effects:
##             Estimate Std. Error      df t value Pr(&gt;|t|)    
## (Intercept)  54.0235     0.8658 37.0961    62.4   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>Die Summary sieht der der normalen linearen Regression sehr ähnlich. Wir schauen uns diese im Detail an.</p>
<pre><code>## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [
## lmerModLmerTest]
## Formula: MatheL ~ 1 + (1 | schulklasse)
##   Data: StudentsInClasses</code></pre>
<p>zeigt uns, dass es sich um ein <em>Linear mixed model</em> handelt (also ein Multi-Level-Modell/hierarchische Regression), welches mit der <strong>RE</strong>stricted <strong>M</strong>aximum <strong>L</strong>ikelihood Methode geschätzt wurde. Außerdem wird unsere Modellgleichung nochmals wiederholt.</p>
<pre><code>## 
## REML criterion at convergence: 6565.3
## 
## Scaled residuals:
##     Min      1Q  Median      3Q     Max
## -4.5448 -0.5642 -0.0015  0.5695  3.5476</code></pre>
<p>gibt uns Informationen über die Konvergenz (sozusagen den Log-Likelihood-Wert), sowie Auskunft über die Verteilung de Residuen (ähnlich wie bei der Regression). Diese scheinen hier recht symmetrisch verteilt zu sein.</p>
<pre><code>## 
## Random effects:
##  Groups      Name        Variance Std.Dev.
##  schulklasse (Intercept)  23.87    4.885
##  Residual                123.12   11.096
## Number of obs: 850, groups:  schulklasse, 40</code></pre>
<p>zeigt uns die Schätzungen der <code>Random effect</code>, also der Varianzen (und Kovarianzen) von <span class="math inline">\(u\)</span> (dem zufälligen Anteil des Interzept und der Slope, falls vorhanden) sowie von <span class="math inline">\(\varepsilon\)</span> (dem Residuum). Eine Signifikanzentscheidung wird nicht mit ausgegeben. Wir müssen diese via einem Modellvergleich, dem Likelihood-Differenzen-Test (LRT) untersuchen - dazu später mehr! Wir erkennen, dass uns sowohl die Varianzen des Interzepts und des Residuums, sowie die Standardabweichung (<code>Std.Dev.</code>) ausgegeben werden, wobei dies einfach nur die Wurzel aus <code>Variance</code> ist. Die Varianz zwischen Klassen beträgt 23.868 und die (Residual-) Varianz innerhalb der Klassen 123.117. Mit Hilfe dieser Informationen können wir den Intraklassenkorrelationskoeffizienten bestimmen. Außerdem entnehmen wir diesem Output, dass insgesamt 850 Schulkinder untersucht wurden in 40 Klassen.</p>
<div id="berechnung-der-intraklassenkorrelation-icc" class="section level4">
<h4>Berechnung der Intraklassenkorrelation (ICC)</h4>
<p>Wir wollen uns noch schnell den ICC ansehen. Entweder machen wir dies per Hand und tippen die Varianzen aus dem Output ab, oder wir entlocken sie dem <code>m0</code> Objekt. Der ICC ergibt sich als
<span class="math display">\[ICC := \frac{\mathbb{V}ar[u_0]}{\mathbb{V}ar[u_0]+\mathbb{V}ar[\varepsilon]}.\]</span></p>
<pre class="r"><code># Per Hand
23.87 / (23.87 + 123.12)</code></pre>
<pre><code>## [1] 0.162392</code></pre>
<pre class="r"><code># Mit Zugriff auf das Nullmodell-Objekt
VarCorr(m0)$schulklasse[1] / (VarCorr(m0)$schulklasse[1] + summary(m0)$sigma^2)</code></pre>
<pre><code>## [1] 0.1623841</code></pre>
<p><em><strong>Achtung:</strong> Unterschiede kommen durch Runden zu stande - die Ergebnisse abgelesen aus dem Output sind nur auf 2 Nachkommastellen genau.</em></p>
<p>Die Funktion <code>VarCorr</code> gibt die Varianz, die Standardabweichung, sowie die Korrelationen zwischen mehreren Random Effekten (z.B. die Korrelation zwischen Interzept und Slope) aus. Wir müssen dann das Interzept via <code>$schulklasse[1]</code> auswählen, weil es der erste zufällige Effekt ist, der auf das Cluster zurückgeführt werden kann.</p>
<pre class="r"><code>VarCorr(m0) # nur die Standardabweichungen (also Wurzel aus den Varianzen) werden angezeigt</code></pre>
<pre><code>##  Groups      Name        Std.Dev.
##  schulklasse (Intercept)  4.8855 
##  Residual                11.0958</code></pre>
<pre class="r"><code>VarCorr(m0)$schulklasse # auch Varianzen werden angezeigt</code></pre>
<pre><code>##             (Intercept)
## (Intercept)    23.86806
## attr(,&quot;stddev&quot;)
## (Intercept) 
##    4.885495 
## attr(,&quot;correlation&quot;)
##             (Intercept)
## (Intercept)           1</code></pre>
<pre class="r"><code>VarCorr(m0)$schulklasse[1] # das erste Element ist die Varianz des Interzepts</code></pre>
<pre><code>## [1] 23.86806</code></pre>
<p>Dem Summary Objekt (also <code>summary(m0)</code>) können wir via <code>$sigma</code> die Standardabweichung der Residuen entlocken, welche quadriert die Varianz von <span class="math inline">\(\varepsilon\)</span> ist.</p>
<pre class="r"><code>summary(m0)$sigma # Residualstandardabweichung</code></pre>
<pre><code>## [1] 11.09581</code></pre>
<pre class="r"><code>summary(m0)$sigma^2 # Residualvarianz</code></pre>
<pre><code>## [1] 123.1171</code></pre>
<pre class="r"><code>names(summary(m0)) # alle Informationen, die wir der Summary entlocken können</code></pre>
<pre><code>##  [1] &quot;methTitle&quot;    &quot;objClass&quot;     &quot;devcomp&quot;      &quot;isLmer&quot;       &quot;useScale&quot;    
##  [6] &quot;logLik&quot;       &quot;family&quot;       &quot;link&quot;         &quot;ngrps&quot;        &quot;coefficients&quot;
## [11] &quot;sigma&quot;        &quot;vcov&quot;         &quot;varcor&quot;       &quot;AICtab&quot;       &quot;call&quot;        
## [16] &quot;residuals&quot;    &quot;fitMsgs&quot;      &quot;optinfo&quot;</code></pre>
<p><strong>Inhaltliche Interpretation</strong>: 16,2% der Varianz in der Mathematikleistung können durch die Klassenzugehörigkeit erklärt werden. Die Multi-Levelstruktur in den Daten muss somit unbedingt berücksichtigt werden.</p>
<p>Nun weiter im Output:</p>
<pre><code>## 
## Fixed effects:
##             Estimate Std. Error      df t value Pr(&gt;|t|)
## (Intercept)  54.0235     0.8658 37.0961    62.4   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>enthält die <code>Fixed effects</code> (also die <span class="math inline">\(\gamma\)</span>s aus den Gleichungen zuvor). Im Nullmodell gibt es nur <span class="math inline">\(\gamma_{00}\)</span>, das globale Interzept. Es liegt bei 54.0236, was bedeutet, dass die durchschnittliche Matheleistung über alle Schulklassen und -kinder hinweig bei ca 54 liegt. Das Interzept ist zudem signifikant von 0 verschieden: <span class="math inline">\(t\)</span>-Wert = 62.4 mit <span class="math inline">\(p &lt; .001\)</span> (<code>&lt;2e-16</code> = <span class="math inline">\(&lt;2*10^{-16}\)</span>). Somit können wir mit einer Irrtumswahrscheinlichkeit von 5% davon ausgehen, dass die durchschnittliche Matheleistung von Null abweicht. Diese Information ist hier nicht spannend, da die Matheleistung gerade von 0 bis 100 geht und somit ein Mittelwert von 0 sehr unwahrscheinlich erscheint.</p>
<p>Nun wollen wir prüfen, ob sich die Matheleistung durch die Motivation zu Lernen vorhesagen lässt.</p>
</div>
</div>
</div>
<div id="hypothese-1-motivation-als-prädiktor" class="section level2">
<h2>Hypothese 1: Motivation als Prädiktor</h2>
<p>Bevor wir den Effekt der Motivation auf die Matheleistung untersuchen, zentrieren wir die Lernmotivation am Stichprobenmittelwert und nennen die Variable <code>$Motivation_c</code> (durch das Dollarzeichen wird sie dem Datensatz angehängt):</p>
<pre class="r"><code>StudentsInClasses$Motivation_c &lt;- StudentsInClasses$Motivation - mean(StudentsInClasses$Motivation)
round(colMeans(StudentsInClasses), 10) # Spaltenmittelwerte gerundet auf 10 Nachkommastellen</code></pre>
<pre><code>##       MatheL   Motivation          KFT     KlassenG  schulklasse Motivation_c 
##    53.616047     4.285882   100.001176    27.090588    20.280000     0.000000</code></pre>
<p>Den Spaltenmittelwerten entnehmen wir, dass <code>Motivation_c</code> nun einen Mittelwert von 0 hat (gerundet mit <code>round</code> auf 10 Nachkommastellen). Nun nehmen wir diese Variable in das Multi-Level-Modell mit auf. Das Modell nennen wir entsprechend der 1. Hypothese <code>m1</code>.</p>
<pre class="r"><code>m1 &lt;- lmer(MatheL ~ 1 + Motivation_c + (1 | schulklasse), data = StudentsInClasses)
summary(m1)</code></pre>
<pre><code>## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [
## lmerModLmerTest]
## Formula: MatheL ~ 1 + Motivation_c + (1 | schulklasse)
##    Data: StudentsInClasses
## 
## REML criterion at convergence: 6231.1
## 
## Scaled residuals: 
##     Min      1Q  Median      3Q     Max 
## -3.9343 -0.5597  0.0146  0.6001  4.7018 
## 
## Random effects:
##  Groups      Name        Variance Std.Dev.
##  schulklasse (Intercept) 26.57    5.154   
##  Residual                81.46    9.026   
## Number of obs: 850, groups:  schulklasse, 40
## 
## Fixed effects:
##              Estimate Std. Error       df t value Pr(&gt;|t|)    
## (Intercept)   54.0708     0.8751  37.7353   61.79   &lt;2e-16 ***
## Motivation_c   6.0879     0.2991 808.6683   20.35   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Correlation of Fixed Effects:
##             (Intr)
## Motivatin_c 0.000</code></pre>
<p>Im Output hat sich nun der Abschnitt <code>Fixed effects</code> erweitert um den Effekt der Motivation. Das Regressionsgewicht für (die am Stichprobenmittelwert zentrierte) Motivation beträgt 6.088 und ist mit <em>p</em> &lt; .001 signifikant. Somit wird die Nullhypothese verworfen: “Mit einer Irrtumswahrscheinlichkeit von 5% ist der Zusammenhang (Steigungskoeffizient, <span class="math inline">\(\gamma_{10}\)</span>) zwischen Motivation und Mathematikleistung in der Population aller Schüler von Null verschieden.” Durch die Zentrierung können wir weiterhin das Interzept (<span class="math inline">\(\gamma_{00}\)</span>) sinnvoll interpretieren. Ein durchschnittlich motiviertes Kind hat im Mittel eine Matheleistung von 54.071.</p>
<p>Insgesamt ist zu sagen, dass unsere Hypothese 1 durch die Daten gestützt wird. Es stellt sich allerdings die Frage, ob die signifikante lineare Beziehung der Variable auch inhaltlich bedeutsam ist. Um dies besser beurteilen zu können, wollen wir ein Pseudo-<span class="math inline">\(R^2\)</span> bestimmen - es ist sehr dem Determinationskoeffizieten der Regression verwandt, kann aber Fehlschätzungen unterliegen, weswegen es nicht für bare Münze genommen werden sollte. Es kann uns allerdings helfen, besser einschätzen zu können, wie groß denn die Varianzaufklärung des Prädiktors ist, auch wenn wir im Hinterkopf behalten sollten, dass mit Pseudo-<span class="math inline">\(R^2\)</span> auch Probleme auftreten können (die es in der Regel mit dem Determinationskoeffizienten nicht gibt). Für mehr Informationen hierzu schaue bspw. in <a href="">Eid, et al. (2017)</a> Kaptiel 20.3.4 ab Seite 750.</p>
<div id="pseudo-r2-within" class="section level3">
<h3>Pseudo <span class="math inline">\(R^2\)</span>: within</h3>
<p>Die Varianz unseres Kriteriums <span class="math inline">\(Y\)</span> haben wir im Null-Modell in Varianz des Cluster (Interzeptvarianz) und (within) Residualvarianz aufgeteilt: <span class="math inline">\(\mathbb{V}ar[Y] = \mathbb{V}ar[u_0]+\mathbb{V}ar[\varepsilon]\)</span>. Die Variation von <span class="math inline">\(u_0\)</span> beschreibt somit die between-Variation, die auf Unterschiede zwischen Klassen (und somit Unterschiede, die auf die Clusterung zurückzuführen sind), während die Variation von <span class="math inline">\(\varepsilon\)</span> gerade die within-Variation ist. Unter ideellen Bedingungen sollte nun ein L1-Prädiktor nur die within-Residualvariation verringern (dies ist dann gegeben, wenn ein L1 Prädiktor sich nicht systematisch zwischen Klassen unterscheidet, es also keine Mittelwertsunterschiede über Klassenhinweg auf dieser L1 Variable gibt!): für den Prädiktor Motivation (<span class="math inline">\(X_1\)</span>) ergibt sich die Variation von <span class="math inline">\(Y\)</span> als <span class="math display">\[\mathbb{V}ar[Y] = \mathbb{V}ar[u_0]+\underbrace{\gamma_{10}^2\mathbb{V}ar[X_1]+\mathbb{V}ar[\varepsilon^*]}_{\mathbb{V}ar[\varepsilon]}.\]</span> Für mehr Informationen zu Varianzrechenregeln siehe im <a href="#AppendixB">Appendix B</a> nach. Wir schreiben hier <span class="math inline">\(\varepsilon^*\)</span>, da es sich um ein anderes Residuum handelt, als im leeren Modell (<span class="math inline">\(X_1\)</span> ist ja mit von der Partie). Dieser ideellen Gleichung ist zu entnehmen, dass die Varianz von <span class="math inline">\(\varepsilon^*\)</span> kleiner ausfällt, also die von <span class="math inline">\(\varepsilon\)</span>, wenn <span class="math inline">\(\gamma_{10}\neq 0\)</span> und <span class="math inline">\(X_1\)</span> nicht konstant ist, also wenn <span class="math inline">\(X_1\)</span> zur Vorhersage vom Kriterium beiträgt (also folgt <span class="math inline">\(\mathbb{V}ar[\varepsilon^*]&lt;\mathbb{V}ar[\varepsilon]\)</span>). Wir machen uns diese Gegebenheit zu nutze und quantifizieren die relative Veränderung in der Varianz des Residuums und nennen diese Pseudo-<span class="math inline">\(R^2\)</span>:
<span class="math display">\[R^2_\text{pseudo:within}=\frac{\mathbb{V}ar[\varepsilon]-\mathbb{V}ar[\varepsilon^*]}{\mathbb{V}ar[\varepsilon]}=1-\frac{\mathbb{V}ar[\varepsilon^*]}{\mathbb{V}ar[\varepsilon]}.\]</span></p>
<p>In der Realität ist es so, dass Prädiktoren je nach Zentrierung auch within und between Variation von <span class="math inline">\(Y\)</span> erklären, da der Mittelwert eines Clusters between-Information enthält und die Abweichungen von diesem Mittelwert within-Informationen. Somit ist es so, dass ein nichtzentrierter Prädiktor sowohl within als auch between Variation am Kriterium erklärt. HInzu kommt dann noch die Schätzungenauigkeit.</p>
<p>Um Pseudo-<span class="math inline">\(R^2\)</span> in <code>R</code> umzusetzen, müssen wir lediglich die Residualvarianzen der beiden Modelle abgreifen und verrechnen:</p>
<pre class="r"><code>VarE0 &lt;- summary(m0)$sigma^2 # Varianz des Residuums im Nullmodell
VarE1 &lt;- summary(m1)$sigma^2 # Varianz des Residuums im Modell mit Motivation als Prädiktor

1- VarE1/VarE0</code></pre>
<pre><code>## [1] 0.3383368</code></pre>
<pre class="r"><code># oder kurz:
1 - summary(m1)$sigma^2/summary(m0)$sigma^2</code></pre>
<pre><code>## [1] 0.3383368</code></pre>
<p>Insgesamt können also 33.83% der Variation der Matheleistung innerhalb einer Klasse erklärt werden. Die Motivation scheint substantielle Anteile zu erklären. Die Residualvarianz im Modell mit der Motivation als Prädiktor ist um 33% geringer als im Nullmodell.</p>
</div>
<div id="pseudo-r2-between" class="section level3">
<h3>Pseudo <span class="math inline">\(R^2\)</span>: between</h3>
<p>Genauso wie wir soeben die relative Veränderung der (within) Residualvarianz quantifiziert haben, können wir auch die relative Veränderung der Interzeptvariation (between Variation, Variation, die auf Unterschiede des Clusters/zwischen Klassen zurückzuführen sind) bestimmen. Da wir die Motivation am Gruppenmittelwert zentriert haben, sind einige Unterschiede zwischen den Klassen immernoch in der Variable <code>Motivation_c</code> enthalten (dazu später mehr im Abschnitt zur <a href="#Datenzentrierung">Datenzentrierung</a>). Diesen Varianzanteil wollen wir nun quantifizieren und vergleichen dazu die beiden Modelle <code>m0</code> und <code>m1</code>:
<span class="math display">\[\begin{align}
\texttt{m0}:&amp;\quad \mathbb{V}ar[Y] = \mathbb{V}ar[u_0]+\mathbb{V}ar[\varepsilon]\\
\texttt{m1}:&amp;\quad \mathbb{V}ar[Y] = \mathbb{V}ar[u_0^*]+\gamma_{10}^2\mathbb{V}ar[X_1]+\mathbb{V}ar[\varepsilon^*]
\end{align}\]</span>
Falls der Prädiktor der Motivation (grand-mean zentriert) auch noch Unterschiede zwischen den Klassen enthält, dann sollten gelten: <span class="math inline">\(\mathbb{V}ar[u_0^*]&lt;\mathbb{V}ar[u_0]\)</span>; also sollte die Interzeptvariation von <code>m0</code> zu <code>m1</code> kleiner werden. Analog zum Pseudo-<span class="math inline">\(R^2\)</span> zuvor wird Pseudo-<span class="math inline">\(R^2\)</span> für die between Ebene (L2) definiert:
<span class="math display">\[R^2_\text{pseudo:between}=\frac{\mathbb{V}ar[u_0]-\mathbb{V}ar[u_0^*]}{\mathbb{V}ar[u_0]}=1-\frac{\mathbb{V}ar[u_0^*]}{\mathbb{V}ar[u_0]}.\]</span>
Wie wir die Interzeptvarianz erhalten, hatten wir uns schon angesehen, als es um den ICC ging. Folglich berechnen wir <span class="math inline">\(R^2_\text{pseudo:between}\)</span> so:</p>
<pre class="r"><code>VarU0 &lt;- VarCorr(m0)$schulklasse[1]  # Varianz des Interzepts im Nullmodell
VarU1 &lt;- VarCorr(m1)$schulklasse[1]  # Varianz des Interzepts im Modell mit Motivation als Prädiktor

1- VarU1/VarU0</code></pre>
<pre><code>## [1] -0.1130776</code></pre>
<pre class="r"><code># oder kurz:
1 - VarCorr(m1)$schulklasse[1]/VarCorr(m0)$schulklasse[1]</code></pre>
<pre><code>## [1] -0.1130776</code></pre>
<p>Am Ergebnis erkennen wir auch, wieso es sich hierbei nur um ein Pseudo-<span class="math inline">\(R^2\)</span> handelt, denn die Varianz des Interzepts steigt tatsächlich von <code>m0</code> zu <code>m1</code>. Dies kann auf die simultane Schätzung der beiden Varianzen mit Hilfe von (restricted) Maximum Likelihood zurückgeführt werden, welche nicht nur von den Varianzen der Mittelwerte abhängt, sondern auch vom Stichprobenfehler (vgl. Eid, et al., 2017, S. 752). In so einem Fall wird Pseudo-<span class="math inline">\(R^2\)</span> auf 0 gesetzt. Folglich gehen wir davon aus, dass der erklärte between Varianzanteil der Matheleistung durch die Motivation 0 ist. Diesem Problem kann durch die zusätzliche Gewichtung der Varianzen durch die Anzahl der Level 1 und Level 2 Einheiten entgegegengewirkt werden, was Sie vielleicht beim Schreiben Ihrer Masterarbeit dann durchführen könnten (vgl. Eid, et al., 2017, S. 752 und folgend).</p>
</div>
<div id="pseudo-r2-between-and-within" class="section level3">
<h3>Pseudo <span class="math inline">\(R^2\)</span>: between and within</h3>
<p>Zum Schluss bestimmen wir nun noch den Anteil der Variation des Kriteriums der insgesamt (between und within) durch den Prädiktor erklärt werden kann. Dazu schauen wir uns die gemeinsame Veränderung der Varianzen auf Level 1 (within) und Level 2 (between) an. Erklärt der Prädiktor substantielle Anteile, so sollte gelten: <span class="math inline">\(\mathbb{V}ar[u_0^*]+\mathbb{V}ar[\varepsilon^*]&lt;\mathbb{V}ar[u_0]+\mathbb{V}ar[\varepsilon]\)</span>; also sollte die gesamte nichterklärte Varianz vom Kriterium von <code>m0</code> zu <code>m1</code> kleiner werden! Die relative Veränderung quantifizieren wir mit Hilfe von Pseudo-<span class="math inline">\(R^2\)</span> für between und within:
<span class="math display">\[\begin{align*}
R^2_\text{pseudo:bw}&amp;=\frac{(\mathbb{V}ar[u_0]+\mathbb{V}ar[\varepsilon])-(\mathbb{V}ar[u_0^*]+\mathbb{V}ar[\varepsilon^*])}{\mathbb{V}ar[u_0]+\mathbb{V}ar[\varepsilon]}\\
&amp;=1-\frac{\mathbb{V}ar[u_0^*]+\mathbb{V}ar[\varepsilon^*]}{\mathbb{V}ar[u_0]+\mathbb{V}ar[\varepsilon]}.
\end{align*}\]</span>
Folglich berechnen wir <span class="math inline">\(R^2_\text{pseudo:bw}\)</span> so:</p>
<pre class="r"><code>VarE0 &lt;- summary(m0)$sigma^2 # Varianz des Residuums im Nullmodell
VarE1 &lt;- summary(m1)$sigma^2 # Varianz des Residuums im Modell mit Motivation als Prädiktor

VarU0 &lt;- VarCorr(m0)$schulklasse[1]  # Varianz des Interzepts im Nullmodell
VarU1 &lt;- VarCorr(m1)$schulklasse[1]  # Varianz des Interzepts im Modell mit Motivation als Prädiktor

1- (VarU1 + VarE1)/(VarU0 + VarE0)</code></pre>
<pre><code>## [1] 0.2650343</code></pre>
<pre class="r"><code># oder kurz:
1 - (VarCorr(m1)$schulklasse[1] + summary(m1)$sigma^2)/(VarCorr(m0)$schulklasse[1] + summary(m0)$sigma^2)</code></pre>
<pre><code>## [1] 0.2650343</code></pre>
<p>Insgesamt lassen sich also 26.5% der Variation der Matheleistung durch die Motivation erklären. Hierbei ist zu beachten, dass <span class="math inline">\(R^2_\text{pseudo:bw}\)</span> nicht einfach der Mittelwert von <span class="math inline">\(R^2_\text{pseudo:between}\)</span> und <span class="math inline">\(R^2_\text{pseudo:within}\)</span> ist, sondern tatsächlich das gewichtete Mittel der beiden, wobei die Varianzen die Gewichte darstellen, denn ist die Residualvarianz sehr groß, dann fällt diese auch insgesamt bei der Gesamtvarianz vom Kriterium stärker ins Gewicht! Lassen wir zusätzlich unterschiedliche Steigungen zu (Random Slope), so müssen wir auch diese Varianzquelle in die Berechnung mit einbeziehen.</p>
</div>
</div>
<div id="hypothese-2-modell-mit-zufälligem-motivations-effekt" class="section level2">
<h2>Hypothese 2: Modell mit zufälligem Motivations-Effekt</h2>
<p>Um Unterschiede in der Beziehung zwischen Matheleistung und Motivation über die Klassen hinweg zu untersuchen, erweitern wir unser Modell um eine Random Slope. So lassen wir zu, dass die Beziehung zwischen der Motivation und der Matheleistung über die Klassen hinweg variiert (<span class="math inline">\(\beta_{1j}=\gamma_{10} + u_{1j}\)</span>).</p>
<pre class="r"><code>m2 &lt;- lmer(MatheL ~ 1 + Motivation_c + (1 + Motivation_c | schulklasse), data = StudentsInClasses)
summary(m2)</code></pre>
<pre><code>## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [
## lmerModLmerTest]
## Formula: MatheL ~ 1 + Motivation_c + (1 + Motivation_c | schulklasse)
##    Data: StudentsInClasses
## 
## REML criterion at convergence: 5769.6
## 
## Scaled residuals: 
##     Min      1Q  Median      3Q     Max 
## -3.2170 -0.6311  0.0160  0.6304  2.8758 
## 
## Random effects:
##  Groups      Name         Variance Std.Dev. Corr
##  schulklasse (Intercept)  29.38    5.420        
##              Motivation_c 37.73    6.143    0.31
##  Residual                 39.85    6.313        
## Number of obs: 850, groups:  schulklasse, 40
## 
## Fixed effects:
##              Estimate Std. Error      df t value Pr(&gt;|t|)    
## (Intercept)   54.0572     0.8858 38.3681  61.025  &lt; 2e-16 ***
## Motivation_c   5.8938     0.9960 39.0897   5.918 6.69e-07 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Correlation of Fixed Effects:
##             (Intr)
## Motivatin_c 0.291</code></pre>
<p>Diesmal wird der Abschnitt <code>Random effects</code> erweitert um die Varianz des Effekts der (zentrierten) Motivation sowie die Korrelation zwischen der Motivation und dem Interzept. Die Korrelation (zwischen <span class="math inline">\(u_{0j}\)</span> und <span class="math inline">\(u_{1j}\)</span>, also zwischen der Variation des Interzepts und der Slope) ist .31 und damit substanziell.</p>
<p><strong>Interpretation</strong>: Der Motivationseffekt hat eine Varianz von 37.73 zwischen Klassen. Außerdem fällt auf, dass sich die Residualvarianz drastisch reduziert hat (von 81.46 in <code>m1</code> zu 39.85 in <code>m2</code>). Allerdings können wir noch keine Aussage über die Signifikanz dieses Unterschieds treffen.</p>
<div id="test-des-zufallseffekts" class="section level3">
<h3>Test des Zufallseffekts</h3>
<p>Um zu Testen, ob die Varianz des Motivationseffekts sigifikant wird, wird das Modell <code>m1</code> ohne <em>random slope</em> mit dem Modell <code>m2</code> mit <em>random slope</em> verglichen. Dies machen wir mit Hilfe der <code>anova</code> Funktion, welche in <code>R</code> dazu genutzt wird, um Modelle zu vergleichen. Ihr müssen wir zunächst das restriktivere Modell (mit weniger <span class="math inline">\(df\)</span>) übergeben und als 2. Argument das weniger restriktive Modell. Außerdem wählen wir explizit die Methode, mit welcher die Modelle verglichen werden sollen via <code>test = "LRT"</code>. Somit verwenden wir den Likelihood-Ratio-Test:</p>
<pre class="r"><code>anova(m1, m2, test = &quot;LRT&quot;)</code></pre>
<pre><code>## refitting model(s) with ML (instead of REML)</code></pre>
<pre><code>## Data: StudentsInClasses
## Models:
## m1: MatheL ~ 1 + Motivation_c + (1 | schulklasse)
## m2: MatheL ~ 1 + Motivation_c + (1 + Motivation_c | schulklasse)
##    npar    AIC    BIC  logLik deviance  Chisq Df Pr(&gt;Chisq)    
## m1    4 6240.1 6259.1 -3116.1   6232.1                         
## m2    6 5784.9 5813.4 -2886.5   5772.9 459.18  2  &lt; 2.2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>Der Modellvergleichsoutput enthält folgende Informationen (dieser ist annähernd identisch aufgebaut und enthält jeweils unterschiedliche Teststatistiken, je nach dem welchen Test wir anfordern - bspw. bei der Regression würde Omnibustest/F-Test verwendet werden, entsprechend stünde dort die <span class="math inline">\(F\)</span>-Statistik).
Zunächst erhalten wir die Warnung, dass das Modell erneut mit ML geschätzt werden muss, damit eine Likelihood-Differenz einfach bestimmt werden kann (<code>refitting model(s) with ML (instead of REML)</code>).</p>
<pre><code>## Data: StudentsInClasses
## Models:
## m1: MatheL ~ 1 + Motivation_c + (1 | schulklasse)
## m2: MatheL ~ 1 + Motivation_c + (1 + Motivation_c | schulklasse)</code></pre>
<p>gibt uns an, welche Daten verwendet werden und welche Modelle verglichen werden. Hier sollte das komplexere Modell an 2. Stelle stehen, da sonst die Likelihood-Differenz negativ sein könnte.</p>
<pre><code>##    npar    AIC    BIC  logLik deviance  Chisq Df Pr(&gt;Chisq)
## m1    4 6240.1 6259.1 -3116.1   6232.1
## m2    6 5784.9 5813.4 -2886.5   5772.9 459.18  2  &lt; 2.2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>gibt uns Kennwerte zum Modellvergleich an. Ganz vorne stehen die Namen der Modelle (der Objekte), die verglichen werden. <code>npar</code> gibt die zu schätzenden Parameter an. Für das Modell <code>m1</code> ist dies <span class="math inline">\(\gamma_{00},\gamma_{10}\)</span> (fixed) und <span class="math inline">\(\mathbb{V}ar[u_0],\mathbb{V}ar[\varepsilon]\)</span> (random), während für <code>m2</code> <span class="math inline">\(\gamma_{00},\gamma_{10}\)</span> (fixed) und <span class="math inline">\(\mathbb{V}ar[u_0], \mathbb{V}ar[u_1], \mathbb{C}ov[u_0,u_1],\mathbb{V}ar[\varepsilon]\)</span> (random) geschätzt werden müssen. Es kommen also die Varianz von <span class="math inline">\(u_1\)</span> sowie die Kovarianz zwischen <span class="math inline">\(u_0\)</span> und <span class="math inline">\(u_1\)</span> hinzu. Der <code>AIC</code> (Akaike’s Information Criterion) sowie der <code>BIC</code> (Bayes’ Information Criterion) sind Informationskriterien, die die Komplexität des Modells sowie die Stichprobengröße mit einbeziehen. Kleinere Werte stehen für besseren Modell-Fit. Allerdings kann keine Aussage über die Signifikanz einer möglichen Differenzen in diesen getroffen werden. <code>logLik</code> gibt die Loglikelihood der Modelle an. Größere Werte sind wünschenswert. <code>deviance</code> ist hier einfach <span class="math inline">\(-2*\)</span><code>logLik</code> und entspricht quasi der Abweichung der Daten vom Modell (kleine Werte sind zu bevorzugen). <code>Chisq</code> ist die Likelihood-Differenz <span class="math inline">\(\chi^2_{emp}=-2(LL_{m_1}-LL_{m_2})=D_{m_1}-D_{m_2}\)</span>, die sich entwender über -2 mal der Log-likelihood (<span class="math inline">\(LL\)</span>) Differenz bestimmen lässt oder via der Differenz der Devianzen (<span class="math inline">\(D\)</span>). <code>Df</code> gibt die Freiheitsgerade der Likelihood-Differenz an. Dies ist hier gerade die Differenz der Anzahl der Parameter der beiden Modelle (siehe <code>npar</code>). <code>Pr(&gt;Chisq)</code> ist der zugehörige <span class="math inline">\(p\)</span>-Wert.</p>
<p><strong>Interpretation</strong>: Modell <code>m1</code> passt signifikant schlechter zu den Daten, <span class="math inline">\(\chi^2(2)=459.18; p&lt;.001\)</span>, also ist die Varianz des Effekts sigifikant von null verschieden. Wir entscheiden uns somit für ein Modell inklusive <em>Random Slope</em> für die Motivation! Hypothese 2 wird somit durch die Daten gestützt. Dies bedeutet, dass sich die Beziehung zwischen Motivation und Matheleistung über die Klassenhinweg unterscheidet (in manchen Klassen hängt die Matheleistung somit stärker von der Lernmotivation eines Kindes ab als in anderen Schulklassen).</p>
<div id="grafische-veranschaulichung-des-zufallseffekts" class="section level4">
<h4>Grafische Veranschaulichung des Zufallseffekts</h4>
<p>Diese Heterogenität lässt sich über ein Streudiagramm der klassenspezifischen Koeffizienten <span class="math inline">\(\beta_{1j}\)</span> veranschaulichen. Den Code zu den hier aufgeführten Grafiken können Interessierte in <a href="#AppendixA">Appendix A</a> einsehen.</p>
<p><img src="/post/2020-10-12-MSc1_Sitzung2_Multi-Level-Modeling_files/figure-html/unnamed-chunk-22-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>Dem Histogramm ist deutlich zu entnehmen, dass die Steigungskoeffizienten annähernd normalverteilt sind (dies ist eine wichtige Annahme, die in die Modellierung einfließt). Außerdem können wir die Heterogenität der Steigungskoeffizienten erkennen.</p>
<p>Eine alternative Visualisierung ist der Plot der klassenspezifischen Regresssionsgeraden, wobei <span class="math inline">\(\beta_{0j}\)</span> und <span class="math inline">\(\beta_{1j}\)</span> klassenspezifisch variieren. Die blaue Linie stellt hierbei den durchschnittliche (fixed) Effekt dar, welcher auch als Formel nochmals in die Grafik geschrieben wurde. Auch entnehmen wir der Grafik, dass die Motivation kategoriell ist (vertikale Ansammlung der Punkte).</p>
<p><img src="/post/2020-10-12-MSc1_Sitzung2_Multi-Level-Modeling_files/figure-html/unnamed-chunk-23-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>Außerdem können wir diesem Plot die Korrelation des Interzepts und der Steigung entnehmen, welche bei .31 lag. Hierbei müssen wir genau aufpassen, wo wir diese Korrelation ablesen. Die Aussage ist nämlich, dass je größer der Interzept, desto stärker der Zusammenhang zwischen Motivation und Matheleistung. Dies müssen wir entlang der y-Achse (vertikale gestrichelte Linie) untersuchen - an der Stelle, wo die Motivation durchschnittlich ausgeprägt ist und die zentrierte Variable somit den Wert 0 annimmt. Wenn wir genau hinsehen, ist es so, dass je größer der Schnittpunkt mit der y-Achse, desto größer die Steigung!</p>
</div>
</div>
</div>
<div id="hypothese-3-klassengröße-als-prädiktor" class="section level2">
<h2>Hypothese 3: Klassengröße als Prädiktor</h2>
<p>Nun nehmen wir die Klassengröße mit in das Modell auf. <em>Um das Modell nicht zu komplex zu machen, lassen wir im Folgenden die Random Slope wieder weg.</em></p>
<p>Bspw. könnte angenommen werden, dass in größeren Klassen die Lehrkraft weniger Zeit pro Schüler/in aufwenden kann und somit es systematische Unterschiede zwischen Klassen mit großer und kleiner Klassengröße gibt (Hypothese 3), bzw. es mehr auf die jeweilige Motivation des Individuums ankommt (Hypothese 4). Die Klassengröße wird als fester Effekt (für eine Ebene-2-Variable ist ein Zufallseffekt auch gar nicht möglich) zusätzlich im Modell aufgenommen - mit einer L2 Variable erhofft man sich Unterschiede zwischen Clustereinheiten (hier Klassen) zu erklären (also die Interzeptvariation zu reduzieren):</p>
<pre class="r"><code>m3 &lt;- lmer(MatheL ~ 1 + KlassenG + Motivation_c  + (1 | schulklasse), data=StudentsInClasses)
summary(m3)</code></pre>
<pre><code>## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [
## lmerModLmerTest]
## Formula: MatheL ~ 1 + KlassenG + Motivation_c + (1 | schulklasse)
##    Data: StudentsInClasses
## 
## REML criterion at convergence: 6230.7
## 
## Scaled residuals: 
##     Min      1Q  Median      3Q     Max 
## -3.9364 -0.5567  0.0190  0.6018  4.6944 
## 
## Random effects:
##  Groups      Name        Variance Std.Dev.
##  schulklasse (Intercept) 25.38    5.038   
##  Residual                81.45    9.025   
## Number of obs: 850, groups:  schulklasse, 40
## 
## Fixed effects:
##              Estimate Std. Error       df t value Pr(&gt;|t|)    
## (Intercept)   59.7531     3.5953  38.6351  16.620   &lt;2e-16 ***
## KlassenG      -0.2198     0.1350  37.5172  -1.628    0.112    
## Motivation_c   6.0893     0.2991 808.8593  20.358   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Correlation of Fixed Effects:
##             (Intr) KlssnG
## KlassenG    -0.971       
## Motivatin_c  0.003 -0.003</code></pre>
<p>Der Output wird erweitert um den Effekt der Klassengröße <span class="math inline">\(\gamma_{01}\)</span>. Außerdem wird uns noch die Korrelation zwischen den festen Effekte ausgegeben (zwischen <span class="math inline">\(\gamma_{00},\gamma_{11},\gamma_{01}\)</span>):</p>
<pre><code>## Correlation of Fixed Effects:
##             (Intr) KlssnG
## KlassenG    -0.971
## Motivatin_c  0.003 -0.003</code></pre>
<p>Diese Informationen sollten nicht inhaltlich interpretiert werden, sondern geben Auskunkft über die Schätzung der Parameter (wenn REML verwendet wird, wird in einem zweistufigen Verfahren zunächst die zufälligen Effekte geschätzt und dann werden die festen Effekte geschätzt und eine Signifikanzentscheidung ist für die festen Effekte möglich). Die Schätzung des Interzepts korreliert sehr hoch negativ mit der Schätzung des Koeffizienten der Klassengröße, was daran liegen kann, dass die Klassengröße keinerlei Vorhersagekraft liefert.</p>
<p><strong>Interpretation</strong>: Bei gleichzeitiger Berücksichtigung der Motivation ist der Effekt der Klassengröße nicht signifikant, bzw. über die Motivation hinaus ist der Effekt der Klassengröße nicht bedeutsam.</p>
<p>Nun wollen wir die Klassengröße noch als zentrierte Variable in das Modell aufnehmen. Wir definieren die am Stichprobenmittelwert zentrierte Klassengröße und fügen sie dem Datensatz folgendermaßen hinzu:</p>
<pre class="r"><code>StudentsInClasses$KlassenG_c &lt;- StudentsInClasses$KlassenG - mean(StudentsInClasses$KlassenG)

m3b &lt;- lmer(MatheL ~ 1 + KlassenG_c + Motivation_c + (1 | schulklasse), data=StudentsInClasses)
summary(m3b)</code></pre>
<pre><code>## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [
## lmerModLmerTest]
## Formula: MatheL ~ 1 + KlassenG_c + Motivation_c + (1 | schulklasse)
##    Data: StudentsInClasses
## 
## REML criterion at convergence: 6230.7
## 
## Scaled residuals: 
##     Min      1Q  Median      3Q     Max 
## -3.9364 -0.5567  0.0190  0.6018  4.6944 
## 
## Random effects:
##  Groups      Name        Variance Std.Dev.
##  schulklasse (Intercept) 25.38    5.038   
##  Residual                81.45    9.025   
## Number of obs: 850, groups:  schulklasse, 40
## 
## Fixed effects:
##              Estimate Std. Error       df t value Pr(&gt;|t|)    
## (Intercept)   53.7974     0.8739  36.0551  61.562   &lt;2e-16 ***
## KlassenG_c    -0.2198     0.1350  37.5172  -1.628    0.112    
## Motivation_c   6.0893     0.2991 808.8593  20.358   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Correlation of Fixed Effects:
##             (Intr) KlssG_
## KlassenG_c   0.190       
## Motivatin_c  0.000 -0.003</code></pre>
<p><strong>Interpretation</strong>: Die Zentrierung hat keinerlei Auswirkungen auf die Signifikanzentscheidung bzgl. der Klassengröße. Die Schätzung des durchschnittlichen Intercepts (<span class="math inline">\(\gamma_{00}\)</span>) ändert sich. Insgesamt findet Hypothese 3 keine Evidenz in den Daten. Da der Effekt nicht signifikant ist, schauen wir uns auch nicht die erklärte between-Variation an.</p>
</div>
<div id="hypothese-4-wechselwirkung-zwischen-klassengröße-und-motivation" class="section level2">
<h2>Hypothese 4: Wechselwirkung zwischen Klassengröße und Motivation</h2>
<p>Eine Wechselwirkung zwischen zwei Prädiktoren kann mit der Syntax <code>X1:X2</code> in das Modell aufgenommen werden: <code>Y ~ X1 + X2 + X1:X2</code>. Eine Kurzschreibweise hierfüre ist <code>Y ~ X1*X2</code>. Insbesondere für dieses Modell empfiehlt es sich, die Klassengröße zu zentrieren, da eine Klassengröße von null wenig sinnvoll ist und Wechelwirkungen von den Mittelwerten der Variablen abhängen (das haben wir im Abschnitt zuvor schon erledigt!). Wir ergänzen das Modell <code>m3b</code> um die Wechselwirkung zwischen (zentrierter) Klassengröße und (zentrierter) Motivation:</p>
<pre class="r"><code>m4 &lt;- lmer(MatheL ~ 1 + KlassenG_c + Motivation_c  + KlassenG_c:Motivation_c + (1 | schulklasse), data=StudentsInClasses)
summary(m4)</code></pre>
<pre><code>## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [
## lmerModLmerTest]
## Formula: MatheL ~ 1 + KlassenG_c + Motivation_c + KlassenG_c:Motivation_c +  
##     (1 | schulklasse)
##    Data: StudentsInClasses
## 
## REML criterion at convergence: 6200.9
## 
## Scaled residuals: 
##     Min      1Q  Median      3Q     Max 
## -4.0830 -0.5785  0.0163  0.6004  4.5850 
## 
## Random effects:
##  Groups      Name        Variance Std.Dev.
##  schulklasse (Intercept) 25.5     5.050   
##  Residual                78.2     8.843   
## Number of obs: 850, groups:  schulklasse, 40
## 
## Fixed effects:
##                          Estimate Std. Error        df t value Pr(&gt;|t|)    
## (Intercept)              53.79131    0.87354  36.11427  61.579  &lt; 2e-16 ***
## KlassenG_c               -0.21300    0.13491  37.53996  -1.579    0.123    
## Motivation_c              6.13299    0.29316 807.83209  20.920  &lt; 2e-16 ***
## KlassenG_c:Motivation_c   0.27575    0.04679 808.15014   5.893 5.56e-09 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Correlation of Fixed Effects:
##             (Intr) KlssG_ Mtvtn_
## KlassenG_c   0.191              
## Motivatin_c  0.000 -0.003       
## KlssnG_c:M_ -0.001  0.009  0.025</code></pre>
<p>Dieses Modell kommt zum selben Ergebnis wie:</p>
<pre class="r"><code>m4b &lt;- lmer(MatheL ~ 1 + KlassenG_c*Motivation_c + (1 | schulklasse), data=StudentsInClasses)
summary(m4b)</code></pre>
<pre><code>## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [
## lmerModLmerTest]
## Formula: MatheL ~ 1 + KlassenG_c * Motivation_c + (1 | schulklasse)
##    Data: StudentsInClasses
## 
## REML criterion at convergence: 6200.9
## 
## Scaled residuals: 
##     Min      1Q  Median      3Q     Max 
## -4.0830 -0.5785  0.0163  0.6004  4.5850 
## 
## Random effects:
##  Groups      Name        Variance Std.Dev.
##  schulklasse (Intercept) 25.5     5.050   
##  Residual                78.2     8.843   
## Number of obs: 850, groups:  schulklasse, 40
## 
## Fixed effects:
##                          Estimate Std. Error        df t value Pr(&gt;|t|)    
## (Intercept)              53.79131    0.87354  36.11427  61.579  &lt; 2e-16 ***
## KlassenG_c               -0.21300    0.13491  37.53996  -1.579    0.123    
## Motivation_c              6.13299    0.29316 807.83209  20.920  &lt; 2e-16 ***
## KlassenG_c:Motivation_c   0.27575    0.04679 808.15014   5.893 5.56e-09 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Correlation of Fixed Effects:
##             (Intr) KlssG_ Mtvtn_
## KlassenG_c   0.191              
## Motivatin_c  0.000 -0.003       
## KlssnG_c:M_ -0.001  0.009  0.025</code></pre>
<p><strong>Interpretation</strong>: Der Koeffizient des Wechselwirkungsterms (<span class="math inline">\(\gamma_{11}\)</span>) ist statistisch signifikant. Er beträgt 0.27575, d.h. mit jedem Kind mehr in der Klasse <em>steigt</em> der Motivationseffekt um ca. 0.28 Punkte. Hypothese 4 wird somit durch die Daten gestützt.</p>
<div id="grafische-veranschaulichung" class="section level4">
<h4>Grafische Veranschaulichung</h4>
<p>Die Wechselwirkung kann veranschaulicht werden, indem die Regressionsgeraden nach Klassengröße unterschieden werden (hier: über die Farbe). Die in der folgenden Grafik goldene/gelbe Geraden repräsentieren (überdurchschnittlich) große Klassen, die blauen kleine (unterdurchschnittlich große/ überdurchschnittlich kleine) Klassen. Die goldenen/gelben Linien sind steiler als die blauen Linien.</p>
<p><img src="/post/2020-10-12-MSc1_Sitzung2_Multi-Level-Modeling_files/figure-html/unnamed-chunk-29-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>Der Grafik ist dieser Effekt deutlich zu entnehmen. Final können wir sagen, dass die individuelle Matheleistung in Schulklassen mit mehr Schülerinnen und Schülern stärker von der Lernmotivation der/des Einzelnen abhängt als in kleinen Schulklassen.</p>
<p>Eigentlich würde eine Cross-Level-Interaktion vor allem dann in ein Modell aufgenommen werden, wenn wir die Random Slope Variation durch eine L2 Variable erklären wollen. Wenn wir ein Modell mit ebenfalls Random Intercept Random Slope untersuchen, erkennen wir allerdings, dass die Wechselwirkung und der Haupteffekt der Klassengröße nun keinen Effekt mehr haben:</p>
<pre class="r"><code>m4c &lt;- lmer(MatheL ~ 1 + KlassenG_c + Motivation_c  + KlassenG_c:Motivation_c + (1 + Motivation_c | schulklasse), data=StudentsInClasses)
summary(m4c)</code></pre>
<pre><code>## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [
## lmerModLmerTest]
## Formula: MatheL ~ 1 + KlassenG_c + Motivation_c + KlassenG_c:Motivation_c +  
##     (1 + Motivation_c | schulklasse)
##    Data: StudentsInClasses
## 
## REML criterion at convergence: 5767.3
## 
## Scaled residuals: 
##     Min      1Q  Median      3Q     Max 
## -3.2062 -0.6242  0.0259  0.6379  2.8811 
## 
## Random effects:
##  Groups      Name         Variance Std.Dev. Corr
##  schulklasse (Intercept)  28.26    5.316        
##              Motivation_c 36.74    6.062    0.39
##  Residual                 39.85    6.313        
## Number of obs: 850, groups:  schulklasse, 40
## 
## Fixed effects:
##                         Estimate Std. Error      df t value Pr(&gt;|t|)    
## (Intercept)              53.7744     0.8889 36.9895  60.495  &lt; 2e-16 ***
## KlassenG_c               -0.2158     0.1366 37.8116  -1.580    0.122    
## Motivation_c              6.1883     1.0062 37.6948   6.150 3.65e-07 ***
## KlassenG_c:Motivation_c   0.2148     0.1542 38.1319   1.394    0.171    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Correlation of Fixed Effects:
##             (Intr) KlssG_ Mtvtn_
## KlassenG_c  0.206               
## Motivatin_c 0.367  0.080        
## KlssnG_c:M_ 0.080  0.365  0.211</code></pre>
<pre class="r"><code>anova(m4, m4c, test = &quot;LRT&quot;)</code></pre>
<pre><code>## refitting model(s) with ML (instead of REML)</code></pre>
<pre><code>## Data: StudentsInClasses
## Models:
## m4: MatheL ~ 1 + KlassenG_c + Motivation_c + KlassenG_c:Motivation_c + 
## m4:     (1 | schulklasse)
## m4c: MatheL ~ 1 + KlassenG_c + Motivation_c + KlassenG_c:Motivation_c + 
## m4c:     (1 + Motivation_c | schulklasse)
##     npar    AIC    BIC  logLik deviance  Chisq Df Pr(&gt;Chisq)    
## m4     6 6207.3 6235.8 -3097.7   6195.3                         
## m4c    8 5782.2 5820.2 -2883.1   5766.2 429.14  2  &lt; 2.2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>Der Modellvergleich zeigt, dass ein Modell nur mit Klassengröße, Motivation und Interaktion von Klassengröße und Motivation signifikant schlechter zu den Daten passt als ein Modell mit zusätzlicher Random Slope. Final würden wir uns also für ein Modell mit Random Intercept und Random Slope entscheiden, allerdings die Klassengröße als Prädiktor (und Cross-Level Interaktion) herauslassen.</p>
</div>
</div>
<div id="Datenzentrierung" class="section level2">
<h2>Datenzentrierung</h2>
<p>Wir wollen uns noch kurz ansehen, wie denn anders zentriert werden hätte können. Dazu müssen wir uns kurz klar machen, was bei der Zentrierung passiert. Dazu sei <span class="math inline">\(X_{ij}\)</span> eine Variable der Person <span class="math inline">\(i\)</span> aus Cluster <span class="math inline">\(j\)</span>, die wir zentrieren wollen.</p>
<div id="grand-mean-centering" class="section level3">
<h3>Grand-Mean-Centering</h3>
<p>Beim Grand-Mean-Centering, also der Zentrierung am Stichprobenmittelwert, ziehen wir einfach den globalen Mittelwert der Variable über alle Erhebungen und Cluster ab (das haben wir oben ja schon gemacht!):
<span class="math display">\[X^*_{ij}=X_{ij}-\bar{X}_{\cdot\cdot}\]</span>
Ein Wert von 0 auf <span class="math inline">\(X_{ij}^*\)</span> bedeutet, dass diese Messung gerade genau dem Mittelwert der gesamten Stichprobe (über alle Personen <span class="math inline">\(i\)</span> und alle Clustereinheiten <span class="math inline">\(j\)</span>) entspricht.</p>
</div>
<div id="group-mean-centering" class="section level3">
<h3>Group-Mean-Centering</h3>
<p>Bei der gruppenspezifischen (auch clusterspezifischen) Zentrierung (Group-Mean-Centering), ziehen wir von jeder Messung <span class="math inline">\(X_{ij}\)</span> den Mittelwert des <span class="math inline">\(j\)</span> Clusters auf dieser Variable ab (also bspw. den Mittelwert der Matheleistung einer Klasse ziehen wir von den individuellen Matheleistungen aller Schüler dieser Klasse ab):</p>
<p><span class="math display">\[X_{ij}^{**}=X_{ij}-\bar{X}_{\cdot j}\]</span>
Ein Wert von 0 auf <span class="math inline">\(X_{ij}^{**}\)</span> entspricht nun dem Durchschnitt in Cluster/Gruppe <span class="math inline">\(j\)</span>. Die Variable <span class="math inline">\(X_{ij}^{**}\)</span> sollte somit within Variation erklären (im Beispiel also die Variation innerhalb einer Klasse), was dafür spricht, dass es sinnvoll ist, diese Varianzaufklärung mit <span class="math inline">\(R^2_\text{pseudo:within}\)</span> zu quantifizieren. Außerdem ist es sinnvoll anschließend die Variable <span class="math inline">\(\bar{X}_{\cdot j}\)</span> mit in die Analysen aufzunehmen, da sie between-Variation enthält (also Variation, die Unterschiede zwischen Clustern darstellt). Die Varianzaufklärung von <span class="math inline">\(\bar{X}_{\cdot j}\)</span> kann somit mit <span class="math inline">\(R^2_\text{pseudo:between}\)</span> quantifiziert werden. Die gemeinsame Varianzaufklärung (quasi den Gesamtanteil between und within) können wir mit <span class="math inline">\(R^2_\text{pseudo:bw}\)</span> quantifizieren.</p>
<p>Um diese Variablen anschließend auch noch sinnvoll hinsichtlich (z.B. Cross-Level-) Interaktionen interpretieren zu können, sollte die Gruppenmittelwertsvariable idealerweise auch noch am zentralen Mittelwert zentriert sein (der zentrale Mittelwert ist gerade auch der Mittelwert dieser Gruppenmittelwertsvariable):
<span class="math display">\[\bar{X}_{\cdot j}^*=\bar{X}_{\cdot j} - \bar{X}_{\cdot \cdot}\]</span>
Somit entspricht ein Wert von 0 auf dieser Variable gerade einer Erhebung, die dem durchschnittlichen Mittelwert über alle Cluster entspricht. Demnach können wir auch sinnvoll beide zentrierten Variablen auf einmal interpretieren. Wenn eine Person auf der Variable <span class="math inline">\(X_{ij}^{**}\)</span> und auf der Variable <span class="math inline">\(\bar{X}_{\cdot j}^*\)</span> einen Wert von Null aufweist, so bedeutet dies, dass die Ausprägung auf dieser Variable durchschnittlich im Bezug auf das Cluster ist und auch auf die Gesamtstichprobe (wir landen also wieder beim gesamten Durchschnitt über die Stichprobe, können aber Effekte nun im Bezug auf Unterschiede zwischen den einzelnen Gruppe und innerhalb der Gruppen auseinanderdröseln). Folgende Aussagen sind möglich: (Kinder aus) Schulkassen mit durchschnittlich höherer Motivation zeigen insgesamt im Durchschnitt eine höhere Matheleistung (<em>quasi:</em> wenn der Durchschnitt der Motivation höher liegt in einer Klasse, so liegt auch der Mittelwert der Matheleistung in dieser Klasse im Mittel höher) und Kinder, die im Vergleich zu ihrer Schulklasse motivierter sind, zeigen ebenfalls eine im Schnitt eine höhere Matheleistung als andere Kinder ihrer Schulklasse. Auch Interaktionen können weitere Einblicke in die Daten bringen. Natürlich könnten diese Effekte auch gegenläufig sein.</p>
</div>
<div id="umsetzung-in-r-group-mean-centering" class="section level3">
<h3>Umsetzung in <code>R</code>: Group-Mean-Centering</h3>
<p>In <code>R</code> sieht das Ganze so aus:</p>
<pre class="r"><code># group-mean-centering:
StudentsInClasses$Motivation_groupc &lt;- group.center(var = StudentsInClasses$Motivation, grp = StudentsInClasses$schulklasse)

# bestimmen der gruppenspezifischen Mittelwerte (durch Umstellen der Gleichung)
StudentsInClasses$Mot_groupmeans &lt;- StudentsInClasses$Motivation - StudentsInClasses$Motivation_groupc

# Zentrieren der Gruppenmittelwertsvariable
StudentsInClasses$Mot_groupmeans_c &lt;- StudentsInClasses$Mot_groupmeans - mean(StudentsInClasses$Motivation)

head(StudentsInClasses)</code></pre>
<pre><code>##   MatheL Motivation KFT KlassenG schulklasse Motivation_c KlassenG_c
## 1  48.76          4  98       26           1   -0.2858824  -1.090588
## 2  46.01          3  96       26           1   -1.2858824  -1.090588
## 3  65.96          5 112       26           1    0.7141176  -1.090588
## 4  42.08          4  94       26           1   -0.2858824  -1.090588
## 5   0.00          2  78       26           1   -2.2858824  -1.090588
## 6  56.52          5 104       26           1    0.7141176  -1.090588
##   Motivation_groupc Mot_groupmeans Mot_groupmeans_c
## 1             -0.36           4.36       0.07411765
## 2             -1.36           4.36       0.07411765
## 3              0.64           4.36       0.07411765
## 4             -0.36           4.36       0.07411765
## 5             -2.36           4.36       0.07411765
## 6              0.64           4.36       0.07411765</code></pre>
<pre class="r"><code># (Spalten-)Mittelwerte (gerundet auf 10 Nachkommastellen)
round(colMeans(StudentsInClasses), 10)</code></pre>
<pre><code>##            MatheL        Motivation               KFT          KlassenG 
##         53.616047          4.285882        100.001176         27.090588 
##       schulklasse      Motivation_c        KlassenG_c Motivation_groupc 
##         20.280000          0.000000          0.000000          0.000000 
##    Mot_groupmeans  Mot_groupmeans_c 
##          4.285882          0.000000</code></pre>
<p>Die Funktion <code>group.center</code> aus dem <code>robumeta</code>-Paket nimmt uns die Arbeit ab, die Daten händisch an den Gruppenmittelwerten zu zentrieren (<span class="math inline">\(X_{ij}^{**}\)</span>). Sie nimmt 2 Argumente entgegen: <code>var</code> die Variable, die zentriert werden soll (hier die Motivation), und <code>grp</code> die Gruppierungsvariable (hier die Schulklasse). Wir erhalten die Gruppenmittelwerte durch Umstellen der Gleichung: Aus <span class="math inline">\(X_{ij}^{**}=X_{ij}-\bar{X}_{\cdot j}\)</span> folgt, dass auch <span class="math inline">\(\bar{X}_{\cdot j}=X_{ij}-X_{ij}^{**}\)</span> gilt. Zum Schluss wird noch die Gruppierungsvariable zentriert am Gesamtmittelwert: <span class="math inline">\(\bar{X}_{\cdot j}^*=\bar{X}_{\cdot j} - \bar{X}_{\cdot \cdot}\)</span>. Den Spaltenmittelwerten entnehmen wir, dass die gruppenzentrierte Variable einen Mittelwert von 0 hat und die zentrierte Gruppenmittelwertsvariable ebenfalls. Außerdem sehen wir hier nochmals, dass der Mittelwert der Motivation gleich dem Mittelwert der Gruppenmittelwertsmotivation ist (<code>Motivation</code> vs. <code>Mot_groupmeans</code>).</p>
<p>Diese Art der Zentrierung spielt insbesondere in Multi-Level-Analyse mit Messwiederholung von Personen (die Person ist die Clusterung und die L1 Varibale sind die Messungen einer Person) eine wichtige Rolle (siehe auch
<a href="https://hds.hebis.de/ubffm/Record/HEB366849158">Eid, et al., 2017,</a> Kapitel 20.4).</p>
<p>In <a href="#AppendixC">Appendix C</a> wird eine Funktion präsentiert, mit welcher wir uns leicht Effekte in Multi-Level-Modellen ansehen können und so bspw. erkennen, wie unterschiedliche within und between Effekte ausfallen können - z.B. dass sie komplett gegenläufig sein können, was gleichzeitig einen wichtigen Vorteil dieser Analysemethode aufzeigt! Es wird auch das Big-Fish Little-Pond Prinzip daran erläutert.</p>
<p>Den gesamten <code>R</code>-Code, der in dieser Sitzung genutzt wird, können Sie <a href="https://raw.githubusercontent.com/jpirmer/MSc1_FEI/master/R-Scripts/2_Multi-Level-Modeling_RCode.R"><svg style="height:0.8em;top:.04em;position:relative;" viewBox="0 0 512 512"><path d="M216 0h80c13.3 0 24 10.7 24 24v168h87.7c17.8 0 26.7 21.5 14.1 34.1L269.7 378.3c-7.5 7.5-19.8 7.5-27.3 0L90.1 226.1c-12.6-12.6-3.7-34.1 14.1-34.1H192V24c0-13.3 10.7-24 24-24zm296 376v112c0 13.3-10.7 24-24 24H24c-13.3 0-24-10.7-24-24V376c0-13.3 10.7-24 24-24h146.7l49 49c20.1 20.1 52.5 20.1 72.6 0l49-49H488c13.3 0 24 10.7 24 24zm-124 88c0-11-9-20-20-20s-20 9-20 20 9 20 20 20 20-9 20-20zm64 0c0-11-9-20-20-20s-20 9-20 20 9 20 20 20 20-9 20-20z"/></svg> hier herunterladen</a>.</p>
</div>
</div>
<div id="appendix" class="section level2">
<h2>Appendix</h2>
<div id="AppendixA" class="section level3">
<h3>Appendix A</h3>
<p>In den folgenden 2 Grafiken müssen Sie für die eigenen Analysen lediglich <code>m2</code> durch Ihr Modell austauschen und anschließend die Gruppierungsvariable (hier <code>schulklasse</code>) durch Ihre Clusterungsvariable ersetzen. Zudem sollten Sie anschließend die Grafikgrenzen bearbeiten.</p>
<pre class="r"><code># Histogramm der Klassenspezifischen Koeffizienten
model &lt;- m2
beta &lt;- coef(model)$schulklasse   # Übergeben der Koeffizienten pro Klasse (Interzept und Steigungskoeffizent)
hist(beta[,2], breaks = 10, freq = F, col = &quot;skyblue&quot;, border = &quot;blue&quot;,
     main = &quot;Verteilung der Steigungskoeffizienten der Motivation&quot;,
     xlab = expression(&quot;Steigungskoeffizient Motivation:&quot;~beta[1~&quot;j&quot;]~&quot;=&quot;~gamma[10]+u[1~&quot;j&quot;])) # Histogramm
gamma10 &lt;- mean(beta[,2]) # Mittlere Steigung
VarU1 &lt;- var(beta[,2]) # Varianz der Steigung
abline(v=gamma10, col = &quot;red&quot;, lwd = 5)   # Mittlere Steigung in der Grafik
text(x = gamma10+2, y = 0.05, labels = expression(gamma[10]), cex = 3, col = &quot;red&quot;) # Bennenung gamma01
lines(x=seq(-10,20,0.01), dnorm(x = seq(-10,20,0.01), mean = gamma10,
                                sd = sqrt(VarU1)), col = &quot;darkblue&quot;, lwd = 3) # Normalverteilung als Vergleich
arrows(y0 = dnorm(x = gamma10+sqrt(VarU1), mean = gamma10,
                  sd = sqrt(VarU1)), y1 = dnorm(x = gamma10+sqrt(VarU1), mean = gamma10,sd = sqrt(VarU1)),
       x0 = gamma10-sqrt(VarU1), x1 = gamma10+sqrt(VarU1),
       code = 3, col = &quot;blue&quot;, lwd = 3, angle = 90) # +/- 1 SD in der Grafik
text(x = 17, y= 0.04, labels = &quot;+/- 1SD&quot;, col = &quot;blue&quot;, cex = 2) # Text in Grafik einfügen</code></pre>
<p><img src="/post/2020-10-12-MSc1_Sitzung2_Multi-Level-Modeling_files/figure-html/unnamed-chunk-32-1.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>  #### Das Modell zeichnen!
model &lt;- m2
beta &lt;- coef(model)$schulklasse   # Übergeben der Koeffizienten pro Klasse (Interzept und Steigungskoeffizent)
summary_model &lt;- summary(model)
plot(StudentsInClasses$Motivation_c, StudentsInClasses$MatheL, xlab = &quot;Motivation (zentriert)&quot;, ylab = &quot;Matheleistung&quot;,
     col = &quot;grey50&quot;)
for(i in 1:summary_model$ngrps)
{
     abline(a = beta[i,1], b = beta[i,2])     # Schleife über jede Gleichung pro Gruppe
}
abline(a = summary_model$coefficients[1,1], b = summary_model$coefficients[2,1],
       col = &quot;blue&quot;, lwd = 5) # durchschnittliche Gerade einzeichnen gamma00 + gamma11*Motivation_c
abline(v = 0, lty = 3) # y-Achse einzeichnen
text(x = 0, y = 98, labels = expression(gamma[&quot;00&quot;]+gamma[10]~&quot;*Motivation_c&quot;), cex = 2, col = &quot;blue&quot;) # Text in Grafik einfügen</code></pre>
<p><img src="/post/2020-10-12-MSc1_Sitzung2_Multi-Level-Modeling_files/figure-html/unnamed-chunk-33-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>Die folgende Grafik können Sie für Ihr Modell replizieren, indem Sie <code>m4</code> durch Ihr Modell ersetzen und anschließend die Clustervariable durch Ihre ersetzen (in <code>group = schulklasse</code>) und die L2 Variable ebenfalls durch Ihre L2 Variable ersetzen (in <code>color = KlassenG_c</code>). In <code>y = MatheL</code> muss Ihre AV rein und <code>x = Motivation_c</code> ist die (zentrierte) UV.</p>
<pre class="r"><code>library(ggplot2) # Lade ggplot2
library(dplyr) # Lade dplyr, um Datensätze zu manipulieren (via &quot;mutate&quot; und &quot;%&gt;%&quot;)

StudentsInClasses %&gt;%             # Datensatz wird manipuliert
  mutate(Leistung = fitted(m4)) %&gt;% # Vorhergesagte Werte in den Datensatz via Funktion fitted(), nenne diese Variable Leistung
  ggplot(aes(x = Motivation_c, Leistung, group = schulklasse, color = KlassenG_c)) +
  scale_color_gradient(low=&quot;blue&quot;, high = &quot;gold3&quot;) +     # von blau bis gold skalieren
  theme_classic() +                                      # klassisches Thema wählen, sodass der Hintergrund nicht grau ist
  geom_point(aes(y = MatheL), alpha = 0.1, color=&quot;grey&quot;)+ # beobachtete Werte als Punkte
  geom_line(size=0.5)  # Vorhergesagte Werte als Linien</code></pre>
<p><img src="/post/2020-10-12-MSc1_Sitzung2_Multi-Level-Modeling_files/figure-html/unnamed-chunk-34-1.png" width="672" style="display: block; margin: auto;" /></p>
</div>
<div id="AppendixB" class="section level3">
<h3>Appendix B</h3>
<p>Wenn Sie sich nun fragen, wieso wir <span class="math inline">\(\gamma_{10}\)</span> in <span class="math inline">\(\mathbb{V}ar[Y] = \mathbb{V}ar[u_0]+\underbrace{\gamma_{10}^2\mathbb{V}ar[X_1]+\mathbb{V}ar[\varepsilon^*]}_{\mathbb{V}ar[\varepsilon]}\)</span> quadrieren mussten, dann überlegen Sie sich folgendes Beispiel anhand der empirischen Stichprobenvarianz von einer Variable <span class="math inline">\(Y\)</span>. Diese berechnen wir so:</p>
<p><span class="math display">\[\hat{\mathbb{V}ar}[Y] = \frac{1}{n}\sum_{i=1}^n(Y_i-\bar{Y})^2,\]</span></p>
<p>wobei <span class="math inline">\(\bar{Y}\)</span> der Mittelwert von <span class="math inline">\(Y\)</span> ist. Wenn wir nun alle Einträge von <span class="math inline">\(Y\)</span> mit einer Konstanten multiplizieren, also für jede Person <span class="math inline">\(i\)</span> das Produkt <span class="math inline">\(aY_i\)</span> berechnen (z.B. <span class="math inline">\(a=10\)</span> oder <span class="math inline">\(a=\gamma_{10}\)</span>) und die Varianz bestimmen (der Mittelwert von <span class="math inline">\(aY\)</span> ist einfach <span class="math inline">\(a\bar{Y}\)</span>), dann ergibt sich:
<span class="math display">\[\begin{align*}
\hat{\mathbb{V}ar}[aY] &amp;= \frac{1}{n}\sum_{i=1}^n(aY_i-a\bar{Y})^2\\
&amp;=\frac{1}{n}\sum_{i=1}^n\big(a(Y_i-\bar{Y})\big)^2\\
&amp;=\frac{1}{n}\sum_{i=1}^na^2(Y_i-\bar{Y})^2\\
&amp;=a^2\frac{1}{n}\sum_{i=1}^n(Y_i-\bar{Y})^2\\
&amp;=a^2\hat{\mathbb{V}ar}[Y],
\end{align*}\]</span></p>
<p>Da <span class="math inline">\(a\)</span> in der Klammer steht, die quadriert wird, muss natürlich <span class="math inline">\(a\)</span> quadriert werden. Da auch <span class="math inline">\(a^2\)</span> eine Konstante ist, kann sie vor die Summe gezogen werden. Daraus wird dann ersichtlich, dass die Varianz des Produktes einer Variablen mit einer Konstanten gleich der Konstanten zum Quadrat multipliziert mit der Varianz der Variablen ist. Das Ganze kann auch als Beweis durchgeführt werden - wir müssten lediglich mit Integralen und Dichten (Wahrscheinlichkeitsverteilungen) rechnen. Weitere wichtige Rechenvorschriften sind (für <span class="math inline">\(A\)</span> und <span class="math inline">\(B\)</span> Zufallsvariablen und <span class="math inline">\(\alpha\)</span> und <span class="math inline">\(\beta\)</span> Konstanten):</p>
<p><span class="math display">\[\begin{align}
\mathbb{V}ar[\alpha] &amp;= 0\\
\mathbb{V}ar[A]&amp;=\mathbb{C}ov[A,A] \\
\mathbb{C}ov[A,B]&amp;= \mathbb{C}ov[B,A]\\
\mathbb{C}ov[\alpha A,\beta B]&amp;=\alpha \beta \mathbb{C}ov[A,B]\\
\mathbb{V}ar[A+B]&amp;= \mathbb{V}ar[A] + 2\mathbb{C}ov[A,B] + \mathbb{V}ar[B]\\
\mathbb{V}ar[\alpha A+\beta B]&amp;= \alpha^2\mathbb{V}ar[A] + 2\alpha \beta \mathbb{C}ov[A,B] + \beta^2\mathbb{V}ar[B]
\end{align}\]</span></p>
<p>Außerdem ist es so, dass wenn <span class="math inline">\(A\)</span> und <span class="math inline">\(B\)</span> unabhängig sind so folgt, dass <span class="math inline">\(\mathbb{C}ov[A,B]=0\)</span> (aber nicht umgekehrt!). Eine Konstante ist unabhängig von allen Variablen und hat eine Varianz von 0. Somit können wir die Variation von <span class="math inline">\(Y\)</span> im Modell mit Motivation <span class="math inline">\(X_1\)</span> als Prädiktor wie folgt berechnen:</p>
<p><span class="math display">\[\begin{align}
\mathbb{V}ar[Y_{ij}]&amp;=\mathbb{V}ar[\gamma_{00} + u_{0j} + \gamma_{10}X_{1,ij} + \varepsilon_{ij}^*]\\
&amp;= \mathbb{V}ar[u_{0j}] + 2\gamma_{10}\mathbb{C}ov[u_{0j},X_{1,ij}] +\mathbb{C}ov[u_{0j},\varepsilon_{ij}^*] + 2\gamma_{10}\mathbb{C}ov[X_{1,ij},\varepsilon_{ij}^*] + \gamma_{10}^2\mathbb{V}ar[X_{1,ij}] + \mathbb{V}ar[\varepsilon_{ij}^*]  \\
&amp;= \mathbb{V}ar[u_0]+\gamma_{10}^2\mathbb{V}ar[X_1]+\mathbb{V}ar[\varepsilon^*],
\end{align}\]</span></p>
<p>da <span class="math inline">\(u_0\)</span> und <span class="math inline">\(\varepsilon^*\)</span> unabhängig von einander und vom Prädiktor sind (somit ihre Kovarianzen jeweils 0 sind).</p>
<p>Außerdem siehe <a href="https://hds.hebis.de/ubffm/Record/HEB366849158">Eid, et al. (2017)</a> S. 195-196 und folgend und S.570-571 und folgend, um weitere Informationen über die Rechenregeln und die Beziehungen zwischen Korrelation und Kovarianz zu wiederholen.</p>
</div>
<div id="AppendixC" class="section level3">
<h3>Appendix C</h3>
<p>Die angegebene Funktion kann einfache Multi-Level-Modelle plotten, in welcher es eine Variable gibt, die einen within und einen between Effekt aufweist. Somit können wir dies so interpretieren, wie eine Group-Mean-gecenterte Variable (<code>ggplot2</code> muss dafür installiert sein):</p>
<pre class="r"><code>plot_within_between_effects &lt;- function(nb = 50, nw = 50, between_effect = 1, within_effect = 1)
{
       # Wiederholungsfunktion
        reps &lt;- function(X, r)
        {
                out &lt;- c()
                for(x in X)
                {
                        out &lt;- c(out, rep(x, r))
                }
                out
        }

        # Daten generieren (Normalverteilt)
        Xb &lt;- rnorm(nb, mean = 0)
        Yb &lt;- between_effect*Xb + rnorm(nb)

        # between Effekte
        between &lt;- cbind(Xb, Yb)
        between &lt;- apply(between, 2, FUN = function(x) reps(X = x, r = nw))

        # Within Effekte
        Xw &lt;- .1*rnorm(dim(between)[1])
        Yw &lt;- within_effect*Xw + .1*rnorm(dim(between)[1])
        within &lt;- cbind(Xw, Yw)

        # Gesamteffekte
        total &lt;- between + within
        Cluster &lt;- rep(1:nb, nw); Cluster &lt;- sort(Cluster)

        total &lt;- cbind(total, Cluster)
        total &lt;- data.frame(total)
        names(total) &lt;- c(&quot;X&quot;, &quot;Y&quot;, &quot;Cluster&quot;)

        total$Cluster &lt;- as.factor(total$Cluster)

        # Grafik erstellen
        library(ggplot2)
        ggplot(data = total, mapping = aes(x = X, y = Y, col = Cluster))+geom_point()
}</code></pre>
<p>Die Funktion nimmt 4 Argumente entgegben. <code>nb</code> die Anzahl an Clustern (Default ist 50), <code>nw</code> Anzahl an Erhebungen innerhalb eines Clusters (Default ist 50), <code>between_effect</code> Effekt zwischen den Clustern (Default ist 1, hier ist es sinnvoll nur Werte zwischen -1 und 1 zu nehmen) und <code>within_effect</code> ist der within Gruppeneffekt (Default ist 1, hier ist es sinnvoll nur Werte zwischen -1 und 1 zu nehmen). Bspw. können wir nun ganz einfach eine Grafik für das Simpson Paradox (oder auch den Ökologischen Fehlschluss) erstellen (siehe auch <a href="https://hds.hebis.de/ubffm/Record/HEB366849158">Eid, et al., 2017,</a> S. 729-730). Hier wird global betrachtet ein anderer Effekt gefunden, wie innerhalb der Gruppen. Wir können dies verstehen, indem wir den Between-Effekt bspw. auf <code>-1</code> setzen und den Within-Effekt auf <code>1</code>:</p>
<pre class="r"><code>plot_within_between_effects(nb = 50, nw = 50, between_effect = -1, within_effect = 1)</code></pre>
<p><img src="/post/2020-10-12-MSc1_Sitzung2_Multi-Level-Modeling_files/figure-html/unnamed-chunk-36-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>Die gesamte Punktewolke sinkt in Y für steigendes X, aber innerhalb einer Gruppe (Cluster) steigt Y für steigendes X. Falls wir hier also die Multi-Level-Struktur ignorieren, so würden wir falsche Schlüsse im Hinblick auf die Beziehung zwischen X und Y ziehen. Dieser Effekt wird manchmal auch Big-Fish-Little-Pond Effekt (siehe auch <a href="https://hds.hebis.de/ubffm/Record/HEB366849158">Eid, et al., 2017</a> S. 740; auch Kapitel 20.2.5 behandelt diese Kontexteffekt etwas ausführlicher) genannt: wenn wir beispielsweise annehmen, dass Y das Leistungsselbstkonzept ist und X ist die Begabung. In bspw. Schulklassen mit niedriger Begabung sollten Kinder mit vergleichsweise hoher Begabung ein höheres Leistungsselbstkonzept haben. Dies gilt auch für Schulklassen mit begabteren Kindern. Allerdings ist in Klassen mit durchschnittlich begabteren Kindern insgesamt das Leistungsselbstkonzept etwas niedriger, da diese sich nur mit ebenfalls sehr begabten Kindern vergleichen können.</p>
<p>Probieren Sie doch einmal verschiedene Effekte aus, indem Sie den Code der Funktion <code>plot_within_between_effects &lt;- function ...</code> kopieren (bis hin zur letzte geschwungenen Klammer <code>}</code>), bei sich ausführen (dann sollte die Funktion oben rechts in Ihrem <code>R</code>-Studiofenser unter der Rubrik <strong>Functions</strong> zu finden sein) und anschließend verschiedene Kombinationen ausführen.</p>
</div>
</div>
<div id="literatur" class="section level2">
<h2>Literatur</h2>
<p><a href="https://hds.hebis.de/ubffm/Record/HEB366849158">Eid, M., Gollwitzer, M., &amp; Schmitt, M. (2017).</a> <em>Statistik und Forschungsmethoden</em> (5. Auflage, 1. Auflage: 2010). Weinheim: Beltz.</p>
<p><a href="https://hds.hebis.de/ubffm/Record/HEB371183324">Pituch, K. A. &amp; Stevens, J. P. (2016).</a> <em>Applied Multivariate Statistics for the Social Sciences</em> (6th ed.). New York: Taylor &amp; Francis.</p>
<ul>
<li><small> <em>Blau hinterlegte Autorenangaben führen Sie direkt zur universitätsinternen Ressource.</em></li>
</ul>
</div>
